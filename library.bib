@article{&na;EuropeanMedicinesAgency2006,
  title = {The {{European Medicines Agency}}'s ({{EMEA}}'s) Guidelines on Similar Biologics Allow Manufacturers to Bypass Comparative Clinical Trials},
  author = {{\&NA;}},
  year = {2006},
  journal = {Inpharma Weekly},
  volume = {\&NA;},
  number = {1532},
  pages = {3},
  issn = {1173-8324},
  doi = {10.2165/00128413-200615320-00004},
  abstract = {ICH Guideline},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/&na;_2006_the european medicines agency's (emea's) guidelines on similar biologics allow.pdf}
}

@misc{1996SanoAD,
  title = {1996\_{{Sano}} et al\_{{AD}} and {{Associated Disorders}}\_(Design and Use of Composites Selegiline).Pdf},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/1996_sano et al_ad and associated disorders_(design and use of composites.pdf}
}

@article{abbasComparisonPhaseDosefinding2020,
  title = {A Comparison of Phase {{I}} Dose-Finding Designs in Clinical Trials with Monotonicity Assumption Violation},
  author = {Abbas, Rachid and Rossoni, Caroline and Jaki, Thomas and Paoletti, Xavier and Mozgunov, Pavel},
  year = {2020},
  month = oct,
  journal = {Clinical Trials},
  volume = {17},
  number = {5},
  pages = {522--534},
  issn = {1740-7745, 1740-7753},
  doi = {10.1177/1740774520932130},
  urldate = {2024-03-19},
  abstract = {Background/Aims: In oncology, new combined treatments make it difficult to order dose levels according to monotonically increasing toxicity. New flexible dose-finding designs that take into account uncertainty in dose levels ordering were compared with classical designs through simulations in the setting of the monotonicity assumption violation. We give recommendations for the choice of dose-finding design. Methods: Motivated by a clinical trial for patients with high-risk neuroblastoma, we considered designs that require a monotonicity assumption, the Bayesian Continual Reassessment Method, the modified Toxicity Probability Interval, the Bayesian Optimal Interval design, and designs that relax monotonicity assumption, the Bayesian Partial Ordering Continual Reassessment Method and the No Monotonicity Assumption design. We considered 15 scenarios including monotonic and non-monotonic dose--toxicity relationships among six dose levels. Results: The No Monotonicity Assumption and Partial Ordering Continual Reassessment Method designs were robust to the violation of the monotonicity assumption. Under non-monotonic scenarios, the No Monotonicity Assumption design selected the correct dose level more often than alternative methods on average. Under the majority of monotonic scenarios, the Partial Ordering Continual Reassessment Method selected the correct dose level more often than the No Monotonicity Assumption design. Other designs were impacted by the violation of the monotonicity assumption with a proportion of correct selections below 20\% in most scenarios. Under monotonic scenarios, the highest proportions of correct selections were achieved using the Continual Reassessment Method and the Bayesian Optimal Interval design (between 52.8\% and 73.1\%). The costs of relaxing the monotonicity assumption by the No Monotonicity Assumption design and Partial Ordering Continual Reassessment Method were decreases in the proportions of correct selections under monotonic scenarios ranging from 5.3\% to 20.7\% and from 1.4\% to 16.1\%, respectively, compared with the best performing design and were higher proportions of patients allocated to toxic dose levels during the trial. Conclusions: Innovative oncology treatments may no longer follow monotonic dose levels ordering which makes standard phase I methods fail. In such a setting, appropriate designs, as the No Monotonicity Assumption or Partial Ordering Continual Reassessment Method designs, should be used to safely determine recommended for phase II dose.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/EIE54F3H/abbas-et-al-2020-a-comparison-of-phase-i-dose-finding-designs-in-clinical-trials-with-monotonicity-assumption-violation.pdf}
}

@misc{AccurateUltraEfficientPValue,
  title = {Accurate and {{Ultra-Efficient}} p-{{Value Calculation}} for {{Higher Criticism Tests}}},
  issn = {1061-8600},
  urldate = {2023-12-15},
  howpublished = {https://www.tandfonline.com/doi/epdf/10.1080/10618600.2023.2270720?needAccess=true},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/WB4H9DQH/10618600.2023.html}
}

@article{acosta2019f4,
  title = {F4-04-02: {{AGE-RELATED CHANGES IN BASELINE COGNITIVE MEASURES IN UNIMPAIRED PSEN1 E280A MUTATION CARRIERS AND NON-CARRIERS IN THE API AUTOSOMAL DOMINANT ALZHEIMER}}'{{S DISEASE COLOMBIA TRIAL}}},
  author = {{Acosta-Baena}, Natalia and {Rios-Romenets}, Silvia and Mu{\~n}oz, Claudia and Bocanegra, Yamile and Henao, Eliana and Giraldo, Margarita and Tobon, Carlos and Sink, Kaycee and Hu, Nan and Guthrie, Heather and others},
  year = {2019},
  journal = {Alzheimer's \& Dementia},
  volume = {15},
  pages = {P1223--P1223}
}

@article{adachiUpperMidbrainProfile2006,
  title = {Upper Midbrain Profile Sign and Cingulate Sulcus Sign: {{MRI}} Findings on Sagittal Images in Idiopathic Normal-Pressure Hydrocephalus, {{Alzheimer}}'s Disease, and Progressive Supranuclear Palsy},
  shorttitle = {Upper Midbrain Profile Sign and Cingulate Sulcus Sign},
  author = {Adachi, Michito and Kawanami, Toru and Ohshima, Fumi and Kato, Takeo},
  year = {2006},
  month = oct,
  journal = {Radiation Medicine},
  volume = {24},
  number = {8},
  pages = {568--572},
  issn = {0288-2043},
  doi = {10.1007/s11604-006-0074-6},
  abstract = {PURPOSE: On magnetic resonance imaging (MRI) sagittal sections, we sometimes encounter abnormal aspects of the superior profile of the midbrain and the cingulate sulcus in patients with dementia. In this preliminary study, we refer to these findings as the "upper midbrain profile sign" and the "cingulate sulcus sign." We prospectively evaluated the usefulness of these signs for the diagnosis of idiopathic normal-pressure hydrocephalus (iNPH), Alzheimer's disease (AD) and progressive supranuclear palsy (PSP). MATERIALS AND METHODS: We evaluated the upper midbrain profile sign and the cingulate sulcus sign on MRI sagittal images obtained from 21 people with headaches but no neurological deficit (controls), 10 iNPH patients, 11 AD patients, and 5 PSP patients. The upper midbrain profile sign indicated a concave shape to the superior profile of the midbrain on mid-sagittal images, and the cingulate sulcus sign indicated a narrow, tight aspect of the posterior part of the cingulate sulcus on paramedian-sagittal images. RESULTS: These signs were never seen in any images from the controls. The upper midbrain profile sign was seen in 7 of 10 patients with iNPH, 5 of 11 with AD, and 3 of 5 with PSP. The cingulate sulcus sign was seen in all 10 patients with iNPH but was never seen in any patient with AD or PSP. CONCLUSION: The upper midbrain profile sign could support a diagnosis of PSP but cannot discriminate among iNPH, AD, and PSP. In contrast, the cingulate sulcus sign has a very high sensitivity for iNPH and should facilitate the distinction of iNPH from other dementias. In the clinical setting, it is momentous to evaluate these signs easily by one simple MRI sequence.},
  langid = {english},
  pmid = {17041793},
  keywords = {Aged,Aged 80 and over,Alzheimer Disease,Controlled Clinical Trials as Topic,Female,Frontal Lobe,Gyrus Cinguli,Headache,Humans,Hydrocephalus Normal Pressure,Image Enhancement,Image Processing Computer-Assisted,Magnetic Resonance Imaging,Male,Mesencephalon,Middle Aged,Prospective Studies,Sensitivity and Specificity,Supranuclear Palsy Progressive}
}

@misc{AdaptiveIncreaseSample,
  title = {Adaptive Increase in Sample Size When Interim Results Are Promising: {{A}} Practical Guide with Examples},
  urldate = {2024-04-14},
  howpublished = {https://onlinelibrary.wiley.com/doi/epdf/10.1002/sim.4102}
}

@article{Admon2019,
  title = {Emulating a Novel Clinical Trial Using Existing Observational Data Predicting Results of the {{PREVENT}} Study},
  author = {Admon, Andrew J. and Donnelly, John P. and Casey, Jonathan D. and Janz, David R. and Russell, Derek W. and Joffe, Aaron M. and Vonderhaar, Derek J. and Dischert, Kevin M. and Stempek, Susan B. and Dargin, James M. and Rice, Todd W. and Iwashyna, Theodore J. and Semler, Matthew W.},
  year = {2019},
  journal = {Annals of the American Thoracic Society},
  volume = {16},
  number = {8},
  pages = {998--1007},
  issn = {23256621},
  doi = {10.1513/AnnalsATS.201903-241OC},
  abstract = {Rationale: ``Target trial emulation'' has been proposed as an observational method to answer comparative effectiveness questions, but it has rarely been attempted concurrently with a randomized clinical trial (RCT). Objectives: We tested the hypothesis that blinded analysts applying target trial emulation to existing observational data could predict the results of an RCT. Methods: PreVent (Preventing Hypoxemia with Manual Ventilation during Endotracheal Intubation) was a multicenter RCT examining the effects of positive-pressure ventilation during tracheal intubation on oxygen saturation and severe hypoxemia. Analysts unaware of PreVent's results used patient-level data from three previous trials evaluating airway management interventions to emulate PreVent's eligibility criteria, randomization procedure, and statistical analysis. After PreVent's release, results of this blinded observational analysis were compared with those of the RCT. Difference-in-differences estimates for comparison of treatment effects between the observational analysis and the PreVent trial are reported on the absolute scale. Results: Using observational data, we were able to emulate PreVent's randomization procedure to produce balanced groups for comparison. The lowest oxygen saturation during intubation was higher in the positive-pressure ventilation group than the no positive-pressure ventilation group in the observational analysis (n = 360; mean difference = 1.8\%; 95\% confidence interval [CI] = 21.0 to 4.6) and in the PreVent trial (n = 401; mean difference = 3.9\%; 95\% CI = 1.4 to 6.4), though the observational analysis could not exclude no difference. Difference-in-differences estimates comparing treatment effects showed reasonable agreement for lowest oxygen saturation between the observational analysis and the PreVent trial (mean difference = 22.1\%; 95\% CI = 25.9 to 1.7). Positive-pressure ventilation resulted in lower rates of severe hypoxemia in both the observational analysis (risk ratio = 0.60; 95\% CI = 0.38 to 0.93) and in the PreVent trial (risk ratio = 0.48; 95\% CI = 0.30 to 0.77). The absolute reduction in the incidence of severe hypoxemia with positive-pressure ventilation was similar in the observational analysis (9.4\%) and the PreVent trial (12.0\%), though the difference between these estimates had wide CIs (mean difference = 2.5\%; 95\% CI = 28.0 to 13.6\%). Conclusions: Applying target trial emulation methods to existing observational data for the evaluation of a novel intervention produced results similar to those of a randomized trial. These findings support the use of target trial emulation for comparative effectiveness research.},
  pmid = {31038996},
  keywords = {Causal inference,Clinical trials,Epidemiology,Intubation,Target trial emulation},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/admon et al_2019_emulating a novel clinical trial using existing observational data predicting.pdf}
}

@article{Agency2016,
  title = {Draft Guideline on the Clinical Investigation of Medicines for the Treatment of {{Alzheimer}} ' s Disease and Other Dementias {{Draft}} Guideline on the Clinical Investigation of Medicines for the Treatment of {{Alzheimer}} ' s Disease and Other Dementias {{Table}} of Co},
  author = {Agency, European Medicines},
  year = {2016},
  volume = {44},
  number = {January},
  pages = {1--35},
  keywords = {Alzheimer disease clinical  diagnostic criteria},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/agency_2016_draft guideline on the clinical investigation of medicines for the treatment of.pdf}
}

@article{agrestiUnconditionalSmallSample2002,
  title = {Unconditional Small-sample Confidence Intervals for the Odds Ratio},
  author = {Agresti, Alan and Min, Yongyi},
  year = {2002},
  month = sep,
  journal = {Biostatistics},
  volume = {3},
  number = {3},
  pages = {379--386},
  issn = {1465-4644},
  doi = {10.1093/biostatistics/3.3.379},
  urldate = {2023-07-21},
  abstract = {The traditional approach to `exact' small-sample interval estimation of the odds ratio for binomial, Poisson, or multinomial samples uses the conditional distribution to eliminate nuisance parameters. This approach can be very conservative. For two independent binomial samples, we study an unconditional approach with overall confidence level guaranteed to equal at least the nominal level. With small samples this interval tends to be shorter and have coverage probabilities nearer the nominal level.},
  file = {/Users/zenn/Zotero/storage/GQ3Y3XCF/Agresti and Min - 2002 - Unconditional small‐sample confidence intervals fo.pdf;/Users/zenn/Zotero/storage/9LUSEMZM/306622.html}
}

@article{aickinAdjustingMultipleTesting1996,
  title = {Adjusting for Multiple Testing When Reporting Research Results: The {{Bonferroni}} vs {{Holm}} Methods.},
  shorttitle = {Adjusting for Multiple Testing When Reporting Research Results},
  author = {Aickin, M and Gensler, H},
  year = {1996},
  month = may,
  journal = {American Journal of Public Health},
  volume = {86},
  number = {5},
  pages = {726--728},
  publisher = {American Public Health Association},
  issn = {0090-0036},
  doi = {10.2105/AJPH.86.5.726},
  urldate = {2024-03-12},
  abstract = {Public health researchers are sometimes required to make adjustments for multiple testing in reporting their results, which reduces the apparent significance of effects and thus reduces statistical power. The Bonferroni procedure is the most widely recommended way of doing this, but another procedure, that of Holm, is uniformly better. Researchers may have neglected Holm's procedure because it has been framed in terms of hypothesis test rejection rather than in terms of P values. An adjustment to P values based on Holm's method is presented in order to promote the method's use in public health research.},
  file = {/Users/zenn/Zotero/storage/3IGA3KSI/Aickin and Gensler - 1996 - Adjusting for multiple testing when reporting rese.pdf}
}

@article{aickinSimulationStudyValidity2009,
  title = {A {{Simulation Study}} of the {{Validity}} and {{Efficiency}} of {{Design-Adaptive Allocation}} to {{Two Groups}} in the {{Regression Situation}}},
  author = {Aickin, Mikel},
  year = {2009},
  month = may,
  journal = {The International Journal of Biostatistics},
  volume = {5},
  number = {1},
  publisher = {De Gruyter},
  issn = {1557-4679},
  doi = {10.2202/1557-4679.1144},
  urldate = {2024-01-12},
  abstract = {Dynamic allocation of participants to treatments in a clinical trial has been an alternative to randomization for nearly 35 years. Design-adaptive allocation is a particularly flexible kind of dynamic allocation. Every investigation of dynamic allocation methods has shown that they improve balance of prognostic factors across treatment groups, but there have been lingering doubts about their influence on the validity of statistical inferences. Here we report the results of a simulation study focused on this and similar issues. Overall, it is found that there are no statistical reasons, in the situations studied, to prefer randomization to design-adaptive allocation. Specifically, there is no evidence of bias, the number of participants wasted by randomization in small studies is not trivial, and when the aim is to place bounds on the prediction of population benefits, randomization is quite substantially less efficient than design-adaptive allocation. A new, adjusted permutation estimate of the standard deviation of the regression estimator under design-adaptive allocation is shown to be an unbiased estimate of the true sampling standard deviation, resolving a long-standing problem with dynamic allocations. These results are shown in situations with varying numbers of balancing factors, different treatment and covariate effects, different covariate distributions, and in the presence of a small number of outliers.},
  copyright = {De Gruyter expressly reserves the right to use all content for commercial text and data mining within the meaning of Section 44b of the German Copyright Act.},
  langid = {english},
  keywords = {clinical trials,covariate balance,dynamic allocation,minimization,randomization},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/aickin_2009_a simulation study of the validity and efficiency of design-adaptive allocation.pdf}
}

@article{aisen2000randomized,
  title = {A Randomized Controlled Trial of Prednisone in {{Alzheimer}}'s Disease},
  author = {Aisen, Paul S and Davis, {\relax KL} and Berg, {\relax JD} and Schafer, K and Campbell, K and Thomas, {\relax RG} and Weiner, {\relax MF} and Farlow, {\relax MR} and Sano, M and Grundman, M and others},
  year = {2000},
  journal = {Neurology},
  volume = {54},
  number = {3},
  pages = {588--588},
  publisher = {Wolters Kluwer Health, Inc. on behalf of the American Academy of Neurology}
}

@article{aisen2000randomized,
  title = {A Randomized Controlled Trial of Prednisone in {{Alzheimer}}'s Disease {{Reply}}},
  author = {Aisen, {\relax PS} and Grundman, M and Thomas, {\relax RG} and Thal, {\relax LJ}},
  year = {2000},
  journal = {NEUROLOGY-MINNEAPOLIS-},
  volume = {55},
  number = {7},
  pages = {1067--1067},
  publisher = {{Lippincott, Williams and Wilkins}}
}

@inproceedings{aisen2002results,
  title = {Results of a Multicenter Trial of Rofecoxib and Naproxen in {{Alzheimer}}'s Disease},
  booktitle = {Neurobiology of Aging},
  author = {Aisen, P and Schafer, K and Grundman, M and Farlow, M and Sano, M and Jin, S and Thomas, R and Thal, L},
  year = {2002},
  volume = {23},
  pages = {S429--S429},
  publisher = {ELSEVIER SCIENCE INC 360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA}
}

@article{aisen2003alzheimer,
  title = {Alzheimer's {{Disease Cooperative Study}}. {{Effects}} of Rofecoxib or Naproxen vs Placebo on {{Alzheimer}} Disease Progression: A Randomized Controlled Trial},
  author = {Aisen, {\relax PS} and Schafer, {\relax KA} and Grundman, M and Pfeiffer, E and Sano, M and Davis, {\relax KL} and Farlow, {\relax MR} and Jin, S and Thomas, {\relax RG} and Thal, {\relax LJ}},
  year = {2003},
  journal = {JAMA : the journal of the American Medical Association},
  volume = {289},
  number = {21},
  pages = {2819--2826}
}

@article{aisen2003effects,
  title = {Effects of Rofecoxib or Naproxen vs Placebo on {{Alzheimer}} Disease Progression: A Randomized Controlled Trial},
  author = {Aisen, Paul S and Schafer, Kimberly A and Grundman, Michael and Pfeiffer, Eric and Sano, Mary and Davis, Kenneth L and Farlow, Martin R and Jin, Shelia and Thomas, Ronald G and Thal, Leon J and others},
  year = {2003},
  journal = {JAMA : the journal of the American Medical Association},
  volume = {289},
  number = {21},
  pages = {2819--2826},
  publisher = {American Medical Association}
}

@article{aisen2003nsaids,
  title = {{{NSAIDs}} and Hypertension},
  author = {Aisen, Paul S and Schafer, Kimberly and Grundman, Michael and Thomas, Ronald and Thal, Leon J},
  year = {2003},
  journal = {Archives of internal medicine},
  volume = {163},
  number = {9},
  pages = {1115--1115},
  publisher = {American Medical Association}
}

@article{aisen2003steroid,
  title = {Steroid-Induced Elevation of Glucose in {{Alzheimer}}'s Disease: Relationship to Gender, Apolipoprotein {{E}} Genotype and Cognition},
  author = {Aisen, {\relax PS} and Berg, {\relax JD} and Craft, S and Peskind, {\relax ER} and Sano, M and Teri, L and Mulnard, {\relax RA} and Thomas, {\relax RG} and Thal, {\relax LJ}},
  year = {2003},
  journal = {Psychoneuroendocrinology},
  volume = {28},
  number = {1},
  pages = {113--120},
  publisher = {Pergamon}
}

@article{aisen2007s3,
  title = {S3--02--01: {{ADCS}} Homocysteine Trial},
  author = {Aisen, Paul S and Jin, Shelia and Thomas, Ronald G and Sano, Mary and {Diaz-Arrastia}, Ramon and Thal, Leon and NIA, Alzheimer's Disease Cooperative Study},
  year = {2007},
  journal = {Alzheimer's \& Dementia},
  volume = {3},
  number = {3S\_Part\_3},
  pages = {S199--S199}
}

@article{aisen2007s3,
  title = {S3-02-01},
  author = {Aisen, Paul S and Jin, Shelia and Thomas, Ronald G and Sano, Mary and {Diaz-Arrastia}, Ramon and Thal, Leon},
  year = {2007},
  journal = {Alzheimer's \& Dementia: The Journal of the Alzheimer's Association},
  volume = {3},
  number = {3},
  pages = {S199}
}

@article{aisen2008alzheimer,
  title = {Alzheimer {{Disease Cooperative Study}}. {{High-dose B}} Vitamin Supplementation and Cognitive Decline in {{Alzheimer}} Disease: A Randomized Controlled Trial},
  author = {Aisen, {\relax PS} and Schneider, {\relax LS} and Sano, M and {Diaz-Arrastia}, R and Van Dyck, {\relax CH} and Weiner, {\relax MF} and Bottiglieri, T and Jin, S and Stokes, {\relax KT} and Thomas, {\relax RG} and others},
  year = {2008},
  journal = {JAMA : the journal of the American Medical Association},
  volume = {300},
  number = {15},
  pages = {1774--1783}
}

@article{aisen2008dual,
  title = {Dual Task Test Could Help Diagnose Dementia},
  author = {Aisen, Paul S and Schneider, Lon S and Sano, Mary and {Diaz-Arrastia}, Ramon and {van Dyck}, Christopher H and Weiner, Myron F and Bottiglieri, Teodoro and Jin, Shelia and Stokes, Karen T and Thomas, Ronald G and others},
  year = {2008},
  journal = {JAMA : the journal of the American Medical Association},
  volume = {300},
  number = {15},
  pages = {1774--1783}
}

@article{aisen2008high,
  title = {High-Dose {{B}} Vitamin Supplementation and Cognitive Decline in {{Alzheimer}} Disease: A Randomized Controlled Trial},
  author = {Aisen, Paul S and Schneider, Lon S and Sano, Mary and {Diaz-Arrastia}, Ramon and Van Dyck, Christopher H and Weiner, Myron F and Bottiglieri, Teodoro and Jin, Shelia and Stokes, Karen T and Thomas, Ronald G and others},
  year = {2008},
  journal = {JAMA : the journal of the American Medical Association},
  volume = {300},
  number = {15},
  pages = {1774--1783},
  publisher = {American Medical Association}
}

@article{aisen2010clinical,
  title = {Clinical Core of the Alzheimer's Disease Neuroimaging Initiative: Progress and Plans},
  author = {Aisen, Paul S and Petersen, Ronald C and Donohue, Michael C and Gamst, Anthony and Raman, Rema and Thomas, Ronald G and Walter, Sarah and Trojanowski, John Q and Shaw, Leslie M and Beckett, Laurel A and others},
  year = {2010},
  journal = {Alzheimer's \& Dementia},
  volume = {6},
  number = {3},
  pages = {239--246}
}

@article{aisen2011report,
  title = {Report of the Task Force on Designing Clinical Trials in Early (Predementia) {{AD}}},
  author = {Aisen, {\relax PS} and Andrieu, S and Sampaio, C and Carrillo, M and Khachaturian, {\relax ZS} and ua Dubois, B and Feldman, {\relax HH} and Petersen, {\relax RC} and Siemers, E and Doody, {\relax RS} and others},
  year = {2011},
  journal = {Neurology},
  volume = {76},
  number = {3},
  pages = {280--286},
  publisher = {Wolters Kluwer Health, Inc. on behalf of the American Academy of Neurology}
}

@article{aisen2012p3,
  title = {P3-384: {{The}} Placebo Data Analysis in {{Alzheimer}}'s Disease and Mild Cognitive Impairment ({{MCI}}) Clinical Trials Project: {{Overview}} of Progress in Trial Data Collection, and Key Findings from the Pooled {{MCI}} Trial Datasets},
  author = {Aisen, Paul and Thomas, Ronald and Carrillo, Maria and Mohs, Richard and Petersen, Ronald and Siuciak, Judith and Albert, Marilyn and Initiative, Alzheimer's Disease Neuroimaging and Team, Foundation for NIH Biomarkers Consortium CSF Proteomics Project},
  year = {2012},
  journal = {Alzheimer's \& Dementia},
  volume = {8},
  number = {4S\_Part\_16},
  pages = {P590--P590}
}

@article{aisenFutilityAnalysesAlzheimer2020,
  title = {Futility {{Analyses}} in {{Alzheimer}}'s {{Disease}} ({{AD}}) {{Clinical Trials}}: {{A Risky Business}}},
  author = {Aisen, P S and Raman, R},
  year = {2020},
  journal = {The Journal of Prevention of Alzheimer's Disease-JPAD},
  volume = {7},
  number = {3},
  pages = {195--196},
  doi = {10.14283/jpad.2020.20},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/aisen_raman_2020_futility analyses in alzheimer's disease (ad) clinical trials.pdf}
}

@article{al-tashiMachineLearningModels2023,
  title = {Machine {{Learning Models}} for the {{Identification}} of {{Prognostic}} and {{Predictive Cancer Biomarkers}}: {{A Systematic Review}}},
  shorttitle = {Machine {{Learning Models}} for the {{Identification}} of {{Prognostic}} and {{Predictive Cancer Biomarkers}}},
  author = {{Al-Tashi}, Qasem and Saad, Maliazurina B. and Muneer, Amgad and Qureshi, Rizwan and Mirjalili, Seyedali and Sheshadri, Ajay and Le, Xiuning and Vokes, Natalie I. and Zhang, Jianjun and Wu, Jia},
  year = {2023},
  month = jan,
  journal = {International Journal of Molecular Sciences},
  volume = {24},
  number = {9},
  pages = {7781},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {1422-0067},
  doi = {10.3390/ijms24097781},
  urldate = {2023-05-05},
  abstract = {The identification of biomarkers plays a crucial role in personalized medicine, both in the clinical and research settings. However, the contrast between predictive and prognostic biomarkers can be challenging due to the overlap between the two. A prognostic biomarker predicts the future outcome of cancer, regardless of treatment, and a predictive biomarker predicts the effectiveness of a therapeutic intervention. Misclassifying a prognostic biomarker as predictive (or vice versa) can have serious financial and personal consequences for patients. To address this issue, various statistical and machine learning approaches have been developed. The aim of this study is to present an in-depth analysis of recent advancements, trends, challenges, and future prospects in biomarker identification. A systematic search was conducted using PubMed to identify relevant studies published between 2017 and 2023. The selected studies were analyzed to better understand the concept of biomarker identification, evaluate machine learning methods, assess the level of research activity, and highlight the application of these methods in cancer research and treatment. Furthermore, existing obstacles and concerns are discussed to identify prospective research areas. We believe that this review will serve as a valuable resource for researchers, providing insights into the methods and approaches used in biomarker discovery and identifying future research opportunities.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {biomarker discovery,deep learning,feature selection,machine learning,personalized medicine,predictive biomarker,prognostic biomarker,subgroup identification},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/al-tashi et al_2023_machine learning models for the identification of prognostic and predictive.pdf}
}

@article{aldenBootstrapSimulationsEstimate2020,
  title = {Bootstrap Simulations to Estimate Relationships between {{Type I}} Error, Power, Effect Size, and Appropriate Sample Numbers for Bioassessments of Aquatic Ecosystems},
  author = {Alden, Raymond W. and Hall, Lenwood W.},
  year = {2020},
  month = nov,
  journal = {Journal of Environmental Science and Health, Part A},
  volume = {55},
  number = {13},
  pages = {1484--1503},
  issn = {1093-4529, 1532-4117},
  doi = {10.1080/10934529.2020.1809924},
  urldate = {2024-03-11},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/QIW2BEBU/Alden and Hall - 2020 - Bootstrap simulations to estimate relationships be.pdf}
}

@article{alginaSampleSizeTables2003,
  title = {Sample {{Size Tables}} for {{Correlation Analysis}} with {{Applications}} in {{Partial Correlation}} and {{Multiple Regression Analysis}}},
  author = {Algina, James and Olejnik, Stephen},
  year = {2003},
  month = jul,
  journal = {Multivariate Behavioral Research},
  volume = {38},
  number = {3},
  pages = {309--323},
  issn = {0027-3171, 1532-7906},
  doi = {10.1207/S15327906MBR3803_02},
  urldate = {2023-03-25},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/algina_olejnik_2003_sample size tables for correlation analysis with applications in partial.pdf}
}

@article{almkvistBiomarkervalidatedTimeScale2023,
  title = {A Biomarker-Validated Time Scale in Years of Disease Progression Has Identified Early- and Late-Onset Subgroups in Sporadic {{Alzheimer}}'s Disease},
  author = {Almkvist, Ove and Nordberg, Agneta},
  year = {2023},
  month = may,
  journal = {Alzheimer's Research \& Therapy},
  volume = {15},
  number = {1},
  pages = {89},
  issn = {1758-9193},
  doi = {10.1186/s13195-023-01231-8},
  urldate = {2023-05-08},
  abstract = {It is possible to calculate the number of years to the expected clinical onset (YECO) of autosomal-dominant Alzheimer's disease (adAD). A similar time scale is lacking for sporadic Alzheimer's disease (sAD). The purpose was to design and validate a time scale in YECO for patients with sAD in relation to CSF and PET biomarkers.},
  keywords = {Alzheimer's disease,Cognition,Disease onset,EOAD,LOAD,Progression,Time scale},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/almkvist_nordberg_2023_a biomarker-validated time scale in years of disease progression has identified.pdf;/Users/zenn/Zotero/storage/ITERYQU4/s13195-023-01231-8.html}
}

@misc{AltmanComparabilityRandomised,
  title = {Altman, Comparability of Randomised Groups. - {{Google Scholar}}},
  urldate = {2024-06-27},
  howpublished = {https://scholar.google.com/scholar?hl=en\&as\_sdt=0\%2C5\&q=altman\%2C+comparability+of+randomised+groups.+\&btnG=},
  file = {/Users/zenn/Zotero/storage/6NJUJNUS/scholar.html}
}

@article{altmanComparabilityRandomisedGroups1985,
  title = {Comparability of {{Randomised Groups}}},
  author = {Altman, Douglas G.},
  year = {1985},
  month = mar,
  journal = {Journal of the Royal Statistical Society Series D: The Statistician},
  volume = {34},
  number = {1},
  pages = {125--136},
  issn = {2515-7884},
  doi = {10.2307/2987510},
  urldate = {2024-06-27},
  abstract = {Randomised allocation in a clinical trial does not guarantee that the treatment groups are comparable with respect to baseline characteristics. It is common for differences between treatment groups to be assessed by significance tests but such tests only assess the correctness of the randomisation, not whether any observed imbalances between the groups might have affected the results of the trial. In particular, it is quite unjustified to conclude that variables that are not significantly differently distributed between groups cannot have affected the results of the trial.The possible effect of imbalance in a prognostic factor is considered, and it is shown that non-significant imbalances can exert a strong influence on the observed result of the trial, even when the risk associated with the factor is not all that great.It is suggested that comparability should be assessed partly on the basis of clinical knowledge and that it is wise to investigate whether any imbalances between the groups could have had an affect by reanalysing the data taking such factors into account. The implications for trial design are considered briefly.},
  file = {/Users/zenn/Zotero/storage/95V273SL/7121455.html}
}

@misc{AlzheimerDiseaseAssessment,
  title = {Alzheimer's {{Disease Assessment}}: {{A Review}} and {{Illustrations Focusing}} on {{Item Response Theory Techniques}}},
  shorttitle = {Alzheimer's {{Disease Assessment}}},
  doi = {10.1177/1073191117745125},
  urldate = {2024-01-18},
  howpublished = {https://journals.sagepub.com/doi/epub/10.1177/1073191117745125},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/76AX2LFH/1073191117745125.html}
}

@article{analysisMajorImprovementNetwork,
  title = {A Major Improvement to the {{Network Algorithm}} for {{Fisher}}'s {{Exact Test}} in 2{\texttimes} c Contingency Tables},
  author = {Analysis, F Requena - Computational Statistics \& Data and 2006, undefined},
  journal = {Elsevier},
  urldate = {2018-04-07},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/analysis_2006_a major improvement to the network algorithm for fisher's exact test in 2× c.pdf}
}

@misc{AnalysisPreTest,
  title = {Analysis of {{Pre}}-test-{{Post}}-test {{Control Group Designs}} in {{Educational Research}}},
  doi = {10.1080/0144341950150207},
  urldate = {2024-03-14},
  howpublished = {https://www.tandfonline.com/doi/epdf/10.1080/0144341950150207?needAccess=true},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/UTQGF6I8/0144341950150207.html}
}

@misc{AnalysisPreTesta,
  title = {Analysis of {{Pre}}-test-{{Post}}-test {{Control Group Designs}} in {{Educational Research}}: {{Educational Psychology}}: {{Vol}} 15, {{No}} 2},
  urldate = {2024-03-14},
  howpublished = {https://www.tandfonline.com/doi/abs/10.1080/0144341950150207?src=recsys},
  file = {/Users/zenn/Zotero/storage/H5GFQX53/0144341950150207.html}
}

@article{andrewsSimulationbasedEffectSize2023,
  title = {Simulation-Based Effect Size Analysis in the Absence of Drug Effects to Inform the Design of Clinical Trials in {{Alzheimer}}'s Disease},
  author = {Andrews, Daniel and Arnold, Douglas L and Bzdok, Danilo and Ducharme, Simon and Chertkow, Howard and Collins, D Louis and Initiative, the Alzheimer's Disease Neuroimaging},
  year = {2023},
  journal = {Alzheimer's \& Dementia},
  volume = {19},
  number = {S21},
  pages = {e074336},
  issn = {1552-5279},
  doi = {10.1002/alz.074336},
  urldate = {2024-03-11},
  abstract = {Background Randomized clinical trials of Alzheimer's-modifying drugs typically report a clinical effect as the final observation difference in means for a cognitive endpoint between treated and placebo groups. However, randomization of subjects naturally following different cognitive decline trajectories could produce a between-group endpoint difference even when a drug has no disease-modifying effect. Recent work used data from ADNI subjects matching trial inclusion criteria to simulate patient trajectories [Jutten et al. (2021). https://doi.org/10.1212/WNL.0000000000012022]. We build on such simulations by incorporating a trial's specific design parameters, including multiple visits, visit time windowing, dropout rate, and measurement noise using jittering. We estimate treatment-independent group differences in a cognitive endpoint's rate of change in simulations of the Phase 3 aducanumab and lecanemab trials. Method 563 ADNI subjects matched inclusion criteria for the identically designed Phase 3 aducanumab trials EMERGE and ENGAGE [clinicaltrials.gov/ct2/show/NCT02484547]. We fitted a continuous time linear mixed effect model tracking CDSRB change from baseline (CDRSB{$\Delta$}bl). ADNI subjects' baseline data were resampled and jittered, generating data for 1,070 synthetic subjects total while preserving the real trials' baseline Alzheimer's stage distribution. Subjects were randomized 1:1 to ``treated'' and ``placebo'' groups, but without any treatment effect. We simulated 4 visits, {$\sim$}26 weeks apart, with 30\% dropout. Our sample size and visit scheme matches the real trials' Statistical Analysis Plans. We generated 10,000 simulated trials, each a unique randomization of subject trajectories. The ``treated'' vs. ``placebo'' CDRSB{$\Delta$}bl linear slope difference was extracted from each simulation. We repeated this procedure for the demographics and design of lecanemab's Phase 3 trial Clarity AD [clinicaltrials.gov/ct2/show/NCT03887455]. Result Histograms of simulated slope differences differ between the trial designs (see Figures). Averages are zero because there is no simulated treatment effect. Each successful trial's real-world difference (EMERGE high dose: --22\%, Clarity AD: --27\%) corresponds to a statistically significant reduction in cognitive decline rate for treated subjects vs. placebo. Conclusion Our results suggest low false positive probabilities for the successful trials. Cohort composition, sampling, and other trial characteristics might influence treatment-independent group difference in cognitive decline rate. With our method, future trials could target treatment effects outside the target population's false positive range.},
  copyright = {{\copyright} 2023 the Alzheimer's Association.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/E6MPG636/Andrews et al. - 2023 - Simulation-based effect size analysis in the absen.pdf;/Users/zenn/Zotero/storage/SHHXQIMR/alz.html}
}

@misc{andrewsSimulationbasedPowerAnalysis2022,
  title = {Simulation-Based Power Analysis Could Improve the Design of Clinical Trials in {{Alzheimer}}'s Disease},
  author = {Andrews, Daniel and Arnold, Douglas L. and Bzdok, Danilo and Ducharme, Simon and Chertkow, Howard and Collins, D. Louis and Initiative, the Alzheimer's Disease Neuroimaging},
  year = {2022},
  month = dec,
  pages = {2022.12.24.22283807},
  publisher = {medRxiv},
  doi = {10.1101/2022.12.24.22283807},
  urldate = {2023-08-01},
  abstract = {Clinical trials of new treatments in different progressive diseases use power analysis to determine the sample size needed for a trial to obtain a statistically significant estimate for an anticipated treatment effect. In trials with parallel designs, the standard power analysis approach is based on a two-sample t-test. For example, the standard t-test approach was used in determining the sample size for the Phase 3 trials of aducanumab, the first drug approved by the United States Food and Drug Administration (FDA) to potentially slow cognitive decline in early-stage Alzheimer's disease. However, t-tests contain normality assumptions, and t-test-based power analyses do not implicitly factor in the uncertainty about anticipated treatment effects that arises due to inter-subject heterogeneity in disease progression. These limitations may lead to recommended sample sizes that are too small, potentially making a trial blind to a treatment effect that is truly present if the cohort's endpoints are not normally distributed and/or the anticipated treatment effect is overestimated. To address these issues, we present a novel power analysis method that (1) simulates clinical trials in a progressive disease using real-world data, (2) accounts for inter-subject heterogeneity in disease progression, and (3) does not depend on normality assumptions. As a showcase example, we used our method to calculate power for a range of sample sizes and treatment effects in simulated trials similar to the Phase 3 aducanumab trials EMERGE and ENGAGE. As expected, our results show that power increases with number of subjects and treatment effect (here defined as the cohort-level percent reduction in the rate of cognitive decline in treated subjects vs. controls). However, inclusion of realistic inter-subject heterogeneity in cognitive decline trajectories leads to increased sample size recommendations compared to a standard t-test power analysis. These results suggest that the sample sizes recommended by the t-test power analyses in the EMERGE and ENGAGE Statistical Analysis Plans were possibly too small to ensure a high probability of detecting the anticipated treatment effect. Insufficient sample sizes could partly explain the statistically significant effect of aducanumab being detected only in EMERGE. We also used our method to analyze power in simulated trials similar the Phase 3 lecanemab trial Clarity AD. Our results suggest that Clarity AD was adequately powered, and that power may be influenced by a trial's number of analysis visits and the characteristics of subgroups within a cohort. By using our simulation-based power analysis approach, clinical trials of treatments in Alzheimer's disease and potentially in other progressive diseases could obtain sample size recommendations that account for heterogeneity in disease progression and uncertainty in anticipated treatment effects. Our approach avoids the limitations of t-tests and thus could help ensure that clinical trials are more adequately powered to detect the treatment effects they seek to measure.},
  archiveprefix = {medRxiv},
  copyright = {{\copyright} 2022, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/R8D95ZIH/Andrews et al. - 2022 - Simulation-based power analysis could improve the .pdf}
}

@article{antoniJournalPsychosomaticResearch2003,
  title = {Journal of Psychosomatic Research},
  author = {Antoni, Michael H and Pitts, Marian},
  year = {2003},
  month = mar,
  journal = {Journal of Psychosomatic Research},
  volume = {54},
  number = {3},
  pages = {179--183},
  issn = {00223999},
  doi = {10.1016/S0022-3999(03)00018-7},
  urldate = {2023-09-15},
  abstract = {Objective: Pharmacological and cognitive-behavioral treatments targeting insomnia and nightmares have been shown to be effective in the treatment of military veterans with sleep complaints comorbid with symptoms of stress-related disorders, including Post-Traumatic Stress Disorder (PTSD), but the two approaches have not been directly compared. This randomized controlled trial compared the effects of prazosin vs. a behavioral sleep intervention (BSI), targeting nightmares and insomnia against a placebo pill control condition on sleep and daytime symptoms. Methods: Fifty United States military veterans (mean age 40.9 years, SD= 13.2 years) with chronic sleep disturbances were randomized to prazosin (n = 18), BSI (n = 17), or placebo (n = 15). Each intervention lasted 8 weeks. Participants completed self-report measures of insomnia severity, sleep quality, and sleep disturbances. All kept a sleep diary throughout the intervention period. Polysomnographic studies were conducted pre- and post-intervention. Results: Both active treatment groups showed greater reductions in insomnia severity and daytime PTSD symptom severity. Sleep improvements were found in 61.9\% of those who completed the active treatments and 25\% of those randomized to placebo. Conclusion: BSI and prazosin were both associated with significant sleep improvements and reductions in daytime PTSD symptoms in this sample of military veterans. Sleep-focused treatments may enhance the benefits of first-line PTSD treatments.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/7RKVWF7G/Antoni and Pitts - 2003 - Journal of psychosomatic research.pdf}
}

@article{apostolovaLongitudinalEarlyonsetAlzheimer2021,
  title = {The {{Longitudinal Early-onset Alzheimer}}'s {{Disease Study}} ({{LEADS}}): {{Framework}} and Methodology},
  author = {Apostolova, Liana G and Aisen, Paul and Eloyan, Ani and Fagan, Anne and Fargo, Keith N and Foroud, Tatiana and Gatsonis, Constantine and Grinberg, Lea T and Jack, Clifford R and Kramer, Joel and Koeppe, Robert and Kukull, Walter A and Murray, Melissa E and Nudelman, Kelly and Rumbaugh, Malia and Toga, Arthur and Vemuri, Prashanthi and Trullinger, Amy and Iaccarino, Leonardo and Day, Gregory S and {Graff-Radford}, Neill R and Honig, Lawrence S and Jones, David T and Masdeu, Joseph and Mendez, Mario and Musiek, Erik and Onyike, Chiadi U and Rogalski, Emily and Salloway, Steve and Wolk, David A and Wingo, Thomas S and Carrillo, Maria C and Dickerson, Bradford C and Rabinovici, Gil D},
  year = {2021},
  doi = {10.1002/alz.12350},
  urldate = {2021-05-25},
  isbn = {1113141727},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/apostolova et al_2021_the longitudinal early-onset alzheimer's disease study (leads).pdf}
}

@article{araujoUnderstandingVariationSets2016,
  title = {Understanding {{Variation}} in {{Sets}} of {{N-of-1 Trials}}},
  author = {Araujo, Artur and Julious, Steven and Senn, Stephen},
  editor = {Tu, Yu-Kang},
  year = {2016},
  month = dec,
  journal = {PLOS ONE},
  volume = {11},
  number = {12},
  pages = {e0167167},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0167167},
  urldate = {2024-02-14},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/XRK2URRL/file.pdf}
}

@article{araujoUnderstandingVariationSets2016a,
  title = {Understanding Variation in Sets of {{N-of-1}} Trials},
  author = {Araujo, Artur and Julious, Steven and Senn, Stephen},
  year = {2016},
  journal = {PloS one},
  volume = {11},
  number = {12},
  pages = {e0167167},
  publisher = {Public Library of Science San Francisco, CA USA},
  urldate = {2024-02-14},
  file = {/Users/zenn/Zotero/storage/Y9H8C99G/article.html}
}

@article{arboleda-velasquezResistanceAutosomalDominant,
  title = {Resistance to Autosomal Dominant {{Alzheimer}} ' s Disease in an {{APOE3 Christchurch}} Homozygote : A Case Report},
  author = {{Arboleda-velasquez}, Joseph F and Lopera, Francisco and Hare, Michael O and {Delgado-tirado}, Santiago and Marino, Claudia and Chmielewska, Natalia and {Saez-torres}, Kahira L and Amarnani, Dhanesh and Schultz, Aaron P and Sperling, Reisa A and {Leyton-cifuentes}, David and Chen, Kewei and Baena, Ana and Aguillon, David and {Rios-romenets}, Silvia and Giraldo, Margarita and Guzma, Edmarie and Norton, Daniel J and {Pardilla-delgado}, Enmanuelle and Artola, Arabiye and Sanchez, Justin S and {Acosta-uribe}, Juliana and Lalli, Matthew and Kosik, Kenneth S and Huentelman, Matthew J and Thiyyagura, Pradeep and Su, Yi and Jun, Gyungah R and Naymik, Marcus and Gai, Xiaowu and Bootwalla, Moiz},
  doi = {10.1038/s41591-019-0611-3},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/arboleda-velasquez et al_resistance to autosomal dominant alzheimer ’ s disease in an apoe3 christchurch.pdf}
}

@article{arel-bundockModelsummaryDataModel2022,
  title = {Modelsummary: {{Data}} and {{Model Summaries}} in {{R}}},
  shorttitle = {Modelsummary},
  author = {{Arel-Bundock}, Vincent},
  year = {2022},
  month = jul,
  journal = {Journal of Statistical Software},
  volume = {103},
  pages = {1--23},
  issn = {1548-7660},
  doi = {10.18637/jss.v103.i01},
  urldate = {2024-07-11},
  abstract = {modelsummary is a package to summarize data and statistical models in R. It supports over one hundred types of models out-of-the-box, and allows users to report the results of those models side-by-side in a table, or in coefficient plots. It makes it easy to execute common tasks such as computing robust standard errors, adding significance stars, and manipulating coefficient and model labels. Beyond model summaries, the package also includes a suite of tools to produce highly flexible data summary tables, such as dataset overviews, correlation matrices, (multi-level) cross-tabulations, and balance tables (also known as "Table 1"). The appearance of the tables produced by modelsummary can be customized using external packages such as kableExtra, gt, flextable, or huxtable; the plots can be customized using ggplot2. Tables can be exported to many output formats, including HTML, LaTeX, Text/Markdown, Microsoft Word, Powerpoint, Excel, RTF, PDF, and image files. Tables and plots can be embedded seamlessly in rmarkdown, knitr, or Sweave dynamic documents. The modelsummary package is designed to be simple, robust, modular, and extensible.},
  copyright = {Copyright (c) 2022 Vincent Arel-Bundock},
  langid = {english},
  keywords = {plot,software,statistics,table,visualization},
  file = {/Users/zenn/Zotero/storage/Q9ZI6BEM/Arel-Bundock - 2022 - modelsummary Data and Model Summaries in R.pdf}
}

@article{arendStatisticalPowerTwolevel2019,
  title = {Statistical Power in Two-Level Models: {{A}} Tutorial Based on {{Monte Carlo}} Simulation.},
  shorttitle = {Statistical Power in Two-Level Models},
  author = {Arend, Matthias G. and Sch{\"a}fer, Thomas},
  year = {2019},
  month = feb,
  journal = {Psychological Methods},
  volume = {24},
  number = {1},
  pages = {1--19},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/met0000195},
  urldate = {2023-04-22},
  abstract = {The estimation of power in two-level models used to analyze data that are hierarchically structured is particularly complex because the outcome contains variance at two levels that is regressed on predictors at two levels. Methods for the estimation of power in two-level models have been based on formulas and Monte Carlo simulation. We provide a hands-on tutorial illustrating how a priori and post hoc power analyses for the most frequently used two-level models are conducted. We describe how a population model for the power analysis can be specified by using standardized input parameters and how the power analysis is implemented in SIMR, a very flexible power estimation method based on Monte Carlo simulation. Finally, we provide case-sensitive rules of thumb for deriving sufficient sample sizes as well as minimum detectable effect sizes that yield a power Ն .80 for the effects and input parameters most frequently analyzed by psychologists. For medium variance components, the results indicate that with lower level (L1) sample sizes up to 30 and higher level (L2) sample sizes up to 200, medium and large fixed effects can be detected. However, small L2 director cross-level interaction effects cannot be detected with up to 200 clusters. The tutorial and guidelines should be of help to researchers dealing with multilevel study designs such as individuals clustered within groups or repeated measurements clustered within individuals.},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/arend_schäfer_2019_statistical power in two-level models.pdf}
}

@article{arendStatisticalPowerTwolevel2019a,
  title = {Statistical Power in Two-Level Models: {{A}} Tutorial Based on {{Monte Carlo}} Simulation.},
  shorttitle = {Statistical Power in Two-Level Models},
  author = {Arend, Matthias G. and Sch{\"a}fer, Thomas},
  year = {2019},
  journal = {Psychological methods},
  volume = {24},
  number = {1},
  pages = {1},
  publisher = {American Psychological Association},
  urldate = {2024-03-11},
  file = {/Users/zenn/Zotero/storage/FP8TXLAU/openurl.html}
}

@article{armitageRepeatedSignificanceTests1985,
  title = {Repeated {{Significance Tests}} for {{Clinical Trials}} with a {{Fixed Number}} of {{Patients}} and {{Variable Follow-Up}}},
  author = {Armitage, Peter and Stratton, Irene M. and Worthington, Helen V.},
  year = {1985},
  month = jun,
  journal = {Biometrics},
  volume = {41},
  number = {2},
  eprint = {2530861},
  eprinttype = {jstor},
  pages = {353},
  issn = {0006341X},
  doi = {10.2307/2530861},
  urldate = {2024-03-30},
  abstract = {Group-sequential tests may be applied to trials in which the number of patients is fixed, a response variable is measured for each patient at successive follow-up visits, and the accumulated responses are compared across treatment groups. The standard theory is inapplicable because the increments in the accumulated responses are no longer independent. An adjustment can be made to allow for the ratio of between-patient to within-patient variance and for possible first-order autocorrelation. The method is illustrated by reference to a dental trial.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/RLV8DX64/2530861.pdf}
}

@article{armitageRepeatedSignificanceTests1985a,
  title = {Repeated Significance Tests for Clinical Trials with a Fixed Number of Patients and Variable Follow-Up},
  author = {Armitage, Peter and Stratton, Irene M. and Worthington, Helen V.},
  year = {1985},
  journal = {Biometrics},
  eprint = {2530861},
  eprinttype = {jstor},
  pages = {353--359},
  publisher = {JSTOR},
  urldate = {2024-03-30}
}

@article{arndtAddingSubjectsAdding2000,
  title = {Adding Subjects or Adding Measurements: Which Increases the Precision of Longitudinal Research?},
  shorttitle = {Adding Subjects or Adding Measurements},
  author = {Arndt, Stephan and Jorge, Ricardo and Turvey, Carolyn and Robinson, Robert G},
  year = {2000},
  month = dec,
  journal = {Journal of Psychiatric Research},
  volume = {34},
  number = {6},
  pages = {449--455},
  issn = {0022-3956},
  doi = {10.1016/S0022-3956(00)00042-X},
  urldate = {2023-08-29},
  abstract = {When designing repeated measurement studies, researchers must strike a balance between increasing the number of subjects and increasing the number of measurement times for each subject. The question often becomes ``Do I gain more statistical precision by adding subjects or by adding additional follow-up measurements?'' This study presents a method for evaluating the relative benefit of adding subjects versus adding measurement times. We used the standard error of estimate (SE) for mean change as the criterion of precision. An existing dataset on post-stroke patients containing six follow-up assessments of six standard rating scales was used. SE values for two common change indices were found and compared for all possible two, three, four, five, and six repeated measurements. Sample sizes required to achieve the same benefit as adding an additional measurement are presented. These data suggest that collecting five or six repeated measurements may be sufficient for accurately assessing change and that attempts to further precision should be accomplished by increasing the sample size.},
  keywords = {Longitudinal,Repeated measures,Research design,Sample size,Tau}
}

@article{arnoldSimulationMethodsEstimate2011,
  title = {Simulation Methods to Estimate Design Power: An Overview for Applied Research},
  shorttitle = {Simulation Methods to Estimate Design Power},
  author = {Arnold, Benjamin F. and Hogan, Daniel R. and Colford, John M. and Hubbard, Alan E.},
  year = {2011},
  month = jun,
  journal = {BMC Medical Research Methodology},
  volume = {11},
  number = {1},
  pages = {94},
  issn = {1471-2288},
  doi = {10.1186/1471-2288-11-94},
  urldate = {2023-07-21},
  abstract = {Estimating the required sample size and statistical power for a study is an integral part of study design. For standard designs, power equations provide an efficient solution to the problem, but they are unavailable for many complex study designs that arise in practice. For such complex study designs, computer simulation is a useful alternative for estimating study power. Although this approach is well known among statisticians, in our experience many epidemiologists and social scientists are unfamiliar with the technique. This article aims to address this knowledge gap.},
  keywords = {Computer Simulation,Power,Research Design,Sample Size},
  file = {/Users/zenn/Zotero/storage/XNNDRWXV/Arnold et al. - 2011 - Simulation methods to estimate design power an ov.pdf;/Users/zenn/Zotero/storage/JLRMSCCB/1471-2288-11-94.html}
}

@article{arnoldSimulationMethodsEstimate2011a,
  title = {Simulation Methods to Estimate Design Power: An Overview for Applied Research},
  shorttitle = {Simulation Methods to Estimate Design Power},
  author = {Arnold, Benjamin F and Hogan, Daniel R and Colford, John M and Hubbard, Alan E},
  year = {2011},
  month = dec,
  journal = {BMC Medical Research Methodology},
  volume = {11},
  number = {1},
  pages = {94},
  issn = {1471-2288},
  doi = {10.1186/1471-2288-11-94},
  urldate = {2024-06-07},
  abstract = {Background: Estimating the required sample size and statistical power for a study is an integral part of study design. For standard designs, power equations provide an efficient solution to the problem, but they are unavailable for many complex study designs that arise in practice. For such complex study designs, computer simulation is a useful alternative for estimating study power. Although this approach is well known among statisticians, in our experience many epidemiologists and social scientists are unfamiliar with the technique. This article aims to address this knowledge gap. Methods: We review an approach to estimate study power for individual- or cluster-randomized designs using computer simulation. This flexible approach arises naturally from the model used to derive conventional power equations, but extends those methods to accommodate arbitrarily complex designs. The method is universally applicable to a broad range of designs and outcomes, and we present the material in a way that is approachable for quantitative, applied researchers. We illustrate the method using two examples (one simple, one complex) based on sanitation and nutritional interventions to improve child growth. Results: We first show how simulation reproduces conventional power estimates for simple randomized designs over a broad range of sample scenarios to familiarize the reader with the approach. We then demonstrate how to extend the simulation approach to more complex designs. Finally, we discuss extensions to the examples in the article, and provide computer code to efficiently run the example simulations in both R and Stata. Conclusions: Simulation methods offer a flexible option to estimate statistical power for standard and nontraditional study designs and parameters of interest. The approach we have described is universally applicable for evaluating study designs used in epidemiologic and social science research.},
  copyright = {http://creativecommons.org/licenses/by/2.0},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/MTQF3BNF/Arnold et al. - 2011 - Simulation methods to estimate design power an ov.pdf}
}

@article{asakuraInterimMonitoringFutility2020,
  title = {Interim {{Monitoring}} for {{Futility}} in {{Clinical Trials With Two Co-Primary Endpoints Using Prediction}}},
  author = {Asakura, Koko and Evans, Scott R. and Hamasaki, Toshimitsu},
  year = {2020},
  month = apr,
  journal = {Statistics in Biopharmaceutical Research},
  volume = {12},
  number = {2},
  pages = {164--175},
  publisher = {{Taylor and Francis Inc.}},
  issn = {19466315},
  doi = {10.1080/19466315.2019.1677494/SUPPL_FILE/USBR_A_1677494_SM6762.ZIP},
  urldate = {2022-01-30},
  abstract = {We discuss using prediction as a flexible and practical approach for monitoring futility in clinical trials with two co-primary endpoints (CPE). This approach is appealing in that it provides quantitative evaluation of potential effect sizes and associated precision, and can be combined with flexible error-spending strategies. We extend prediction of effect size estimates and the construction of predicted intervals to the two CPE case, and illustrate interim futility monitoring of treatment effects using prediction with an example. We also discuss alternative approaches based on the conditional and predictive powers, compare these methods and provide some guidance on the use of prediction for better decision in clinical trials with CPE.},
  keywords = {Conditional power,Group-sequential designs,Interim analyses,Predicted intervals,Predictive power,Type I error},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/asakura et al_2020_interim monitoring for futility in clinical trials with two co-primary.pdf}
}

@article{astion1993overtraining,
  title = {Overtraining in Neural Networks That Interpret Clinical Data},
  author = {Astion, {\relax ML} and Wener, {\relax MH} and Thomas, {\relax RG} and Hunder, {\relax GG} and Bloch, {\relax DA}},
  year = {1993},
  journal = {Clinical chemistry},
  volume = {39},
  number = {9},
  pages = {1998--2004},
  publisher = {Oxford University Press}
}

@article{astion1994application,
  title = {Application of Neural Networks to the Classification of Giant Cell Arteritis},
  author = {Astion, Michael L and Wener, Mark H and Thomas, Ronald G and Hunder, Gene G and Bloch, Daniel A},
  year = {1994},
  journal = {Arthritis \& Rheumatism: Official Journal of the American College of Rheumatology},
  volume = {37},
  number = {5},
  pages = {760--770},
  publisher = {John Wiley \& Sons, Inc. New York}
}

@article{austinIntroductionPropensityScore2011,
  title = {An {{Introduction}} to {{Propensity Score Methods}} for {{Reducing}} the {{Effects}} of {{Confounding}} in {{Observational Studies}}},
  author = {Austin, Peter C.},
  year = {2011},
  month = may,
  journal = {https://doi.org/10.1080/00273171.2011.568786},
  volume = {46},
  number = {3},
  pages = {399--424},
  publisher = {Taylor \& Francis Group},
  issn = {00273171},
  doi = {10.1080/00273171.2011.568786},
  urldate = {2021-11-10},
  abstract = {The propensity score is the probability of treatment assignment conditional on observed baseline characteristics. The propensity score allows one to design and analyze an observational (nonrandomiz...},
  pmid = {21818162},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/austin_2011_an introduction to propensity score methods for reducing the effects of.pdf}
}

@article{ayutyanontCarriers2015,
  title = {Carriers},
  author = {Ayutyanont, Napatkamon and Langbaum, Jessica B and Hendrix, Suzanne B and Chen, Kewei and Fleisher, Adam S and Friesenhahn, Michel and Aguirre, Camilo and {Acosta-baena}, Natalia and Madrigal, Luc{\`i}a and Lopera, Francisco and Reiman, Eric M},
  year = {2015},
  volume = {75},
  number = {6},
  pages = {652--660},
  doi = {10.4088/JCP.13m08927.The},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/ayutyanont et al_2015_carriers.pdf}
}

@article{azherComparisonRandomizationMethods2023,
  title = {A {{Comparison}} of {{Randomization Methods}} for {{Multi-Arm Clinical Trials}}},
  author = {Azher, Ruqayya A. and Wason, James M. S. and Grayling, Michael J.},
  year = {2023},
  month = aug,
  journal = {Statistics in Biopharmaceutical Research},
  pages = {1--13},
  issn = {1946-6315},
  doi = {10.1080/19466315.2023.2238645},
  urldate = {2024-02-02},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/azher et al_2023_a comparison of randomization methods for multi-arm clinical trials.pdf}
}

@article{Azimbagirad2021,
  title = {Tsallis Generalized Entropy for {{Gaussian}} Mixture Model Parameter Estimation on Brain Segmentation Application},
  author = {Azimbagirad, Mehran and Murta Junior, Luiz Otavio},
  year = {2021},
  month = sep,
  journal = {Neuroscience Informatics},
  volume = {1},
  number = {1-2},
  pages = {100002},
  publisher = {Elsevier},
  issn = {27725286},
  doi = {10.1016/j.neuri.2021.100002},
  urldate = {2021-11-18},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/azimbagirad_murta junior_2021_tsallis generalized entropy for gaussian mixture model parameter estimation on.pdf}
}

@article{baghfalakiBayesianSampleSize2019,
  title = {Bayesian Sample Size Determination for Longitudinal Studies with Continuous Response Based on Different Scientific Questions of Interest},
  author = {Baghfalaki, Taban},
  year = {2019},
  month = mar,
  journal = {Journal of Biopharmaceutical Statistics},
  volume = {29},
  number = {2},
  pages = {244--270},
  publisher = {Taylor \& Francis},
  issn = {1054-3406},
  doi = {10.1080/10543406.2018.1535501},
  urldate = {2023-08-12},
  abstract = {Longitudinal study designs are commonly applied in much scientific research, especially in the medical, social, and economic sciences. Longitudinal studies allow researchers to measure changes in each individual's responses over time and often have higher statistical power than cross-sectional studies. Choosing an appropriate sample size is a crucial step in a successful study. In longitudinal studies, because of the complexity of their design, including the selection of the number of individuals and the number of repeated measurements, sample size determination is less studied. This paper uses a simulation-based method to determine the sample size from a Bayesian perspective. For this purpose, several Bayesian criteria for sample size determination are used, of which the most important one is the Bayesian power criterion. We determine the sample size of a longitudinal study based on the scientific question of interest, by the choice of an appropriate model. Most of the methods of determining sample size are based on the definition of a single hypothesis. In this paper, in addition to using this method, we determine the sample size using multiple hypotheses. Using several examples, the proposed Bayesian methods are illustrated and discussed.},
  pmid = {30359549},
  keywords = {Bayesian analysis,Bayesian power criterion,longitudinal data,marginal model,random effects model,transition model},
  file = {/Users/zenn/Zotero/storage/CD6CL8L5/Baghfalaki - 2019 - Bayesian sample size determination for longitudina.pdf}
}

@article{Bailey2021,
  title = {The Diagonal Graph},
  author = {Bailey, R. A. and Cameron, Peter J.},
  year = {2021},
  eprint = {2101.02451},
  pages = {1--16},
  abstract = {According to the O'Nan--Scott Theorem, a finite primitive permutation group either preserves a structure of one of three types (affine space, Cartesian lattice, or diagonal semilattice), or is almost simple. However, diagonal groups are a much larger class than those occurring in this theorem. For any positive integer \$m\$ and group \$G\$ (finite or infinite), there is a diagonal semilattice, a sub-semilattice of the lattice of partitions of a set \${\textbackslash}Omega\$, whose automorphism group is the corresponding diagonal group. Moreover, there is a graph (the diagonal graph), bearing much the same relation to the diagonal semilattice and group as the Hamming graph does to the Cartesian lattice and the wreath product of symmetric groups. Our purpose here, after a brief introduction to this semilattice and graph, is to establish some properties of this graph. The diagonal graph \${\textbackslash}Gamma\_D(G,m)\$ is a Cayley graph for the group{\textasciitilde}\$G{\textasciicircum}m\$, and so is vertex-transitive. We establish its clique number in general and its chromatic number in most cases, with a conjecture about the chromatic number in the remaining cases. We compute the spectrum of the adjacency matrix of the graph, using a calculation of the M{\textbackslash}"obius function of the diagonal semilattice. We also compute some other graph parameters and symmetry properties of the graph. We believe that this family of graphs will play a significant role in algebraic graph theory.},
  archiveprefix = {arXiv},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/bailey_cameron_2021_the diagonal graph.pdf}
}

@article{baileyOptimalCrossoverDesigns2006,
  title = {On Optimal Crossover Designs When Carryover Effects Are Proportional to Direct Effects},
  author = {Bailey, {\relax RA} and Biometrika, J Kunert - and 2006, undefined},
  year = {2006},
  journal = {academic.oup.com},
  volume = {93},
  number = {3},
  pages = {613--625},
  urldate = {2021-11-06},
  abstract = {S There are a number of different models for crossover designs which take account of carryover effects. Since it seems plausible that a treatment with a large direct effect should generally have a larger carryover effect, Kempton et al. (2001) considered a model where the carryover effects are proportional to the direct effects. The advantage of this model lies in the fact that there are fewer parameters to be estimated. Its problem lies in the nonlinearity of the estimators. Kempton et al. (2001) considered the least squares estimator. They point out that this estimator is asymptotically equivalent to the estimator in a linear model which assumes the true parameters to be known. For this estimator they determine optimal designs numerically for some cases. The present paper generalises some of their results. Our results are derived with the help of a generalisation of the methods used in Kunert \& Martin (2000). Some key words: Carryover effect; Crossover design; Universal optimality. 1. I In crossover designs the experimental subjects are exposed to a series of treatments, one after the other. One important example of crossover designs is the case of a sensory trial. Here, products are described with the human senses. Each assessor tastes and evaluates a series of products, such as the bitterness of several brands of beer. A problem with this kind of experiment is the liability to have carryover effects. This may be a lingering taste of a product that infuences the perception of the next product, or it may be the well-known tendency to give a lower rating to the next product after a very intense product. There are a number of models for crossover designs which take account of carryover effects. It seems plausible from what was said above that a treatment with a large direct effect should generally have a large carryover effect. Kempton et al. (2001) considered a model where the carryover effects are proportional to the direct effects. The advantage of this model lies in the fact that there are fewer parameters to be estimated. The problem lies in the nonlinearity of the estimators. Kempton et al. (2001) considered the least squares},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/bailey et al_2006_on optimal crossover designs when carryover effects are proportional to direct.pdf}
}

@article{baileyUniformSemiLatinSquares2020,
  title = {Uniform Semi-{{Latin}} Squares and Their Pairwise-Variance Aberrations},
  author = {Bailey, R.A. and Soicher, Leonard H.},
  year = {2020},
  month = dec,
  journal = {Journal of Statistical Planning and Inference},
  pages = {S0378375820301373},
  issn = {03783758},
  doi = {10.1016/j.jspi.2020.12.003},
  urldate = {2021-01-09},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/bailey_soicher_2020_uniform semi-latin squares and their pairwise-variance aberrations.pdf}
}

@article{baiOptimalityMatchedPairDesigns2022,
  title = {Optimality of {{Matched-Pair Designs}} in {{Randomized Controlled Trials}}},
  author = {Bai, Yuehao},
  year = {2022},
  month = dec,
  journal = {American Economic Review},
  volume = {112},
  number = {12},
  pages = {3911--3940},
  issn = {0002-8282},
  doi = {10.1257/aer.20201856},
  urldate = {2023-12-15},
  abstract = {In randomized controlled trials, treatment is often assigned by stratified randomization. I show that among all stratified randomization schemes that treat all units with probability one half, a certain matched-pair design achieves the maximum statistical precision for estimating the average treatment effect. In an important special case, the optimal design pairs units according to the baseline outcome. In a simulation study based on datasets from ten randomized controlled trials, this design lowers the standard error for the estimator of the average treatment effect by 10 percent on average, and by up to 34 percent, relative to the original designs.},
  langid = {english},
  keywords = {Estimation: General Single Equation Models,Quantile Regressions,Single Variables: Cross-Sectional Models,Spatial Models,Treatment Effect Models},
  file = {/Users/zenn/Zotero/storage/IHX34ZKS/Bai - 2022 - Optimality of Matched-Pair Designs in Randomized C.pdf}
}

@article{balmerAlgorithm236Recursive1988,
  title = {Algorithm {{AS}} 236: {{Recursive Enumeration}} of r {\texttimes} c {{Tables}} for {{Exact Likelihood Evaluation}}},
  shorttitle = {Algorithm {{AS}} 236},
  author = {Balmer, D. W.},
  year = {1988},
  journal = {Journal of the Royal Statistical Society. Series C (Applied Statistics)},
  volume = {37},
  number = {2},
  eprint = {2347356},
  eprinttype = {jstor},
  pages = {290--301},
  publisher = {[Wiley, Royal Statistical Society]},
  issn = {0035-9254},
  doi = {10.2307/2347356},
  urldate = {2023-08-18},
  file = {/Users/zenn/Zotero/storage/GF7APNCT/Balmer - 1988 - Algorithm AS 236 Recursive Enumeration of r × c T.pdf}
}

@article{balmerAlgorithm236Recursive1988a,
  title = {Algorithm {{AS}} 236: {{Recursive Enumeration}} of r {\texttimes} c {{Tables}} for {{Exact Likelihood Evaluation}}},
  shorttitle = {Algorithm {{AS}} 236},
  author = {Balmer, D. W.},
  year = {1988},
  journal = {Applied Statistics},
  volume = {37},
  number = {2},
  eprint = {10.2307/2347356},
  eprinttype = {jstor},
  pages = {290},
  issn = {00359254},
  doi = {10.2307/2347356},
  urldate = {2023-08-18},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/ETFEHNA3/Balmer - 1988 - Algorithm AS 236 Recursive Enumeration of r × c T.pdf}
}

@article{Balsis2012,
  title = {Gaining Precision on the {{Alzheimer}}'s {{Disease Assessment Scale-cognitive}}: {{A}} Comparison of Item Response Theory-Based Scores and Total Scores},
  author = {Balsis, Steve and Unger, Alexis A. and Benge, Jared F. and Geraci, Lisa and Doody, Rachelle S.},
  year = {2012},
  journal = {Alzheimer's \& Dementia},
  volume = {8},
  number = {4},
  pages = {288--294},
  urldate = {2013-11-30},
  abstract = {BACKGROUND The Alzheimer's Disease Assessment Scale-cognitive (ADAS-cog) is a commonly used measure for assessing cognitive dysfunction in patients with Alzheimer's disease (AD). The measure has 11 subscales, each of which captures an important aspect of cognitive dysfunction in AD. Traditional scoring of the ADAS-cog involves adding up the scores from the subscales without regarding their varying difficulty or their strength of relationship to AD-associated cognitive dysfunction. The present article analyzes problems associated with this approach and offers solutions for gaining measurement precision by modeling how the subscales function.  METHODS We analyzed data collected at the Baylor College of Medicine Alzheimer's Disease and Memory Disorders Clinic from 1240 patients diagnosed with varying degrees of dementia. Item response theory was used to determine the relationship between total scores on the ADAS-cog and the underlying level of cognitive dysfunction reflected by the scores.  RESULTS Results revealed that each total score corresponded to a spectrum of cognitive dysfunction, indicating that total scores were relatively imprecise indicators of underlying cognitive dysfunction. Furthermore, it was common for two individuals with the same total score to have significantly different degrees of cognitive dysfunction.  CONCLUSIONS These findings suggest that item response theory scoring of the ADAS-cog may measure cognitive dysfunction more precisely than a total score method.},
  keywords = {ADAS,Alzheimer's disease,Clinical trial,Item response theory,Measurement},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/balsis et al_2012_gaining precision on the alzheimer’s disease assessment scale-cognitive.pdf}
}

@article{balsisAlzheimerDiseaseAssessment2018,
  title = {Alzheimer's {{Disease Assessment}}: {{A Review}} and {{Illustrations Focusing}} on {{Item Response Theory Techniques}}},
  shorttitle = {Alzheimer's {{Disease Assessment}}},
  author = {Balsis, Steve and Choudhury, Tabina K. and Geraci, Lisa and Benge, Jared F. and Patrick, Christopher J.},
  year = {2018},
  month = apr,
  journal = {Assessment},
  volume = {25},
  number = {3},
  pages = {360--373},
  issn = {1073-1911, 1552-3489},
  doi = {10.1177/1073191117745125},
  urldate = {2024-01-18},
  abstract = {Alzheimer's disease (AD) affects neurological, cognitive, and behavioral processes. Thus, to accurately assess this disease, researchers and clinicians need to combine and incorporate data across these domains. This presents not only distinct methodological and statistical challenges but also unique opportunities for the development and advancement of psychometric techniques. In this article, we describe relatively recent research using item response theory (IRT) that has been used to make progress in assessing the disease across its various symptomatic and pathological manifestations. We focus on applications of IRT to improve scoring, test development (including cross-validation and adaptation), and linking and calibration. We conclude by describing potential future multidimensional applications of IRT techniques that may improve the precision with which AD is measured.},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/balsis et al_2018_alzheimer’s disease assessment.pdf}
}

@article{balsisGainingPrecisionAlzheimer2012,
  title = {Gaining Precision on the {{Alzheimer}}'s {{Disease Assessment Scale-cognitive}}: A Comparison of Item Response Theory-Based Scores and Total Scores},
  shorttitle = {Gaining Precision on the {{Alzheimer}}'s {{Disease Assessment Scale-cognitive}}},
  author = {Balsis, Steve and Unger, Alexis A. and Benge, Jared F. and Geraci, Lisa and Doody, Rachelle S.},
  year = {2012},
  journal = {Alzheimer's \& Dementia},
  volume = {8},
  number = {4},
  pages = {288--294},
  publisher = {Elsevier},
  urldate = {2024-01-18},
  file = {/Users/zenn/Zotero/storage/S5S8YBNJ/S155252601102574X.html}
}

@article{balsisHowScoresADASCog2015,
  title = {How {{Do Scores}} on the {{ADAS-Cog}}, {{MMSE}}, and {{CDR-SOB Correspond}}?},
  author = {Balsis, Steve and Benge, Jared F. and Lowe, Deborah A. and Geraci, Lisa and Doody, Rachelle S.},
  year = {2015},
  month = oct,
  journal = {The Clinical Neuropsychologist},
  volume = {29},
  number = {7},
  pages = {1002--1009},
  issn = {1385-4046, 1744-4144},
  doi = {10.1080/13854046.2015.1119312},
  urldate = {2024-01-18},
  langid = {english}
}

@article{bangPredictingDiseaseProgression2016,
  title = {Predicting Disease Progression in Progressive Supranuclear Palsy in Multicenter Clinical Trials},
  author = {Bang, Jee and Lobach, Iryna V. and Lang, Anthony E. and Grossman, Murray and Knopman, David S. and Miller, Bruce L. and Schneider, Lon S. and Doody, Rachelle S. and Lees, Andrew and Gold, Michael and Morimoto, Bruce H. and Boxer, Adam L. and {AL-108-231 Investigators}},
  year = {2016},
  month = jul,
  journal = {Parkinsonism \& Related Disorders},
  volume = {28},
  pages = {41--48},
  issn = {1873-5126},
  doi = {10.1016/j.parkreldis.2016.04.014},
  abstract = {INTRODUCTION: Clinical and MRI measurements can track disease progression in PSP, but many have not been extensively evaluated in multicenter clinical trials. We identified optimal measures to capture clinical decline and predict disease progression in multicenter PSP trials. METHODS: Longitudinal clinical rating scales, neuropsychological test scores, and volumetric MRI data from an international, phase 2/3 clinical trial of davunetide for PSP (intent to treat population, n~=~303) were used to identify measurements with largest effect size, strongest correlation with clinical change, and best ability to predict dropout or clinical decline over one year as measured by PSP Rating Scale (PSPRS). RESULTS: Baseline cognition as measured by Repeatable Battery for Assessing Neuropsychological Status (RBANS) was associated with attrition, but had only a small effect. PSPRS and Clinical Global Impression (CGI) had the largest effect size for measuring change. Annual change in CGI, RBANS, color trails, and MRI midbrain and ventricular volumes were most strongly correlated with annual PSPRS and had the largest effect sizes for detecting annual change. At baseline, shorter disease duration, more severe depression, and lower performance on RBANS and executive function tests were associated with faster worsening of the PSPRS in completers. With dropouts included, SEADL, RBANS, and executive function tests had significant effect on PSPRS trajectory of change. CONCLUSION: Baseline cognitive status and mood influence the rate of disease progression in PSP. Multiple clinical, neuropsychological, and volumetric MRI measurements are sensitive to change over one year in PSP and appropriate for use in multicenter clinical trials.},
  langid = {english},
  pmcid = {PMC4914418},
  pmid = {27172829},
  keywords = {Clinical trial methodology,Clinical Trials as Topic,Disease Progression,Female,Humans,Magnetic Resonance Imaging,Male,Middle Aged,Multicenter Studies as Topic,Outcome Assessment Health Care,Patient Dropouts,Prognosis,Progressive supranuclear palsy,Supranuclear Palsy Progressive},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/bang et al_2016_predicting disease progression in progressive supranuclear palsy in multicenter4.pdf}
}

@article{bangPredictingDiseaseProgression2016a,
  title = {Predicting Disease Progression in Progressive Supranuclear Palsy in Multicenter Clinical Trials},
  author = {Bang, Jee and Lobach, Iryna V. and Lang, Anthony E. and Grossman, Murray and Knopman, David S. and Miller, Bruce L. and Schneider, Lon S. and Doody, Rachelle S. and Lees, Andrew and Gold, Michael and Morimoto, Bruce H. and Boxer, Adam L. and {AL-108-231 Investigators}},
  year = {2016},
  month = jul,
  journal = {Parkinsonism \& Related Disorders},
  volume = {28},
  pages = {41--48},
  issn = {1873-5126},
  doi = {10.1016/j.parkreldis.2016.04.014},
  abstract = {INTRODUCTION: Clinical and MRI measurements can track disease progression in PSP, but many have not been extensively evaluated in multicenter clinical trials. We identified optimal measures to capture clinical decline and predict disease progression in multicenter PSP trials. METHODS: Longitudinal clinical rating scales, neuropsychological test scores, and volumetric MRI data from an international, phase 2/3 clinical trial of davunetide for PSP (intent to treat population, n~=~303) were used to identify measurements with largest effect size, strongest correlation with clinical change, and best ability to predict dropout or clinical decline over one year as measured by PSP Rating Scale (PSPRS). RESULTS: Baseline cognition as measured by Repeatable Battery for Assessing Neuropsychological Status (RBANS) was associated with attrition, but had only a small effect. PSPRS and Clinical Global Impression (CGI) had the largest effect size for measuring change. Annual change in CGI, RBANS, color trails, and MRI midbrain and ventricular volumes were most strongly correlated with annual PSPRS and had the largest effect sizes for detecting annual change. At baseline, shorter disease duration, more severe depression, and lower performance on RBANS and executive function tests were associated with faster worsening of the PSPRS in completers. With dropouts included, SEADL, RBANS, and executive function tests had significant effect on PSPRS trajectory of change. CONCLUSION: Baseline cognitive status and mood influence the rate of disease progression in PSP. Multiple clinical, neuropsychological, and volumetric MRI measurements are sensitive to change over one year in PSP and appropriate for use in multicenter clinical trials.},
  langid = {english},
  pmcid = {PMC4914418},
  pmid = {27172829},
  keywords = {Clinical trial methodology,Clinical Trials as Topic,Disease Progression,Female,Humans,Magnetic Resonance Imaging,Male,Middle Aged,Multicenter Studies as Topic,Outcome Assessment Health Care,Patient Dropouts,Prognosis,Progressive supranuclear palsy,Supranuclear Palsy Progressive},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/bang et al_2016_predicting disease progression in progressive supranuclear palsy in multicenter3.pdf}
}

@article{bangPredictingDiseaseProgression2016b,
  title = {Predicting Disease Progression in Progressive Supranuclear Palsy in Multicenter Clinical Trials},
  author = {Bang, Jee and Lobach, Iryna V. and Lang, Anthony E. and Grossman, Murray and Knopman, David S. and Miller, Bruce L. and Schneider, Lon S. and Doody, Rachelle S. and Lees, Andrew and Gold, Michael and Morimoto, Bruce H. and Boxer, Adam L. and {AL-108-231 Investigators}},
  year = {2016},
  month = jul,
  journal = {Parkinsonism \& Related Disorders},
  volume = {28},
  pages = {41--48},
  issn = {1873-5126},
  doi = {10.1016/j.parkreldis.2016.04.014},
  abstract = {INTRODUCTION: Clinical and MRI measurements can track disease progression in PSP, but many have not been extensively evaluated in multicenter clinical trials. We identified optimal measures to capture clinical decline and predict disease progression in multicenter PSP trials. METHODS: Longitudinal clinical rating scales, neuropsychological test scores, and volumetric MRI data from an international, phase 2/3 clinical trial of davunetide for PSP (intent to treat population, n~=~303) were used to identify measurements with largest effect size, strongest correlation with clinical change, and best ability to predict dropout or clinical decline over one year as measured by PSP Rating Scale (PSPRS). RESULTS: Baseline cognition as measured by Repeatable Battery for Assessing Neuropsychological Status (RBANS) was associated with attrition, but had only a small effect. PSPRS and Clinical Global Impression (CGI) had the largest effect size for measuring change. Annual change in CGI, RBANS, color trails, and MRI midbrain and ventricular volumes were most strongly correlated with annual PSPRS and had the largest effect sizes for detecting annual change. At baseline, shorter disease duration, more severe depression, and lower performance on RBANS and executive function tests were associated with faster worsening of the PSPRS in completers. With dropouts included, SEADL, RBANS, and executive function tests had significant effect on PSPRS trajectory of change. CONCLUSION: Baseline cognitive status and mood influence the rate of disease progression in PSP. Multiple clinical, neuropsychological, and volumetric MRI measurements are sensitive to change over one year in PSP and appropriate for use in multicenter clinical trials.},
  langid = {english},
  pmcid = {PMC4914418},
  pmid = {27172829},
  keywords = {Clinical trial methodology,Clinical Trials as Topic,Disease Progression,Female,Humans,Magnetic Resonance Imaging,Male,Middle Aged,Multicenter Studies as Topic,Outcome Assessment Health Care,Patient Dropouts,Prognosis,Progressive supranuclear palsy,Supranuclear Palsy Progressive},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/bang et al_2016_predicting disease progression in progressive supranuclear palsy in multicenter2.pdf}
}

@article{bangPredictingDiseaseProgression2016c,
  title = {Predicting Disease Progression in Progressive Supranuclear Palsy in Multicenter Clinical Trials},
  author = {Bang, Jee and Lobach, Iryna V. and Lang, Anthony E. and Grossman, Murray and Knopman, David S. and Miller, Bruce L. and Schneider, Lon S. and Doody, Rachelle S. and Lees, Andrew and Gold, Michael and Morimoto, Bruce H. and Boxer, Adam L. and {AL-108-231 Investigators}},
  year = {2016},
  month = jul,
  journal = {Parkinsonism \& Related Disorders},
  volume = {28},
  pages = {41--48},
  issn = {1873-5126},
  doi = {10.1016/j.parkreldis.2016.04.014},
  abstract = {INTRODUCTION: Clinical and MRI measurements can track disease progression in PSP, but many have not been extensively evaluated in multicenter clinical trials. We identified optimal measures to capture clinical decline and predict disease progression in multicenter PSP trials. METHODS: Longitudinal clinical rating scales, neuropsychological test scores, and volumetric MRI data from an international, phase 2/3 clinical trial of davunetide for PSP (intent to treat population, n~=~303) were used to identify measurements with largest effect size, strongest correlation with clinical change, and best ability to predict dropout or clinical decline over one year as measured by PSP Rating Scale (PSPRS). RESULTS: Baseline cognition as measured by Repeatable Battery for Assessing Neuropsychological Status (RBANS) was associated with attrition, but had only a small effect. PSPRS and Clinical Global Impression (CGI) had the largest effect size for measuring change. Annual change in CGI, RBANS, color trails, and MRI midbrain and ventricular volumes were most strongly correlated with annual PSPRS and had the largest effect sizes for detecting annual change. At baseline, shorter disease duration, more severe depression, and lower performance on RBANS and executive function tests were associated with faster worsening of the PSPRS in completers. With dropouts included, SEADL, RBANS, and executive function tests had significant effect on PSPRS trajectory of change. CONCLUSION: Baseline cognitive status and mood influence the rate of disease progression in PSP. Multiple clinical, neuropsychological, and volumetric MRI measurements are sensitive to change over one year in PSP and appropriate for use in multicenter clinical trials.},
  langid = {english},
  pmcid = {PMC4914418},
  pmid = {27172829},
  keywords = {Clinical trial methodology,Clinical Trials as Topic,Disease Progression,Female,Humans,Magnetic Resonance Imaging,Male,Middle Aged,Multicenter Studies as Topic,Outcome Assessment Health Care,Patient Dropouts,Prognosis,Progressive supranuclear palsy,Supranuclear Palsy Progressive},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/bang et al_2016_predicting disease progression in progressive supranuclear palsy in multicenter.pdf}
}

@article{bangPredictingDiseaseProgression2016d,
  title = {Predicting Disease Progression in Progressive Supranuclear Palsy in Multicenter Clinical Trials},
  author = {Bang, Jee and Lobach, Iryna V. and Lang, Anthony E. and Grossman, Murray and Knopman, David S. and Miller, Bruce L. and Schneider, Lon S. and Doody, Rachelle S. and Lees, Andrew and Gold, Michael and Morimoto, Bruce H. and Boxer, Adam L. and {AL-108-231 Investigators}},
  year = {2016},
  month = jul,
  journal = {Parkinsonism \& Related Disorders},
  volume = {28},
  pages = {41--48},
  issn = {1873-5126},
  doi = {10.1016/j.parkreldis.2016.04.014},
  abstract = {INTRODUCTION: Clinical and MRI measurements can track disease progression in PSP, but many have not been extensively evaluated in multicenter clinical trials. We identified optimal measures to capture clinical decline and predict disease progression in multicenter PSP trials. METHODS: Longitudinal clinical rating scales, neuropsychological test scores, and volumetric MRI data from an international, phase 2/3 clinical trial of davunetide for PSP (intent to treat population, n~=~303) were used to identify measurements with largest effect size, strongest correlation with clinical change, and best ability to predict dropout or clinical decline over one year as measured by PSP Rating Scale (PSPRS). RESULTS: Baseline cognition as measured by Repeatable Battery for Assessing Neuropsychological Status (RBANS) was associated with attrition, but had only a small effect. PSPRS and Clinical Global Impression (CGI) had the largest effect size for measuring change. Annual change in CGI, RBANS, color trails, and MRI midbrain and ventricular volumes were most strongly correlated with annual PSPRS and had the largest effect sizes for detecting annual change. At baseline, shorter disease duration, more severe depression, and lower performance on RBANS and executive function tests were associated with faster worsening of the PSPRS in completers. With dropouts included, SEADL, RBANS, and executive function tests had significant effect on PSPRS trajectory of change. CONCLUSION: Baseline cognitive status and mood influence the rate of disease progression in PSP. Multiple clinical, neuropsychological, and volumetric MRI measurements are sensitive to change over one year in PSP and appropriate for use in multicenter clinical trials.},
  langid = {english},
  pmcid = {PMC4914418},
  pmid = {27172829},
  keywords = {Clinical trial methodology,Clinical Trials as Topic,Disease Progression,Female,Humans,Magnetic Resonance Imaging,Male,Middle Aged,Multicenter Studies as Topic,Outcome Assessment Health Care,Patient Dropouts,Prognosis,Progressive supranuclear palsy,Supranuclear Palsy Progressive},
  file = {/Users/zenn/Zotero/storage/M4QYU29S/Bang et al. - 2016 - Predicting disease progression in progressive supr.pdf}
}

@article{baronMissingDataRandomized2008,
  title = {Missing Data in Randomized Controlled Trials of Rheumatoid Arthritis with Radiographic Outcomes: A Simulation Study},
  shorttitle = {Missing Data in Randomized Controlled Trials of Rheumatoid Arthritis with Radiographic Outcomes},
  author = {Baron, Gabriel and Ravaud, Philippe and Samson, Adeline and Giraudeau, Bruno},
  year = {2008},
  journal = {Arthritis Care \& Research: Official Journal of the American College of Rheumatology},
  volume = {59},
  number = {1},
  pages = {25--31},
  publisher = {Wiley Online Library},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/baron et al_2008_missing data in randomized controlled trials of rheumatoid arthritis with.pdf;/Users/zenn/Zotero/storage/B7DF734C/art.html}
}

@article{barrett1997estrogen,
  title = {Estrogen, Apolipoprotein {{E}}, and Dementia},
  author = {{Barrett-Connor}, Elizabeth and Thomas, Ronald G},
  year = {1997},
  journal = {Journal of Women's Health},
  volume = {6},
  number = {6},
  pages = {677--677}
}

@article{basuTrialsRandomizedControl2018,
  title = {The Trials of Randomized Control: {{Probability}}, Intuition and the Dinosaur Risk. {{A}} Commentary on {{Deaton}} and {{Cartwright}}},
  shorttitle = {The Trials of Randomized Control},
  author = {Basu, Kaushik},
  year = {2018},
  journal = {Social Science \& Medicine},
  volume = {210},
  pages = {26--28},
  publisher = {Elsevier},
  file = {/Users/zenn/Zotero/storage/8ASBDSFB/S027795361830203X.html}
}

@article{batesFittingLinearMixed2005,
  title = {Fitting Linear Mixed Models in {{R}}},
  author = {Bates, Douglas},
  year = {2005},
  journal = {R news},
  volume = {5},
  number = {1},
  pages = {27--30},
  urldate = {2024-03-11},
  file = {/Users/zenn/Zotero/storage/NIZJ2G64/Bates - 2005 - Fitting linear mixed models in R.pdf}
}

@article{batesFittingLinearMixedEffects2015,
  title = {Fitting {{Linear Mixed-Effects Models Using}} Lme4},
  author = {Bates, Douglas and M{\"a}chler, Martin and Bolker, Ben and Walker, Steve},
  year = {2015},
  month = oct,
  journal = {Journal of Statistical Software},
  volume = {67},
  pages = {1--48},
  issn = {1548-7660},
  doi = {10.18637/jss.v067.i01},
  urldate = {2023-08-07},
  abstract = {Maximum likelihood or restricted maximum likelihood (REML) estimates of the parameters in linear mixed-effects models can be determined using the lmer function in the lme4 package for R. As for most model-fitting functions in R, the model is described in an lmer call by a formula, in this case including both fixed- and random-effects terms. The formula and data together determine a numerical representation of the model from which the profiled deviance or the profiled REML criterion can be evaluated as a function of some of the model parameters. The appropriate criterion is optimized, using one of the constrained optimization functions in R, to provide the parameter estimates. We describe the structure of the model, the steps in evaluating the profiled deviance or REML criterion, and the structure of classes or types that represents such a model. Sufficient detail is included to allow specialization of these structures by users who wish to write functions to fit specialized linear mixed models, such as models incorporating pedigrees or smoothing splines, that are not easily expressible in the formula language used by lmer.},
  copyright = {Copyright (c) 2015 Douglas Bates, Martin M{\"a}chler, Ben Bolker, Steve Walker},
  langid = {english},
  keywords = {Cholesky decomposition,linear mixed models,penalized least squares,sparse matrix methods},
  file = {/Users/zenn/Zotero/storage/I9RYA365/Bates et al. - 2015 - Fitting Linear Mixed-Effects Models Using lme4.pdf}
}

@inproceedings{batesStatisticalModels1992,
  title = {Statistical Models in {{S}}},
  booktitle = {Computer Science and Statistics: Proceedings of the 19th {{Symposium}} on the {{Interface}}. {{Wadsworth}} \& {{Brooks}}, {{California}}},
  author = {Bates, D. M. and Chambers, J. M. and Hastie, T.},
  year = {1992},
  urldate = {2024-05-20},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/bates et al_1992_statistical models in s.pdf}
}

@article{bayley2000comparison,
  title = {Comparison of the Serial Position Effect in Very Mild {{Alzheimer}}'s Disease, Mild {{Alzheimer}}'s Disease, and Amnesia Associated with Electroconvulsive Therapy},
  author = {Bayley, Peter J and Salmon, David P and Bondi, Mark W and Bui, Barbara K and Olichney, John and Delis, Dean C and Thomas, Ronald G and Thal, Leon J},
  year = {2000},
  journal = {Journal of the International Neuropsychological Society},
  volume = {6},
  number = {3},
  pages = {290--298},
  publisher = {Cambridge University Press}
}

@article{Beekly2007,
  title = {The {{National Alzheimer}}'s {{Coordinating Center}} ({{NACC}}) Database: {{The}} Uniform Data Set},
  author = {Beekly, Duane L. and Ramos, Erin M. and Lee, William W. and Deitrich, Woodrow D. and Jacka, Mary E. and Wu, Joylee and Hubbard, Janene L. and Koepsell, Thomas D. and Morris, John C. and Kukull, Walter A. and Reiman, Eric M. and Kowall, Neil and Landreth, Gary and Shelanski, Michael and {Welsh-Bohmer}, Kathleen and Levey, Allan I. and Potter, Huntington and Ghetti, Bernardino and Price, Donald and Hyman, Bradley and Petersen, Ronald C. and Sano, Mary and Ferris, Steven H. and Mesulam, M. Marsel and Kaye, Jeffrey and Bennett, David A. and Yesavage, Jerome and Marson, Daniel and Beck, Cornelia and DeCarli, Charles and Cotman, Carl and Cummings, Jeffrey L. and Thal, Leon J. and Markesbery, William and Gilman, Sid and Trojanowski, John Q. and DeKosky, Steven T. and Chui, Helena and Rosenberg, Roger and Raskind, Murray},
  year = {2007},
  journal = {Alzheimer Disease and Associated Disorders},
  volume = {21},
  number = {3},
  pages = {249--258},
  issn = {08930341},
  doi = {10.1097/WAD.0b013e318142774e},
  abstract = {The National Alzheimer's Coordinating Center (NACC) is responsible for developing and maintaining a database of participant information collected from the 29 Alzheimer's Disease Centers (ADCs) funded by the National Institute on Aging (NIA). The NIA appointed the ADC Clinical Task Force to determine and define an expanded, standardized clinical data set, called the Uniform Data Set (UDS). The goal of the UDS is to provide ADC researchers a standard set of assessment procedures, collected longitudinally, to better characterize ADC participants with mild Alzheimer disease and mild cognitive impairment in comparison with nondemented controls. NACC implemented the UDS (September 2005) by developing data collection forms for initial and follow-up visits based on Clinical Task Force definitions, a relational database, and a data submission system accessible by all ADCs. The NIA requires ADCs to submit UDS data to NACC for all their Clinical Core participants. Thus, the NACC web site (https://www.alz.washington.edu) was enhanced to provide efficient and secure access data submission and retrieval systems. {\copyright} 2007 Lippincott Williams \& Wilkins, Inc.},
  pmid = {17804958},
  keywords = {Alzheimer disease,Data submission,Database,Dementia,NACC,UDS},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/beekly et al_2007_the national alzheimer's coordinating center (nacc) database.pdf}
}

@inproceedings{bell1999ethnic,
  title = {Ethnic Differences in Clinical Measures among Participants in {{Alzheimer}}'s Disease Clinical Trials},
  booktitle = {Neurology},
  author = {Bell, {\relax KL} and Sano, {\relax MC} and Jin, S and Thomas, {\relax RG} and Thal, {\relax LJ}},
  year = {1999},
  volume = {52},
  pages = {A396--A396},
  publisher = {LIPPINCOTT WILLIAMS \& WILKINS 530 WALNUT ST, PHILADELPHIA, PA 19106-3621 USA}
}

@article{bellissimoAcutePhysiologicalPerceptual2022,
  title = {The {{Acute Physiological}} and {{Perceptual Responses Between Bodyweight}} and {{Treadmill Running High-Intensity Interval Exercises}}},
  author = {Bellissimo, Gabriella F. and Ducharme, Jeremy and Mang, Zachary and Millender, Desmond and Smith, Jessica and Stork, Matthew J. and Little, Johnathan P. and Deyhle, Michael R. and Gibson, Ann L. and {de Castro Magalhaes}, Flavio and Amorim, Fabiano},
  year = {2022},
  journal = {Frontiers in Physiology},
  volume = {13},
  issn = {1664-042X},
  urldate = {2022-11-05},
  abstract = {ObjectiveThe purpose of this study was to compare the acute physiological, perceptual, and enjoyment responses between bodyweight high-intensity interval exercise (BW-HIIE) and treadmill running high-intensity interval exercise HIIE (RUN-HIIE).MethodsTwelve adults [age: 29.5\,{\textpm}\,5.3\,years; weight: 70.9\,{\textpm}\,15.0\,kg; height: 167.9\,{\textpm}\,8.9\,cm; peak oxygen consumption (VO2 peak): 48.7\,{\textpm}\,6.5\,ml min-1{$\cdot$}kg-1] performed both RUN-HIIE and BW-HIIE. RUN-HIIE consisted of two sets of 5, 60-s (s) run intervals at 100\% of the speed achieved during VO2 peak testing followed by 60s of walking at 4.02 km/h. BW-HIIE consisted of two sets of 5, 60s `all-out' effort calisthenic exercises followed by 60s of marching in place at 100 steps per minute. Oxygen consumption (VO2), blood lactate (Blac), heart rate (HR), and rating of perceived exertion (RPE) were measured during exercise. Physical activity enjoyment (PACES) was assessed post-exercise. Creatine Kinase (CK) was measured before exercise and 48-h post-exercise. Muscle soreness was assessed before exercise, post-exercise, and 48-h post-exercise.ResultsOxygen consumption relative to VO2 peak was higher (p\,{$<$}\,0.001) during RUN-HIIE (88\,{\textpm}\,3\%) compared to BW-HIIE (77\,{\textpm}\,4\%). HR relative to HRpeak was higher (p\,=\,0.002) for RUN-HIIE (93\,{\textpm}\,1\%) compared to BW-HIIE (88\,{\textpm}\,2\%). Blac was higher (p\,{$<$}\,0.001) after BW-HIIE (11.2\,{\textpm}\,3.2\,mmol/l) compared to RUN-HIIE (6.9\,{\textpm}\,2.0\,mmol/l). Average RPE achieved was higher (p\,=\,0.003) during BW-HIIE (16\,{\textpm}\,2) than RUN-HIIE (14\,{\textpm}\,2). PACES was similar for RUN-HIIE and BW-HIIE (p\,{$>$}\,0.05). No differences (p\,{$>$}\,0.05) in CK were observed between RUN-HIIE and BW-HIIE.ConclusionOur results indicate `all-out' calisthenic exercise can elicit vigorous cardiorespiratory, Blac, and RPE responses. Implementing this style of exercise into training requires minimal space, no equipment, and may elicit cardiometabolic adaptations seen with traditional forms of high-intensity exercise.},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/bellissimo et al_2022_the acute physiological and perceptual responses between bodyweight and.pdf}
}

@article{benderAdjustingMultipleTesting2001,
  title = {Adjusting for Multiple Testing---When and How?},
  author = {Bender, Ralf and Lange, Stefan},
  year = {2001},
  month = apr,
  journal = {Journal of Clinical Epidemiology},
  volume = {54},
  number = {4},
  pages = {343--349},
  issn = {08954356},
  doi = {10.1016/S0895-4356(00)00314-0},
  urldate = {2024-03-12},
  abstract = {Multiplicity of data, hypotheses, and analyses is a common problem in biomedical and epidemiological research. Multiple testing theory provides a framework for defining and controlling appropriate error rates in order to protect against wrong conclusions. However, the corresponding multiple test procedures are underutilized in biomedical and epidemiological research. In this article, the existing multiple test procedures are summarized for the most important multiplicity situations. It is emphasized that adjustments for multiple testing are required in confirmatory studies whenever results from multiple tests have to be combined in one final conclusion and decision. In case of multiple significance tests a note on the error rate that will be controlled for is desirable. {\copyright} 2001 Elsevier Science Inc. All rights reserved.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/JBIWLDZF/Bender and Lange - 2001 - Adjusting for multiple testing—when and how.pdf}
}

@article{benderAdjustingMultipleTesting2001a,
  title = {Adjusting for Multiple Testing---When and How?},
  author = {Bender, Ralf and Lange, Stefan},
  year = {2001},
  month = apr,
  journal = {Journal of Clinical Epidemiology},
  volume = {54},
  number = {4},
  pages = {343--349},
  issn = {0895-4356},
  doi = {10.1016/S0895-4356(00)00314-0},
  urldate = {2024-03-12},
  abstract = {Multiplicity of data, hypotheses, and analyses is a common problem in biomedical and epidemiological research. Multiple testing theory provides a framework for defining and controlling appropriate error rates in order to protect against wrong conclusions. However, the corresponding multiple test procedures are underutilized in biomedical and epidemiological research. In this article, the existing multiple test procedures are summarized for the most important multiplicity situations. It is emphasized that adjustments for multiple testing are required in confirmatory studies whenever results from multiple tests have to be combined in one final conclusion and decision. In case of multiple significance tests a note on the error rate that will be controlled for is desirable.},
  keywords = {Adjustment for multiple testing,Bonferroni method,Error rates,Multiple hypotheses testing,UKPDS,value},
  file = {/Users/zenn/Zotero/storage/JGMKMWVI/S0895435600003140.html}
}

@article{benfordTreesFewLeaves2021,
  title = {Trees with Few Leaves in Tournaments},
  author = {Benford, Alistair and Montgomery, Richard},
  year = {2021},
  month = mar,
  journal = {arXiv:2103.06229 [math]},
  eprint = {2103.06229},
  primaryclass = {math},
  urldate = {2021-03-11},
  abstract = {We prove that there exists \$C{$>$}0\$ such that any \$(n+Ck)\$-vertex tournament contains a copy of every \$n\$-vertex oriented tree with \$k\$ leaves, improving the previously best known bound of \$n+O(k{\textasciicircum}2)\$ vertices to give a result tight up to the value of \$C\$. Furthermore, we show that, for each \$k\$, there exists \$n\_0\$, such that, whenever \$n{\textbackslash}geqslant n\_0\$, any \$(n+k-2)\$-vertex tournament contains a copy of every \$n\$-vertex oriented tree with at most \$k\$ leaves, confirming a conjecture of Dross and Havet.},
  archiveprefix = {arXiv},
  keywords = {Mathematics - Combinatorics},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/benford_montgomery_2021_trees with few leaves in tournaments.pdf;/Users/zenn/Zotero/storage/PSGHSHX7/2103.html}
}

@article{bengeHowWellADAScog2009,
  title = {How Well Do the {{ADAS-cog}} and Its Subscales Measure Cognitive Dysfunction in {{Alzheimer}}'s Disease?},
  author = {Benge, Jared F. and Balsis, Steve and Geraci, Lisa and Massman, Paul J. and Doody, Rachelle S.},
  year = {2009},
  journal = {Dementia and geriatric cognitive disorders},
  volume = {28},
  number = {1},
  pages = {63--69},
  publisher = {S. Karger AG Basel, Switzerland},
  urldate = {2024-01-18},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/benge et al_2009_how well do the adas-cog and its subscales measure cognitive dysfunction in.pdf}
}

@article{benjaminiControllingFalseDiscovery1995,
  title = {Controlling the {{False Discovery Rate}}: {{A Practical}} and {{Powerful Approach}} to {{Multiple Testing}}},
  shorttitle = {Controlling the {{False Discovery Rate}}},
  author = {Benjamini, Yoav and Hochberg, Yosef},
  year = {1995},
  month = jan,
  journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
  volume = {57},
  number = {1},
  pages = {289--300},
  issn = {0035-9246, 2517-6161},
  doi = {10.1111/j.2517-6161.1995.tb02031.x},
  urldate = {2024-03-12},
  abstract = {SUMMARY             The common approach to the multiplicity problem calls for controlling the familywise error rate (FWER). This approach, though, has faults, and we point out a few. A different approach to problems of multiple significance testing is presented. It calls for controlling the expected proportion of falsely rejected hypotheses --- the false discovery rate. This error rate is equivalent to the FWER when all hypotheses are true but is smaller otherwise. Therefore, in problems where the control of the false discovery rate rather than that of the FWER is desired, there is potential for a gain in power. A simple sequential Bonferronitype procedure is proved to control the false discovery rate for independent test statistics, and a simulation study shows that the gain in power is substantial. The use of the new procedure and the appropriateness of the criterion are illustrated with examples.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/6A2875BR/Benjamini and Hochberg - 1995 - Controlling the False Discovery Rate A Practical .pdf}
}

@article{benjaminiMultipleHypothesesTesting1997,
  title = {Multiple {{Hypotheses Testing}} with {{Weights}}},
  author = {Benjamini, Yoav and Hochberg, Yosef},
  year = {1997},
  journal = {Scandinavian Journal of Statistics},
  volume = {24},
  number = {3},
  pages = {407--418},
  issn = {1467-9469},
  doi = {10.1111/1467-9469.00072},
  urldate = {2024-03-12},
  abstract = {In this paper we offer a multiplicity of approaches and procedures for multiple testing problems with weights. Some rationale for incorporating weights in multiple hypotheses testing are discussed. Various type-I error-rates and different possible formulations are considered, for both the intersection hypothesis testing and the multiple hypotheses testing problems. An optimal per family weighted error-rate controlling procedure a la Spjotvoll (1972) is obtained. This model serves as a vehicle for demonstrating the different implications of the approaches to weighting. Alternative approach es to that of Holm (1979) for family-wise error-rate control with weights are discussed, one involving an alternative procedure for family-wise error-rate control, and the other involving the control of a weighted family-wise error-rate. Extensions and modifications of the procedures based on Simes (1986) are given. These include a test of the overall intersec tion hypothesis with general weights, and weighted sequentially rejective procedures for testing the individual hypotheses. The false discovery rate controlling approach and procedure of Benjamini \& Hochberg (1995) are extended to allow for different weights.},
  copyright = {Board of the Foundation  of the Scandinavian Journal of Statistics 1997},
  langid = {english},
  keywords = {control weights,false discovery rate,family-wise error-rate,p-values,per-family error-rate,procedural weights},
  file = {/Users/zenn/Zotero/storage/ZY6KQYMT/Benjamini and Hochberg - 1997 - Multiple Hypotheses Testing with Weights.pdf;/Users/zenn/Zotero/storage/IAKSGWDA/1467-9469.html}
}

@article{benjaminiMultipleHypothesesTesting1997a,
  title = {Multiple {{Hypotheses Testing}} with {{Weights}}},
  author = {Benjamini, Yoav and Hochberg, Yosef},
  year = {1997},
  month = sep,
  journal = {Scandinavian Journal of Statistics},
  volume = {24},
  number = {3},
  pages = {407--418},
  issn = {0303-6898, 1467-9469},
  doi = {10.1111/1467-9469.00072},
  urldate = {2024-03-12},
  abstract = {In this paper we offer a multiplicity of approaches and procedures for multiple testing problems with weights. Some rationale for incorporating weights in multiple hypotheses testing are discussed. Various type-I error-rates and different possible formulations are considered, for both the intersection hypothesis testing and the multiple hypotheses testing problems. An optimal per family weighted error-rate controlling procedure               a la               Spjotvoll (1972) is obtained. This model serves as a vehicle for demonstrating the different implications of the approaches to weighting. Alternative approach es to that of Holm (1979) for family-wise error-rate control with weights are discussed, one involving an alternative procedure for family-wise error-rate control, and the other involving the control of a weighted family-wise error-rate. Extensions and modifications of the procedures based on Simes (1986) are given. These include a test of the overall intersec tion hypothesis with general weights, and weighted sequentially rejective procedures for testing the individual hypotheses. The false discovery rate controlling approach and procedure of Benjamini \& Hochberg (1995) are extended to allow for different weights.},
  langid = {english}
}

@article{bennettAntisenseOligonucleotideTherapies2019,
  title = {Antisense {{Oligonucleotide Therapies}} for {{Neurodegenerative Diseases}}},
  author = {Bennett, C. Frank and Krainer, Adrian R. and Cleveland, Don W.},
  year = {2019},
  month = jul,
  journal = {Annual Review of Neuroscience},
  volume = {42},
  number = {1},
  pages = {385--406},
  issn = {0147-006X, 1545-4126},
  doi = {10.1146/annurev-neuro-070918-050501},
  urldate = {2022-11-19},
  abstract = {Antisense oligonucleotides represent a novel therapeutic platform for the discovery of medicines that have the potential to treat most neurodegenerative diseases. Antisense drugs are currently in development for the treatment of amyotrophic lateral sclerosis, Huntington's disease, and Alzheimer's disease, and multiple research programs are underway for additional neurodegenerative diseases. One antisense drug, nusinersen, has been approved for the treatment of spinal muscular atrophy. Importantly, nusinersen improves disease symptoms when administered to symptomatic patients rather than just slowing the progression of the disease. In addition to the benefit to spinal muscular atrophy patients, there are discoveries from nusinersen that can be applied to other neurological diseases, including method of delivery, doses, tolerability of intrathecally delivered antisense drugs, and the biodistribution of intrathecal dosed antisense drugs. Based in part on the early success of nusinersen, antisense drugs hold great promise as a therapeutic platform for the treatment of neurological diseases.},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/bennett et al_2019_antisense oligonucleotide therapies for neurodegenerative diseases.pdf}
}

@article{Benussi2021,
  title = {Prodromal Frontotemporal Dementia: Clinical Features and Predictors of Progression},
  author = {Benussi, Alberto and Ashton, Nicholas J. and Karikari, Thomas K. and Alberici, Antonella and Saraceno, Claudia and Ghidoni, Roberta and Benussi, Luisa and Zetterberg, Henrik and Blennow, Kaj and Borroni, Barbara},
  year = {2021},
  month = nov,
  journal = {Alzheimer's Research and Therapy},
  volume = {13},
  number = {1},
  pages = {1--10},
  publisher = {BioMed Central},
  issn = {17589193},
  doi = {10.1186/s13195-021-00932-2},
  urldate = {2021-11-20},
  abstract = {Background: The prodromal phase of frontotemporal dementia (FTD) is still not well characterized, and conversion rates to dementia and predictors of progression at 1-year follow-up are currently unknown. Methods: In this retrospective study, disease severity was assessed using the global CDR plus NACC FTLD. Prodromal FTD was defined to reflect mild cognitive or behavioural impairment with relatively preserved functional independence (global CDR plus NACC = 0.5) as well as mild, moderate and severe dementia (classified as global CDR plus NACC = 1, 2, 3, respectively). Disease progression at 1-year follow-up and serum NfL measurements were acquired in a subgroup of patients. Results: Of 563 participants, 138 were classified as prodromal FTD, 130 as mild, 175 as moderate and 120 as severe FTD. In the prodromal and mild phases, we observed an early increase in serum NfL levels followed by behavioural disturbances and deficits in executive functions. Negative symptoms, such as apathy, inflexibility and loss of insight, predominated in the prodromal phase. Serum NfL levels were significantly increased in the prodromal phase compared with healthy controls (average difference 14.5, 95\% CI 2.9 to 26.1 pg/mL), but lower than in patients with mild FTD (average difference -15.5, 95\% CI -28.4 to -2.7 pg/mL). At 1-year follow-up, 51.2\% of patients in the prodromal phase had converted to dementia. Serum NfL measurements at baseline were the strongest predictors of disease progression at 1-year follow-up (OR 1.07, 95\% CI 1.03 to 1.11, p {$<$} 0.001). Conclusions: Prodromal FTD is a mutable stage with high rate of progression to fully symptomatic disease at 1-year follow-up. High serum NfL levels may support prodromal FTD diagnosis and represent a helpful marker to assess disease progression.},
  pmid = {34782010},
  keywords = {Conversion,Frontotemporal dementia,Mild,Prodromal,Progression,Serum neurofilament light},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/benussi et al_2021_prodromal frontotemporal dementia.pdf}
}

@article{berg1998measuring,
  title = {Measuring Cognitive Progression in {{Alzheimer}}'s Disease},
  author = {Berg, Julie D and Thomas, Ronald G and Thal, Leon J and Sano, Mary},
  year = {1998},
  journal = {Controlled Clinical Trials},
  volume = {19},
  number = {3},
  pages = {S57--S58},
  publisher = {Elsevier}
}

@article{bergerDirectEffectValidity2003,
  title = {Direct Effect on Validity of Response Run-in Selection in Clinical Trials},
  author = {Berger, Vance W and Rezvani, Azadeh and Makarewicz, Vanessa A},
  year = {2003},
  month = apr,
  journal = {Controlled Clinical Trials},
  volume = {24},
  number = {2},
  pages = {156--166},
  issn = {0197-2456},
  doi = {10.1016/S0197-2456(02)00316-1},
  urldate = {2022-10-20},
  abstract = {A run-in is a period prior to randomization during which potential participants who have met all entry criteria for a randomized clinical trial are assigned the same regimen, either the control (possibly placebo) or the experimental treatment. Typically, the intention is to exclude from the subsequent study (i.e., randomization) some segment of this cohort, based on their experiences during the run-in period. Selecting patients based on the run-in thereby forces differential representation of certain subpopulations relative to others. Previous studies have addressed the potential for a run-in to jeopardize validity through unintended mechanisms. While these concerns are valid, they leave open the possibility that modifications to the design of the run-in might be able to preserve validity, even if patient selection is based on the results of the run-in. As such, we address the potential for selecting patients based on response during a run-in period to jeopardize validity directly, through its intended effect of overrepresenting (relative to the screened population) some segments in the randomized portion of the trial and underrepresenting others. Sackett D, Vist G. {$<$}},
  langid = {english},
  keywords = {Clinical relevance,Inference discrepancy,Inference population,Target population},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/berger et al_2003_direct effect on validity of response run-in selection in clinical trials.pdf;/Users/zenn/Zotero/storage/9HRAMYTI/S0197245602003161.html}
}

@article{berkowitzPrecisionMedicineAlzheimer2018,
  title = {Precision Medicine for {{Alzheimer}}'s Disease Prevention},
  author = {Berkowitz, Cara L and Mosconi, Lisa and Scheyer, Olivia and Rahman, Aneela and Hristov, Hollie and Isaacson, Richard S},
  year = {2018},
  month = jul,
  journal = {mdpi.com},
  volume = {6},
  number = {3},
  doi = {10.3390/healthcare6030082},
  urldate = {2021-11-06},
  abstract = {Precision medicine is an approach to medical treatment and prevention that takes into account individual variability in genes, environment, and lifestyle and allows for personalization that is based on factors that may affect the response to treatment. Several genetic and epigenetic risk factors have been shown to increase susceptibility to late-onset Alzheimer's disease (AD). As such, it may be beneficial to integrate genetic risk factors into the AD prevention approach, which in the past has primarily been focused on universal risk-reduction strategies for the general population rather than individualized interventions in a targeted fashion. This review discusses examples of a "one-size-fits-all" versus clinical precision medicine AD prevention strategy, in which the precision medicine approach considers two genes that can be commercially sequenced for polymorphisms associated with AD, apolipoprotein E (APOE), and methylenetetrahydrofolate reductase (MTHFR). Comparing these two distinct approaches provides support for a clinical precision medicine prevention strategy, which may ultimately lead to more favorable patient outcomes as the interventions are targeted to address individualized risks.},
  keywords = {Alzheimer's disease prevention,APOE,apolipoprotein 4,clinical precision medicine,methylenetetrahydrofolate reductase,MTHFR,precision medicine},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/berkowitz et al_2018_precision medicine for alzheimer's disease prevention.pdf}
}

@article{berry-kravisInhibitionPhosphodiesterase4DAdults,
  title = {Inhibition of Phosphodiesterase-{{4D}} in Adults with Fragile {{X}} Syndrome: A Randomized, Placebo-Controlled, Phase 2 Clinical Trial},
  author = {{Berry-Kravis}, Elizabeth M and Harnett, Mark D and Reines, Scott A and Reese, Melody A and Ethridge, Lauren E and Outterson, Abigail H and Michalak, Claire and Furman, Jeremiah and Gurney, Mark E},
  journal = {Nature Medicine},
  doi = {10.1038/s41591-021-01321-w},
  abstract = {F XS is a serious genetic, neurodevelopmental disorder with severe impact on intellect, behavior and daily function. Children with FXS fall behind neurotypical children with respect to intellect and behavioral function from early in development 1. FXS affects 1 in 4,000 US men and 1 in 8,000 US women or upwards of 60,000 people in the United States 2. The majority of males with FXS present with moderate-to-severe intellectual disability with an IQ on average in the range of 40-45 and an average mental age of 5-6 years 2,3. Some men with FXS acquire only rudimentary language skills and more than 50\% have autism spectrum disorder (ASD). The most severely affected men with FXS may be unable to learn to use the toilet independently. FXS has severe impact on patients and on families, caregivers and the community who provide lifelong care. The disorder is due to expansion of a CGG repeat sequence in the promoter region of the FMR1 gene that encodes the fragile X mental retardation 1 protein (FMRP) 4,5. Expansion of the CGG repeat beyond 200 repeats leads to methylation and full or partial silencing of FMR1 depending on the degree of methylation. The gene is fully methylated in up to 80\% of cases of FXS, which leads to an absence of FMRP. FMR1 is expressed in most tissues in the body but the brain is the tissue most severely impacted by the absence or reduction of FMRP 2. Since the FMR1 gene is located on the X chromosome, males are affected more than females. Females show a broader range of disability due to mosaicism caused by X chromosome inactivation during embryonic development. Due to the ran-domness of X chromosome inactivation in tissue progenitor cells, brain development and function can be relatively normal in females if the mutant X chromosome is predominantly inactivated, while other females may be severely affected if the normal X chromosome is predominantly inactivated. About a third of females inheriting an FMR1 full mutation develop intellectual disability, typically in the mild range, but disability can be moderate or severe. Another third are diagnosed with a less severe learning disability and roughly a third have normal cognition but may have emotional or behavioral issues. Average IQ in females with FXS is in the 75-80 range and 20\% have ASD 2,3. Although supportive behavioral treatment with medications addressing symptoms is available, currently there are no specific therapeutic options that target the underlying disorder or treat intellectual disability in FXS and exploration of multiple disease-targeting therapeutic strategies has not yet met with success 3. Negative clinical trial results may reflect issues with trial design or clinical development strategy although much has been learned 6-8. A consistent observation across patients and FXS animal models is an alteration in cyclic AMP (cAMP) metabolism. An initial report 9 of lower basal and stimulated levels of cAMP in platelets from patients with FXS compared to patients with other types of intellectual disability, such as trisomy 21, was confirmed in subsequent studies of human lymphoblastoid cell lines and fibroblasts derived from patients with FXS 10 and later with human progenitor cells carrying a mutant FXS chromosome that had been induced to form neuronal cells in cell culture 11. Transfection of neural cells The goal of this study was to determine whether a phosphodiesterase-4D (PDE4D) allosteric inhibitor (BPN14770) would improve cognitive function and behavioral outcomes in patients with fragile X syndrome (FXS). This phase 2 trial was a 24-week randomized, placebo-controlled, two-way crossover study in 30 adult male patients (age 18-41 years) with FXS. Participants received oral doses of BPN14770 25 mg twice daily or placebo. Primary outcomes were prespecified as safety and tolerability with secondary efficacy outcomes of cognitive performance, caregiver rating scales and physician rating scales (ClinicalTrials. gov identifier: NCT03569631). The study met the primary outcome measure since BPN14770 was well tolerated with no meaningful differences between the active and placebo treatment arms. The study also met key secondary efficacy measures of cognition and daily function. Cognitive benefit was demonstrated using the National Institutes of Health Toolbox Cognition Battery assessments of Oral Reading Recognition (least squares mean difference +2.81, P = 0.0157), Picture Vocabulary (+5.81, P = 0.0342) and Cognition Crystallized Composite score (+5.31, P = 0.0018). Benefit as assessed by visual analog caregiver rating scales was judged to be clinically meaningful for language (+14.04, P = 0.0051) and daily functioning (+14.53, P = 0.0017). Results from this study using direct, computer-based assessment of cognitive performance by adult males with FXS indicate significant cognitive improvement in domains related to language with corresponding improvement in caregiver scales rating language and daily functioning. NAtuRE MEDICINE {\textbar} VOL 27 {\textbar} MAy 2021 {\textbar} 862-870 {\textbar} www.nature.com/naturemedicine 862},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/berry-kravis et al_inhibition of phosphodiesterase-4d in adults with fragile x syndrome.pdf}
}

@article{berryExactChisquareFisher1987,
  title = {Exact Chi-Square and {{Fisher}}'s Exact Probability Test for 3 by 2 Cross-Classification Tables},
  author = {Berry, Kenneth J. and Mielke Jr, Paul W.},
  year = {1987},
  journal = {Educational and psychological measurement},
  volume = {47},
  number = {3},
  pages = {631--636},
  publisher = {Sage Publications Sage CA: Thousand Oaks, CA}
}

@article{berryRapidFORTRANSubroutine1983,
  title = {A Rapid {{FORTRAN}} Subroutine for the {{Fisher}} Exact Probability Test},
  author = {Berry, Kenneth J. and Mielke Jr, Paul W.},
  year = {1983},
  journal = {Educational and Psychological Measurement},
  volume = {43},
  number = {1},
  pages = {167--171},
  publisher = {Sage Publications Sage CA: Thousand Oaks, CA},
  file = {/Users/zenn/Zotero/storage/DMIP7BZW/Berry and Mielke Jr - 1983 - A rapid FORTRAN subroutine for the Fisher exact pr.pdf}
}

@article{berrySubroutinesComputingExact1985,
  title = {Subroutines for Computing Exact Chi-Square and {{Fisher}}'s Exact Probability Tests},
  author = {Berry, Kenneth J. and Mielke Jr, Paul W.},
  year = {1985},
  journal = {Educational and psychological measurement},
  volume = {45},
  number = {1},
  pages = {153--159},
  publisher = {Sage Publications Sage CA: Thousand Oaks, CA}
}

@article{bhaskaranWhatDifferenceMissing2014,
  title = {What Is the Difference between Missing Completely at Random and Missing at Random?},
  author = {Bhaskaran, Krishnan and Smeeth, Liam},
  year = {2014},
  month = aug,
  journal = {International Journal of Epidemiology},
  volume = {43},
  number = {4},
  pages = {1336--1339},
  issn = {0300-5771},
  doi = {10.1093/ije/dyu080},
  urldate = {2024-02-06},
  abstract = {The terminology describing missingness mechanisms is confusing. In particular the meaning of `missing at random' is often misunderstood, leading researchers faced with missing data problems away from multiple imputation, a method with considerable advantages. The purpose of this article is to clarify how `missing at random' differs from `missing completely at random' via an imagined dialogue between a clinical researcher and statistician.},
  pmcid = {PMC4121561},
  pmid = {24706730},
  file = {/Users/zenn/Zotero/storage/XBCCL7KY/Bhaskaran and Smeeth - 2014 - What is the difference between missing completely .pdf}
}

@article{bhattAdaptiveDesignsClinical2016,
  title = {Adaptive {{Designs}} for {{Clinical Trials}}},
  author = {Bhatt, Deepak L. and Mehta, Cyrus},
  editor = {Drazen, Jeffrey M. and Harrington, David P. and McMurray, John J.V. and Ware, James H. and Woodcock, Janet},
  year = {2016},
  month = jul,
  journal = {New England Journal of Medicine},
  volume = {375},
  number = {1},
  pages = {65--74},
  issn = {0028-4793, 1533-4406},
  doi = {10.1056/NEJMra1510061},
  urldate = {2024-04-14},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/FRQ2FHZV/NEJMra1510061.pdf}
}

@misc{BibliographyManagementBibtex,
  title = {Bibliography Management with Bibtex},
  urldate = {2023-09-05},
  abstract = {An online LaTeX editor that's easy to use. No installation, real-time collaboration, version control, hundreds of LaTeX templates, and more.},
  howpublished = {https://www.overleaf.com/learn/latex/Bibliography\_management\_with\_bibtex},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/LNCGNLAE/Bibliography_management_with_bibtex.html}
}

@article{binette2021amyloid,
  title = {Amyloid and Tau Pathology Associations with Personality Traits, Neuropsychiatric Symptoms, and Cognitive Lifestyle in the Preclinical Phases of Sporadic and Autosomal Dominant {{Alzheimer}}'s Disease},
  author = {Binette, Alexa Pichet and {Vachon-Presseau}, {\'E}tienne and Morris, John and Bateman, Randall and Benzinger, Tammie and Collins, D Louis and Poirier, Judes and Breitner, John CS and Villeneuve, Sylvia and Allegri, Ricardo and others},
  year = {2021},
  journal = {Biological psychiatry},
  volume = {89},
  number = {8},
  pages = {776--785},
  publisher = {Elsevier}
}

@article{blackstonComparisonAggregatedNof12019,
  title = {Comparison of {{Aggregated N-of-1 Trials}} with {{Parallel}} and {{Crossover Randomized Controlled Trials Using Simulation Studies}}},
  author = {Blackston, J. Walker and Chapple, Andrew G. and McGree, James M. and McDonald, Suzanne and Nikles, Jane},
  year = {2019},
  month = dec,
  journal = {Healthcare},
  volume = {7},
  number = {4},
  pages = {137},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2227-9032},
  doi = {10.3390/healthcare7040137},
  urldate = {2023-12-13},
  abstract = {Background: N-of-1 trials offer an innovative approach to delivering personalized clinical care together with population-level research. While increasingly used, these methods have raised some statistical concerns in the healthcare community. Methods: We discuss concerns of selection bias, carryover effects from treatment, and trial data analysis conceptually, then rigorously evaluate concerns of effect sizes, power and sample size through simulation study. Four variance structures for patient heterogeneity and model error are considered in a series of 5000 simulated trials with 3 cycles, which compare aggregated N-of-1 trials to parallel randomized controlled trials (RCTs) and crossover trials. Results: Aggregated N-of-1 trials outperformed both traditional parallel RCT and crossover designs when these trial designs were simulated in terms of power and required sample size to obtain a given power. N-of-1 designs resulted in a higher type-I error probability than parallel RCT and cross over designs when moderate-to-strong carryover effects were not considered or in the presence of modeled selection bias. However, N-of-1 designs allowed better estimation of patient-level random effects. These results reinforce the need to account for these factors when planning N-of-1 trials. Conclusion: N-of-1 trial designs offer a rigorous method for advancing personalized medicine and healthcare with the potential to minimize costs and resources. Interventions can be tested with adequate power with far fewer patients than traditional RCT and crossover designs. Operating characteristics compare favorably to both traditional RCT and crossover designs.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {clinical trial,comparative effectiveness,evidence-based medicine,N-of-1 trial,simulation study,single-case study,statistical methods},
  file = {/Users/zenn/Zotero/storage/YJ6GT86W/Blackston et al. - 2019 - Comparison of Aggregated N-of-1 Trials with Parall.pdf}
}

@article{blakesleyComparisonsMethodsMultiple2009,
  title = {Comparisons of Methods for Multiple Hypothesis Testing in Neuropsychological Research},
  author = {Blakesley, Richard E. and Mazumdar, Sati and Dew, Mary Amanda and Houck, Patricia R. and Tang, Gong and Reynolds III, Charles F. and Butters, Meryl A.},
  year = {2009},
  journal = {Neuropsychology},
  volume = {23},
  number = {2},
  pages = {255--264},
  publisher = {American Psychological Association},
  address = {US},
  issn = {1931-1559},
  doi = {10.1037/a0012850},
  abstract = {Hypothesis testing with multiple outcomes requires adjustments to control Type I error inflation, which reduces power to detect significant differences. Maintaining the prechosen Type I error level is challenging when outcomes are correlated. This problem concerns many research areas, including neuropsychological research in which multiple, interrelated assessment measures are common. Standard p value adjustment methods include Bonferroni-, Sidak-, and resampling-class methods. In this report, the authors aimed to develop a multiple hypothesis testing strategy to maximize power while controlling Type I error. The authors conducted a sensitivity analysis, using a neuropsychological dataset, to offer a relative comparison of the methods and a simulation study to compare the robustness of the methods with respect to varying patterns and magnitudes of correlation between outcomes. The results lead them to recommend the Hochberg and Hommel methods (step-up modifications of the Bonferroni method) for mildly correlated outcomes and the step-down minP method (a resampling-based method) for highly correlated outcomes. The authors note caveats regarding the implementation of these methods using available software. (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
  keywords = {Error Analysis,Hypothesis Testing,Test Performance,Testing,Type I Errors},
  file = {/Users/zenn/Zotero/storage/5EYWYFN7/Blakesley et al. - 2009 - Comparisons of methods for multiple hypothesis tes.pdf;/Users/zenn/Zotero/storage/YIZM9BCY/2009-02621-013.html}
}

@article{Blennow2018,
  title = {Biomarkers for {{Alzheimer}}'s Disease: Current Status and Prospects for the Future},
  author = {Blennow, K. and Zetterberg, H.},
  year = {2018},
  month = dec,
  journal = {Journal of Internal Medicine},
  volume = {284},
  number = {6},
  pages = {643--663},
  publisher = {Blackwell Publishing Ltd},
  issn = {13652796},
  doi = {10.1111/joim.12816},
  urldate = {2021-11-11},
  abstract = {Accumulating data from the clinical research support that the core Alzheimer's disease (AD) cerebrospinal fluid (CSF) biomarkers amyloid-{$\beta$} (A{$\beta$}42), total tau (T-tau), and phosphorylated tau (P-tau) reflect key elements of AD pathophysiology. Importantly, a large number of clinical studies very consistently show that these biomarkers contribute with diagnostically relevant information, also in the early disease stages. Recent technical developments have made it possible to measure these biomarkers using fully automated assays with high precision and stability. Standardization efforts have given certified reference materials for CSF A{$\beta$}42, with the aim to harmonize results between assay formats that would allow for uniform global reference limits and cut-off values. These encouraging developments have led to that the core AD CSF biomarkers have a central position in the novel diagnostic criteria for the disease and in the recent National Institute on Aging and Alzheimer's Association biological definition of AD. Taken together, this progress will likely serve as the basis for a more general introduction of these diagnostic tests in clinical routine practice. However, the heterogeneity of pathology in late-onset AD calls for an expansion of the AD CSF biomarker toolbox with additional biomarkers reflecting additional aspects of AD pathophysiology. One promising candidate is the synaptic protein neurogranin that seems specific for AD and predicts future rate of cognitive deterioration. Further, recent studies bring hope for easily accessible and cost-effective screening tools in the early diagnostic evaluation of patients with cognitive problems (and suspected AD) in primary care. In this respect, technical developments with ultrasensitive immunoassays and novel mass spectrometry techniques give promise of biomarkers to monitor brain amyloidosis (the A{$\beta$}42/40 or APP669-711/A{$\beta$}42 ratios) and neurodegeneration (tau and neurofilament light proteins) in plasma samples, but future studies are warranted to validate these promising results further.},
  pmid = {30051512},
  keywords = {Alzheimer's disease,biomarkers,blood,cerebrospinal fluid,diagnosis},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/blennow_zetterberg_2018_biomarkers for alzheimer's disease.pdf}
}

@article{blischakQuickIntroductionVersion2016,
  title = {A {{Quick Introduction}} to {{Version Control}} with {{Git}} and {{GitHub}}},
  author = {Blischak, John D. and Davenport, Emily R. and Wilson, Greg},
  year = {2016},
  journal = {PLoS Computational Biology},
  volume = {12},
  number = {1},
  publisher = {Public Library of Science},
  issn = {15537358},
  doi = {10.1371/journal.pcbi.1004668},
  urldate = {2022-06-09},
  pmid = {26785377},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/blischak et al_2016_a quick introduction to version control with git and github.pdf}
}

@article{boeveProgressiveSupranuclearPalsy2012,
  title = {Progressive Supranuclear Palsy},
  author = {Boeve, Bradley F.},
  year = {2012},
  month = jan,
  journal = {Parkinsonism \& Related Disorders},
  volume = {18 Suppl 1},
  pages = {S192-194},
  issn = {1873-5126},
  doi = {10.1016/S1353-8020(11)70060-8},
  abstract = {Progressive supranuclear palsy (PSP) is a neurodegenerative tauopathy which can manifest clinically in a variety of syndromes. In this review, the classic and most common variant syndrome -PSP-Richardson's syndrome (PSP-RS) -is the focus, with the core clinical features, varying cognitive/motor/neuropsychiatric/sleep manifestations, neuropsychological findings, and typical neuroimaging findings all reviewed. Management strategies are also discussed. Of particular interest are the recently commenced clinical trials involving agents which affect key steps in the presumed pathogenesis of the tauopathies. The distinctive and recognizable characteristics of PSP-RS and advent of clinical trials involving potential disease modifying agents underscore the importance of identifying patients with this disorder and encouraging their involvement in trials.},
  langid = {english},
  pmid = {22166432},
  keywords = {Animals,Clinical Trials as Topic,Humans,Neuroimaging,Supranuclear Palsy Progressive,Tauopathies}
}

@article{boeveProgressiveSupranuclearPalsy2012a,
  title = {Progressive Supranuclear Palsy},
  author = {Boeve, Bradley F.},
  year = {2012},
  month = jan,
  journal = {Parkinsonism \& Related Disorders},
  volume = {18 Suppl 1},
  pages = {S192-194},
  issn = {1873-5126},
  doi = {10.1016/S1353-8020(11)70060-8},
  abstract = {Progressive supranuclear palsy (PSP) is a neurodegenerative tauopathy which can manifest clinically in a variety of syndromes. In this review, the classic and most common variant syndrome -PSP-Richardson's syndrome (PSP-RS) -is the focus, with the core clinical features, varying cognitive/motor/neuropsychiatric/sleep manifestations, neuropsychological findings, and typical neuroimaging findings all reviewed. Management strategies are also discussed. Of particular interest are the recently commenced clinical trials involving agents which affect key steps in the presumed pathogenesis of the tauopathies. The distinctive and recognizable characteristics of PSP-RS and advent of clinical trials involving potential disease modifying agents underscore the importance of identifying patients with this disorder and encouraging their involvement in trials.},
  langid = {english},
  pmid = {22166432},
  keywords = {Animals,Clinical Trials as Topic,Humans,Neuroimaging,Supranuclear Palsy Progressive,Tauopathies}
}

@article{boggessMaternalPeriodontalDisease2003,
  title = {Maternal {{Periodontal Disease Is Associated With}} an {{Increased Risk}} for {{Preeclampsia}}},
  author = {Boggess, Kim A and Lieff, Susi and Murtha, Amy P and Moss, Kevin and Beck, James and Offenbacher, Steven},
  year = {2003},
  volume = {101},
  number = {2},
  abstract = {OBJECTIVE: To determine if maternal periodontal disease is associated with the development of preeclampsia. METHODS: A cohort of 1115 healthy pregnant women were enrolled at less than 26 weeks' gestation and followed until delivery. Maternal demographic and medical data were collected. Periodontal examinations were performed at enrollment and within 48 hours of delivery to determine the presence of severe periodontal disease or periodontal disease progression. Preeclampsia was defined as blood pressure greater than 140/90 on two separate occasions, and at least 1؉ proteinuria on catheterized urine specimen. The potential effects of maternal age, race, smoking, gestational age at delivery, and insurance status were analyzed, and adjusted odds ratios for preeclampsia were calculated using multivariable logistic regression. RESULTS: During the study period, 763 women delivered live infants and had data available for analysis. Thirtynine women had preeclampsia. Women were at higher risk for preeclampsia if they had severe periodontal disease at delivery (adjusted odds ratio 2.4, 95\% confidence interval 1.1, 5.3), or if they had periodontal disease progression during pregnancy (adjusted odds ratio 2.1, 95\% confidence interval 1.0, 4.4). CONCLUSION: After adjusting for other risk factors, active maternal periodontal disease during pregnancy is associated with an increased risk for the development of preeclampsia. (Obstet Gynecol 2003;101:227--31. {\copyright} 2003 by The American College of Obstetricians and Gynecologists.)},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/7DH67RWZ/Boggess et al. - 2003 - Maternal Periodontal Disease Is Associated With an.pdf}
}

@article{boggessMaternalPeriodontalDisease2003a,
  title = {Maternal Periodontal Disease Is Associated with an Increased Risk for Preeclampsia},
  author = {Boggess, Kim A and Lieff, Susi and Murtha, Amy P and Moss, Kevin and Beck, James and Offenbacher, Steven},
  year = {2003},
  month = feb,
  journal = {Obstetrics \& Gynecology},
  volume = {101},
  number = {2},
  pages = {227--231},
  issn = {0029-7844},
  doi = {10.1016/S0029-7844(02)02314-1},
  urldate = {2024-02-27},
  abstract = {OBJECTIVE: To determine if maternal periodontal disease is associated with the development of preeclampsia. METHODS: A cohort of 1115 healthy pregnant women were enrolled at less than 26 weeks' gestation and followed until delivery. Maternal demographic and medical data were collected. Periodontal examinations were performed at enrollment and within 48 hours of delivery to determine the presence of severe periodontal disease or periodontal disease progression. Preeclampsia was defined as blood pressure greater than 140/90 on two separate occasions, and at least 1+ proteinuria on catheterized urine specimen. The potential effects of maternal age, race, smoking, gestational age at delivery, and insurance status were analyzed, and adjusted odds ratios for preeclampsia were calculated using multivariable logistic regression. RESULTS: During the study period, 763 women delivered live infants and had data available for analysis. Thirty-nine women had preeclampsia. Women were at higher risk for preeclampsia if they had severe periodontal disease at delivery (adjusted odds ratio 2.4, 95\% confidence interval 1.1, 5.3), or if they had periodontal disease progression during pregnancy (adjusted odds ratio 2.1, 95\% confidence interval 1.0, 4.4). CONCLUSION: After adjusting for other risk factors, active maternal periodontal disease during pregnancy is associated with an increased risk for the development of preeclampsia.},
  file = {/Users/zenn/Zotero/storage/JQ57UIF3/S0029784402023141.html}
}

@article{boggessMaternalPeriodontalDisease2003b,
  title = {Maternal Periodontal Disease Is Associated with an Increased Risk for Preeclampsia},
  author = {Boggess, Kim A. and Lieff, Susi and Murtha, Amy P. and Moss, Kevin and Beck, James and Offenbacher, Steven},
  year = {2003},
  journal = {Obstetrics \& Gynecology},
  volume = {101},
  number = {2},
  pages = {227--231},
  publisher = {Elsevier},
  urldate = {2024-02-27},
  file = {/Users/zenn/Zotero/storage/PBG9QUQ2/S0029784402023141.html}
}

@article{bolandSchurConvexityMaximum1987,
  title = {Schur Convexity of the Maximum Likelihood Function for the Multivariate Hypergeometric and Multinomial Distributions},
  author = {Boland, Philip J and Proschan, Frank},
  year = {1987},
  month = aug,
  journal = {Statistics \& Probability Letters},
  volume = {5},
  number = {5},
  pages = {317--322},
  issn = {0167-7152},
  doi = {10.1016/0167-7152(87)90002-2},
  urldate = {2023-07-30},
  abstract = {We define for a family distributions p{\texttheta}(x), {\texttheta} {$\epsilon$} {$\Theta$}, the maximum likelihood function L at a sample point x by L(x) = sup{\texttheta}{$\epsilon\Theta$}P{\texttheta}(x). We show that for the multivariate hypergeometric and multinomial families, the maximum likelihood function is a Schur convex function of x. In the language of majorization, this implies that the more diverse the elements or components of x are, the larger is the function L(x). Several applications of this result are given in the areas of parameter estimation and combinatorics. An improvement and generalization of a classical inequality of Khintchine is also derived as a consequence.},
  langid = {english},
  keywords = {Khintchine's inequality,majorization,maximum likelihood function,multinomial,multivariate hypergeometric,Schur convexity},
  file = {/Users/zenn/Zotero/storage/WWA22SUR/Boland and Proschan - 1987 - Schur convexity of the maximum likelihood function.pdf;/Users/zenn/Zotero/storage/L9M248UM/0167715287900022.html}
}

@article{bolandSchurConvexityMaximum1987a,
  title = {Schur Convexity of the Maximum Likelihood Function for the Multivariate Hypergeometric and Multinomial Distributions},
  author = {Boland, Philip J. and Proschan, Frank},
  year = {1987},
  journal = {Statistics \& probability letters},
  volume = {5},
  number = {5},
  pages = {317--322},
  publisher = {Elsevier},
  urldate = {2023-12-23}
}

@article{bolandSchurConvexityMaximum1987b,
  title = {Schur Convexity of the Maximum Likelihood Function for the Multivariate Hypergeometric and Multinomial Distributions},
  author = {Boland, Philip J and Proschan, Frank},
  year = {1987},
  month = aug,
  journal = {Statistics \& Probability Letters},
  volume = {5},
  number = {5},
  pages = {317--322},
  issn = {0167-7152},
  doi = {10.1016/0167-7152(87)90002-2},
  urldate = {2023-12-23},
  abstract = {We define for a family distributions p{\texttheta}(x), {\texttheta} {$\epsilon$} {$\Theta$}, the maximum likelihood function L at a sample point x by L(x) = sup{\texttheta}{$\epsilon\Theta$}P{\texttheta}(x). We show that for the multivariate hypergeometric and multinomial families, the maximum likelihood function is a Schur convex function of x. In the language of majorization, this implies that the more diverse the elements or components of x are, the larger is the function L(x). Several applications of this result are given in the areas of parameter estimation and combinatorics. An improvement and generalization of a classical inequality of Khintchine is also derived as a consequence.},
  keywords = {Khintchine's inequality,majorization,maximum likelihood function,multinomial,multivariate hypergeometric,Schur convexity},
  file = {/Users/zenn/Zotero/storage/UK4WMJFG/0167715287900022.html}
}

@article{bolandSchurConvexityMaximum1987c,
  title = {Schur Convexity of the Maximum Likelihood Function for the Multivariate Hypergeometric and Multinomial Distributions},
  author = {Boland, Philip J and Proschan, Frank},
  year = {1987},
  month = aug,
  journal = {Statistics \& Probability Letters},
  volume = {5},
  number = {5},
  pages = {317--322},
  issn = {01677152},
  doi = {10.1016/0167-7152(87)90002-2},
  urldate = {2023-12-23},
  abstract = {We define for a family distributions pc(x), 0 {\textasciitilde} {\textasciitilde}9, the maximum likelihood function L at a sample point x by L(x) = supe{\textasciitilde}ope(x ). We show that for the multivariate hypergeometric and multinomial families, the maximum likelihood function is a Schur convex function of x. In the language of majorization, this implies that the more diverse the elements or components of x are, the larger is the function L(x). Several applications of this result are given in the areas of parameter estimation and combinatorics. An improvement and generalization of a classical inequality of Khintchine is also derived as a consequence.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/UF53P7KZ/Boland and Proschan - 1987 - Schur convexity of the maximum likelihood function.pdf}
}

@article{bolkerGeneralizedLinearMixed2009,
  title = {Generalized Linear Mixed Models: A Practical Guide for Ecology and Evolution},
  shorttitle = {Generalized Linear Mixed Models},
  author = {Bolker, Benjamin M. and Brooks, Mollie E. and Clark, Connie J. and Geange, Shane W. and Poulsen, John R. and Stevens, M. Henry H. and White, Jada-Simone S.},
  year = {2009},
  journal = {Trends in ecology \& evolution},
  volume = {24},
  number = {3},
  pages = {127--135},
  publisher = {Elsevier},
  urldate = {2024-03-11},
  file = {/Users/zenn/Zotero/storage/G9VCFADB/Bolker et al. - 2009 - Generalized linear mixed models a practical guide.pdf}
}

@article{bolkerGeneralizedLinearMixed2009a,
  title = {Generalized Linear Mixed Models for Ecologists and Evolutionary Biologists},
  author = {Bolker, Ben},
  year = {2009},
  urldate = {2024-03-11}
}

@article{bondi1999neuropsychological,
  title = {Neuropsychological Function and Apolipoprotein {{E}} Genotype in the Preclinical Detection of {{Alzheimer}}'s Disease.},
  author = {Bondi, Mark W and Salmon, David P and Galasko, Douglas and Thomas, Ronald G and Thal, Leon J},
  year = {1999},
  journal = {Psychology and aging},
  volume = {14},
  number = {2},
  pages = {295},
  publisher = {American Psychological Association}
}

@article{bonellPotentialRoleSociologists2018,
  title = {The Potential Role for Sociologists in Designing {{RCTs}} and of {{RCTs}} in Refining Sociological Theory: {{A}} Commentary on {{Deaton}} and {{Cartwright}}.},
  shorttitle = {The Potential Role for Sociologists in Designing {{RCTs}} and of {{RCTs}} in Refining Sociological Theory},
  author = {Bonell, Chris and {Melendez-Torres}, G. J. and Quilley, Stephen},
  year = {2018},
  journal = {Social science \& medicine (1982)},
  volume = {210},
  pages = {29--31},
  publisher = {Elsevier},
  file = {/Users/zenn/Zotero/storage/IUPKS9DI/Bonell et al. - 2018 - The potential role for sociologists in designing R.pdf}
}

@article{bonoReportQualityGeneralized2021,
  title = {Report {{Quality}} of {{Generalized Linear Mixed Models}} in {{Psychology}}: {{A Systematic Review}}},
  shorttitle = {Report {{Quality}} of {{Generalized Linear Mixed Models}} in {{Psychology}}},
  author = {Bono, Roser and Alarc{\'o}n, Rafael and Blanca, Mar{\'i}a J.},
  year = {2021},
  journal = {Frontiers in Psychology},
  volume = {12},
  issn = {1664-1078},
  urldate = {2023-07-21},
  abstract = {Generalized linear mixed models (GLMMs) estimate fixed and random effects and are especially useful when the dependent variable is binary, ordinal, count or quantitative but not normally distributed. They are also useful when the dependent variable involves repeated measures, since GLMMs can model autocorrelation. This study aimed to determine how and how often GLMMs are used in psychology and to summarize how the information about them is presented in published articles. Our focus in this respect was mainly on frequentist models. In order to review studies applying GLMMs in psychology we searched the Web of Science for articles published over the period 2014--2018. A total of 316 empirical articles were selected for trend study from 2014 to 2018. We then conducted a systematic review of 118 GLMM analyses from 80 empirical articles indexed in Journal Citation Reports during 2018 in order to evaluate report quality. Results showed that the use of GLMMs increased over time and that 86.4\% of articles were published in first- or second-quartile journals. Although GLMMs have, in recent years, been increasingly used in psychology, most of the important information about them was not stated in the majority of articles. Report quality needs to be improved in line with current recommendations for the use of GLMMs.},
  file = {/Users/zenn/Zotero/storage/3QK67BM2/Bono et al. - 2021 - Report Quality of Generalized Linear Mixed Models .pdf}
}

@article{bormSimpleSampleSize2007,
  title = {A Simple Sample Size Formula for Analysis of Covariance in Randomized Clinical Trials},
  author = {Borm, George F. and Fransen, Jaap and Lemmens, Wim A. J. G.},
  year = {2007},
  month = dec,
  journal = {Journal of Clinical Epidemiology},
  volume = {60},
  number = {12},
  pages = {1234--1238},
  issn = {0895-4356},
  doi = {10.1016/j.jclinepi.2007.02.006},
  urldate = {2023-12-23},
  abstract = {Objective Randomized clinical trials that compare two treatments on a continuous outcome can be analyzed using analysis of covariance (ANCOVA) or a t-test approach. We present a method for the sample size calculation when ANCOVA is used. Study Design and Setting We derived an approximate sample size formula. Simulations were used to verify the accuracy of the formula and to improve the approximation for small trials. The sample size calculations are illustrated in a clinical trial in rheumatoid arthritis. Results If the correlation between the outcome measured at baseline and at follow-up is {$\rho$}, ANCOVA comparing groups of (1-{$\rho$}2)n subjects has the same power as t-test comparing groups of n subjects. When on the same data, ANCOVA is used instead of t-test, the precision of the treatment estimate is increased, and the length of the confidence interval is reduced by a factor 1-{$\rho$}2. Conclusion ANCOVA may considerably reduce the number of patients required for a trial.},
  keywords = {Analysis of covariance,Clinical trial,Power,Precision,Sample size,Statistical test},
  file = {/Users/zenn/Zotero/storage/2IESND6V/S0895435607000613.html}
}

@misc{borowsky2019alzheimer,
  title = {The Alzheimer Prevention Initiative Generation Program: {{Evaluation}} of {{CNP520}} in Preclinical Alzheimer's Disease (P4. 1-005)},
  author = {Borowsky, Beth and Lopez, Cristina Lopez and Tariot, Pierre and Caputo, Angelika and Liu, Fonda and Riviere, Marie-Emmanuelle and {Rouzade-Dominguez}, Marie-Laure and Thomas, Ronald and Langbaum, Jessica and Viglietta, Vissia and others},
  year = {2019},
  publisher = {Wolters Kluwer Health, Inc. on behalf of the American Academy of Neurology}
}

@article{Borson2000,
  title = {The Mini-Cog: A Cognitive'vital Signs' Measure for Dementia Screening in Multi-Lingual Elderly.},
  author = {Borson, S and Scanlan, J and Brush, M},
  year = {2000},
  journal = {{\dots}  journal of geriatric  {\dots}},
  urldate = {2015-02-04},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/borson et al_2000_the mini-cog.pdf}
}

@article{boultonRemarkAlgorithm4341976,
  title = {Remark on ``{{Algorithm}} 434: {{Exact Probabilities}} for {{R}}{\textbackslash}times {{C Contingency Tables}} [{{G2}}]''},
  shorttitle = {Remark on ``{{Algorithm}} 434},
  author = {Boulton, D. M.},
  year = {1976},
  journal = {ACM Transactions on Mathematical Software (TOMS)},
  volume = {2},
  number = {1},
  pages = {108},
  publisher = {ACM New York, NY, USA}
}

@article{boxerDavunetidePatientsProgressive2014,
  title = {Davunetide in Patients with Progressive Supranuclear Palsy: A Randomised, Double-Blind, Placebo-Controlled Phase 2/3 Trial},
  shorttitle = {Davunetide in Patients with Progressive Supranuclear Palsy},
  author = {Boxer, Adam L and Lang, Anthony E and Grossman, Murray and Knopman, David S and Miller, Bruce L and Schneider, Lon S and Doody, Rachelle S and Lees, Andrew and Golbe, Lawrence I and Williams, David R and Corvol, Jean-Cristophe and Ludolph, Albert and Burn, David and Lorenzl, Stefan and Litvan, Irene and Roberson, Erik D and H{\"o}glinger, G{\"u}nter U and Koestler, Mary and Jack, Clifford R and Van Deerlin, Viviana and Randolph, Christopher and Lobach, Iryna V and Heuer, Hilary W and Gozes, Illana and Parker, Lesley and Whitaker, Steve and Hirman, Joe and Stewart, Alistair J and Gold, Michael and Morimoto, Bruce H},
  year = {2014},
  month = jul,
  journal = {The Lancet Neurology},
  volume = {13},
  number = {7},
  pages = {676--685},
  issn = {1474-4422},
  doi = {10.1016/S1474-4422(14)70088-2},
  urldate = {2024-04-23},
  abstract = {Background In preclinical studies, davunetide promoted microtubule stability and reduced tau phosphorylation. Because progressive supranuclear palsy (PSP) is linked to tau pathology, davunetide could be a treatment for PSP. We assessed the safety and efficacy of davunetide in patients with PSP. Methods In a double-blind, parallel group, phase 2/3 trial, participants were randomly assigned with permuted blocks in a 1:1 ratio to davunetide (30 mg twice daily, intranasally) or placebo for 52 weeks at 48 centres in Australia, Canada, France, Germany, the UK, and the USA. Participants met the modified Neuroprotection and Natural History in Parkinson Plus Syndrome study criteria for PSP. Primary endpoints were the change from baseline in PSP Rating Scale (PSPRS) and Schwab and England Activities of Daily Living (SEADL) scale at up to 52 weeks. All participants and study personnel were masked to treatment assignment. Analysis was by intention to treat. The trial is registered with Clinicaltrials.gov, number NCT01110720. Findings 313 participants were randomly assigned to davunetide (n=157) or to placebo (n=156), and 241 (77\%) completed the study (118 and 156 in the davunetide and placebo groups, respectively). There were no differences in the davunetide and placebo groups in the baseline PSPRS and SEADL. The davunetide and placebo groups did not differ in the change from baseline in PSPRS (median 11{$\cdot$}8 [95\% CI 10{$\cdot$}5 to 13{$\cdot$}0] vs 11{$\cdot$}8 [10{$\cdot$}5 to 13{$\cdot$}0], respectively, p=0{$\cdot$}41) or SEADL (-0{$\cdot$}20 [-0{$\cdot$}20 to -0{$\cdot$}17] vs -0{$\cdot$}20 [-0{$\cdot$}22 to -0{$\cdot$}17], respectively, p=0{$\cdot$}92). 54 serious adverse events were reported in each of the treatment groups, including 11 deaths in the davunetide group and ten in the placebo group. The frequency of nasal adverse events was greater in the davunetide group than in the placebo group (epistaxis 18 [12\%] of 156 vs 13 [8\%] of 156, rhinorrhoea 15 [10\%] vs eight [5\%], and nasal discomfort 15 [10\%] vs one [{$<$}1\%]). Interpretation Davunetide is not an effective treatment for PSP. Clinical trials of disease-modifying treatment are feasible in patients with PSP and should be pursued with other promising tau-directed treatments. Funding Allon Therapeutics.},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/boxer et al_2014_davunetide in patients with progressive supranuclear palsy.pdf;/Users/zenn/Zotero/storage/IRXJE7ZD/S1474442214700882.html}
}

@article{boxerNewDirectionsClinical2020,
  title = {New Directions in Clinical Trials for Frontotemporal Lobar Degeneration: {{Methods}} and Outcome Measures},
  shorttitle = {New Directions in Clinical Trials for Frontotemporal Lobar Degeneration},
  author = {Boxer, Adam L. and Gold, Michael and Feldman, Howard and Boeve, Bradley F. and Dickinson, Susan L.-J. and Fillit, Howard and Ho, Carole and Paul, Robert and Pearlman, Rodney and Sutherland, Margaret and Verma, Ajay and Arneric, Stephen P. and Alexander, Brian M. and Dickerson, Bradford C. and Dorsey, Earl Ray and Grossman, Murray and Huey, Edward D. and Irizarry, Michael C. and Marks, William J. and Masellis, Mario and McFarland, Frances and Niehoff, Debra and Onyike, Chiadi U. and Paganoni, Sabrina and Panzara, Michael A. and Rockwood, Kenneth and Rohrer, Jonathan D. and Rosen, Howard and Schuck, Robert N. and Soares, Holly D. and Tatton, Nadine},
  year = {2020},
  month = jan,
  journal = {Alzheimer's \& Dementia: The Journal of the Alzheimer's Association},
  volume = {16},
  number = {1},
  pages = {131--143},
  issn = {1552-5279},
  doi = {10.1016/j.jalz.2019.06.4956},
  abstract = {INTRODUCTION: Frontotemporal lobar degeneration (FTLD) is the most common form of dementia for those under 60~years of age. Increasing numbers of therapeutics targeting FTLD syndromes are being developed. METHODS: In March 2018, the Association for Frontotemporal Degeneration convened the Frontotemporal Degeneration Study Group meeting in Washington, DC, to discuss advances in the clinical science of FTLD. RESULTS: Challenges exist for conducting clinical trials in FTLD. Two of the greatest challenges are (1) the heterogeneity of FTLD syndromes leading to difficulties in efficiently measuring treatment effects and (2) the rarity of FTLD disorders leading to recruitment challenges. DISCUSSION: New personalized endpoints that are clinically meaningful to individuals and their families should be developed. Personalized approaches to analyzing MRI data, development of new fluid biomarkers and wearable technologies will help to improve the power to detect treatment effects in FTLD clinical trials and enable new, clinical trial designs, possibly leveraged from the experience of oncology trials. A computational visualization and analysis platform that can support novel analyses of combined clinical, genetic, imaging, biomarker data with other novel modalities will be critical to the success of these endeavors.},
  langid = {english},
  pmcid = {PMC6949386},
  pmid = {31668596},
  keywords = {ARTFL,Atrophy,Biomarker,Biomarkers,C9orf72,Clinical trial,Clinical Trials as Topic,Congresses as Topic,Frontotemporal dementia,Frontotemporal lobar degeneration,Frontotemporal Lobar Degeneration,FTD,FTLD,GRN,Humans,LEFFTDS,Magnetic Resonance Imaging,MAPT,Primary progressive aphasia,Progressive supranuclear palsy},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/boxer et al_2020_new directions in clinical trials for frontotemporal lobar degeneration.pdf}
}

@article{breimanStatisticalModelingTwo2001,
  title = {Statistical {{Modeling}}: {{The Two Cultures}} (with Comments and a Rejoinder by the Author)},
  shorttitle = {Statistical {{Modeling}}},
  author = {Breiman, Leo},
  year = {2001},
  month = aug,
  journal = {Statistical Science},
  volume = {16},
  number = {3},
  pages = {199--231},
  publisher = {Institute of Mathematical Statistics},
  issn = {0883-4237, 2168-8745},
  doi = {10.1214/ss/1009213726},
  urldate = {2024-05-20},
  abstract = {There are two cultures in the use of statistical modeling to reach conclusions from data. One assumes that the data are generated by a given stochastic data model. The other uses algorithmic models and treats the data mechanism as unknown. The statistical community has been committed to the almost exclusive use of data models. This commitment has led to irrelevant theory, questionable conclusions, and has kept statisticians from working on a large range of interesting current problems. Algorithmic modeling, both in theory and practice, has developed rapidly in fields outside statistics. It can be used both on large complex data sets and as a more accurate and informative alternative to data modeling on smaller data sets. If our goal as a field is to use data to solve problems, then we need to move away from exclusive dependence on data models and adopt a more diverse set of tools.},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/breiman_2001_statistical modeling.pdf}
}

@article{bretzGraphicalApproachSequentially2009,
  title = {A Graphical Approach to Sequentially Rejective Multiple Test Procedures},
  author = {Bretz, Frank and Maurer, Willi and Brannath, Werner and Posch, Martin},
  year = {2009},
  month = feb,
  journal = {Statistics in Medicine},
  volume = {28},
  number = {4},
  pages = {586--604},
  issn = {02776715},
  doi = {10.1002/sim.3495},
  urldate = {2018-09-01},
  abstract = {For clinical trials with multiple treatment arms or endpoints a variety of sequentially rejective, weighted Bonferroni-type tests have been proposed, such as gatekeeping procedures, fixed sequence tests, and fallback procedures. They allow to map the difference in importance as well as the relationship between the various research questions onto an adequate multiple test procedure. Since these procedures rely on the closed test principle, they usually require the explicit specification of a large number of intersection hypotheses tests. The underlying test strategy may therefore be difficult to communicate. We propose a simple iterative graphical approach to construct and perform such Bonferroni-type tests. The resulting multiple test procedures are represented by directed, weighted graphs, where each node corresponds to an elementary hypothesis, together with a simple algorithm to generate such graphs while sequentially testing the individual hypotheses. The approach is illustrated with the visualization of several common gatekeeping strategies. A case study is used to illustrate how the methods from this article can be used to tailor a multiple test procedure to given study objectives.},
  arxiv = {NIHMS150003},
  isbn = {0277-6715 (Print){\textbackslash}n0277-6715 (Linking)},
  pmid = {19051220},
  keywords = {Adjusted p-values,Bonferroni,Closure principle,Gatekeeping procedures,Multiple comparison procedures,Shortcut procedures,Simultaneous confidence intervals},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/bretz et al_2009_a graphical approach to sequentially rejective multiple test procedures.pdf}
}

@article{brody1999age,
  title = {Age-Related Macular Degeneration: A Randomized Clinical Trial of a Self-Management Intervention},
  author = {Brody, Barbara L and Williams, Rebecca A and Thomas, Ronald G and Kaplan, Robert M and Chu, Ray M and Brown, Stuart I},
  year = {1999},
  journal = {Annals of Behavioral Medicine},
  volume = {21},
  number = {4},
  pages = {322--329},
  publisher = {Springer-Verlag}
}

@article{brody2003self,
  title = {Self-Management of Age-Related Macular Degeneration and Quality of Life at 6 Months Follow-up: {{A}} Randomized Controlled Trial},
  author = {Brody, {\relax BL} and {Roch-Levecq}, {\relax AC} and Thomas, {\relax RG} and Maclean, {\relax KK} and Kaplan, {\relax RM} and Brown, {\relax SI}},
  year = {2003},
  journal = {Investigative Ophthalmology \& Visual Science},
  volume = {44},
  number = {13},
  pages = {1834--1834},
  publisher = {{The Association for Research in Vision and Ophthalmology}}
}

@article{brody2005self,
  title = {Self-Management of Age-Related Macular Degeneration at the 6-Month Follow-up: A Randomized Controlled Trial},
  author = {Brody, Barbara L and {Roch-Levecq}, Anne-Catherine and Thomas, Ronald G and Kaplan, Robert M and Brown, Stuart I},
  year = {2005},
  journal = {Archives of Ophthalmology},
  volume = {123},
  number = {1},
  pages = {46--53},
  publisher = {American Medical Association}
}

@article{broganComparativeAnalysesPretestposttest1980,
  title = {Comparative Analyses of Pretest-Posttest Research Designs},
  author = {Brogan, Donna R. and Kutner, Michael H.},
  year = {1980},
  journal = {The American Statistician},
  volume = {34},
  number = {4},
  pages = {229--232},
  publisher = {Taylor \& Francis},
  file = {/Users/zenn/Zotero/storage/PS3IIYA8/Brogan and Kutner - 1980 - Comparative analyses of pretest-posttest research .pdf;/Users/zenn/Zotero/storage/TUI2JMB2/00031305.1980.html}
}

@article{broganComparativeAnalysesPretestposttest1980a,
  title = {Comparative Analyses of Pretest-Posttest Research Designs},
  author = {Brogan, Donna R. and Kutner, Michael H.},
  year = {1980},
  journal = {American Statistician},
  eprint = {2684066},
  eprinttype = {jstor},
  pages = {229--232},
  publisher = {JSTOR},
  urldate = {2023-12-23},
  file = {/Users/zenn/Zotero/storage/M89T9Y5F/Brogan and Kutner - 1980 - Comparative analyses of pretest-posttest research .pdf}
}

@article{broganComparativeAnalysesPretestPosttest1980b,
  title = {Comparative {{Analyses}} of {{Pretest-Posttest Research Designs}}},
  author = {Brogan, Donna R. and Kutner, Michael H.},
  year = {1980},
  month = nov,
  journal = {The American Statistician},
  volume = {34},
  number = {4},
  pages = {229--232},
  issn = {0003-1305, 1537-2731},
  doi = {10.1080/00031305.1980.10483034},
  urldate = {2024-03-14},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/US8NLCC9/00031305.1980.pdf}
}

@article{brooksImagingDopamineTransporters2010,
  title = {Imaging Dopamine Transporters in {{Parkinson}}'s Disease},
  author = {Brooks, David J.},
  year = {2010},
  month = oct,
  journal = {Biomarkers in Medicine},
  volume = {4},
  number = {5},
  pages = {651--660},
  issn = {1752-0371},
  doi = {10.2217/bmm.10.86},
  abstract = {The dopamine transporter (DAT) is responsible for clearance of dopamine from the synaptic cleft after its release. Imaging DAT availability provides a measure of dopamine terminal function and a method for detecting striatal dopamine deficiency states present in idiopathic Parkinson's disease and atypical neurodegenerative Parkinsonian disorders such as multiple system atrophy and progressive supranuclear palsy. DAT imaging with PET or single photon emission computed tomography can be used to support a diagnosis of dopamine-deficient parkinsonism in cases where this is suspected and rationalize the use of dopaminergic agents as therapy. It can also detect subclinical dopaminergic dysfunction when present in subjects at risk of Parkinson's disease, such as relatives of patients, susceptibility gene mutation carriers, and subjects with late-onset hyposmia or sleep disorders. Finally, the presence of normal DAT availability on imaging can help exclude nondopamine-deficient syndromes, such as dystonic and severe essential tremors, drug-induced and psychogenic parkinsonism that, on occasion, mimic Parkinson's disease.},
  langid = {english},
  pmid = {20945978},
  keywords = {Clinical Trials as Topic,Contrast Media,Dopamine Plasma Membrane Transport Proteins,Humans,Parkinson Disease,Positron-Emission Tomography,Radiopharmaceuticals,Tomography Emission-Computed Single-Photon,Tropanes,Vesicular Monoamine Transport Proteins}
}

@article{bryanExcuseMeYou2018,
  title = {Excuse {{Me}}, {{Do You Have}} a {{Moment}} to {{Talk About Version Control}}?},
  author = {Bryan, Jennifer},
  year = {2018},
  month = jan,
  journal = {The American Statistician},
  volume = {72},
  number = {1},
  pages = {20--27},
  publisher = {Taylor \& Francis},
  issn = {0003-1305},
  doi = {10.1080/00031305.2017.1399928},
  urldate = {2024-02-06},
  abstract = {Data analysis, statistical research, and teaching statistics have at least one thing in common: these activities all produce many files! There are data files, source code, figures, tables, prepared reports, and much more. Most of these files evolve over the course of a project and often need to be shared with others, for reading or edits, as a project unfolds. Without explicit and structured management, project organization can easily descend into chaos, taking time away from the primary work and reducing the quality of the final product. This unhappy result can be avoided by repurposing tools and workflows from the software development world, namely, distributed version control. This article describes the use of the version control system Git and the hosting site GitHub for statistical and data scientific workflows. Special attention is given to projects that use the statistical language R and, optionally, R Markdown documents. Supplementary materials include an annotated set of links to step-by-step tutorials, real world examples, and other useful learning resources. Supplementary materials for this article are available online.},
  keywords = {Data science,Git,GitHub,R language R Markdown,Reproducibility,Workflow},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/bryan_2018_excuse me, do you have a moment to talk about version control.pdf}
}

@article{bryanExcuseMeYou2018a,
  title = {Excuse {{Me}}, {{Do You Have}} a {{Moment}} to {{Talk About Version Control}}?},
  author = {Bryan, Jennifer},
  year = {2018},
  month = jan,
  journal = {The American Statistician},
  volume = {72},
  number = {1},
  pages = {20--27},
  publisher = {Taylor \& Francis},
  issn = {0003-1305},
  doi = {10.1080/00031305.2017.1399928},
  urldate = {2024-02-01},
  abstract = {Data analysis, statistical research, and teaching statistics have at least one thing in common: these activities all produce many files! There are data files, source code, figures, tables, prepared reports, and much more. Most of these files evolve over the course of a project and often need to be shared with others, for reading or edits, as a project unfolds. Without explicit and structured management, project organization can easily descend into chaos, taking time away from the primary work and reducing the quality of the final product. This unhappy result can be avoided by repurposing tools and workflows from the software development world, namely, distributed version control. This article describes the use of the version control system Git and the hosting site GitHub for statistical and data scientific workflows. Special attention is given to projects that use the statistical language R and, optionally, R Markdown documents. Supplementary materials include an annotated set of links to step-by-step tutorials, real world examples, and other useful learning resources. Supplementary materials for this article are available online.},
  keywords = {Data science,Git,GitHub,R language R Markdown,Reproducibility,Workflow},
  file = {/Users/zenn/Zotero/storage/JI2E2T73/Bryan - 2018 - Excuse Me, Do You Have a Moment to Talk About Vers.pdf}
}

@article{brysbaertPowerAnalysisEffect,
  title = {Power {{Analysis}} and {{Effect Size}} in {{Mixed Effects Models}}: {{A Tutorial}}},
  shorttitle = {Power {{Analysis}} and {{Effect Size}} in {{Mixed Effects Models}}},
  author = {Brysbaert, Marc and Stevens, Micha{\"e}l},
  journal = {Journal of Cognition},
  volume = {1},
  number = {1},
  pages = {9},
  issn = {2514-4820},
  doi = {10.5334/joc.10},
  urldate = {2023-07-10},
  abstract = {In psychology, attempts to replicate published findings are less successful than expected. For properly powered studies replication rate should be around 80\%, whereas in practice less than 40\% of the studies selected from different areas of psychology can be replicated. Researchers in cognitive psychology are hindered in estimating the power of their studies, because the designs they use present a sample of stimulus materials to a sample of participants, a situation not covered by most power formulas. To remedy the situation, we review the literature related to the topic and introduce recent software packages, which we apply to the data of two masked priming studies with high power. We checked how we could estimate the power of each study and how much they could be reduced to remain powerful enough. On the basis of this analysis, we recommend that a properly powered reaction time experiment with repeated measures has at least 1,600 word observations per condition (e.g., 40 participants, 40 stimuli). This is considerably more than current practice. We also show that researchers must include the number of observations in meta-analyses because the effect sizes currently reported depend on the number of stimuli presented to the participants. Our analyses can easily be applied to new datasets gathered.},
  pmcid = {PMC6646942},
  pmid = {31517183},
  file = {/Users/zenn/Zotero/storage/4BMN3CFV/Brysbaert and Stevens - Power Analysis and Effect Size in Mixed Effects Mo.pdf}
}

@article{brysbaertPowerAnalysisEffect2018,
  title = {Power Analysis and Effect Size in Mixed Effects Models: {{A}} Tutorial},
  shorttitle = {Power Analysis and Effect Size in Mixed Effects Models},
  author = {Brysbaert, Marc and Stevens, Micha{\"e}l},
  year = {2018},
  journal = {Journal of cognition},
  volume = {1},
  number = {1},
  publisher = {Ubiquity Press},
  urldate = {2024-03-11},
  file = {/Users/zenn/Zotero/storage/7CRUJBNT/PMC6646942.html}
}

@article{brysbaertPowerAnalysisEffect2018a,
  title = {Power {{Analysis}} and {{Effect Size}} in {{Mixed Effects Models}}: {{A Tutorial}}},
  shorttitle = {Power {{Analysis}} and {{Effect Size}} in {{Mixed Effects Models}}},
  author = {Brysbaert, Marc and Stevens, Micha{\"e}l},
  year = {2018},
  month = jan,
  journal = {Journal of Cognition},
  volume = {1},
  number = {1},
  pages = {9},
  issn = {2514-4820},
  doi = {10.5334/joc.10},
  urldate = {2024-03-11},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/V47NXITK/Brysbaert and Stevens - 2018 - Power Analysis and Effect Size in Mixed Effects Mo.pdf}
}

@article{brysbaertPowerAnalysisEffect2018b,
  title = {Power {{Analysis}} and {{Effect Size}} in {{Mixed Effects Models}}: {{A Tutorial}}},
  shorttitle = {Power {{Analysis}} and {{Effect Size}} in {{Mixed Effects Models}}},
  author = {Brysbaert, Marc and Stevens, Micha{\"e}l},
  year = {2018},
  month = jan,
  journal = {Journal of Cognition},
  volume = {1},
  number = {1},
  pages = {9},
  issn = {2514-4820},
  doi = {10.5334/joc.10},
  urldate = {2024-03-11},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/CJM5WWNB/PM R - 2010 - Sainani - Making Sense of Intention‐to‐Treat-1.pdf;/Users/zenn/Zotero/storage/GCASDQA6/Ferguson_ITT_BMJ2002.pdf;/Users/zenn/Zotero/storage/ZT9Z7XYQ/Brysbaert and Stevens - 2018 - Power Analysis and Effect Size in Mixed Effects Mo.pdf}
}

@article{bucklesDifferentRatesCognitive2021,
  title = {Different Rates of Cognitive Decline in Autosomal Dominant and Late-Onset {{Alzheimer}} Disease},
  author = {Buckles, Virginia D. and Xiong, Chengjie and Bateman, Randall J. and Hassenstab, Jason and Allegri, Ricardo and Berman, Sarah B. and Chhatwal, Jasmeer P. and Danek, Adrian and Fagan, Anne M. and Ghetti, Bernardino and Goate, Alison and {Graff-Radford}, Neill and Jucker, Mathias and Levin, Johannes and Marcus, Daniel S. and Masters, Colin L. and McCue, Lena and McDade, Eric and Mori, Hiroshi and Moulder, Krista L. and Noble, James M. and Paumier, Katrina and Preische, Oliver and Ringman, John M. and Fox, Nick C. and Salloway, Stephen and Schofield, Peter R. and Martins, Ralph and V{\"o}glein, Jonathan and Morris, John C.},
  year = {2021},
  month = dec,
  journal = {Alzheimer's \& Dementia},
  publisher = {John Wiley \& Sons, Ltd},
  issn = {1552-5279},
  doi = {10.1002/ALZ.12505},
  urldate = {2021-12-07},
  keywords = {Alzheimer disease,autosomal dominant Alzheimer disease,cognitive,comorbidities,late,onset Alzheimer disease},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/buckles et al_2021_different rates of cognitive decline in autosomal dominant and late-onset.pdf}
}

@article{buczakAnalyzingEffectImputation2023,
  title = {Analyzing the {{Effect}} of {{Imputation}} on {{Classification Performance}} under {{MCAR}} and {{MAR Missing Mechanisms}}},
  author = {Buczak, Philip and Chen, Jian-Jia and Pauly, Markus},
  year = {2023},
  month = mar,
  journal = {Entropy},
  volume = {25},
  number = {3},
  pages = {521},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {1099-4300},
  doi = {10.3390/e25030521},
  urldate = {2023-04-15},
  abstract = {Many datasets in statistical analyses contain missing values. As omitting observations containing missing entries may lead to information loss or greatly reduce the sample size, imputation is usually preferable. However, imputation can also introduce bias and impact the quality and validity of subsequent analysis. Focusing on binary classification problems, we analyzed how missing value imputation under MCAR as well as MAR missingness with different missing patterns affects the predictive performance of subsequent classification. To this end, we compared imputation methods such as several MICE variants, missForest, Hot Deck as well as mean imputation with regard to the classification performance achieved with commonly used classifiers such as Random Forest, Extreme Gradient Boosting, Support Vector Machine and regularized logistic regression. Our simulation results showed that Random Forest based imputation (i.e., MICE Random Forest and missForest) performed particularly well in most scenarios studied. In addition to these two methods, simple mean imputation also proved to be useful, especially when many features (covariates) contained missing values.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {classification,imputation,machine learning,MICE,missForest,missing values},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/buczak et al_2023_analyzing the effect of imputation on classification performance under mcar and.pdf}
}

@article{burstein2013p1,
  title = {P1--332: {{Evaluation}} of the Relationship between {{TTP488}} Plasma Concentrations and Changes in {{ADAS-cog}} Relative to Placebo},
  author = {Burstein, Aaron and Galasko, Douglas and Aisen, Paul and Thomas, Ronald and Grimes, Imogene and Clark, David J and Mjalli, Adnan and Orlande, Cesare},
  year = {2013},
  journal = {Alzheimer's \& Dementia},
  volume = {9},
  pages = {P279--P280}
}

@article{buyseLimitationsAdaptiveClinical2012,
  title = {Limitations of {{Adaptive Clinical Trials}}},
  author = {Buyse, Marc},
  year = {2012},
  month = jun,
  journal = {American Society of Clinical Oncology Educational Book},
  number = {32},
  pages = {133--137},
  issn = {1548-8748, 1548-8756},
  doi = {10.14694/EdBook_AM.2012.32.13},
  urldate = {2024-01-12},
  abstract = {Overview:               Adaptive designs are aimed at introducing flexibility in clinical research by allowing important characteristics of a trial to be adapted during the course of the trial based on data coming from the trial itself. Adaptive designs can be used in all phases of clinical research, from phase I to phase III. They tend to be especially useful in early development, when the paucity of prior data makes their flexibility a key benefit. The need for adaptive designs lessened as new treatments progress to later phases of development, when emphasis shifts to confirmation of hypotheses using fully prespecified, well-controlled designs.},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/buyse_2012_limitations of adaptive clinical trials.pdf}
}

@article{caiInitialLevelsVamyloid2023,
  title = {Initial Levels of {$\beta$}-Amyloid and Tau Deposition Have Distinct Effects on Longitudinal Tau Accumulation in {{Alzheimer}}'s Disease},
  author = {Cai, Yue and Du, Jing and Li, Anqi and Zhu, Yalin and Xu, Linsen and Sun, Kun and Ma, Shaohua and Guo, Tengfei and {for the Alzheimer's Disease Neuroimaging Initiative}},
  year = {2023},
  month = feb,
  journal = {Alzheimer's Research \& Therapy},
  volume = {15},
  number = {1},
  pages = {30},
  issn = {1758-9193},
  doi = {10.1186/s13195-023-01178-w},
  urldate = {2023-02-13},
  abstract = {To better assist with the design of future clinical trials for Alzheimer's disease (AD) and aid in our understanding of the disease's symptomatology, it is essential to clarify what roles {$\beta$}-amyloid (A{$\beta$}) plaques and tau tangles play in longitudinal tau accumulation inside and outside the medial temporal lobe (MTL) as well as how age, sex, apolipoprotein E (APOE) {$\varepsilon$}4 (APOE-{$\varepsilon$}4), and Klotho-VS heterozygosity (KL-VShet) modulate these relationships.},
  keywords = {-Amyloid,Alzheimer's disease,Longitudinal,PET imaging,Tau},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/cai et al_2023_initial levels of β-amyloid and tau deposition have distinct effects on.pdf;/Users/zenn/Zotero/storage/8EFJ6VBR/s13195-023-01178-w.html}
}

@article{callegaroInferenceCovariateadaptiveRandomization2021,
  title = {Inference under Covariate-Adaptive Randomization: {{A}} Simulation Study},
  shorttitle = {Inference under Covariate-Adaptive Randomization},
  author = {Callegaro, Andrea and Harsha Shree, B S and Karkada, Naveen},
  year = {2021},
  month = apr,
  journal = {Statistical Methods in Medical Research},
  volume = {30},
  number = {4},
  pages = {1072--1080},
  issn = {0962-2802, 1477-0334},
  doi = {10.1177/0962280220985564},
  urldate = {2023-12-15},
  abstract = {In clinical trials, several covariate-adaptive designs have been proposed to balance treatment arms with respect to key covariates. Although some argue that conventional asymptotic tests are still appropriate when covariate-adaptive randomization is used, others think that re-randomization tests should be used. In this manuscript, we compare by simulation the performance of asymptotic and re-randomization tests under covariate-adaptive randomization. Our simulation study confirms results expected by the existing theory (e.g. asymptotic tests do not control type I error when the model is miss-specified). Furthermore, it shows that (i) re-randomization tests are as powerful as the asymptotic tests if the model is correct; (ii) re-randomization tests are more powerful when adjusting for covariates; (iii) minimization and permuted blocks provide similar results.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/2HAPJP8V/0962280220985564.html}
}

@article{campbellChisquaredFisherIrwin2007,
  title = {Chi-Squared and {{Fisher}}--{{Irwin}} Tests of Two-by-Two Tables with Small Sample Recommendations},
  author = {Campbell, Ian},
  year = {2007},
  journal = {Statistics in Medicine},
  volume = {26},
  number = {19},
  pages = {3661--3675},
  issn = {1097-0258},
  doi = {10.1002/sim.2832},
  urldate = {2023-07-30},
  abstract = {Two-by-two tables commonly arise in comparative trials and cross-sectional studies. In medical studies, two-by-two tables may have a small sample size due to the rarity of a condition, or to limited resources. Current recommendations on the appropriate statistical test mostly specify the chi-squared test for tables where the minimum expected number is at least 5 (following Fisher and Cochran), and otherwise the Fisher--Irwin test; but there is disagreement on which versions of the chi-squared and Fisher--Irwin tests should be used. A further uncertainty is that, according to Cochran, the number 5 was chosen arbitrarily. Computer-intensive techniques were used in this study to compare seven two-sided tests of two-by-two tables in terms of their Type I errors. The tests were K. Pearson's and Yates's chi-squared tests and the `N-1' chi-squared test (first proposed by E. Pearson), together with four versions of the Fisher--Irwin test (including two mid-P versions). The optimum test policy was found to be analysis by the `N-1' chi-squared test when the minimum expected number is at least 1, and otherwise, by the Fisher--Irwin test by Irwin's rule (taking the total probability of tables in either tail that are as likely as, or less likely than the one observed). This policy was found to have increased power compared to Cochran's recommendations. Copyright {\copyright} 2007 John Wiley \& Sons, Ltd.},
  copyright = {Copyright {\copyright} 2007 John Wiley \& Sons, Ltd.},
  langid = {english},
  keywords = {chi-squared test,Fisher-Irwin test,power,small sample recommendations,two-by-two tables},
  file = {/Users/zenn/Zotero/storage/BWX9NLQQ/Campbell - 2007 - Chi-squared and Fisher–Irwin tests of two-by-two t.pdf;/Users/zenn/Zotero/storage/YZCYZ3V8/sim.html}
}

@article{candelBestOftForgotten2023,
  title = {Best (but Oft Forgotten) Practices: {{Efficient}} Sample Sizes for Commonly Used Trial Designs},
  shorttitle = {Best (but Oft Forgotten) Practices},
  author = {Candel, Math J.J.M. and Van Breukelen, Gerard J.P.},
  year = {2023},
  month = jun,
  journal = {The American Journal of Clinical Nutrition},
  volume = {117},
  number = {6},
  pages = {1063--1085},
  issn = {00029165},
  doi = {10.1016/j.ajcnut.2023.02.013},
  urldate = {2023-08-02},
  abstract = {Designing studies such that they have a high level of power to detect an effect or association of interest is an important tool to improve the quality and reproducibility of findings from such studies. Since resources (research subjects, time, and money) are scarce, it is important to obtain sufficient power with minimum use of such resources. For commonly used randomized trials of the treatment effect on a continuous outcome, designs are presented that minimize the number of subjects or the amount of research budget when aiming for a desired power level. This concerns the optimal allocation of subjects to treatments and, in case of nested designs such as cluster-randomized trials and multicenter trials, also the optimal number of centers versus the number of persons per center. Since such optimal designs require knowledge of parameters of the analysis model that are not known in the design stage, in particular outcome variances, maximin designs are presented. These designs guarantee a prespecified power level for plausible ranges of the unknown parameters and minimize research costs for the worst-case values of these parameters. The focus is on a 2-group parallel design, the AB/BA crossover design, and cluster-randomized and multicenter trials with a continuous outcome. How to calculate sample sizes for maximin designs is illustrated for examples from nutrition. Several computer programs that are helpful in calculating sample sizes for optimal and maximin designs are discussed as well as some results on optimal designs for other types of outcomes.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/PUMT9RZU/Candel and Van Breukelen - 2023 - Best (but oft forgotten) practices Efficient samp.pdf}
}

@article{cano2009o4,
  title = {O4-04-07: {{The ADAS-cog}}'s Performance as a Measure---Lessons from the {{ADNI}} Study: {{Part}} 2-Evaluation Using Modern Psychometric Methods},
  author = {Cano, Stefan and Posner, Holly and Aisen, Paul and Selnes, Ola and Stern, Yaakov and Thomas, Ronald and Weiner, Michael and Zajicek, John and Zeger, Scott and Hobart, Jeremy},
  year = {2009},
  journal = {Alzheimer's \& Dementia},
  volume = {5},
  number = {4S\_Part\_5},
  pages = {P158--P158}
}

@article{caoLastObservationCarried2016,
  title = {On Last Observation Carried Forward and Asynchronous Longitudinal Regression Analysis},
  author = {Cao, Hongyuan and Li, Jialiang and Fine, Jason P.},
  year = {2016},
  month = jan,
  journal = {Electronic Journal of Statistics},
  volume = {10},
  number = {1},
  pages = {1155--1180},
  publisher = {{Institute of Mathematical Statistics and Bernoulli Society}},
  issn = {1935-7524, 1935-7524},
  doi = {10.1214/16-EJS1141},
  urldate = {2024-07-10},
  abstract = {In many longitudinal studies, the covariates and response are often intermittently observed at irregular, mismatched and subject-specific times. Last observation carried forward (LOCF) is one of the most commonly used methods to deal with such data when covariates and response are observed asynchronously. However, this can lead to considerable bias. In this paper, we propose a weighted LOCF estimation using asynchronous longitudinal data for the generalized linear model. We further generalize this approach to utilize previously observed covariates in addition to the most recent observation. In comparison to earlier methods, the current methods are valid under weaker assumptions on the covariate process and allow informative observation times which may depend on response even conditional on covariates. Extensive simulation studies provide numerical support for the theoretical findings. Data from an HIV study is used to illustrate our methodology.},
  keywords = {60G05,60G20,Asynchronous longitudinal data,Kernel weighted estimation,last observation carried forward,Nonparametric regression},
  file = {/Users/zenn/Zotero/storage/88PLDL2C/Cao et al. - 2016 - On last observation carried forward and asynchrono.pdf}
}

@article{caoRegressionAnalysisSparse2015,
  title = {Regression {{Analysis}} of {{Sparse Asynchronous Longitudinal Data}}},
  author = {Cao, Hongyuan and Zeng, Donglin and Fine, Jason P.},
  year = {2015},
  month = sep,
  journal = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  volume = {77},
  number = {4},
  pages = {755--776},
  issn = {1369-7412},
  doi = {10.1111/rssb.12086},
  urldate = {2024-07-10},
  abstract = {We consider estimation of regression models for sparse asynchronous longitudinal observations, where time-dependent responses and covariates are observed intermittently within subjects. Unlike with synchronous data, where the response and covariates are observed at the same time point, with asynchronous data, the observation times are mismatched. Simple kernel-weighted estimating equations are proposed for generalized linear models with either time invariant or time-dependent coefficients under smoothness assumptions for the covariate processes which are similar to those for synchronous data. For models with either time invariant or time-dependent coefficients, the estimators are consistent and asymptotically normal but converge at slower rates than those achieved with synchronous data. Simulation studies evidence that the methods perform well with realistic sample sizes and may be superior to a naive application of methods for synchronous data based on an ad hoc last value carried forward approach. The practical utility of the methods is illustrated on data from a study on human immunodeficiency virus.},
  file = {/Users/zenn/Zotero/storage/GQTAIGA6/Cao et al. - 2015 - Regression Analysis of Sparse Asynchronous Longitu.pdf;/Users/zenn/Zotero/storage/N3W95TQE/7040614.html}
}

@article{caputo2017o5,
  title = {[{{O5}}--01--02]: {{RATIONALE FOR SELECTION OF PRIMARY ENDPOINTS IN THE ALZHEIMER PREVENTION INITIATIVE GENERATION STUDY IN COGNITIVELY HEALTHY APOE4 HOMOZYGOTES}}},
  author = {Caputo, Angelika and Racine, Amy and Paule, Ines and Martens, Edwin P and Tariot, Pierre and Langbaum, Jessica B and Thomas, Ronald G and Hendrix, Suzanne and Ryan, J Michael and {Lopez-Lopez}, Cristina and others},
  year = {2017},
  journal = {Alzheimer's \& Dementia},
  volume = {13},
  number = {7S\_Part\_30},
  pages = {P1452--P1452},
  publisher = {The Alzheimer's Association, Inc.}
}

@article{carriereMethodologicalConsiderationsNof12015,
  title = {Methodological {{Considerations}} for {{N-of-1 Trials}}},
  author = {Carriere, Keumhee C. and Li, Yin and Mitchell, Geoffrey and Senior, Hugh},
  year = {2015},
  journal = {The Essential Guide to N-of-1 Trials in Health},
  pages = {67--80},
  publisher = {Springer Netherlands},
  doi = {10.1007/978-94-017-7200-6_6},
  urldate = {2021-11-06},
  abstract = {N-of-1 trials are extremely useful in subject-focused investigations, for example, medical experiments. As far as we are aware, no guidelines are available in the literature on how to plan such a trial optimally. In this chapter, we discuss the considerations when choosing a particular N-of-1 trial design. We assume that the outcome of interest is measured on a continuous scale. Our discussion will be limited to comparisons of two treatments, without implying that the designs constructed can apply to noncontinuous or binary outcomes. We construct optimal N-of-1 trials under various models depending upon how we accommodate the carryover effects and the error structures for the repeated measurements. Overall, we conclude that alternating between AB and BA pairs in subsequent cycles will result in practically optimal N-of-1 trials for a single patient, under all the models we considered without the need to guess at the correlation structure or conduct a pilot study. Alternating between AB and BA pairs in a single trial is nearly robust to misspecification of the error structure of the repeated measurements. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/carriere et al_2015_methodological considerations for n-of-1 trials.pdf}
}

@misc{casulliTensorizedBlockRational2023,
  title = {Tensorized Block Rational {{Krylov}} Methods for Tensor {{Sylvester}} Equations},
  author = {Casulli, Angelo Alberto},
  year = {2023},
  month = jun,
  number = {arXiv:2306.00705},
  eprint = {2306.00705},
  primaryclass = {cs, math},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2306.00705},
  urldate = {2023-06-04},
  abstract = {We introduce the definition of tensorized block rational Krylov subspaces and its relation with multivariate rational functions, extending the formulation of tensorized Krylov subspaces introduced in [Kressner D., Tobler C., Krylov subspace methods for linear systems with tensor product structure, SIMAX, 2010]. Moreover, we develop methods for the solution of tensor Sylvester equations with low multilinear or Tensor Train rank, based on projection onto a tensor block rational Krylov subspace. We provide a convergence analysis, some strategies for pole selection, and techniques to efficiently compute the residual.},
  archiveprefix = {arXiv},
  keywords = {Mathematics - Numerical Analysis},
  file = {/Users/zenn/Zotero/storage/WAPEDBSI/Casulli - 2023 - Tensorized block rational Krylov methods for tenso.pdf;/Users/zenn/Zotero/storage/J652UFGJ/2306.html}
}

@article{chadhaACCELERATEDOPTIMALPARALLEL,
  title = {{{ACCELERATED}}, {{OPTIMAL}}, {{AND PARALLEL}}: {{SOME RESULTS ON MODEL-BASED STOCHASTIC OPTIMIZATION}}},
  author = {Chadha, Karan and Cheng, Gary and Duchi, John C},
  pages = {24},
  abstract = {We extend the Approximate-Proximal Point (aProx) family of model-based methods for solving stochastic convex optimization problems, including stochastic subgradient, proximal point, and bundle methods, to the minibatch and accelerated setting. To do so, we propose specific model-based algorithms and an acceleration scheme for which we provide non-asymptotic convergence guarantees, which are order-optimal in all problem-dependent constants and provide linear speedup in minibatch size, while maintaining the desirable robustness traits (e.g. to stepsize) of the aProx family. Additionally, we show improved convergence rates and matching lower bounds identifying new fundamental constants for ``interpolation'' problems, whose importance in statistical machine learning is growing; this, for example, gives a parallelization strategy for alternating projections. We corroborate our theoretical results with empirical testing to demonstrate the gains accurate modeling, acceleration, and minibatching provide.},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/chadha et al_accelerated, optimal, and parallel.pdf}
}

@article{chambers1999weight,
  title = {Weight Gain in Infants Breastfed by Mothers Who Take Fluoxetine},
  author = {Chambers, Christina D and Anderson, Philip O and Thomas, Ronald G and Dick, Lyn M and Felix, Robert J and Johnson, Kathleen A and Jones, Kenneth Lyons},
  year = {1999},
  journal = {Pediatrics},
  volume = {104},
  number = {5},
  pages = {e61--e61},
  publisher = {American Academy of Pediatrics}
}

@article{chambersDataScience2020,
  title = {S, {{R}}, and Data Science},
  author = {Chambers, John M.},
  year = {2020},
  month = jun,
  journal = {Proceedings of the ACM on Programming Languages},
  volume = {4},
  number = {HOPL},
  pages = {84:1--84:17},
  doi = {10.1145/3386334},
  urldate = {2024-05-20},
  abstract = {Data science is increasingly important and challenging. It requires computational tools and programming environments that handle big data and difficult computations, while supporting creative, high-quality analysis. The R language and related software play a major role in computing for data science. R is featured in most programs for training in the field. R packages provide tools for a wide range of purposes and users. The description of a new technique, particularly from research in statistics, is frequently accompanied by an R package, greatly increasing the usefulness of the description. The history of R makes clear its connection to data science. R was consciously designed to replicate in open-source software the contents of the S software. S in turn was written by data analysis researchers at Bell Labs as part of the computing environment for research in data analysis and collaborations to apply that research, rather than as a separate project to create a programming language. The features of S and the design decisions made for it need to be understood in this broader context of supporting effective data analysis (which would now be called data science). These characteristics were all transferred to R and remain central to its effectiveness. Thus, R can be viewed as based historically on a domain-specific language for the domain of data science.},
  keywords = {data science,scientific computing,statistical computing},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/chambers_2020_s, r, and data science.pdf}
}

@book{chambersExtending2016,
  title = {Extending {{R}}},
  author = {Chambers, John M.},
  year = {2016},
  month = jul,
  publisher = {{Chapman and Hall/CRC}},
  address = {New York},
  doi = {10.1201/9781315381305},
  abstract = {Up-to-Date Guidance from One of the Foremost Members of the R Core Team Written by John M. Chambers, the leading developer of the original S software, Extending R covers key concepts and techniques in R to support analysis and research projects. It presents the core ideas of R, provides programming guidance for projects of all scales, and introduces new, valuable techniques that extend R. The book first describes the fundamental characteristics and background of R, giving readers a foundation for the remainder of the text. It next discusses topics relevant to programming with R, including the apparatus that supports extensions. The book then extends R's data structures through object-oriented programming, which is the key technique for coping with complexity. The book also incorporates a new structure for interfaces applicable to a variety of languages. A reflection of what R is today, this guide explains how to design and organize extensions to R by correctly using objects, functions, and interfaces. It enables current and future users to add their own contributions and packages to R. ~ A 2017 Choice Outstanding Academic Title},
  isbn = {978-1-315-38130-5}
}

@article{chambersObjectOrientedProgrammingFunctional2014,
  title = {Object-{{Oriented Programming}}, {{Functional Programming}} and {{R}}},
  author = {Chambers, John M.},
  year = {2014},
  month = may,
  journal = {Statistical Science},
  volume = {29},
  number = {2},
  pages = {167--180},
  publisher = {Institute of Mathematical Statistics},
  issn = {0883-4237, 2168-8745},
  doi = {10.1214/13-STS452},
  urldate = {2024-05-20},
  abstract = {This paper reviews some programming techniques in R that have proved useful, particularly for substantial projects. These include several versions of object-oriented programming, used in a large number of R packages. The review tries to clarify the origins and ideas behind the various versions, each of which is valuable in the appropriate context. R has also been strongly influenced by the ideas of functional programming and, in particular, by the desire to combine functional with object oriented programming. To clarify how this particular mix of ideas has turned out in the current R language and supporting software, the paper will first review the basic ideas behind object-oriented and functional programming, and then examine the evolution of R with these ideas providing context. Functional programming supports well-defined, defensible software giving reproducible results. Object-oriented programming is the mechanism par excellence for managing complexity while keeping things simple for the user. The two paradigms have been valuable in supporting major software for fitting models to data and numerous other statistical applications. The paradigms have been adopted, and adapted, distinctively in R. Functional programming motivates much of R but R does not enforce the paradigm. Object-oriented programming from a functional perspective differs from that used in non-functional languages, a distinction that needs to be emphasized to avoid confusion. R initially replicated the S language from Bell Labs, which in turn was strongly influenced by earlier program libraries. At each stage, new ideas have been added, but the previous software continues to show its influence in the design as well. Outlining the evolution will further clarify why we currently have this somewhat unusual combination of ideas.},
  keywords = {functional programming,object-oriented programming,Programming languages},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/chambers_2014_object-oriented programming, functional programming and r.pdf}
}

@incollection{chambersStatisticalModels1992,
  title = {Statistical {{Models}}},
  booktitle = {Statistical {{Models}} in {{S}}},
  author = {Chambers, John M. and Hastie, Trevor J.},
  year = {1992},
  publisher = {Routledge},
  abstract = {This chapter explores statistical models---how to think about them, specify them, fit them, and analyze them. Statistical models are simplified descriptions of data, usually constructed from some mathematically or numerically defined relationships. The chapter presents statistical models in three parts: formula that defines the structural part of the model---that is, what data are being modeled and by what other data, in what form; data to which the modeling should be applied. Finally, the stochastic part of the model---that is, how to regard the discrepancy or residuals between the data and the fit. Models are objects that imitate the properties of other, "real" objects, but in a simpler or more convenient form. We make inferences from the models and apply them to the real objects, for which the same inferences would be impossible or inconvenient. The modeling formula defines the structural form of the model, and is used by the model-fitting functions to carry out the actual fitting.},
  isbn = {978-0-203-73853-5}
}

@article{chassagnolGaussianMixtureModels2023,
  title = {Gaussian {{Mixture Models}} in {{R}}},
  author = {Chassagnol, Bastien and Bichat, Antoine and Boudjeniba, Che{\"i}ma and Wuillemin, Pierre-Henri and Guedj, Micka{\"e}l and Gohel, David and Nuel, Gregory and Becht, Etienne},
  year = {2023},
  month = nov,
  journal = {The R Journal},
  volume = {15},
  number = {2},
  pages = {56--76},
  issn = {2073-4859},
  doi = {10.32614/RJ-2023-043},
  urldate = {2023-11-21},
  abstract = {Gaussian mixture models (GMMs) are widely used for modelling stochastic problems. Indeed, a wide diversity of packages have been developed in R. However, no recent review describing the main features offered by these packages and comparing their performances has been performed. In this article, we first introduce GMMs and the EM algorithm used to retrieve the parameters of the model and analyse the main features implemented among seven of the most widely used R packages. We then empirically compare their statistical and computational performances in relation with the choice of the initialisation algorithm and the complexity of the mixture. We demonstrate that the best estimation with well-separated components or with a small number of components with distinguishable modes is obtained with REBMIX initialisation, implemented in the rebmix package, while the best estimation with highly overlapping components is obtained with k-means or random initialisation. Importantly, we show that implementation details in the EM algorithm yield differences in the parameters' estimation. Especially, packages mixtools (Young et al. 2020) and Rmixmod (Langrognet et al. 2021) estimate the parameters of the mixture with smaller bias, while the RMSE and variability of the estimates is smaller with packages bgmm (Ewa Szczurek 2021) , EMCluster (W.-C. Chen and Maitra 2022) , GMKMcharlie (Liu 2021), flexmix (Gruen and Leisch 2022) and mclust (Fraley, Raftery, and Scrucca 2022). The comparison of these packages provides R users with useful recommendations for improving the computational and statistical performance of their clustering and for identifying common deficiencies. Additionally, we propose several improvements in the development of a future, unified mixture model package.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/XKC7BFMQ/Chassagnol et al. - 2023 - Gaussian Mixture Models in R.pdf}
}

@article{chen1996apoe,
  title = {{{ApoE}} and {{CYP2D6}} Polymorphism with and without Parkinsonism-Dementia Complex in the People of {{Chamorro}}, {{Guam}}},
  author = {Chen, X and Xia, Y and Gresham, {\relax LS} and Molgaard, {\relax CA} and Thomas, {\relax RG} and Galasko, D and Wiederholt, {\relax WC} and Saitoh, T},
  year = {1996},
  journal = {Neurology},
  volume = {47},
  number = {3},
  pages = {779--784},
  publisher = {Wolters Kluwer Health, Inc. on behalf of the American Academy of Neurology}
}

@misc{chen2014bayesian,
  title = {Bayesian Longitudinal Modeling on Placebo Data from Alzheimer's Disease Clinical Studies (P1. 010)},
  author = {Chen, Yun-Fei and Mohs, Richard and Ding, Ying and Aisen, Paul and Thomas, Ronald},
  year = {2014},
  publisher = {Wolters Kluwer Health, Inc. on behalf of the American Academy of Neurology}
}

@article{chenComparisonFourMethods2014,
  title = {A {{Comparison}} of {{Four Methods}} for the {{Analysis}} of {{N-of-1 Trials}}},
  author = {Chen, Xinlin and Chen, Pingyan},
  year = {2014},
  month = feb,
  journal = {PLOS ONE},
  volume = {9},
  number = {2},
  pages = {e87752},
  publisher = {Public Library of Science},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0087752},
  urldate = {2024-02-14},
  abstract = {Objective To provide a practical guidance for the analysis of N-of-1 trials by comparing four commonly used models. Methods The four models, paired t-test, mixed effects model of difference, mixed effects model and meta-analysis of summary data were compared using a simulation study. The assumed 3-cycles and 4-cycles N-of-1 trials were set with sample sizes of 1, 3, 5, 10, 20 and 30 respectively under normally distributed assumption. The data were generated based on variance-covariance matrix under the assumption of (i) compound symmetry structure or first-order autoregressive structure, and (ii) no carryover effect or 20\% carryover effect. Type I error, power, bias (mean error), and mean square error (MSE) of effect differences between two groups were used to evaluate the performance of the four models. Results The results from the 3-cycles and 4-cycles N-of-1 trials were comparable with respect to type I error, power, bias and MSE. Paired t-test yielded type I error near to the nominal level, higher power, comparable bias and small MSE, whether there was carryover effect or not. Compared with paired t-test, mixed effects model produced similar size of type I error, smaller bias, but lower power and bigger MSE. Mixed effects model of difference and meta-analysis of summary data yielded type I error far from the nominal level, low power, and large bias and MSE irrespective of the presence or absence of carryover effect. Conclusion We recommended paired t-test to be used for normally distributed data of N-of-1 trials because of its optimal statistical performance. In the presence of carryover effects, mixed effects model could be used as an alternative.},
  langid = {english},
  keywords = {Covariance,Mathematical functions,Metaanalysis,Normal distribution,Physicians,Research errors,Simulation and modeling,Statistical data},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/chen_chen_2014_a comparison of four methods for the analysis of n-of-1 trials.pdf}
}

@article{chengPrognosticSerumMiRNA2015,
  title = {Prognostic Serum {{miRNA}} Biomarkers Associated with {{Alzheimer}}'s Disease Shows Concordance with Neuropsychological and Neuroimaging Assessment},
  author = {Cheng, L. and Doecke, J. D. and Sharples, R. A. and Villemagne, V. L. and Fowler, C. J. and Rembach, A. and Martins, R. N. and Rowe, C. C. and Macaulay, S. L. and Masters, C. L. and Hill, A. F.},
  year = {2015},
  journal = {Molecular Psychiatry},
  volume = {20},
  number = {10},
  pages = {1188--1196},
  publisher = {Nature Publishing Group},
  issn = {14765578},
  doi = {10.1038/mp.2014.127},
  abstract = {There is no consensus for a blood-based test for the early diagnosis of Alzheimer's disease (AD). Expression profiling of small non-coding RNA's, microRNA (miRNA), has revealed diagnostic potential in human diseases. Circulating miRNA are found in small vesicles known as exosomes within biological fluids such as human serum. The aim of this work was to determine a set of differential exosomal miRNA biomarkers between healthy and AD patients, which may aid in diagnosis. Using next-generation deep sequencing, we profiled exosomal miRNA from serum (N=49) collected from the Australian Imaging, Biomarkers and Lifestyle Flagship Study (AIBL). Sequencing results were validated using quantitative reverse transcription PCR (qRT-PCR; N=60), with predictions performed using the Random Forest method. Additional risk factors collected during the 4.5-year AIBL Study including clinical, medical and cognitive assessments, and amyloid neuroimaging with positron emission tomography were assessed. An AD-specific 16-miRNA signature was selected and adding established risk factors including age, sex and apolipoprotein {$\varepsilon$}4 (APOE {$\varepsilon$}4) allele status to the panel of deregulated miRNA resulted in a sensitivity and specificity of 87\% and 77\%, respectively, for predicting AD. Furthermore, amyloid neuroimaging information for those healthy control subjects incorrectly classified with AD-suggested progression in these participants towards AD. These data suggest that an exosomal miRNA signature may have potential to be developed as a suitable peripheral screening tool for AD.},
  pmid = {25349172},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/cheng et al_2015_prognostic serum mirna biomarkers associated with alzheimer's disease shows.pdf}
}

@article{chenLatticePointsContingency2005,
  title = {Lattice Points, Contingency Tables, and Sampling},
  author = {Chen, Yuguo and Dinwoodie, Ian and Dobra, Adrian and Huber, Mark},
  year = {2005},
  journal = {Contemporary Mathematics},
  volume = {374},
  pages = {65--78},
  publisher = {Providence, RI: American Mathematical Society},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/chen et al_2005_lattice points, contingency tables, and sampling.pdf;/Users/zenn/Zotero/storage/YJHATY3V/books.html}
}

@article{chenPredictiveBiomarkersTreatment2015,
  title = {Predictive Biomarkers for Treatment Selection: Statistical Considerations},
  shorttitle = {Predictive Biomarkers for Treatment Selection},
  author = {Chen, James J and Lu, Tzu-Pin and Chen, Yu-Chuan and Lin, Wei-Jiun},
  year = {2015},
  month = nov,
  journal = {Biomarkers in Medicine},
  volume = {9},
  number = {11},
  pages = {1121--1135},
  publisher = {Future Medicine},
  issn = {1752-0363},
  doi = {10.2217/bmm.15.84},
  urldate = {2023-05-05},
  abstract = {Predictive biomarkers are developed for treatment selection to identify patients who are likely to benefit from a particular therapy. This review describes statistical methods and discusses issues in the development of predictive biomarkers to enhance study efficiency for detection of treatment effect on the selected responder patients in clinical studies. The statistical procedure for treatment selection consists of three components: biomarker identification, subgroup selection and clinical utility assessment. Major statistical issues discussed include biomarker designs, procedures to identify predictive biomarkers, classification models for subgroup selection, subgroup analysis and multiple testing for clinical utility assessment and evaluation.},
  keywords = {biomarker adaptive design,personalized and precision medicine,predictive biomarker,predictive classifier,subgroup analysis,subgroup selection},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/chen et al_2015_predictive biomarkers for treatment selection.pdf}
}

@article{chenSimulationStudyComparing2018,
  title = {A Simulation Study Comparing Slope Model with Mixed-model Repeated Measure to Assess Cognitive Data in Clinical Trials of {{Alzheimer}}'s Disease},
  author = {Chen, Yun-Fei and Ni, Xiao and Fleisher, Adam S. and Zhou, Wei and Aisen, Paul and Mohs, Richard},
  year = {2018},
  month = jan,
  journal = {Alzheimer's \& Dementia: Translational Research \& Clinical Interventions},
  volume = {4},
  number = {1},
  pages = {46--53},
  issn = {2352-8737, 2352-8737},
  doi = {10.1016/j.trci.2017.12.002},
  urldate = {2023-08-12},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/4CLW2YMD/Chen et al. - 2018 - A simulation study comparing slope model with mixe.pdf}
}

@article{chenSimulationStudyComparing2018a,
  title = {A Simulation Study Comparing Slope Model with Mixed-Model Repeated Measure to Assess Cognitive Data in Clinical Trials of {{Alzheimer}}'s Disease},
  author = {Chen, Yun-Fei and Ni, Xiao and Fleisher, Adam S. and Zhou, Wei and Aisen, Paul and Mohs, Richard},
  year = {2018},
  month = jan,
  journal = {Alzheimer's \& Dementia : Translational Research \& Clinical Interventions},
  volume = {4},
  pages = {46--53},
  issn = {2352-8737},
  doi = {10.1016/j.trci.2017.12.002},
  urldate = {2023-08-12},
  abstract = {Introduction In clinical trials of Alzheimer's disease, a mixed-model repeated measure approach often serves as the primary analysis when evaluating disease progression; a slope model may be secondary. Methods Longitudinal change from baseline (14-item version of Alzheimer's Disease Assessment Scale--Cognitive Subscale) was simulated for treatment/placebo from multivariate normal distributions with the variance-covariance matrix estimated from solanezumab trial data. Type I error, power, and bias were based on 18-month treatment contrast. Sample sizes included 500 and 1000 patients/arm. Results The slope model was more powerful in most scenarios. Mixed-model repeated measure was relatively unbiased in parameter estimation. The slope model yielded unbiased estimates whenever the underlying trajectory was not detectably different from linear. Both methods led to similar type I error. Discussion In clinical trials of Alzheimer's disease, mixed-model repeated measure analysis with relaxed assumptions on disease progression seems to be preferred. The slope model might be more powerful if the trajectory has little departure from linearity.},
  pmcid = {PMC6021263},
  pmid = {29955651},
  file = {/Users/zenn/Zotero/storage/6R7ZCV94/Chen et al. - 2018 - A simulation study comparing slope model with mixe.pdf}
}

@article{CholinesteraseInhibitorsTreatment2008,
  title = {{[Cholinesterase inhibitors for the treatment of dementia in Parkinson's disease]}},
  year = {2008},
  month = sep,
  journal = {Der Nervenarzt},
  volume = {79},
  number = {9},
  pages = {1076--1079},
  issn = {0028-2804},
  doi = {10.1007/s00115-008-2544-9},
  langid = {german},
  pmid = {18704357},
  keywords = {Cholinesterase Inhibitors,Dementia,Humans,Lewy Body Disease,Parkinsonian Disorders,Randomized Controlled Trials as Topic,Supranuclear Palsy Progressive,Treatment Outcome}
}

@misc{chopraConversationalChallengesAIPowered2023,
  title = {Conversational {{Challenges}} in {{AI-Powered Data Science}}: {{Obstacles}}, {{Needs}}, and {{Design Opportunities}}},
  shorttitle = {Conversational {{Challenges}} in {{AI-Powered Data Science}}},
  author = {Chopra, Bhavya and Singha, Ananya and Fariha, Anna and Gulwani, Sumit and Parnin, Chris and Tiwari, Ashish and Henley, Austin Z.},
  year = {2023},
  month = oct,
  number = {arXiv:2310.16164},
  eprint = {2310.16164},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2310.16164},
  urldate = {2024-07-15},
  abstract = {Large Language Models (LLMs) are being increasingly employed in data science for tasks like data preprocessing and analytics. However, data scientists encounter substantial obstacles when conversing with LLM-powered chatbots and acting on their suggestions and answers. We conducted a mixed-methods study, including contextual observations, semi-structured interviews (n=14), and a survey (n=114), to identify these challenges. Our findings highlight key issues faced by data scientists, including contextual data retrieval, formulating prompts for complex tasks, adapting generated code to local environments, and refining prompts iteratively. Based on these insights, we propose actionable design recommendations, such as data brushing to support context selection, and inquisitive feedback loops to improve communications with AI-based assistants in data-science tools.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Human-Computer Interaction},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/chopra et al_2023_conversational challenges in ai-powered data science.pdf;/Users/zenn/Zotero/storage/4KHMLJUE/2310.html}
}

@article{chungStatisticalSignificanceCluster2020,
  title = {Statistical Significance of Cluster Membership for Unsupervised Evaluation of Cell Identities},
  author = {Chung, Neo Christopher},
  year = {2020},
  month = may,
  journal = {Bioinformatics},
  volume = {36},
  number = {10},
  pages = {3107--3114},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/btaa087},
  urldate = {2024-04-05},
  abstract = {Single-cell RNA-sequencing (scRNA-seq) allows us to dissect transcriptional heterogeneity arising from cellular types, spatio-temporal contexts and environmental stimuli. Transcriptional heterogeneity may reflect phenotypes and molecular signatures that are often unmeasured or unknown a priori. Cell identities of samples derived from heterogeneous subpopulations are then determined by clustering of scRNA-seq data. These cell identities are used in downstream analyses. How can we examine if cell identities are accurately inferred? Unlike external measurements or labels for single cells, using clustering-based cell identities result in spurious signals and false discoveries.We introduce non-parametric methods to evaluate cell identities by testing cluster memberships in an unsupervised manner. Diverse simulation studies demonstrate accuracy of the jackstraw test for cluster membership. We propose a posterior probability that a cell should be included in that clustering-based subpopulation. Posterior inclusion probabilities (PIPs) for cluster memberships can be used to select and visualize samples relevant to subpopulations. The proposed methods are applied on three scRNA-seq datasets. First, a mixture of Jurkat and 293T cell lines provides two distinct cellular populations. Second, Cell Hashing yields cell identities corresponding to eight donors which are independently analyzed by the jackstraw. Third, peripheral blood mononuclear cells are used to explore heterogeneous immune populations. The proposed P-values and PIPs lead to probabilistic feature selection of single cells that can be visualized using principal component analysis (PCA), t-distributed stochastic neighbor embedding (t-SNE) and others. By learning uncertainty in clustering high-dimensional data, the proposed methods enable unsupervised evaluation of cluster membership.https://cran.r-project.org/package=jackstraw.Supplementary data are available at Bioinformatics online.},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/chung_2020_statistical significance of cluster membership for unsupervised evaluation of.pdf;/Users/zenn/Zotero/storage/2TF7VQSS/5788523.html}
}

@article{chungStatisticalSignificanceVariables2015,
  title = {Statistical Significance of Variables Driving Systematic Variation in High-Dimensional Data},
  author = {Chung, Neo Christopher and Storey, John D.},
  year = {2015},
  month = feb,
  journal = {Bioinformatics},
  volume = {31},
  number = {4},
  pages = {545--554},
  issn = {1367-4803, 1367-4811},
  doi = {10.1093/bioinformatics/btu674},
  urldate = {2024-04-12},
  abstract = {Motivation: There are a number of well-established methods such as principal component analysis (PCA) for automatically capturing systematic variation due to latent variables in large-scale genomic data. PCA and related methods may directly provide a quantitative characterization of a complex biological variable that is otherwise difficult to precisely define or model. An unsolved problem in this context is how to systematically identify the genomic variables that are drivers of systematic variation captured by PCA. Principal components (PCs) (and other estimates of systematic variation) are directly constructed from the genomic variables themselves, making measures of statistical significance artificially inflated when using conventional methods due to over-fitting.},
  copyright = {http://creativecommons.org/licenses/by/4.0/},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/FNYAXXBH/bioinformatics_31_4_545.pdf}
}

@article{ciotti1996familial,
  title = {Familial Melanoma and Pancreatic Cancer [2]},
  author = {Ciotti, P and Strigini, P and {Bianchi-Scarra}, G and Wright, {\relax FA} and Thomas, {\relax RG} and Bergman, W and Gruis, N and Goldstein, {\relax AM} and Tucker, {\relax MA} and Whelan, {\relax AJ} and others},
  year = {1996},
  journal = {New England Journal of Medicine},
  volume = {334},
  number = {7},
  pages = {469--472},
  publisher = {Massachussetts Medical Society}
}

@incollection{clark2000neuro,
  title = {Biostatistical Issues in Neurodegenerative Disease},
  author = {Thomas, Ronald G},
  year = {2000},
  pages = {411--414},
  publisher = {McGraw-Hill, New York},
  booktitl = {Neurodegenerative Dementias}
}

@article{Clemmensen2011,
  title = {Sparse Discriminant Analysis},
  author = {Clemmensen, Line and Hastie, Trevor and Witten, Daniela and Ersboll, Bjarne},
  year = {2011},
  journal = {Technometrics},
  volume = {53},
  number = {4},
  pages = {406--413},
  issn = {00401706},
  doi = {10.1198/TECH.2011.08118},
  abstract = {We consider the problem of performing interpretable classification in the high-dimensional setting, in which the number of features is very large and the number of observations is limited. This setting has been studied extensively in the chemometrics literature, and more recently has become commonplace in biological and medical applications. In this setting, a traditional approach involves performing feature selection before classification. We propose sparse discriminant analysis, a method for performing linear discriminant analysis with a sparseness criterion imposed such that classification and feature selection are performed simultaneously. Sparse discriminant analysis is based on the optimal scoring interpretation of linear discriminant analysis, and can be extended to perform sparse discrimination via mixtures of Gaussians if boundaries between classes are nonlinear or if subgroups are present within each class. Our proposal also provides low-dimensional views of the discriminative directions. {\copyright} 2011 American Statistical Association and the American Society for Qualitys.},
  keywords = {Classification,Dimension reduction,Feature selection,Linear discriminant analysis,Mixture discriminant analysis},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/clemmensen et al_2011_sparse discriminant analysis.pdf}
}

@article{cliftonCorrelationBaselineScore2019,
  title = {The Correlation between Baseline Score and Post-Intervention Score, and Its Implications for Statistical Analysis},
  author = {Clifton, Lei and Clifton, David A.},
  year = {2019},
  month = jan,
  journal = {Trials},
  volume = {20},
  number = {1},
  pages = {43},
  issn = {1745-6215},
  doi = {10.1186/s13063-018-3108-3},
  urldate = {2023-05-06},
  abstract = {When using a continuous outcome measure in a randomised controlled trial (RCT), the baseline score should be measured in addition to the post-intervention score, and it should be analysed using the appropriate statistical analysis.},
  keywords = {Analysis of covariance (ANCOVA),Baseline,Bland-Altman plot,Change score,Correlation,Independent,Means,Outcome,Post-intervention,Randomised controlled trial (RCT),Regression to the mean (RTM),Sample size,Standard deviation (SD),Standard error (SE),Statistical analysis,Treatment},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/clifton_clifton_2019_the correlation between baseline score and post-intervention score, and its.pdf}
}

@article{coartMinimizationRandomizedClinical2023,
  title = {Minimization in Randomized Clinical Trials},
  author = {Coart, Elisabeth and Bamps, Perrine and Quinaux, Emmanuel and Sturbois, Genevi{\`e}ve and Saad, Everardo D. and Burzykowski, Tomasz and Buyse, Marc},
  year = {2023},
  month = dec,
  journal = {Statistics in Medicine},
  volume = {42},
  number = {28},
  pages = {5285--5311},
  issn = {0277-6715, 1097-0258},
  doi = {10.1002/sim.9916},
  urldate = {2024-02-02},
  abstract = {In randomized trials, comparability of the treatment groups is ensured through allocation of treatments using a mechanism that involves some random element, thus controlling for confounding of the treatment effect. Completely random allocation ensures comparability between the treatment groups for all known and unknown prognostic factors. For a specific trial, however, imbalances in prognostic factors among the treatment groups may occur. Although accidental bias can be avoided in the presence of such imbalances by stratifying the analysis, most trialists, regulatory agencies, and other stakeholders prefer a balanced distribution of prognostic factors across the treatment groups. Some procedures attempt to achieve balance in baseline covariates, by stratifying the allocation for these covariates, or by dynamically adapting the allocation using covariate information during the trial (covariate-adaptive procedures). In this Tutorial, the performance of minimization, a popular covariate-adaptive procedure, is compared with two other commonly used procedures, completely random allocation and stratified blocked designs. Using individual patient data of 2 clinical trials (in advanced ovarian cancer and age-related macular degeneration), the procedures are compared in terms of operating characteristics (using asymptotic and randomization tests), predictability of treatment allocation, and achieved balance. Fifty actual trials of various sizes that applied minimization for treatment allocation are used to investigate the achieved balance. Implementation issues of minimization are described. Minimization procedures are useful in all trials but especially when (1) many major prognostic factors are known, (2) many centers of different sizes accrue patients, or (3) the trial sample size is moderate.},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/coart et al_2023_minimization in randomized clinical trials.pdf}
}

@article{cobigoDetectionEmergingNeurodegeneration2022,
  title = {Detection of Emerging Neurodegeneration Using {{Bayesian}} Linear Mixed-Effect Modeling},
  author = {Cobigo, Yann and Goh, Matthew S. and Wolf, Amy and Staffaroni, Adam M. and Kornak, John and Miller, Bruce L. and Rabinovici, Gil D. and Seeley, William W. and Spina, Salvatore and Boxer, Adam L. and Boeve, Bradley F. and Wang, Lei and Allegri, Ricardo and Farlow, Marty and Mori, Hiroshi and Perrin, Richard J. and Kramer, Joel and Rosen, Howard J.},
  year = {2022},
  month = jan,
  journal = {NeuroImage: Clinical},
  volume = {36},
  pages = {103144},
  issn = {2213-1582},
  doi = {10.1016/j.nicl.2022.103144},
  urldate = {2022-10-20},
  abstract = {Early detection of neurodegeneration, and prediction of when neurodegenerative diseases will lead to symptoms, are critical for developing and initiating disease modifying treatments for these disorders. While each neurodegenerative disease has a typical pattern of early changes in the brain, these disorders are heterogeneous, and early manifestations can vary greatly across people. Methods for detecting emerging neurodegeneration in any part of the brain are therefore needed. Prior publications have described the use of Bayesian linear mixed-effects (BLME) modeling for characterizing the trajectory of change across the brain in healthy controls and patients with neurodegenerative disease. Here, we use an extension of such a model to detect emerging neurodegeneration in cognitively healthy individuals at risk for dementia. We use BLME to quantify individualized rates of volume loss across the cerebral cortex from the first two MRIs in each person and then extend the BLME model to predict future values for each voxel. We then compare observed values at subsequent time points with the values that were expected from the initial rates of change and identify voxels that are lower than the expected values, indicating accelerated volume loss and neurodegeneration. We apply the model to longitudinal imaging data from cognitively normal participants in the Alzheimer's Disease Neuroimaging Initiative (ADNI), some of whom subsequently developed dementia, and two cognitively normal cases who developed pathology-proven frontotemporal lobar degeneration (FTLD). These analyses identified regions of accelerated volume loss prior to or accompanying the earliest symptoms, and expanding across the brain over time, in all cases. The changes were detected in regions that are typical for the likely diseases affecting each patient, including medial temporal regions in patients at risk for Alzheimer's disease, and insular, frontal, and/or anterior/inferior temporal regions in patients with likely or proven FTLD. In the cases where detailed histories were available, the first regions identified were consistent with early symptoms. Furthermore, survival analysis in the ADNI cases demonstrated that the rate of spread of accelerated volume loss across the brain was a statistically significant predictor of time to conversion to dementia. This method for detection of neurodegeneration is a potentially promising approach for identifying early changes due to a variety of diseases, without prior assumptions about what regions are most likely to be affected first in an individual.},
  langid = {english},
  keywords = {Alzheimer's Disease,Bayesian linear mixed-effect,Bayesian prediction,Frontotemporal Lobar Degeneration},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/cobigo et al_2022_detection of emerging neurodegeneration using bayesian linear mixed-effect.pdf;/Users/zenn/Zotero/storage/TJRVIV8K/S2213158222002091.html}
}

@article{coeExactRepeatedConfidence,
  title = {Exact Repeated Confidence Intervals for {{Bernoulli}} Parameters in a Group Sequential Clinical Trial},
  author = {Coe, {\relax PR} and clinical {trials}, AC Tamhane - Controlled and 1993, undefined},
  journal = {contemporaryclinicaltrials.com},
  urldate = {2018-09-01},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/coe et al_exact repeated confidence intervals for bernoulli parameters in a group.pdf}
}

@misc{CoefficientDeterminationGeneralized,
  title = {A Coefficient of Determination ( {{R}} 2 ) for Generalized Linear Mixed Models - {{UC San Diego}}},
  urldate = {2023-12-15},
  abstract = {A coefficient of determination ( R 2 ) for generalized linear mixed models-article},
  howpublished = {https://search-library.ucsd.edu},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/L9UAVANC/openurl.html}
}

@article{collectionAlgorithmDistanceTwo,
  title = {Algorithm for the Distance between Two Finite Sequences},
  author = {{collection}, PH Sellers - Plant Genome Data {and} Information Center and 1974, undefined},
  journal = {agris.fao.org},
  urldate = {2018-09-01},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/collection_1974_algorithm for the distance between two finite sequences.pdf}
}

@misc{ComparisonPhaseDosefinding,
  title = {A Comparison of Phase {{I}} Dose-Finding Designs in Clinical Trials with Monotonicity Assumption Violation},
  urldate = {2024-03-19},
  howpublished = {https://journals.sagepub.com/doi/epub/10.1177/1740774520932130},
  file = {/Users/zenn/Zotero/storage/GMPS599A/1740774520932130.html}
}

@misc{ComparisonPhaseDosefindinga,
  title = {A Comparison of Phase {{I}} Dose-Finding Designs in Clinical Trials with Monotonicity Assumption Violation - {{Rachid Abbas}}, {{Caroline Rossoni}}, {{Thomas Jaki}}, {{Xavier Paoletti}}, {{Pavel Mozgunov}}, 2020},
  urldate = {2024-03-19},
  howpublished = {https://journals.sagepub.com/doi/full/10.1177/1740774520932130},
  file = {/Users/zenn/Zotero/storage/573637X8/1740774520932130.html}
}

@article{conlon1990new,
  title = {A New Confidence Interval for the Difference of Two Binomial Proportions},
  author = {Conlon, Michael and Thomas, Ronald G},
  year = {1990},
  journal = {Computational Statistics \& Data Analysis},
  volume = {9},
  number = {2},
  pages = {237--241},
  publisher = {North-Holland}
}

@article{conlon1993algorithm,
  title = {Algorithm {{AS}} 280: The Power Function for {{Fisher}}'s Exact Test},
  author = {Conlon, Michael and Thomas, Ronald G},
  year = {1993},
  journal = {Journal of the Royal Statistical Society. Series C (Applied Statistics)},
  volume = {42},
  number = {1},
  pages = {258--260},
  publisher = {Wiley, Royal Statistical Society}
}

@article{conlonAlgorithm280Power1993,
  title = {Algorithm {{AS}} 280: {{The Power Function}} for {{Fisher}}'s {{Exact Test}}},
  shorttitle = {Algorithm {{AS}} 280},
  author = {Conlon, Michael and Thomas, Ronald G.},
  year = {1993},
  journal = {Journal of the Royal Statistical Society. Series C (Applied Statistics)},
  volume = {42},
  number = {1},
  eprint = {2347431},
  eprinttype = {jstor},
  pages = {258--260},
  publisher = {[Wiley, Royal Statistical Society]},
  issn = {0035-9254},
  doi = {10.2307/2347431},
  urldate = {2023-07-21},
  file = {/Users/zenn/Zotero/storage/MFPAX96A/Conlon and Thomas - 1993 - Algorithm AS 280 The Power Function for Fisher's .pdf}
}

@misc{ContinuousEmpiricalCharacteristic,
  title = {Continuous {{Empirical Characteristic Function Estimation}} of {{Mixtures}} of {{Normal Parameters}}},
  issn = {0747-4938},
  urldate = {2024-05-11},
  howpublished = {https://www.tandfonline.com/doi/epdf/10.1080/07474938.2011.520565?needAccess=true},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/UAUMZHFU/07474938.2011.html}
}

@article{cookTwentysixAssumptionsThat2018,
  title = {Twenty-Six Assumptions That Have to Be Met If Single Random Assignment Experiments Are to Warrant ``Gold Standard'' Status: {{A}} Commentary on {{Deaton}} and {{Cartwright}}},
  shorttitle = {Twenty-Six Assumptions That Have to Be Met If Single Random Assignment Experiments Are to Warrant ``Gold Standard'' Status},
  author = {Cook, Thomas D.},
  year = {2018},
  journal = {Social science \& medicine},
  volume = {210},
  pages = {37--40},
  publisher = {Elsevier},
  file = {/Users/zenn/Zotero/storage/Z2FSNRZ7/Cook - 2018 - Twenty-six assumptions that have to be met if sing.pdf;/Users/zenn/Zotero/storage/M2WVB2US/S0277953618301989.html}
}

@article{cordyDeconvolutionDistributionFunction1997,
  title = {Deconvolution of a {{Distribution Function}}},
  author = {Cordy, Clifford B. and Thomas, David R.},
  year = {1997},
  month = dec,
  journal = {Journal of the American Statistical Association},
  volume = {92},
  number = {440},
  pages = {1459--1465},
  publisher = {Taylor \& Francis},
  issn = {0162-1459},
  doi = {10.1080/01621459.1997.10473667},
  urldate = {2023-03-01},
  abstract = {We consider the estimation of a distribution function when observations from this distribution are contaminated by measurement error. The unknown distribution is modeled as a mixture of a finite number of known distributions. Model parameters can be estimated and confidence intervals constructed using well-known likelihood theory. We show that it is also possible to apply this approach to estimation of a unimodal distribution. An application is presented using data from a dietary survey. Simulation results are given to indicate the performance of the estimators and the confidence interval procedures.},
  keywords = {Expectation-maximization algorithm,Mixture of distributions,Profile likelihood,Unimodal distribution.},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/cordy_thomas_1997_deconvolution of a distribution function.pdf}
}

@article{cummingsRoleBasketTrials2022,
  title = {The Role of Basket Trials in Drug Development for Neurodegenerative Disorders},
  author = {Cummings, Jeffrey and Montes, Arturo and Kamboj, Sana and Cacho, Jorge Fonseca},
  year = {2022},
  journal = {Alzheimer's Research \& Therapy},
  pages = {1--9},
  publisher = {BioMed Central},
  issn = {1758-9193},
  doi = {10.1186/s13195-022-01015-6},
  keywords = {alzheimer,Alzheimer's disease,amyotrophic lateral sclerosis,Amyotrophic lateral sclerosis,basket trial,Basket trial,bodies,clinical trials,Clinical trials,corticobasal degeneration,Corticobasal degeneration,dementia with lewy,Dementia with Lewy bodies,frontotemporal dementia,Frontotemporal dementia,multiple system atrophy,Multiple system atrophy,neurodegenerative disease,Neurodegenerative disease,palsy,parkinson,Parkinson's disease,progressive supranuclear,Progressive supranuclear palsy,s disease},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/cummings et al_2022_the role of basket trials in drug development for neurodegenerative disorders.pdf}
}

@article{damSafetyEfficacyAntitau2021,
  title = {Safety and Efficacy of Anti-Tau Monoclonal Antibody Gosuranemab in Progressive Supranuclear Palsy: A Phase 2, Randomized, Placebo-Controlled Trial},
  shorttitle = {Safety and Efficacy of Anti-Tau Monoclonal Antibody Gosuranemab in Progressive Supranuclear Palsy},
  author = {Dam, Tien and Boxer, Adam L. and Golbe, Lawrence I. and H{\"o}glinger, G{\"u}nter U. and Morris, Huw R. and Litvan, Irene and Lang, Anthony E. and Corvol, Jean-Christophe and Aiba, Ikuko and Grundman, Michael and Yang, Lili and {Tidemann-Miller}, Beth and Kupferman, Joseph and Harper, Kristine and Kamisoglu, Kubra and Wald, Michael J. and Graham, Danielle L. and Gedney, Liz and O'Gorman, John and Haeberlein, Samantha Budd},
  year = {2021},
  month = aug,
  journal = {Nature Medicine},
  volume = {27},
  number = {8},
  pages = {1451--1457},
  publisher = {Nature Publishing Group},
  issn = {1546-170X},
  doi = {10.1038/s41591-021-01455-x},
  urldate = {2024-07-12},
  abstract = {A randomized, double-blind, placebo-controlled, 52-week study (no. NCT03068468) evaluated gosuranemab, an anti-tau monoclonal antibody, in the treatment of progressive supranuclear palsy (PSP). In total, 486\,participants dosed were assigned to either gosuranemab (n\,=\,321) or placebo (n\,=\,165). Efficacy was not demonstrated on adjusted mean change of PSP Rating Scale score at week\,52 between gosuranemab and placebo (10.4 versus 10.6, P\,=\,0.85, primary endpoint), or at secondary endpoints, resulting in discontinuation of the open-label, long-term extension. Unbound N-terminal tau in cerebrospinal fluid decreased by 98\% with gosuranemab and increased by 11\% with placebo (P\,{$<$}\,0.0001). Incidences of adverse events and deaths were similar between groups. This well-powered study suggests that N-terminal tau neutralization does not translate into clinical efficacy.},
  copyright = {2021 The Author(s), under exclusive licence to Springer Nature America, Inc.},
  langid = {english},
  keywords = {Movement disorders,Neuroscience},
  file = {/Users/zenn/Zotero/storage/B4C37LQA/Dam et al. - 2021 - Safety and efficacy of anti-tau monoclonal antibod.pdf}
}

@article{Danaei2013,
  title = {Observational Data for Comparative Effectiveness Research: {{An}} Emulation of Randomised Trials of Statins and Primary Prevention of Coronary Heart Disease},
  author = {Danaei, Goodarz and Rodr{\'i}guez, Luis A.Garc{\'i}a and Cantero, Oscar Fern{\'a}ndez and Logan, Roger and Hern{\'a}n, Miguel A.},
  year = {2013},
  journal = {Statistical Methods in Medical Research},
  volume = {22},
  number = {1},
  pages = {70--96},
  issn = {09622802},
  doi = {10.1177/0962280211403603},
  abstract = {This article reviews methods for comparative effectiveness research using observational data. The basic idea is using an observational study to emulate a hypothetical randomised trial by comparing initiators versus non-initiators of treatment. After adjustment for measured baseline confounders, one can then conduct the observational analogue of an intention-to-treat analysis. We also explain two approaches to conduct the analogues of per-protocol and as-treated analyses after further adjusting for measured time-varying confounding and selection bias using inverse-probability weighting. As an example, we implemented these methods to estimate the effect of statins for primary prevention of coronary heart disease (CHD) using data from electronic medical records in the UK. Despite strong confounding by indication, our approach detected a potential benefit of statin therapy. The analogue of the intention-to-treat hazard ratio (HR) of CHD was 0.89 (0.73, 1.09) for statin initiators versus non-initiators. The HR of CHD was 0.84 (0.54, 1.30) in the per-protocol analysis and 0.79 (0.41, 1.41) in the as-treated analysis for 2 years of use versus no use. In contrast, a conventional comparison of current users versus never users of statin therapy resulted in a HR of 1.31 (1.04, 1.66). We provide a flexible and annotated SAS program to implement the proposed analyses. {\copyright} 2011 The Author(s).},
  pmid = {22016461},
  keywords = {as-treated analysis,comparative effectiveness,confounding,intention-to-treat analysis,inverse-probability weighting,per-protocol analysis,selection bias},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/danaei et al_2013_observational data for comparative effectiveness research.pdf}
}

@article{dawsonSampleSizeCalculations1998,
  title = {Sample {{Size Calculations Based}} on {{Slopes}} and {{Other Summary Statistics}}},
  author = {Dawson, Jeffrey D.},
  year = {1998},
  journal = {Biometrics},
  volume = {54},
  number = {1},
  eprint = {2534019},
  eprinttype = {jstor},
  pages = {323--330},
  publisher = {[Wiley, International Biometric Society]},
  issn = {0006-341X},
  doi = {10.2307/2534019},
  urldate = {2023-08-12},
  abstract = {Sample size calculations based on two-sample comparisons of slopes have been reported by many. This paper extends such discussions to include summary statistics other than slopes, such as post-baseline means, change scores, and final observations. Specifically, sample size formulas for analyses based on a broad class of summary statistics are presented, with modifications proposed to allow for missing data caused by staggered entry and random dropouts. The formulas developed are used to illustrate how required sample size is affected by summary statistic choice, variance parameters, the type of treatment difference of interest, and the manner in which incomplete observations are used in the analysis. An example based on longitudinal data from the Muscatine Study is presented.},
  file = {/Users/zenn/Zotero/storage/RTT9H7EL/Dawson - 1998 - Sample Size Calculations Based on Slopes and Other.pdf}
}

@article{dawsonStratificationSummaryStatistic1994,
  title = {Stratification of Summary Statistic Tests According to Missing Data Patterns},
  author = {Dawson, Jeffrey D.},
  year = {1994},
  journal = {Statistics in Medicine},
  volume = {13},
  number = {18},
  pages = {1853--1863},
  issn = {1097-0258},
  doi = {10.1002/sim.4780131807},
  urldate = {2023-08-12},
  abstract = {Summary statistics, such as slope or area under the time-response curve, reduce the dimensionality of repeated measures data and can thereby simplify the comparison of groups in longitudinal studies. Since summary statistic distributions vary according to the amount, timing, and type of any missingness that occurs, one must choose between analysing the data unconditionally or conditionally on the missingness patterns. This paper uses simulations to compare such unstratified and stratified summary statistic analyses with respect to their size and power under models that allow for both non-informative and informative missingness mechanisms. Of particular interest is the robustness of these methods to violations of the assumptions that one must make if they are to have proper test size. It is found that stratification of the analysis tends to result in an increase of power, and improves the robustness to violations of missing data assumptions.},
  copyright = {Copyright {\copyright} 1994 John Wiley \& Sons, Ltd.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/DEMVS3BL/sim.html}
}

@article{dayReflectionsRandomizationForgotten2019,
  title = {Reflections on ``{{Randomization}}: {{The Forgotten Component}} of the {{Randomized Clinical Trial}}''},
  shorttitle = {Reflections on ``{{Randomization}}},
  author = {Day, Simon},
  year = {2019},
  month = jan,
  journal = {Statistics in Medicine},
  volume = {38},
  number = {1},
  pages = {17--18},
  issn = {0277-6715, 1097-0258},
  doi = {10.1002/sim.7924},
  urldate = {2022-10-20},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/day_2019_reflections on “randomization.pdf}
}

@article{deatonUnderstandingMisunderstandingRandomized2018,
  title = {Understanding and Misunderstanding Randomized Controlled Trials},
  author = {Deaton, Angus and Cartwright, Nancy},
  year = {2018},
  journal = {Social science \& medicine},
  volume = {210},
  pages = {2--21},
  publisher = {Elsevier},
  file = {/Users/zenn/Zotero/storage/ML4BCHQK/S0277953617307359.html}
}

@article{debastianiTranscriptomicSimilaritiesDifferences2021,
  title = {Transcriptomic Similarities and Differences between Mouse Models and Human {{Alzheimer}}'s {{Disease}}},
  author = {De Bastiani, Marco Ant{\^o}nio and Bellaver, Bruna and {Carello-Collar}, Giovanna and Forner, Stefania and Martini, Alessandra Cadete and Pascoal, Tharick A and Zimmer, Eduardo R},
  year = {2021},
  journal = {bioRxiv},
  pages = {2021.06.09.447404},
  doi = {10.1101/2021.06.09.447404},
  abstract = {Alzheimer's disease (AD) is a multifactorial pathology responsible for most cases of dementia worldwide. Only a small percentage of AD cases are due to autosomal dominant mutations, while the vast majority have a sporadic presentation. Yet, preclinical research studies relied for decades on animal models that overexpress human genes found in AD autosomal dominant patients. Thus, one could argue that these models do not recapitulate sporadic AD. To avoid human gene overexpression artifacts, knock-in (KI) models have been developed, such as the novel hA{$\beta$}-KI mouse model, which are still in early phases of characterization. We hypothesize that comparisons at the transcriptomic level may elucidate critical similarities and differences between transgenic/KI models and AD patients. Thus, we aimed at comparing the hippocampal transcriptomic profiling of overexpression (5xFAD and APP/PS1) and KI (hA{$\beta$}-KI) mouse models with early- (EOAD) and late- (LOAD) onset AD patients. We first evaluated differentially expressed genes (DEGs) and Gene Ontology biological processes (GOBP) overlapping cross-species. After, we explored a network-based strategy to identify master regulators (MR) and the similarities of such elements among models and AD subtypes. A multiple sclerosis (MS) dataset was included to test the molecular specificity of the mouse models to AD. Our analysis revealed that all three mouse models presented more DEGs, GOBP terms and enriched signaling pathways in common with LOAD than with EOAD subjects. Furthermore, semantic similarity of enriched GOBP terms showed mouse model-specific biological alterations, and protein-protein interaction analysis of DEGs identified clusters of genes exclusively shared between hA{$\beta$}-KI mice and LOAD. Furthermore, we identified 17 transcription factor candidates potentially acting as MR of AD in all three models. Finally, though all mouse models showed transcriptomic similarities to LOAD, hA{$\beta$}-KI mice presented a remarkable specificity to this AD subtype, which might support the use of the novel hA{$\beta$}-KI mouse model to advance our understanding of sporadic LOAD. \#\#\# Competing Interest Statement The authors have declared no competing interest.},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/de bastiani et al_2021_transcriptomic similarities and differences between mouse models and human.pdf}
}

@article{debruineUnderstandingMixedEffectsModels2021,
  title = {Understanding {{Mixed-Effects Models Through Data Simulation}}},
  author = {DeBruine, Lisa M. and Barr, Dale J.},
  year = {2021},
  month = jan,
  journal = {Advances in Methods and Practices in Psychological Science},
  volume = {4},
  number = {1},
  pages = {251524592096511},
  issn = {2515-2459, 2515-2467},
  doi = {10.1177/2515245920965119},
  urldate = {2024-03-11},
  abstract = {Experimental designs that sample both subjects and stimuli from a larger population need to account for random effects of both subjects and stimuli using mixed-effects models. However, much of this research is analyzed using analysis of variance on aggregated responses because researchers are not confident specifying and interpreting mixed-effects models. This Tutorial explains how to simulate data with random-effects structure and analyze the data using linear mixed-effects regression (with the lme4 R package), with a focus on interpreting the output in light of the simulated parameters. Data simulation not only can enhance understanding of how these models work, but also enables researchers to perform power calculations for complex designs. All materials associated with this article can be accessed at https://osf.io/3cz2e/ .},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/PVTK3MQS/DeBruine and Barr - 2021 - Understanding Mixed-Effects Models Through Data Si.pdf}
}

@misc{DeepLearningReveals,
  title = {Deep Learning Reveals {{Alzheimer}}'s Disease Onset in {{MCI}} Subjects: {{Results}} from an International Challenge {\textbar} {{Elsevier Enhanced Reader}}},
  shorttitle = {Deep Learning Reveals {{Alzheimer}}'s Disease Onset in {{MCI}} Subjects},
  doi = {10.1016/j.jneumeth.2017.12.011},
  urldate = {2023-04-06},
  howpublished = {https://reader.elsevier.com/reader/sd/pii/S0165027017304296?token=A68A88D868CE7B8FF4E7A75F8B4AB0EADA0AA7078A586D5CB703FC1696DF15DB3F023212767C9C351BF98FDD573A8C4C\&originRegion=us-east-1\&originCreation=20230406001621},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/deep learning reveals alzheimer's disease onset in mci subjects.pdf}
}

@article{dehghanMetabolomewideAssociationStudy2022,
  title = {Metabolome-Wide Association Study on {{ABCA7}} Indicates a Role of Ceramide Metabolism in {{Alzheimer}}'s Disease},
  author = {Dehghan, Abbas and Pinto, Rui Climaco and Karaman, Ibrahim and Huang, Jian and Durainayagam, Brenan R. and Ghanbari, Mohsen and Nazeer, Areesha and Zhong, Qi and Liggi, Sonia and Whiley, Luke and Mustafa, Rima and Kivipelto, Miia and Solomon, Alina and Ngandu, Tiia and Kanekiyo, Takahisa and Aikawa, Tomonori and Radulescu, Carola I. and Barnes, Samuel J. and Gra{\c c}a, Gon{\c c}alo and Chekmeneva, Elena and Camuzeaux, Stephane and Lewis, Matthew R. and Kaluarachchi, Manuja R. and Ikram, M. Arfan and Holmes, Elaine and Tzoulaki, Ioanna and Matthews, Paul M. and Griffin, Julian L. and Elliott, Paul},
  year = {2022},
  month = oct,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {119},
  number = {43},
  pages = {e2206083119},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.2206083119},
  urldate = {2022-10-30},
  abstract = {Genome-wide association studies (GWASs) have identified genetic loci associated with the risk of Alzheimer's disease (AD), but the molecular mechanisms by which they confer risk are largely unknown. We conducted a metabolome-wide association study (MWAS) of AD-associated loci from GWASs using untargeted metabolic profiling (metabolomics) by ultraperformance liquid chromatography--mass spectrometry (UPLC-MS). We identified an association of lactosylceramides (LacCer) with AD-related single-nucleotide polymorphisms (SNPs) in ABCA7 (P = 5.0 {\texttimes} 10-5 to 1.3 {\texttimes} 10-44). We showed that plasma LacCer concentrations are associated with cognitive performance and genetically modified levels of LacCer are associated with AD risk. We then showed that concentrations of sphingomyelins, ceramides, and hexosylceramides were altered in brain tissue from Abca7 knockout mice, compared with wild type (WT) (P = 0.049--1.4 {\texttimes} 10-5), but not in a mouse model of amyloidosis. Furthermore, activation of microglia increases intracellular concentrations of hexosylceramides in part through induction in the expression of sphingosine kinase, an enzyme with a high control coefficient for sphingolipid and ceramide synthesis. Our work suggests that the risk for AD arising from functional variations in ABCA7 is mediated at least in part through ceramides. Modulation of their metabolism or downstream signaling may offer new therapeutic opportunities for AD.},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/dehghan et al_2022_metabolome-wide association study on abca7 indicates a role of ceramide.pdf}
}

@article{demetsInterimAnalysisAlpha1994,
  title = {Interim Analysis: The Alpha Spending Function Approach},
  author = {Demets, {\relax DL} and Lan, {\relax KK}},
  year = {1994},
  journal = {Statistics in medicine},
  urldate = {2016-11-02},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/demets_lan_1994_interim analysis.pdf}
}

@article{desilvaComparisonMultipleImputation2017,
  title = {A Comparison of Multiple Imputation Methods for Handling Missing Values in Longitudinal Data in the Presence of a Time-Varying Covariate with a Non-Linear Association with Time: A Simulation Study},
  shorttitle = {A Comparison of Multiple Imputation Methods for Handling Missing Values in Longitudinal Data in the Presence of a Time-Varying Covariate with a Non-Linear Association with Time},
  author = {De Silva, Anurika Priyanjali and {Moreno-Betancur}, Margarita and De Livera, Alysha Madhu and Lee, Katherine Jane and Simpson, Julie Anne},
  year = {2017},
  month = dec,
  journal = {BMC Medical Research Methodology},
  volume = {17},
  number = {1},
  pages = {114},
  issn = {1471-2288},
  doi = {10.1186/s12874-017-0372-y},
  urldate = {2023-02-12},
  abstract = {Background: Missing data is a common problem in epidemiological studies, and is particularly prominent in longitudinal data, which involve multiple waves of data collection. Traditional multiple imputation (MI) methods (fully conditional specification (FCS) and multivariate normal imputation (MVNI)) treat repeated measurements of the same time-dependent variable as just another `distinct' variable for imputation and therefore do not make the most of the longitudinal structure of the data. Only a few studies have explored extensions to the standard approaches to account for the temporal structure of longitudinal data. One suggestion is the two-fold fully conditional specification (two-fold FCS) algorithm, which restricts the imputation of a time-dependent variable to time blocks where the imputation model includes measurements taken at the specified and adjacent times. To date, no study has investigated the performance of two-fold FCS and standard MI methods for handling missing data in a timevarying covariate with a non-linear trajectory over time -- a commonly encountered scenario in epidemiological studies. Methods: We simulated 1000 datasets of 5000 individuals based on the Longitudinal Study of Australian Children (LSAC). Three missing data mechanisms: missing completely at random (MCAR), and a weak and a strong missing at random (MAR) scenarios were used to impose missingness on body mass index (BMI) for age z-scores; a continuous time-varying exposure variable with a non-linear trajectory over time. We evaluated the performance of FCS, MVNI, and two-fold FCS for handling up to 50\% of missing data when assessing the association between childhood obesity and sleep problems. Results: The standard two-fold FCS produced slightly more biased and less precise estimates than FCS and MVNI. We observed slight improvements in bias and precision when using a time window width of two for the two-fold FCS algorithm compared to the standard width of one. Conclusion: We recommend the use of FCS or MVNI in a similar longitudinal setting, and when encountering convergence issues due to a large number of time points or variables with missing values, the two-fold FCS with exploration of a suitable time window.},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/de silva et al_2017_a comparison of multiple imputation methods for handling missing values in.pdf}
}

@article{desmaraisTherapeuticTrialDesign2019,
  title = {Therapeutic Trial Design for Frontotemporal Dementia and Related Disorders},
  author = {Desmarais, Philippe and Rohrer, Jonathan D. and Nguyen, Quoc Dinh and Herrmann, Nathan and Stuss, Donald T. and Lang, Anthony E. and Boxer, Adam L. and Dickerson, Bradford C. and Rosen, Howie and {van Swieten}, John Cornelis and Meeter, Lieke H. and Borroni, Barbara and Tartaglia, Maria Carmela and Feldman, Howard H. and Black, Sandra E. and Masellis, Mario},
  year = {2019},
  month = apr,
  journal = {Journal of Neurology, Neurosurgery, and Psychiatry},
  volume = {90},
  number = {4},
  pages = {412--423},
  issn = {1468-330X},
  doi = {10.1136/jnnp-2018-318603},
  abstract = {The frontotemporal dementia (FTD) spectrum is a heterogeneous group of neurodegenerative syndromes with overlapping clinical, molecular and pathological features, all of which challenge the design of clinical trials in these conditions. To date, no pharmacological interventions have been proven effective in significantly modifying the course of these disorders. This study critically reviews the construct and methodology of previously published randomised controlled trials (RCTs) in FTD spectrum disorders in order to identify limitations and potential reasons for negative results. Moreover, recommendations based on the identified gaps are elaborated in order to guide future clinical trial design. A systematic literature review was carried out and presented in conformity with the Preferred Reporting Items for Systematic Reviews and Meta-Analyses criteria. A total of 23 RCTs in cohorts with diagnoses of behavioural and language variants of FTD, corticobasal syndrome and progressive supranuclear palsy syndrome were identified out of the 943 citations retrieved and were included in the qualitative review. Most studies identified were early-phase clinical trials that were small in size, short in duration and frequently underpowered. Diagnoses of populations enrolled in clinical trials were based on clinical presentation and rarely included precision-medicine tools, such as genetic and molecular testing. Uniformity and standardisation of research outcomes in the FTD spectrum are essential. Several elements should be carefully considered and planned in future clinical trials. We anticipate that precision-medicine approaches will be crucial to adequately address heterogeneity in the FTD spectrum research.},
  langid = {english},
  pmid = {30361298},
  keywords = {frontotemporal dementia,Frontotemporal Dementia,Frontotemporal Lobar Degeneration,Humans,neurogenetics,Outcome Assessment Health Care,pharmacology,randomised trials,Randomized Controlled Trials as Topic,Reference Standards,Research Design,Supranuclear Palsy Progressive,systematic reviews},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/desmarais et al_2019_therapeutic trial design for frontotemporal dementia and related disorders.pdf}
}

@article{devroyeConsistentDeconvolutionDensity1989,
  title = {Consistent Deconvolution in Density Estimation},
  author = {Devroye, Luc},
  year = {1989},
  journal = {The Canadian Journal of Statistics/La Revue Canadienne de Statistique},
  pages = {235--239},
  publisher = {JSTOR},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/devroye_1989_consistent deconvolution in density estimation.pdf;/Users/zenn/Zotero/storage/FL4GCJ2U/3314852.html}
}

@misc{diamondModJacquetLanglandsRelation2021,
  title = {A Mod p {{Jacquet-Langlands}} Relation and {{Serre}} Filtration via the Geometry of {{Hilbert}} Modular Varieties: {{Splicing}} and Dicing},
  shorttitle = {A Mod p {{Jacquet-Langlands}} Relation and {{Serre}} Filtration via the Geometry of {{Hilbert}} Modular Varieties},
  author = {Diamond, Fred and Kassaei, Payman and Sasaki, Shu},
  year = {2021},
  month = sep,
  number = {arXiv:2001.00530},
  eprint = {2001.00530},
  primaryclass = {math},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2001.00530},
  urldate = {2023-06-08},
  abstract = {We consider Hilbert modular varieties in characteristic p with Iwahori level at p and construct a geometric Jacquet-Langlands relation showing that the irreducible components are isomorphic to products of projective bundles over quaternionic Shimura varieties of level prime to p. We use this to establish a relation between mod p Hilbert and quaternionic modular forms that reflects the representation theory of GL\_2 in characteristic p and generalizes a result of Serre for classical modular forms. Finally we study the fibres of the degeneracy map to level prime to p and prove a cohomological vanishing result that is used to associate Galois representations to mod p Hilbert modular forms.},
  archiveprefix = {arXiv},
  keywords = {Mathematics - Number Theory},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/diamond et al_2021_a mod p jacquet-langlands relation and serre filtration via the geometry of.pdf;/Users/zenn/Zotero/storage/4R49D9BT/2001.html}
}

@misc{diamondModJacquetLanglandsRelation2021a,
  title = {A Mod p {{Jacquet-Langlands}} Relation and {{Serre}} Filtration via the Geometry of {{Hilbert}} Modular Varieties: {{Splicing}} and Dicing},
  shorttitle = {A Mod p {{Jacquet-Langlands}} Relation and {{Serre}} Filtration via the Geometry of {{Hilbert}} Modular Varieties},
  author = {Diamond, Fred and Kassaei, Payman and Sasaki, Shu},
  year = {2021},
  month = sep,
  number = {arXiv:2001.00530},
  eprint = {2001.00530},
  primaryclass = {math},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2001.00530},
  urldate = {2023-07-29},
  abstract = {We consider Hilbert modular varieties in characteristic p with Iwahori level at p and construct a geometric Jacquet-Langlands relation showing that the irreducible components are isomorphic to products of projective bundles over quaternionic Shimura varieties of level prime to p. We use this to establish a relation between mod p Hilbert and quaternionic modular forms that reflects the representation theory of GL\_2 in characteristic p and generalizes a result of Serre for classical modular forms. Finally we study the fibres of the degeneracy map to level prime to p and prove a cohomological vanishing result that is used to associate Galois representations to mod p Hilbert modular forms.},
  archiveprefix = {arXiv},
  keywords = {Mathematics - Number Theory},
  file = {/Users/zenn/Zotero/storage/MPH95IPR/Diamond et al. - 2021 - A mod p Jacquet-Langlands relation and Serre filtr.pdf;/Users/zenn/Zotero/storage/9DGD22DI/2001.html}
}

@article{diaz-galvanDifferentialResponseDonepezil2023,
  title = {Differential Response to Donepezil in {{MRI}} Subtypes of Mild Cognitive Impairment},
  author = {{Diaz-Galvan}, Patricia and Lorenzon, Giulia and Mohanty, Rosaleena and M{\aa}rtensson, Gustav and Cavedo, Enrica and Lista, Simone and Vergallo, Andrea and Kantarci, Kejal and Hampel, Harald and Dubois, Bruno and Grothe, Michel J. and Ferreira, Daniel and Westman, Eric},
  year = {2023},
  month = jun,
  journal = {Alzheimer's Research \& Therapy},
  volume = {15},
  number = {1},
  pages = {117},
  issn = {1758-9193},
  doi = {10.1186/s13195-023-01253-2},
  urldate = {2023-07-13},
  abstract = {Donepezil is an approved therapy for the treatment of Alzheimer's disease (AD). Results across clinical trials have been inconsistent, which may be explained by design-methodological issues, the pathophysiological heterogeneity of AD, and diversity of included study participants. We investigated whether response to donepezil differs in mild cognitive impaired (MCI) individuals demonstrating different magnetic resonance imaging (MRI) subtypes.},
  keywords = {Alzheimer's disease,Donepezil,Heterogeneity,Mild cognitive impairment,Precision medicine,Randomized controlled trial,Subtypes},
  file = {/Users/zenn/Zotero/storage/CRN5Z9N2/Diaz-Galvan et al. - 2023 - Differential response to donepezil in MRI subtypes.pdf;/Users/zenn/Zotero/storage/H9NLSYKZ/s13195-023-01253-2.html}
}

@misc{diepeveenCurvatureCorrectedTangent2023,
  title = {Curvature Corrected Tangent Space-Based Approximation of Manifold-Valued Data},
  author = {Diepeveen, Willem and Chew, Joyce and Needell, Deanna},
  year = {2023},
  month = jun,
  number = {arXiv:2306.00507},
  eprint = {2306.00507},
  primaryclass = {cs, math},
  publisher = {arXiv},
  urldate = {2023-06-04},
  abstract = {When generalizing schemes for real-valued data approximation or decomposition to data living in Riemannian manifolds, tangent space-based schemes are very attractive for the simple reason that these spaces are linear. An open challenge is to do this in such a way that the generalized scheme is applicable to general Riemannian manifolds, is global-geometry aware and is computationally feasible. Existing schemes have been unable to account for all three of these key factors at the same time. In this work, we take a systematic approach to developing a framework that is able to account for all three factors. First, we will restrict ourselves to the -- still general -- class of symmetric Riemannian manifolds and show how curvature affects general manifold-valued tensor approximation schemes. Next, we show how the latter observations can be used in a general strategy for developing approximation schemes that are also global-geometry aware. Finally, having general applicability and global-geometry awareness taken into account we restrict ourselves once more in a case study on low-rank approximation. Here we show how computational feasibility can be achieved and propose the curvature-corrected truncated higher-order singular value decomposition (CC-tHOSVD), whose performance is subsequently tested in numerical experiments with both synthetic and real data living in symmetric Riemannian manifolds with both positive and negative curvature.},
  archiveprefix = {arXiv},
  keywords = {53Z50 15A69 90C26 90C30 53-04 53-08 49Q99,Mathematics - Differential Geometry,Mathematics - Numerical Analysis,Mathematics - Optimization and Control},
  file = {/Users/zenn/Zotero/storage/5HJIYGHP/Diepeveen et al. - 2023 - Curvature corrected tangent space-based approximat.pdf;/Users/zenn/Zotero/storage/H7N6393M/2306.html}
}

@article{diggleFourierApproachNonparametric1993,
  title = {A {{Fourier Approach}} to {{Nonparametric Deconvolution}} of a {{Density Estimate}}},
  author = {Diggle, Peter J. and Hall, Peter},
  year = {1993},
  journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
  volume = {55},
  number = {2},
  eprint = {2346211},
  eprinttype = {jstor},
  pages = {523--531},
  publisher = {[Royal Statistical Society, Wiley]},
  issn = {0035-9246},
  urldate = {2023-03-01},
  abstract = {We consider the problem of constructing a nonparametric estimate of a probability density function h from independent random samples of observations from densities a and f, when a represents the convolution of h and f. Our approach is based on truncated Fourier inversion, in which the truncation point plays the role of a smoothing parameter. We derive the asymptotic mean integrated squared error of the estimate and use this formula to suggest a simple practical method for choosing the truncation point from the data. Strikingly, when the smoothing parameter is chosen in this way then in many circumstances the estimator behaves, to first order, as though the true f were known. Simulated data sets are used to demonstrate that the method can give good results in practice.},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/diggle_hall_1993_a fourier approach to nonparametric deconvolution of a density estimate.pdf}
}

@article{Dimitriadis2020,
  title = {How Random Is the Random Forest? {{Random}} Forest Algorithm on the Service of Structural Imaging Biomarkers for {{Alzheimer}}'s Disease: {{From Alzheimer}}'s Disease Neuroimaging Initiative ({{ADNI}}) Database},
  author = {Dimitriadis, Stavros I. and Liparas, Dimitris},
  year = {2018},
  month = jun,
  journal = {Neural Regeneration Research},
  volume = {13},
  number = {6},
  pages = {962--970},
  publisher = {Wolters Kluwer Medknow Publications},
  issn = {18767958},
  doi = {10.4103/1673-5374.233433},
  abstract = {Neuroinformatics is a fascinating research field that applies computational models and analytical tools to high dimensional experimental neuroscience data for a better understanding of how the brain functions or dysfunctions in brain diseases. Neuroinformaticians work in the intersection of neuroscience and informatics supporting the integration of various sub-disciplines (behavioural neuroscience, genetics, cognitive psychology, etc.) working on brain research. Neuroinformaticians are the pathway of information exchange between informaticians and clinicians for a better understanding of the outcome of computational models and the clinical interpretation of the analysis. Machine learning is one of the most significant computational developments in the last decade giving tools to neuroinformaticians and finally to radiologists and clinicians for an automatic and early diagnosis-prognosis of a brain disease. Random forest (RF) algorithm has been successfully applied to high-dimensional neuroimaging data for feature reduction and also has been applied to classify the clinical label of a subject using single or multi-modal neuroimaging datasets. Our aim was to review the studies where RF was applied to correctly predict the Alzheimer's disease (AD), the conversion from mild cognitive impairment (MCI) and its robustness to overfitting, outliers and handling of non-linear data. Finally, we described our RF-based model that gave us the 1st position in an international challenge for automated prediction of MCI from MRI data.},
  keywords = {adni,Alzheimer's disease,biomarker,classification,machine learning,magnetic resonance imaging,mild cognitive impairment,neuroimaging,random forest},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/dimitriadis_liparas_2018_how random is the random forest.pdf}
}

@misc{DissectingDomainsParkinson,
  title = {Dissecting the {{Domains}} of {{Parkinson}}'s {{Disease}}: {{Insights}} from {{Longitudinal Item Response Theory Modeling}} - {{Luo}} - 2022 - {{Movement Disorders}} - {{Wiley Online Library}}},
  urldate = {2024-01-18},
  howpublished = {https://movementdisorders.onlinelibrary.wiley.com/doi/full/10.1002/mds.29154},
  file = {/Users/zenn/Zotero/storage/FYGLBGBH/mds.html}
}

@article{dmit2003,
  title = {Fallback Tests in Dose-Response Clinical Trials},
  author = {Dmitrienko, Alex and Wiens, Brian and Westfall, Peter},
  year = {2006},
  month = oct,
  journal = {Journal of Biopharmaceutical Statistics},
  volume = {16},
  number = {5},
  pages = {745--755},
  issn = {10543406},
  doi = {10.1080/10543400600860600},
  abstract = {This article introduces a general testing procedure for performing dose-control comparisons in dose-response trials with one or more endpoints. The procedure (termed multi-stage fallback procedure) is an extension of the fallback test proposed by Wiens (2003). The multi-stage fallback procedure features a simple stepwise form and improves the power of dose-control tests at higher doses by taking into account the ordering of the doses. It also serves as an efficient tool for handling multiplicity caused by multiple endpoints. It is shown in this article that the multi-stage fallback procedure can be formulated as a closed testing procedure and thus controls the Type I error rate with respect to multiple dose-control comparisons as well as multiple endpoints. The proposed testing method is illustrated using examples from dose-response clinical trials with single and multiple endpoints. Copyright {\copyright} Taylor \& Francis Group, LLC.},
  pmid = {17037269},
  keywords = {Clinical trials,Dose-response,Multiple endpoints,Multiple tests},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/dmitrienko et al_2006_fallback tests in dose-response clinical trials.pdf}
}

@article{dmitrienkoStepwiseGatekeepingProcedures2006,
  title = {Stepwise {{Gatekeeping Procedures}} in {{Clinical Trial Applications}}},
  author = {Dmitrienko, Alex and Tamhane, Ajit C. and Wang, Xin and Chen, Xun},
  year = {2006},
  month = dec,
  journal = {Biometrical Journal},
  volume = {48},
  number = {6},
  pages = {984--991},
  issn = {03233847},
  doi = {10.1002/bimj.200610274},
  abstract = {This paper discusses multiple testing problems in which families of null hypotheses are tested in a sequential manner and each family serves as a gatekeeper for the subsequent families. Gatekeeping testing strategies of this type arise frequently in clinical trials with multiple objectives, e.g., multiple endpoints and/or multiple dose-control comparisons. It is demonstrated in this paper that the parallel gatekeeping procedure of Dmitrienko, Offen and Westfall (2003) admits a simple stepwise representation (n null hypotheses can be tested in n steps rather than 2n steps required in the closed procedure). The stepwise representation considerably simplifies the implementation of gatekeeping procedures in practice and provides an important insight into the nature of gatekeeping inferences. The derived stepwise gatekeeping procedure is illustrated using clinical trial examples. {\copyright} 2006 WILEY-VCH Verlag GmbH \& Co. KGaA.},
  pmid = {17240656},
  keywords = {Clinical trials,Multiple comparisons,Stepwise tests},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/dmitrienko et al_2006_stepwise gatekeeping procedures in clinical trial applications.pdf}
}

@article{dmitrienkoTradeoffbasedOptimizationCriteria2016,
  title = {Tradeoff-Based Optimization Criteria in Clinical Trials with Multiple Objectives and Adaptive Designs},
  author = {Dmitrienko, Alex and Paux, Gautier and Pulkstenis, Erik and Zhang, Jianliang},
  year = {2016},
  journal = {Journal of Biopharmaceutical Statistics},
  volume = {26},
  number = {1},
  pages = {120--140},
  publisher = {Taylor \& Francis},
  issn = {15205711},
  doi = {10.1080/10543406.2015.1092032},
  abstract = {The article discusses clinical trial optimization problems in the context of mid-to late-stage drug development. Using the Clinical Scenario Evaluation approach, main objectives of clinical trial optimization are formulated, including selection of clinically relevant optimization criteria, identification of sets of optimal and nearly optimal values of the parameters of interest, and sensitivity assessments. The paper focuses on a class of optimization criteria arising in clinical trials with several competing goals, termed tradeoff-based optimization criteria, and discusses key considerations in constructing and applying tradeoff-based criteria. The clinical trial optimization framework considered in the paper is illustrated using two case studies based on a clinical trial with multiple objectives and a two-stage clinical trial which utilizes adaptive decision rules.},
  pmid = {26391238},
  keywords = {Adaptive designs,clinical scenario evaluation,clinical trial optimization,clinical trials,multiple testing},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/dmitrienko et al_2016_tradeoff-based optimization criteria in clinical trials with multiple.pdf}
}

@article{dominguezEvidenceIrreversibleInhibition2012,
  title = {Evidence for Irreversible Inhibition of Glycogen Synthase Kinase-3{$\beta$} by Tideglusib},
  author = {Dom{\'i}nguez, Juan Manuel and Fuertes, Ana and Orozco, Leyre and {del Monte-Mill{\'a}n}, Mar{\'i}a and Delgado, Elena and Medina, Miguel},
  year = {2012},
  month = jan,
  journal = {The Journal of Biological Chemistry},
  volume = {287},
  number = {2},
  pages = {893--904},
  issn = {1083-351X},
  doi = {10.1074/jbc.M111.306472},
  abstract = {Tideglusib is a GSK-3 inhibitor currently in phase II clinical trials for the treatment of Alzheimer disease and progressive supranuclear palsy. Sustained oral administration of the compound to a variety of animal models decreases Tau hyperphosphorylation, lowers brain amyloid plaque load, improves learning and memory, and prevents neuronal loss. We report here that tideglusib inhibits GSK-3{$\beta$} irreversibly, as demonstrated by the lack of recovery in enzyme function after the unbound drug has been removed from the reaction medium and the fact that its dissociation rate constant is non-significantly different from zero. Such irreversibility may explain the non-competitive inhibition pattern with respect to ATP shown by tideglusib and perhaps other structurally related compounds. The replacement of Cys-199 by an Ala residue in the enzyme seems to increase the dissociation rate, although the drug retains its inhibitory activity with decreased potency and long residence time. In addition, tideglusib failed to inhibit a series of kinases that contain a Cys homologous to Cys-199 in their active site, suggesting that its inhibition of GSK-3{$\beta$} obeys to a specific mechanism and is not a consequence of nonspecific reactivity. Results obtained with [(35)S]tideglusib do not support unequivocally the existence of a covalent bond between the drug and GSK-3{$\beta$}. The irreversibility of the inhibition and the very low protein turnover rate observed for the enzyme are particularly relevant from a pharmacological perspective and could have significant implications on its therapeutic potential.},
  langid = {english},
  pmcid = {PMC3256883},
  pmid = {22102280},
  keywords = {Administration Oral,Alzheimer Disease,Animals,Cell Line,Clinical Trials Phase II as Topic,Enzyme Inhibitors,Glycogen Synthase Kinase 3,Glycogen Synthase Kinase 3 beta,Humans,Spodoptera,Structure-Activity Relationship},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/domínguez et al_2012_evidence for irreversible inhibition of glycogen synthase kinase-3β by.pdf}
}

@article{donohoHigherCriticismDetecting2004,
  title = {Higher {{Criticism}} for {{Detecting Sparse Heterogeneous Mixtures}}},
  author = {Donoho, David and Jin, Jiashun},
  year = {2004},
  journal = {The Annals of Statistics},
  volume = {32},
  number = {3},
  eprint = {3448581},
  eprinttype = {jstor},
  pages = {962--994},
  publisher = {Institute of Mathematical Statistics},
  issn = {0090-5364},
  urldate = {2023-12-15},
  abstract = {Higher criticism, or second-level significance testing, is a multiple-comparisons concept mentioned in passing by Tukey. It concerns a situation where there are many independent tests of significance and one is interested in rejecting the joint null hypothesis. Tukey suggested comparing the fraction of observed significances at a given {$\alpha$}-level to the expected fraction under the joint null. In fact, he suggested standardizing the difference of the two quantities and forming a z-score; the resulting z-score tests the significance of the body of significance tests. We consider a generalization, where we maximize this z-score over a range of significance levels \$0 {$<$} {\textbackslash}alpha {\textbackslash}leq {\textbackslash}alpha\_0\$. We are able to show that the resulting higher criticism statistic is effective at resolving a very subtle testing problem: testing whether n normal means are all zero versus the alternative that a small fraction is nonzero. The subtlety of this "sparse normal means" testing problem can be seen from work of Ingster and Jin, who studied such problems in great detail. In their studies, they identified an interesting range of cases where the small fraction of nonzero means is so small that the alternative hypothesis exhibits little noticeable effect on the distribution of the p-values either for the bulk of the tests or for the few most highly significant tests. In this range, when the amplitude of nonzero means is calibrated with the fraction of nonzero means, the likelihood ratio test for a precisely specified alternative would still succeed in separating the two hypotheses. We show that the higher criticism is successful throughout the same region of amplitude sparsity where the likelihood ratio test would succeed. Since it does not require a specification of the alternative, this shows that higher criticism is in a sense optimally adaptive to unknown sparsity and size of the nonnull effects. While our theoretical work is largely asymptotic, we provide simulations in finite samples and suggest some possible applications. We also show that higher critcism works well over a range of non-Gaussian cases.},
  file = {/Users/zenn/Zotero/storage/REPQILUG/Donoho and Jin - 2004 - Higher Criticism for Detecting Sparse Heterogeneou.pdf}
}

@article{donohoJournalComputationalGraphical2017,
  title = {Journal of {{Computational}} and {{Graphical Statistics}} 50 {{Years}} of {{Data Science}}},
  author = {Donoho, David},
  year = {2017},
  issn = {1537-2715},
  doi = {10.1080/10618600.2017.1384734},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/donoho_2017_journal of computational and graphical statistics 50 years of data science.pdf}
}

@article{Donohue2010,
  title = {Power for Linear Models of Longitudinal Data with Applications to {{Alzheimer}}'s {{Disease Phase II}} Study Design},
  author = {Donohue, M C and Edland, S D and Gamst, A C},
  year = {2010},
  number = {iid},
  pages = {1--7},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/donohue et al_2010_power for linear models of longitudinal data with applications to alzheimer’s.pdf}
}

@article{donohue2010o3,
  title = {O3-01-07: {{Rate}} of Decline in {{ADNI}} Normal Controls with Evidence of Amyloid Burden},
  author = {Donohue, Michael and Gamst, Anthony and Thomas, Ron and Brewer, Jim and Weiner, Michael and Aisen, Paul},
  year = {2010},
  journal = {Alzheimer's \& Dementia},
  volume = {6},
  pages = {S126--S126},
  publisher = {The Alzheimer's Association}
}

@article{donohue2011relative,
  title = {The Relative Efficiency of Time-to-Threshold and Rate of Change in Longitudinal Data},
  author = {Donohue, Michael C and Gamst, {\relax AC} and Thomas, {\relax RG} and Xu, R and Beckett, L and Petersen, {\relax RC} and Weiner, {\relax MW} and Aisen, P and Initiative, Alzheimer's Disease Neuroimaging and others},
  year = {2011},
  journal = {Contemporary clinical trials},
  volume = {32},
  number = {5},
  pages = {685--693},
  publisher = {Elsevier}
}

@article{donohue2014australian,
  title = {Australian Imaging, Biomarkers, and Lifestyle Flagship Study of Ageing; {{Alzheimer}}'s Disease Neuroimaging Initiative; {{Alzheimer}}'s Disease Cooperative Study. {{The}} Preclinical {{Alzheimer}} Cognitive Composite: Measuring Amyloid-Related Decline},
  author = {Donohue, {\relax MC} and Sperling, {\relax RA} and Salmon, {\relax DP} and Rentz, {\relax DM} and Raman, R and Thomas, {\relax RG} and Weiner, M and Aisen, {\relax PS}},
  year = {2014},
  journal = {JAMA neurology},
  volume = {71},
  number = {8},
  pages = {961--970}
}

@article{donohue2014estimating,
  title = {Estimating Long-Term Multivariate Progression from Short-Term Data},
  author = {Donohue, Michael C and {Jacqmin-Gadda}, H{\'e}l{\`e}ne and Le Goff, M{\'e}lanie and Thomas, Ronald G and Raman, Rema and Gamst, Anthony C and Beckett, Laurel A and Jack Jr, Clifford R and Weiner, Michael W and Dartigues, Jean-Fran{\c c}ois and others},
  year = {2014},
  journal = {Alzheimer's \& Dementia},
  volume = {10},
  pages = {S400--S410}
}

@article{donohue2014f3,
  title = {F3-02-02: {{MODELING LONG-TERM DISEASE PROGRESSION WITH COVARIATES}}},
  author = {Donohue, Michael C and Gamst, Anthony and Jack, Clifford and Beckett, Laurel and Weiner, Michael and Aisen, Paul and Raman, Rema and Thomas, Ronald},
  year = {2014},
  journal = {Alzheimer's \& Dementia},
  volume = {10},
  pages = {P203--P204},
  publisher = {The Alzheimer's Association}
}

@article{donohue2014preclinical,
  title = {The Preclinical {{Alzheimer}} Cognitive Composite: Measuring Amyloid-Related Decline},
  author = {Donohue, Michael C and Sperling, Reisa A and Salmon, David P and Rentz, Dorene M and Raman, Rema and Thomas, Ronald G and Weiner, Michael and Aisen, Paul S},
  year = {2014},
  journal = {JAMA neurology},
  volume = {71},
  number = {8},
  pages = {961--970},
  publisher = {American Medical Association}
}

@article{donohue2015longitudinal,
  title = {Longitudinal Plasma Amyloid {{ beta}} in {{Alzheimer}}'s Disease Clinical Trials},
  author = {Donohue, Michael C and Moghadam, Setareh H and Roe, Allyson D and Sun, Chung-Kai and Edland, Steven D and Thomas, Ronald G and Petersen, Ronald C and Sano, Mary and Galasko, Douglas and Aisen, Paul S and others},
  year = {2015},
  journal = {Alzheimer's \& Dementia},
  volume = {11},
  number = {9},
  pages = {1069--1079},
  publisher = {No longer published by Elsevier}
}

@misc{DonohueMixedModel,
  title = {Donohue: {{Mixed}} Model of Repeated Measures versus... - {{Google Scholar}}},
  urldate = {2023-08-12},
  howpublished = {https://scholar.google.com/scholar\_lookup?journal=J+Nutr+Health+Aging\&title=Mixed+model+of+repeated+measures+versus+slope+models+in+Alzheimer\%27s+disease+clinical+trials\&author=M.C.+Donohue\&author=P.S.+Aisen\&volume=16\&publication\_year=2012\&pages=360-364\&pmid=22499459\&},
  file = {/Users/zenn/Zotero/storage/PL2JIG7Z/scholar_lookup.html}
}

@article{donohueMixedModelRepeated2012,
  title = {Mixed Model of Repeated Measures versus Slope Models in {{Alzheimer}}'s Disease Clinical Trials},
  author = {Donohue, M. C. and Aisen, P. S.},
  year = {2012},
  month = apr,
  journal = {The journal of nutrition, health \& aging},
  volume = {16},
  number = {4},
  pages = {360--364},
  issn = {1760-4788},
  doi = {10.1007/s12603-012-0047-7},
  urldate = {2023-08-12},
  abstract = {Randomized clinical trials of Alzheimer's disease (AD) and Mild Cognitive Impairment (MCI) typically assess intervention efficacy with measures of cognitive or functional assessments repeated every six months for one to two years. The Mixed Model of Repeated Measures (MMRM), which assumes an ``unstructured mean'' by treating time as categorical, is attractive because it makes no assumptions about the shape of the mean trajectory of the outcome over time. However, categorical time models may be over-parameterized and inefficient in detecting treatment effects relative to continuous time models of, say, the linear trend of the outcome over time. Mixed effects models can also be extended to model quadratic time effects, although it is questionable whether the duration and interval of observations in AD and MCI studies is sufficient to support such models. Furthermore, it is unknown which of these models are most robust to missing data, which plagues AD and MCI studies. We review the literature and compare estimates of treatment effects from four potential models fit to data from five AD Cooperative Study (ADCS) trials in MCI and AD.},
  langid = {english},
  keywords = {Clinical trials efficiency,missing data,mixed effects models,mixed model of repeated measures (MMRM),quantitative review},
  file = {/Users/zenn/Zotero/storage/KSW8IABH/Donohue and Aisen - 2012 - Mixed model of repeated measures versus slope mode.pdf}
}

@article{donohueMixedModelRepeated2012a,
  title = {Mixed Model of Repeated Measures versus Slope Models in {{Alzheimer}}'s Disease Clinical Trials},
  author = {Donohue, M. C. and Aisen, P. S.},
  year = {2012},
  journal = {The journal of nutrition, health \& aging},
  volume = {16},
  pages = {360--364},
  publisher = {Springer},
  file = {/Users/zenn/Zotero/storage/EVSIBVBR/Donohue and Aisen - 2012 - Mixed model of repeated measures versus slope mode.pdf;/Users/zenn/Zotero/storage/MU23F8ZZ/s12603-012-0047-7.html}
}

@article{donohueRelativeEfficiencyTimetothreshold2011,
  title = {The Relative Efficiency of Time-to-Threshold and Rate of Change in Longitudinal Data},
  author = {Donohue, M. C. and Gamst, A. C. and Thomas, R. G. and Xu, R. and Beckett, L. and Petersen, R. C. and Weiner, M. W. and Aisen, P.},
  year = {2011},
  month = sep,
  journal = {Contemporary Clinical Trials},
  volume = {32},
  number = {5},
  pages = {685--693},
  issn = {1551-7144},
  doi = {10.1016/j.cct.2011.04.007},
  urldate = {2023-08-27},
  abstract = {Randomized, placebo-controlled trials often use time-to-event as the primary endpoint, even when a continuous measure of disease severity is available. We compare the power to detect a treatment effect using either rate of change, as estimated by linear models of longitudinal continuous data, or time-to-event estimated by Cox proportional hazards models. We propose an analytic inflation factor for comparing the two types of analyses assuming that the time-to-event can be expressed as a time-to-threshold of the continuous measure. We conduct simulations based on a publicly available Alzheimer's disease data set in which the time-to-event is algorithmically defined based on a battery of assessments. A Cox proportional hazards model of the time-to-event endpoint is compared to a linear model of a single assessment from the battery. The simulations also explore the impact of baseline covariates in either analysis.},
  keywords = {Linear mixed models,Longitudinal data,Marginal linear models,Power,Survival analysis},
  file = {/Users/zenn/Zotero/storage/U4D7Z8LN/Donohue et al. - 2011 - The relative efficiency of time-to-threshold and r.pdf;/Users/zenn/Zotero/storage/CQFJMJ8U/S1551714411000978.html}
}

@article{donohueRelativeEfficiencyTimetothreshold2011a,
  title = {The Relative Efficiency of Time-to-Threshold and Rate of Change in Longitudinal Data},
  author = {Donohue, M.C. and Gamst, A.C. and Thomas, R.G. and Xu, R. and Beckett, L. and Petersen, R.C. and Weiner, M.W. and Aisen, P.},
  year = {2011},
  month = sep,
  journal = {Contemporary Clinical Trials},
  volume = {32},
  number = {5},
  pages = {685--693},
  issn = {15517144},
  doi = {10.1016/j.cct.2011.04.007},
  urldate = {2023-08-27},
  abstract = {Randomized, placebo-controlled trials often use time-to-event as the primary endpoint, even when a continuous measure of disease severity is available. We compare the power to detect a treatment effect using either rate of change, as estimated by linear models of longitudinal continuous data, or time-to-event estimated by Cox proportional hazards models. We propose an analytic inflation factor for comparing the two types of analyses assuming that the time-toevent can be expressed as a time-to-threshold of the continuous measure. We conduct simulations based on a publicly available Alzheimer's disease data set in which the time-toevent is algorithmically defined based on a battery of assessments. A Cox proportional hazards model of the time-to-event endpoint is compared to a linear model of a single assessment from the battery. The simulations also explore the impact of baseline covariates in either analysis.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/QJIJ8K76/Donohue et al. - 2011 - The relative efficiency of time-to-threshold and r.pdf}
}

@inproceedings{doody2007dimebon,
  title = {Dimebon Improves Cognition, Function, and Behavior in Patients with Mild-Moderate {{Alzheimer}}'s Disease: {{Results}} of a Randomized, Double-Blind, Placebo-Controlled Study},
  booktitle = {Neurology},
  author = {Doody, Rochelle and Gavrilova, Svetlana and Sano, Mary and Thomas, Ronald and Aisen, Paul and Seely, Lynn and Hung, David},
  year = {2007},
  volume = {68},
  pages = {A353--A353},
  publisher = {LIPPINCOTT WILLIAMS \& WILKINS 530 WALNUT ST, PHILADELPHIA, PA 19106-3621 USA}
}

@article{doody2007results,
  title = {Results of a One-Year Randomized, Placebo-Controlled Trial of {{Dimebon}} for the Treatment of Mild to Moderate {{Alzheimer}}'s {{Disease}}},
  author = {Doody, {\relax RS} and Gavrilova, S and Sano, M and Thomas, R and Aisen, P and Bachurin, S and Seely, L and Hung, D},
  year = {2007},
  journal = {Alzheimer's and Dementia},
  volume = {3},
  pages = {S199--S200}
}

@article{doody2008dimebon,
  title = {Dimebon Investigators: {{Effect}} of Dimebon on Cognition, Activities of Daily Living, Behaviour, and Global Function in Patients with Mild-to-Moderate {{Alzheimer}}'s Disease: A Randomised, Double-Blind, Placebo-Controlled Study},
  author = {Doody, {\relax RS} and Gavrilova, {\relax SI} and Sano, M and Thomas, {\relax RG} and Aisen, {\relax PS} and Bachurin, {\relax SO} and Seely, L and Hung, D},
  year = {2008},
  journal = {Lancet (London, England)},
  volume = {372},
  number = {9634},
  pages = {207--215}
}

@article{doody2008effect,
  title = {Effect of Dimebon on Cognition, Activities of Daily Living, Behaviour, and Global Function in Patients with Mild-to-Moderate {{Alzheimer}}'s Disease: A Randomised, Double-Blind, Placebo-Controlled Study},
  author = {Doody, Rachelle S and Gavrilova, Svetlana I and Sano, Mary and Thomas, Ronald G and Aisen, Paul S and Bachurin, Sergey O and Seely, Lynn and Hung, David and others},
  year = {2008},
  journal = {The Lancet},
  volume = {372},
  number = {9634},
  pages = {207--215},
  publisher = {Elsevier}
}

@article{doody2008p4,
  title = {P4-337: {{Dimebon}} Improves Cognition, Function, and Behavior in Mild and Moderate {{Alzheimer}}'s Disease: {{Results}} by Severity of a One-Year, Double-Blind, Placebo-Controlled Study},
  author = {Doody, Rachelle S and Gavrilova, Svetlana and Thomas, Ronald and Aisen, Paul and Bachurin, Sergey and Seely, Lynn and Hung, David},
  year = {2008},
  journal = {Alzheimer''s and Dementia},
  volume = {4},
  number = {4},
  pages = {T771}
}

@article{doody2008statistical,
  title = {Statistical Treatment of Withdrawal in Trials of Anti-Dementia Drugs--{{Authors}}' Reply},
  author = {Doody, Rachelle and Seely, Lynn and Thomas, Ronald and Sano, Mary and Aisen, Paul},
  year = {2008},
  journal = {The Lancet},
  volume = {372},
  number = {9647},
  pages = {1383},
  publisher = {Elsevier}
}

@article{doody2013alzheimer,
  title = {Alzheimer's Disease Cooperative Study Steering Committee, Siemers {{E}}, Sethuraman {{G}}, Mohs {{R}}, Semagacestat Study Group. {{A}} Phase 3 Trial of Semagacestat for Treatment of Alzheimer's Disease},
  author = {Doody, {\relax RS} and Raman, R and Farlow, M and Iwatsubo, T and Vellas, B and Joffe, S and Kieburtz, K and He, F and Sun, X and Thomas, {\relax RG} and others},
  year = {2013},
  journal = {The New England journal of medicine},
  volume = {369},
  number = {4},
  pages = {341--50}
}

@article{doody2013phase,
  title = {A Phase 3 Trial of Semagacestat for Treatment of {{Alzheimer}}'s Disease},
  author = {Doody, Rachelle S and Raman, Rema and Farlow, Martin and Iwatsubo, Takeshi and Vellas, Bruno and Joffe, Steven and Kieburtz, Karl and He, Feng and Sun, Xiaoying and Thomas, Ronald G and others},
  year = {2013},
  journal = {New England Journal of Medicine},
  volume = {369},
  number = {4},
  pages = {341--350},
  publisher = {Mass Medical Soc}
}

@article{doody2014alzheimer,
  title = {Alzheimer's Disease Cooperative Study Steering Committee; Solanezumab Study Group. {{Phase}} 3 Trials of Solanezumab for Mild-to-Moderate Alzheimer's Disease},
  author = {Doody, {\relax RS} and Thomas, {\relax RG} and Farlow, M and Iwatsubo, T and Vellas, B and Joffe, S and Kieburtz, K and Raman, R and Sun, X and Aisen, {\relax PS} and others},
  year = {2014},
  journal = {The New England journal of medicine},
  volume = {370},
  number = {4},
  pages = {311--321}
}

@article{doody2014phase,
  title = {Phase 3 Trials of Solanezumab for Mild-to-Moderate {{Alzheimer}}'s Disease},
  author = {Doody, Rachelle S and Thomas, Ronald G and Farlow, Martin and Iwatsubo, Takeshi and Vellas, Bruno and Joffe, Steven and Kieburtz, Karl and Raman, Rema and Sun, Xiaoying and Aisen, Paul S and others},
  year = {2014},
  journal = {New England Journal of Medicine},
  volume = {370},
  number = {4},
  pages = {311--321},
  publisher = {Mass Medical Soc}
}

@article{doody2014phase,
  title = {" {{Phase}} 3 Trials of Solanezumab for Mild-to-Moderate {{Alzheimer}}'s Disease": {{Correction}}.},
  author = {Doody, Rachelle S and Thomas, Ronald G and Farlow, Martin and Iwatsubo, Takeshi and Vellas, Bruno and Joffe, Steven and Kieburtz, Karl and Raman, Rema and Sun, Xiaoying and Aisen, Paul S and others},
  year = {2014},
  publisher = {Massachusetts Medical Society}
}

@article{doody2015peripheral,
  title = {Peripheral and Central Effects of {{ gamma}}-Secretase Inhibition by Semagacestat in {{Alzheimer}}'s Disease},
  author = {Doody, Rachelle S and Raman, Rema and Sperling, Reisa A and Seimers, Eric and Sethuraman, Gopalan and Mohs, Richard and Farlow, Martin and Iwatsubo, Takeshi and Vellas, Bruno and Sun, Xiaoying and others},
  year = {2015},
  journal = {Alzheimer's research \& therapy},
  volume = {7},
  number = {1},
  pages = {1--7},
  publisher = {BioMed Central}
}

@article{dupontSensitivityFisherExact1986,
  title = {Sensitivity of {{Fisher}}'s Exact Test to Minor Perturbations in 2 {\texttimes} 2 Contingency Tables},
  author = {Dupont, William D.},
  year = {1986},
  journal = {Statistics in Medicine},
  volume = {5},
  number = {6},
  pages = {629--635},
  issn = {1097-0258},
  doi = {10.1002/sim.4780050610},
  urldate = {2023-02-05},
  abstract = {The two tailed Fisher's exact P value is extremely sensitive to small perturbations in 2 {\texttimes} 2 contingency tables. An example indicates that a 1 per cent increase in the denominator of one treatment group results in a 32 per cent drop in the exact P value, but a mere 0.1 per cent decrease in the treatment success rate. This is equivalent to the increase in significance obtained by a 20 per cent increase in the sample size of both treatments without changing the observed success rates. This drop results from small changes in the probabilities of unobserved events. A systematic evaluation of 920 pairs of similar contingency tables shows that these fluctuations occur frequently over a wide range of sample sizes and significance levels. Doubling the one tailed exact P value provides a more consistent measure of inferential strength. We discuss various chi-squared continuity corrections.},
  langid = {english},
  keywords = {Chi-squared tests,Contingency tables,Continuity corrections,Fisher's exact test,Likelihood principle},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/dupont_1986_sensitivity of fisher's exact test to minor perturbations in 2 × 2 contingency.pdf;/Users/zenn/Zotero/storage/FR28VVYG/sim.html}
}

@article{durairajGeometricusRepresentsProtein2020,
  title = {Geometricus {{Represents Protein Structures}} as {{Shape-mers Derived}} from {{Moment Invariants}}},
  author = {Durairaj, Janani and Akdel, Mehmet and {de Ridder}, Dick and {van Dijk}, Aalt D.J.},
  year = {2020},
  month = sep,
  journal = {bioRxiv},
  publisher = {bioRxiv},
  issn = {26928205},
  doi = {10.1101/2020.09.07.285569},
  abstract = {Motivation: As the number of experimentally solved protein structures rises, it becomes increasingly appealing to use structural information for predictive tasks involving proteins. Due to the large variation in protein sizes, folds, and topologies, an attractive approach is to embed protein structures into fixed-length vectors, which can be used in machine learning algorithms aimed at predicting and understanding functional and physical properties. Many existing embedding approaches are alignment-based, which is both time-consuming and ineffective for distantly related proteins. On the other hand, library- or model-based approaches depend on a small library of fragments or require the use of a trained model, both of which may not generalize well. Results: We present Geometricus, a novel and universally applicable approach to embedding proteins in a fixed-dimensional space. The approach is fast, accurate, and interpretable. Geometricus uses a set of 3D moment invariants to discretize fragments of protein structures into shape-mers, which are then counted to describe the full structure as a vector of counts. We demonstrate the applicability of this approach in various tasks, ranging from fast structure similarity search, unsupervised clustering, and structure classification across proteins from different superfamilies as well as within the same family.},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/durairaj et al_2020_geometricus represents protein structures as shape-mers derived from moment.pdf}
}

@article{dyrbaImproving3DConvolutional2021,
  title = {Improving {{3D}} Convolutional Neural Network Comprehensibility via Interactive Visualization of Relevance Maps: Evaluation in {{Alzheimer}}'s Disease},
  author = {Dyrba, Martin and Hanzig, Moritz and Altenstein, Slawek and Bader, Sebastian and Ballarini, Tommaso and Brosseron, Frederic and Buerger, Katharina and Cantr{\'e}, Daniel and Dechent, Peter and Dobisch, Laura and D{\"u}zel, Emrah and Ewers, Michael and Fliessbach, Klaus and Glanz, Wenzel and Haynes, John-Dylan and Heneka, Michael T. and Janowitz, Daniel and Keles, Deniz B. and Kilimann, Ingo and Laske, Christoph and Maier, Franziska and Metzger, Coraline D. and Munk, Matthias H. and Perneczky, Robert and Peters, Oliver and Preis, Lukas and Priller, Josef and Rauchmann, Boris and Roy, Nina and Scheffler, Klaus and Schneider, Anja and Schott, Bj{\"o}rn H. and Spottke, Annika and Spruth, Eike J. and Weber, Marc-Andr{\'e} and {Ertl-Wagner}, Birgit and Wagner, Michael and Wiltfang, Jens and Jessen, Frank and Teipel, Stefan J.},
  year = {2021},
  month = nov,
  journal = {Alzheimer's Research \& Therapy 2021 13:1},
  volume = {13},
  number = {1},
  pages = {1--18},
  publisher = {BioMed Central},
  issn = {1758-9193},
  doi = {10.1186/S13195-021-00924-2},
  urldate = {2021-11-29},
  abstract = {Although convolutional neural networks (CNNs) achieve high diagnostic accuracy for detecting Alzheimer's disease (AD) dementia based on magnetic resonance imaging (MRI) scans, they are not yet applied in clinical routine. One important reason for this is a lack of model comprehensibility. Recently developed visualization methods for deriving CNN relevance maps may help to fill this gap as they allow the visualization of key input image features that drive the decision of the model. We investigated whether models with higher accuracy also rely more on discriminative brain regions predefined by prior knowledge. We trained a CNN for the detection of AD in N = 663 T1-weighted MRI scans of patients with dementia and amnestic mild cognitive impairment (MCI) and verified the accuracy of the models via cross-validation and in three independent samples including in total N = 1655 cases. We evaluated the association of relevance scores and hippocampus volume to validate the clinical utility of this approach. To improve model comprehensibility, we implemented an interactive visualization of 3D CNN relevance maps, thereby allowing intuitive model inspection. Across the three independent datasets, group separation showed high accuracy for AD dementia versus controls (AUC {$\geq$} 0.91) and moderate accuracy for amnestic MCI versus controls (AUC {$\approx$} 0.74). Relevance maps indicated that hippocampal atrophy was considered the most informative factor for AD detection, with additional contributions from atrophy in other cortical and subcortical regions. Relevance scores within the hippocampus were highly correlated with hippocampal volumes (Pearson's r {$\approx$} -0.86, p {$<$} 0.001). The relevance maps highlighted atrophy in regions that we had hypothesized a priori. This strengthens the comprehensibility of the CNN models, which were trained in a purely data-driven manner based on the scans and diagnosis labels. The high hippocampus relevance scores as well as the high performance achieved in independent samples support the validity of the CNN models in the detection of AD-related MRI abnormalities. The presented data-driven and hypothesis-free CNN modeling approach might provide a useful tool to automatically derive discriminative features for complex diagnostic tasks where clear clinical criteria are still missing, for instance for the differential diagnosis between various types of dementia.},
  keywords = {Geriatric Psychiatry,Geriatrics/Gerontology,Neurology,Neurosciences,Risk factors,Time-to-event analysis,Vascular dementia},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/dyrba et al_2021_improving 3d convolutional neural network comprehensibility via interactive.pdf}
}

@article{ebellClinicallyImportantBenefits2024,
  title = {Clinically {{Important Benefits}} and {{Harms}} of {{Monoclonal Antibodies Targeting Amyloid}} for the {{Treatment}} of {{Alzheimer Disease}}: {{A Systematic Review}} and {{Meta-Analysis}}},
  shorttitle = {Clinically {{Important Benefits}} and {{Harms}} of {{Monoclonal Antibodies Targeting Amyloid}} for the {{Treatment}} of {{Alzheimer Disease}}},
  author = {Ebell, Mark H. and Barry, Henry C. and Baduni, Kanishka and Grasso, Gabrielle},
  year = {2024},
  month = jan,
  journal = {The Annals of Family Medicine},
  volume = {22},
  number = {1},
  pages = {50--62},
  issn = {1544-1709, 1544-1717},
  doi = {10.1370/afm.3050},
  urldate = {2024-02-04},
  abstract = {PURPOSE We conducted a meta-analysis to evaluate clinically meaningful benefits and harms of monoclonal antibodies targeting amyloid in patients with Alzheimer dementia. METHODS We searched PubMed, Cochrane CENTRAL, and 5 trial registries, as well as the reference lists of identified studies. We included randomized controlled trials comparing a monoclonal antibody with placebo at a dose consistent with that used in phase 3 trials or for Food and Drug Administration approval. Studies had to report at least 1 clinically relevant benefit or harm. Data were extracted independently by at least 2 researchers for random effects meta-analysis. Changes in cognitive and functional scales were compared between groups, and each difference was assessed to determine if it met the minimal clinically important difference (MCID). RESULTS We identified 19 publications with 23,202 total participants that evaluated 8 antiamyloid antibodies. There were small improvements over placebo in the Alzheimer's Disease Assessment Scale (ADAS)-Cog-11 to -14 score (standardized mean difference\,=\,-0.07; 95\% CI, -0.10 to -0.04), Mini Mental State Examination score (0.32 points; 95\% CI, 0.13 to 0.50), and Clinical Dementia Rating--Sum of Boxes scale score (mean difference\,=\,-0.18 points; 95\% CI, -0.34 to -0.03), and the combined functional scores (standardized mean difference\,=\,0.09; 95\% CI, 0.05 to 0.13). None of the changes, including those for lecanemab, aducanumab, and donanemab, exceeded the MCID. Harms included significantly increased risks of amyloid-related imaging abnormalities (ARIA)-edema (relative risk [RR]\,=\,10.29; number needed to harm [NNH]\,=\,9), ARIA-hemorrhage (RR\,=\,1.74; NNH\,=\,13), and symptomatic ARIA-edema (RR\,=\,24.3; NNH\,=\,86). CONCLUSIONS Although monoclonal antibodies targeting amyloid provide small benefits on cognitive and functional scales in patients with Alzheimer dementia, these improvements are far below the MCID for each outcome and are accompanied by clinically meaningful harms.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/VZ4HVEEI/50.full.pdf}
}

@article{edgarIncludingRandomCentre2021,
  title = {Including Random Centre Effects in Design, Analysis and Presentation of Multi-Centre Trials},
  author = {Edgar, Kate and Roberts, Ian and Sharples, Linda},
  year = {2021},
  month = may,
  journal = {Trials},
  volume = {22},
  number = {1},
  pages = {357},
  issn = {1745-6215},
  doi = {10.1186/s13063-021-05266-w},
  urldate = {2023-05-06},
  abstract = {In large multicentre trials in diverse settings, there is uncertainty about the need to adjust for centre variation in design and analysis. A key distinction is the difference between variation in outcome (independent of treatment) and variation in treatment effect. Through re-analysis of the CRASH-2 trial (2010), this study clarifies when and how to use multi-level models for multicentre studies with binary outcomes.},
  langid = {english},
  keywords = {Heterogeneity,Multi-centre trials,Random effects},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/edgar et al_2021_including random centre effects in design, analysis and presentation of.pdf}
}

@inproceedings{edland2005sample,
  title = {Sample Size Considerations in Dementia Prevention Trials: {{Data}} from the {{Alzheimer}}'s Disease {{Cooperative Study MCI Trial}}},
  booktitle = {{{NEUROLOGY}}},
  author = {Edland, {\relax SD} and May, S and Emond, {\relax JA} and Wolfson, T and Thal, L and Petersen, {\relax RC} and Thomas, {\relax RG}},
  year = {2005},
  volume = {64},
  pages = {A364--A365},
  publisher = {LIPPINCOTT WILLIAMS \& WILKINS 530 WALNUT ST, PHILADELPHIA, PA 19106-3621 USA}
}

@article{edlandCounterpointJinWeighted2020,
  title = {Counterpoint to {{Jin}} et al, {{On}} Weighted Composite Scores for Early {{Alzheimer}}'s Trials. {{Pharm Stat}}. 18 (2):239-47, 2019, {{DOI}}: 10.1002/Pst.1920},
  author = {Edland, Steven D. and Raghavan, Nandini and Ard, M. Colin},
  year = {2020},
  journal = {Pharmaceutical Statistics},
  volume = {19},
  number = {4},
  pages = {492--493},
  issn = {15391612},
  doi = {10.1002/pst.2007},
  pmid = {32147862},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/edland et al_2020_counterpoint to jin et al, on weighted composite scores for early alzheimer's.pdf}
}

@article{ehwerhemuephaMorePowerfulUnconditional2019,
  title = {A More Powerful Unconditional Exact Test of Homogeneity for 2 {\texttimes} {\emph{c}} Contingency Table Analysis},
  author = {Ehwerhemuepha, Louis and Sok, Heng and Rakovski, Cyril},
  year = {2019},
  month = oct,
  journal = {Journal of Applied Statistics},
  volume = {46},
  number = {14},
  pages = {2572--2582},
  issn = {0266-4763, 1360-0532},
  doi = {10.1080/02664763.2019.1601689},
  urldate = {2022-10-31},
  abstract = {The classical unconditional exact p-value test can be used to compare two multinomial distributions with small samples. This general hypothesis requires parameter estimation under the null which makes the test severely conservative. Similar property has been observed for Fisher's exact test with Barnard and Boschloo providing distinct adjustments that produce more powerful testing approaches. In this study, we develop a novel adjustment for the conservativeness of the unconditional multinomial exact p-value test that produces nominal type I error rate and increased power in comparison to all alternative approaches. We used a large simulation study to empirically estimate the 5th percentiles of the distributions of the p-values of the exact test over a range of scenarios and implemented a regression model to predict the values for twosample multinomial settings. Our results show that the new test is uniformly more powerful than Fisher's, Barnard's, and Boschloo's tests with gains in power as large as several hundred percent in certain scenarios. Lastly, we provide a real-life data example where the unadjusted unconditional exact test wrongly fails to reject the null hypothesis and the corrected unconditional exact test rejects the null appropriately.},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/ehwerhemuepha et al_2019_a more powerful unconditional exact test of homogeneity for 2 × ic-i.pdf}
}

@article{ellis1988angiographic,
  title = {Angiographic and Clinical Predictors of Acute Closure after Native Vessel Coronary Angioplasty.},
  author = {Ellis, {\relax SG} and Roubin, {\relax GS} and King 3rd, {\relax SB} and Douglas Jr, {\relax JS} and Weintraub, {\relax WS} and Thomas, {\relax RG} and Cox, {\relax WR}},
  year = {1988},
  journal = {Circulation},
  volume = {77},
  number = {2},
  pages = {372--379}
}

@article{ellis1989risk,
  title = {Risk Factors, Time Course and Treatment Effect for Restenosis after Successful Percutaneous Transluminal Coronary Angioplasty of Chronic Total Occlusion},
  author = {Ellis, Stephen G and Shaw, Richard E and Gershony, Gary and Thomas, Ronald and Roubin, Gary S and Douglas Jr, John S and Topol, Eric J and Startzer, Simon H and Myler, Richard K and King III, Spencer B},
  year = {1989},
  journal = {The American journal of cardiology},
  volume = {63},
  number = {13},
  pages = {897--901},
  publisher = {Excerpta Medica}
}

@article{emersonParameterEstimationFollowing1990,
  title = {Parameter Estimation Following Group Sequential Hypothesis Testing},
  author = {EMERSON, SCOTT S. and FLEMING, THOMAS R.},
  year = {1990},
  month = dec,
  journal = {Biometrika},
  volume = {77},
  number = {4},
  pages = {875--892},
  issn = {0006-3444},
  doi = {10.1093/biomet/77.4.875},
  urldate = {2024-03-30},
  abstract = {Parameter estimation techniques which fail to adjust for the interim analyses of group sequential test designs will introduce bias in much the same way that the repeated use of single sample hypothesis testing causes inflation of the type one statistical error rate. Methods based on the duality of hypothesis testing and interval estimation require definition of an ordering for the outcome space for the test statistic. In this paper, estimation following a group sequential hypothesis test for the mean of a normal distribution with known variance is investigated. A proposed ordering of the sample space based on the maximum likelihood estimate of the mean is found to result in estimates which compare favourably with estimates computed from orderings investigated by Tsiatis, Rosner \&amp; Mehta (1984) and Chang \&amp; O'Brien (1986) for a variety of group sequential designs. The proposed ordering is then adapted for use when the sizes of groups accrued between analyses is random.},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/emerson_fleming_1990_parameter estimation following group sequential hypothesis testing.pdf;/Users/zenn/Zotero/storage/PGXGIVCA/291010.html}
}

@misc{EmpiricalInvestigationGoodnessofFit,
  title = {An {{Empirical Investigation}} of {{Goodness-of-Fit Statistics}} for {{Sparse Multinomials}}: {{Journal}} of the {{American Statistical Association}}: {{Vol}} 75, {{No}} 370},
  urldate = {2024-02-09},
  howpublished = {https://www.tandfonline.com/doi/abs/10.1080/01621459.1980.10477473},
  file = {/Users/zenn/Zotero/storage/EAWZEBM2/01621459.1980.html}
}

@article{eschlbockInterventionalTrialsAtypical2016,
  title = {Interventional Trials in Atypical Parkinsonism},
  author = {Eschlb{\"o}ck, S. and Krismer, F. and Wenning, G. K.},
  year = {2016},
  month = jan,
  journal = {Parkinsonism \& Related Disorders},
  volume = {22 Suppl 1},
  pages = {S82-92},
  issn = {1873-5126},
  doi = {10.1016/j.parkreldis.2015.09.038},
  abstract = {Atypical parkinson disorders (APD) are rapidly progressive neurodegenerative diseases with a variable clinical presentation that may even mimic Parkinson's disease. Multiple system atrophy (MSA), progressive supranuclear palsy (PSP) and corticobasal degeneration (CBD) are commonly summarized under this umbrella term. Significant developments in research have expanded knowledge and have broadened available symptomatic treatments, particularly for the treatment of neurogenic orthostatic hypotension. Nonetheless, symptomatic support still remains limited in all of these disorders. Currently, there exists no effective treatment to delay disease progression and disease-modifying trials have failed to provide coherent and convincing results. Recent trials of rasagiline (in MSA), rifampicin (in MSA), tideglusib (in PSP) and davunetide (in PSP) reported negative results. Nevertheless, large cohorts of patients were recruited for interventional studies in the last few years which improved our understanding of trial methodology in APDs immensely. In addition, remarkable progress in basic research has been reported recently and will provide a solid foundation for future therapeutic trials. In this review, we will summarize published randomized, placebo-controlled clinical trials (RCTs) in APDs. Additionally, the design of ongoing and unpublished interventions will be presented.},
  langid = {english},
  pmid = {26421389},
  keywords = {Basal Ganglia Diseases,Calcium-Binding Proteins,Clinical trials,Corticobasal degeneration,Diagnosis Differential,Early Medical Intervention,Humans,Membrane Proteins,Multiple system atrophy,Multiple System Atrophy,Muscle Proteins,Parkinson Disease,Parkinsonian Disorders,Progressive supranuclear palsy,Randomized Controlled Trials as Topic,Supranuclear Palsy Progressive,Therapies}
}

@article{EuropeanMedicinesAgency2018,
  title = {Guideline on the Clinical Investigation of Medicines for the Treatment of {{Alzheimer}}'s Disease},
  author = {{European Medicines Agency}},
  year = {2018},
  volume = {44},
  number = {February},
  keywords = {30 churchill place,alzheimer biomarkers,Alzheimer biomarkers,alzheimer disease,Alzheimer disease,canary wharf,clinical  diagnostic criteria,clinical diagnostic criteria,london e14 5eu,preclinical alzheimer disease,preclinical Alzheimer disease,united kingdom},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/european medicines agency_2018_guideline on the clinical investigation of medicines for the treatment of.pdf}
}

@article{europeanmedicinesagencyICHE9R12017,
  title = {{{ICH E9}} ({{R1}}) Addendum on Estimands and Sensitivity Analysis in Clinical Trials to the Guideline on Statistical Principles for Clinical Trials - {{Step}} 2b},
  author = {{European Medicines Agency}},
  year = {2017},
  volume = {44},
  number = {August},
  pages = {1--23},
  abstract = {Telephone +44 (0)20 3660 6000 Facsimile +44 (0)20 3660 5555 Send a question via our website www.ema.europa.eu/contact},
  keywords = {ICH E9 (R1) addendum on estimands and sensitivity},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/european medicines agency_2017_ich e9 (r1) addendum on estimands and sensitivity analysis in clinical trials.pdf}
}

@article{evansBenefitriskEvaluationDiagnostics2016,
  title = {Benefit-Risk Evaluation for Diagnostics: A Framework ({{BED-FRAME}})},
  shorttitle = {Benefit-Risk Evaluation for Diagnostics},
  author = {Evans, Scott R. and Pennello, Gene and {Pantoja-Galicia}, Norberto and Jiang, Hongyu and Hujer, Andrea M. and Hujer, Kristine M. and Manca, Claudia and Hill, Carol and Jacobs, Michael R. and Chen, Liang},
  year = {2016},
  journal = {Clinical Infectious Diseases},
  volume = {63},
  number = {6},
  pages = {812--817},
  publisher = {Oxford University Press},
  urldate = {2024-06-21}
}

@article{evansBenefitriskEvaluationDiagnostics2016a,
  title = {Benefit-Risk {{Evaluation}} for {{Diagnostics}}: {{A Framework}} ({{BED-FRAME}})},
  shorttitle = {Benefit-Risk {{Evaluation}} for {{Diagnostics}}},
  author = {Evans, Scott R. and Pennello, Gene and {Pantoja-Galicia}, Norberto and Jiang, Hongyu and Hujer, Andrea M. and Hujer, Kristine M. and Manca, Claudia and Hill, Carol and Jacobs, Michael R. and Chen, Liang and Patel, Robin and Kreiswirth, Barry N. and Bonomo, Robert A.},
  editor = {Weinstein, Robert A.},
  year = {2016},
  month = sep,
  journal = {Clinical Infectious Diseases},
  volume = {63},
  number = {6},
  pages = {812--817},
  issn = {1058-4838, 1537-6591},
  doi = {10.1093/cid/ciw329},
  urldate = {2024-06-21},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/CGN7NWIL/Evans et al. - 2016 - Benefit-risk Evaluation for Diagnostics A Framewo.pdf}
}

@article{evansUsingOutcomesAnalyze2016,
  title = {Using {{Outcomes}} to {{Analyze Patients Rather}} than {{Patients}} to {{Analyze Outcomes}}: {{A Step Toward Pragmatism}} in {{Benefit}}:{{Risk Evaluation}}},
  author = {Evans, Scott R. and Follmann, Dean},
  year = {2016},
  month = oct,
  journal = {Statistics in Biopharmaceutical Research},
  volume = {8},
  number = {4},
  pages = {386--393},
  publisher = {{Taylor and Francis Inc.}},
  issn = {19466315},
  doi = {10.1080/19466315.2016.1207561},
  abstract = {In the future, clinical trials will have an increased emphasis on pragmatism, providing a practical description of the effects of new treatments in realistic clinical settings. Accomplishing pragmatism requires better summaries of the totality of the evidence in ways that clinical trials consumers---patients, physicians, insurers---find transparent and allow for informed benefit:risk decision-making. The current approach to the analysis of clinical trials is to analyze efficacy and safety separately and then combine these analyses into a benefit:risk assessment. Many assume that this will effectively describe the impact on patients. But this approach is suboptimal for evaluating the totality of effects on patients. We discuss methods for benefit:risk assessment that have greater pragmatism than methods that separately analyze efficacy and safety. These include the concepts of within-patient analyses and composite benefit:risk endpoints with a goal of understanding how to analyze one patient before trying to figure out how to analyze many. We discuss the desirability of outcome ranking (DOOR) and introduce the partial credit strategy using an example in a clinical trial evaluating the effects of a new antibiotic. As part of the example, we introduce a strategy to engage patients as a resource to inform benefit:risk analyses consistent with the goal of measuring and weighing outcomes that are most important from the patient's perspective. We describe a broad vision for the future of clinical trials consistent with increased pragmatism. Greater focus on using endpoints to analyze patients rather than patients to analyze endpoints particularly in late-phase/stage clinical trials is an important part of this vision.},
  keywords = {Benefit:risk,Clinical trials,DOOR,Partial credit strategy,Pragmatism},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/evans_follmann_2016_using outcomes to analyze patients rather than patients to analyze outcomes.pdf}
}

@misc{ExactInferenceKendall,
  title = {Exact {{Inference}} for {{Kendall}}'s {{S}} and {{Spearman}}'s {$\rho$} with {{Extension}} to {{Fisher}}'s {{Exact Test}} in r {\texttimes} c {{Contingency Tables}}},
  issn = {1061-8600},
  urldate = {2024-05-01},
  howpublished = {https://www.tandfonline.com/doi/epdf/10.1080/10618600.1994.10474658?needAccess=true},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/KTBQY8V9/10618600.1994.html}
}

@misc{ExactPowerConditional,
  title = {Exact {{Power}} of {{Conditional}} and {{Unconditional Tests}}: {{Going}} beyond the 2 {\texttimes} 2 {{Contingency Table}}},
  shorttitle = {Exact {{Power}} of {{Conditional}} and {{Unconditional Tests}}},
  issn = {0003-1305},
  urldate = {2023-08-12},
  howpublished = {https://www.tandfonline.com/doi/epdf/10.1080/00031305.1993.10475946?needAccess=true},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/WIBJQMRN/00031305.1993.html}
}

@article{fengDissolutionReassemblyFurther,
  title = {The Dissolution, Reassembly and Further Clearance of Amyloid-{$\beta$} Fibrils by Tailor-Designed Dissociable Nanosystem for {{Alzheimer}}'s Disease Therapy},
  author = {Feng, Qianhua and Zhang, Xueli and Zhang, Nan and Gu, Huan and Wang, Ning and Chen, Jing and Yuan, Xiaomin and Wang, Lei},
  journal = {Exploration},
  volume = {n/a},
  number = {n/a},
  pages = {20230048},
  issn = {2766-2098},
  doi = {10.1002/EXP.20230048},
  urldate = {2023-12-07},
  abstract = {The fibrillation of amyloid-{$\beta$} (A{$\beta$}) is the critical causal factor in Alzheimer's disease (AD), the dissolution and clearance of which are promising for AD therapy. Although many A{$\beta$} inhibitors are developed, their low A{$\beta$}-binding affinity results in unsatisfactory effect. To solve this challenge, the A{$\beta$} sequence-matching strategy is proposed to tail-design dissociable nanosystem (B6-PNi NPs). Herein, B6-PNi NPs aim to improve A{$\beta$}-binding affinity for effective dissolution of amyloid fibrils, as well as to interfere with the in vivo fate of amyloid for A{$\beta$} clearance. Results show that B6-PNi NPs decompose into small nanostructures and expose A{$\beta$}-binding sites in response to AD microenvironment, and then capture A{$\beta$} via multiple interactions, including covalent linkage formed by nucleophilic substitution reaction. Such high A{$\beta$}-binding affinity disassembles A{$\beta$} fibrils into A{$\beta$} monomers, and induces the reassembly of A{$\beta\&$}nanostructure composite, thereby promoting microglial A{$\beta$} phogocytosis/clearance via A{$\beta$} receptor-mediated endocytosis. After B6-PNi NPs treatment, the A{$\beta$} burden, neuroinflammation and cognitive impairments are relieved in AD transgenic mice. This work provides the A{$\beta$} sequence-matching strategy for A{$\beta$} inhibitor design in AD treatment, showing meaningful insight in biomedicine.},
  langid = {english},
  keywords = {Alzheimer's disease,amyloid-,dissociable nanosystem,neuroinflammation},
  file = {/Users/zenn/Zotero/storage/MGAA5JYR/Feng et al. - The dissolution, reassembly and further clearance .pdf;/Users/zenn/Zotero/storage/3ZZS9FIN/EXP.html}
}

@article{fergussonPostrandomisationExclusionsIntention2002,
  title = {Post-Randomisation Exclusions: The Intention to Treat Principle and Excluding Patients from Analysis},
  shorttitle = {Post-Randomisation Exclusions},
  author = {Fergusson, D.},
  year = {2002},
  month = sep,
  journal = {BMJ},
  volume = {325},
  number = {7365},
  pages = {652--654},
  issn = {09598138, 14685833},
  doi = {10.1136/bmj.325.7365.652},
  urldate = {2024-03-06},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/LJSAC45T/Ferguson_ITT_BMJ2002.pdf}
}

@article{ferreiraHierarchicalBayesianModel2021,
  title = {A Hierarchical {{Bayesian}} Model to Find Brain-Behaviour Associations in Incomplete Data Sets},
  author = {Ferreira, Fabio S. and Mihalik, Agoston and Adams, Rick A. and Ashburner, John and {Mourao-Miranda}, Janaina},
  year = {2021},
  month = mar,
  journal = {arXiv:2103.06845 [cs, stat]},
  eprint = {2103.06845},
  primaryclass = {cs, stat},
  urldate = {2021-03-13},
  abstract = {Canonical Correlation Analysis (CCA) and its regularised versions have been widely used in the neuroimaging community to uncover multivariate associations between two data modalities (e.g., brain imaging and behaviour). However, these methods have inherent limitations: (1) statistical inferences about the associations are often not robust; (2) the associations within each data modality are not modelled; (3) missing values need to be imputed or removed. Group Factor Analysis (GFA) is a hierarchical model that addresses the first two limitations by providing Bayesian inference and modelling modality-specific associations. Here, we propose an extension of GFA that handles missing data, and highlight that GFA can be used as a predictive model. We applied GFA to synthetic and real data consisting of brain connectivity and non-imaging measures from the Human Connectome Project (HCP). In synthetic data, GFA uncovered the underlying shared and specific factors and predicted correctly the non-observed data modalities in complete and incomplete data sets. In the HCP data, we identified four relevant shared factors, capturing associations between mood, alcohol and drug use, cognition, demographics and psychopathological measures and the default mode, frontoparietal control, dorsal and ventral networks and insula, as well as two factors describing associations within brain connectivity. In addition, GFA predicted a set of non-imaging measures from brain connectivity. These findings were consistent in complete and incomplete data sets, and replicated previous findings in the literature. GFA is a promising tool that can be used to uncover associations between and within multiple data modalities in benchmark datasets (such as, HCP), and easily extended to more complex models to solve more challenging tasks.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/ferreira et al_2021_a hierarchical bayesian model to find brain-behaviour associations in.pdf;/Users/zenn/Zotero/storage/5ANDF5KC/2103.html}
}

@article{ferry1998design,
  title = {Design and Baseline Characteristics of the Veterans Affairs Non-{{Q-wave}} Infarction Strategies in-Hospital ({{VANQWISH}}) Trial},
  author = {Ferry, David R and O'Rourke, Robert A and Blaustein, Alvin S and Crawford, Michael H and Deedwania, Prakash C and Carson, Peter E and Zoble, Robert G and Pepine, Carl J and Thomas, Ronald G and Chow, Bruce K and others},
  year = {1998},
  journal = {Journal of the American College of Cardiology},
  volume = {31},
  number = {2},
  pages = {312--320},
  publisher = {American College of Cardiology Foundation Washington, DC}
}

@misc{fischerMathematicalModelAlzheimer2023,
  title = {A Mathematical Model of the {{Alzheimer}}'s {{Disease}} Biomarker Cascade Demonstrates Statistical Pitfalls in Identifying Neurobiological Surrogates of Cognitive Reserve},
  author = {Fischer, Florian Udo and Gerber, Susanne and Tuescher, Oliver},
  year = {2023},
  month = oct,
  primaryclass = {New Results},
  pages = {2023.10.26.563793},
  publisher = {bioRxiv},
  doi = {10.1101/2023.10.26.563793},
  urldate = {2023-10-30},
  abstract = {Introduction: In order to investigate neurobiological surrogates of cognitive reserve, statistical interaction analyses have been put forward and used by several studies. However, as these neurobiological surrogates are potentially affected by neurodegeneration as part of the amyloid cascade, which is characterized by chronological time-moderated associations between biomarkers, cross sectional sampling in combination with the disregard of time as a confounder could introduce interaction effects that may be misinterpretabed as cognitive reserve in statistical analyses. Methods: We modeled the amyloid cascade with a minimal set of three biomarkers amyloid load, corticospinal fluid tau, hippocampal volume and cognitive outcome using a differential equation system, whose parameters were estimated from empirical data from the ADNI. Interaction effects between pathology markers amyloid and tau with hippocampal volume as potential marker of cognitive reserve were estimated on two simulated data samples. Both samples were calculated from varying amyloid, tau and hippocampal volume for the initial configuration of individual trajectories. For Sample 1, data points were sampled at a fixed time after baseline. For Sample 2, data points were sampled at random time points. Results: Regression analyses on Sample 1 yielded estimates for interaction effects of 0. For Sample 2, estimates were -.1692 and -.0807 for amyloid and tau with hippocampal volume, respectively. The interaction effect estimates for Sample 2 decreased several orders of magnitude when taking into account the timepoint of sampling. Conclusion: Studies aiming to investigate neurobiological surrogates of cognitive reserve that are affected by Alzheimer's Disease-related neurodegenerative processes need to consider inter-individually varying sampling time points in the data to avoid misinterpreting interaction effects.},
  archiveprefix = {bioRxiv},
  chapter = {New Results},
  copyright = {{\copyright} 2023, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/CNJWL4S5/Fischer et al. - 2023 - A mathematical model of the Alzheimer's Disease bi.pdf}
}

@misc{FisherLogicInductive,
  title = {Fisher, the Logic of Inductive Inference - {{Google Scholar}}},
  urldate = {2024-07-06},
  howpublished = {https://scholar.google.com/scholar?hl=en\&as\_sdt=0\%2C5\&q=fisher\%2C+the+logic+of+inductive+inference\&btnG=},
  file = {/Users/zenn/Zotero/storage/RFD453BR/scholar.html}
}

@article{fisherLogicInductiveInference1935,
  title = {The {{Logic}} of {{Inductive Inference}}},
  author = {Fisher, R. A.},
  year = {1935},
  journal = {Journal of the Royal Statistical Society},
  volume = {98},
  number = {1},
  eprint = {2342435},
  eprinttype = {jstor},
  pages = {39--82},
  publisher = {[Wiley, Royal Statistical Society]},
  issn = {0952-8385},
  doi = {10.2307/2342435},
  urldate = {2024-07-06},
  file = {/Users/zenn/Zotero/storage/YESGHYGI/Fisher - 1935 - The Logic of Inductive Inference.pdf}
}

@article{fleisher2010p1,
  title = {P1-433: {{Brain}} Volume Changes with Divalproex Sodium in {{Alzheimer}}'s Disease},
  author = {Fleisher, Adam S and Jack Jr, Clifford R and Weiner, Michael W and Truran, Diana and Mai, Jacqueline and Aisen, Paul S and Cummings, Jeffrey L and Thomas, Ronald G and Schneider, Lon S and Tariot, Pierre N},
  year = {2010},
  journal = {Alzheimer's \& Dementia},
  volume = {6},
  pages = {S302--S303},
  publisher = {The Alzheimer's Association}
}

@article{fleisher2011chronic,
  title = {Chronic Divalproex Sodium Use and Brain Atrophy in {{Alzheimer}} Disease},
  author = {Fleisher, {\relax AS} and Truran, D and Mai, {\relax JT} and Langbaum, {\relax JBS} and Aisen, {\relax PS} and Cummings, {\relax JL} and Jack, {\relax CR} and Weiner, {\relax MW} and Thomas, {\relax RG} and Schneider, {\relax LS} and others},
  year = {2011},
  journal = {Neurology},
  volume = {77},
  number = {13},
  pages = {1263--1271},
  publisher = {Wolters Kluwer Health, Inc. on behalf of the American Academy of Neurology}
}

@article{fleishmanProgramCalculatingExact1977,
  title = {A Program for Calculating the Exact Probability along with Explorations of {{M}} by {{N}} Contingency Tables},
  author = {Fleishman, Allen I.},
  year = {1977},
  journal = {Educational and Psychological Measurement},
  volume = {37},
  number = {3},
  pages = {799--803},
  publisher = {Sage Publications Sage CA: Thousand Oaks, CA}
}

@article{flemingOneSampleMultipleTesting1982,
  title = {One-{{Sample Multiple Testing Procedure}} for {{Phase II Clinical Trials}}},
  author = {Fleming, Thomas R.},
  year = {1982},
  journal = {Biometrics},
  volume = {38},
  number = {1},
  eprint = {2530297},
  eprinttype = {jstor},
  pages = {143--151},
  publisher = {[Wiley, International Biometric Society]},
  issn = {0006-341X},
  doi = {10.2307/2530297},
  urldate = {2024-03-19},
  abstract = {Commonly, the central objective of Phase II clinical trials is the assessment of the antitumor 'therapeutic efficacy' of a specific treatment regimen. It is of interest to formulate test procedures which can be employed in these trials to decide whether or not this therapeutic efficacy warrants further investigation. For ethical reasons, these procedures should allow for early termination if initial results are extreme. In this paper, a one-sample multiple testing procedure is proposed which employs the standard single-stage test procedure at the last test, and which both allows for early termination and essentially preserves the size, power and simplicity of the single-stage procedure.},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/fleming_1982_one-sample multiple testing procedure for phase ii clinical trials.pdf}
}

@article{follmannTwoStageDesigns,
  title = {Two {{Stage Designs}} for {{Phase III Clinical Trials}}},
  author = {Follmann, Dean and Proschan, Michael},
  doi = {10.1101/2020.07.29.20164525},
  urldate = {2022-01-30},
  abstract = {Phase III platform trials are increasingly used to evaluate a sequence of treatments for a specific disease. Traditional approaches to structure such trials tend to focus on the sequential questions rather than the performance of the entire enterprise. We consider two-stage trials where an early evaluation is used to determine whether to continue with an individual study. To evaluate performance, we use the ratio of expected wins (RW), that is, the expected number of reported efficacious treatments using a two-stage approach compared to that using standard phase III trials. We approximate the test statistics during the course of a single trial using Brow-nian Motion and determine the optimal stage 1 time and type I error rate to maximize RW for fixed power. At times, a surrogate or intermediate endpoint may provide a quicker read on potential efficacy than use of the primary endpoint at stage 1. We generalize our approach to the surrogate endpoint setting and show improved performance, provided a good quality and powerful surrogate is available. We apply our methods to the design of a platform trial to evaluate treatments for COVID-19 disease.},
  keywords = {Brownian Motion; Optimal Design,Platform Trial,Surrogate Endpoint,Two-Stage Design},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/follmann_proschan_two stage designs for phase iii clinical trials.pdf}
}

@article{foodanddrugadministrationAdaptiveDesignClinical2019,
  title = {Adaptive {{Design Clinical Trials}} for {{Drugs}} and {{Biologics Guidance}} for {{Industry}}},
  author = {{Food and Drug Administration}},
  year = {2019},
  number = {November},
  abstract = {This document provides guidance to sponsors and applicants submitting investigational new drug applications (INDs), new drug applications (NDAs), biologics licensing applications (BLAs), or supplemental applications on the appropriate use of adaptive designs for clinical trials to provide evidence of the effectiveness and safety of a drug or biologic. The guidance describes important principles for designing, conducting, and reporting the results from an adaptive clinical trial. The guidance also advises sponsors on the types of information to submit to facilitate FDA evaluation of clinical trials with adaptive designs, including Bayesian adaptive and complex trials that rely on computer simulations for their design.},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/food and drug administration_2019_adaptive design clinical trials for drugs and biologics guidance for industry.pdf}
}

@article{foodanddrugadministrationE9R1Statistical2021,
  title = {E9({{R1}}) {{Statistical Principles}} for {{Clinical Trials}}: {{Addendum}}: {{Estimands}} and {{Sensitivity Analysis}} in {{Clinical Trials}}. {{International Council}} for {{Harmonisation}}. {{Guidance}} for {{Industry}}.},
  author = {{Food and Drug Administration}},
  year = {2021},
  journal = {Federal Register},
  volume = {86 FR 2604},
  number = {May},
  pages = {26047--26048},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/food and drug administration_2021_e9(r1) statistical principles for clinical trials.pdf}
}

@article{fosterFailureCholinergicAgonist1989,
  title = {Failure of Cholinergic Agonist {{RS-86}} to Improve Cognition and Movement in {{PSP}} despite Effects on Sleep},
  author = {Foster, N. L. and Aldrich, M. S. and Bluemlein, L. and White, R. F. and Berent, S.},
  year = {1989},
  month = feb,
  journal = {Neurology},
  volume = {39},
  number = {2 Pt 1},
  pages = {257--261},
  issn = {0028-3878},
  doi = {10.1212/wnl.39.2.257},
  abstract = {Postmortem studies of patients with progressive supranuclear palsy (PSP) have demonstrated loss of cholinergic neurons in the striatum, nucleus basalis of Meynert, and the pedunculopontine nucleus. These findings suggest that cholinergic drugs might be an effective treatment for this disease. We studied the efficacy of RS-86, a direct cholinergic agonist, upon motor abilities, eye movements, and psychometric performance in 10 patients with PSP during a 9-week placebo-controlled, double-blinded, crossover trial. Glycopyrrolate, a peripheral anticholinergic drug, was given throughout the trial to minimize cholinergic side effects. We used changes in rapid eye movement (REM) sleep to assess the degree of cholinergic activation achieved by treatment. Despite the enhancement of cholinergic activity in the CNS as indicated by increases in REM sleep latency and REM sleep time, RS-86 did not improve motor signs, eye movements, or cognition. Pharmacologic replacement of the cholinergic deficits in PSP does not result in significant clinical benefit.},
  langid = {english},
  pmid = {2644580},
  keywords = {Aged,Clinical Trials as Topic,Cognition,Female,Humans,Male,Middle Aged,Movement,Parasympathomimetics,Sleep,Succinimides,Supranuclear Palsy Progressive}
}

@article{francaEffectsCerebellarNeuromodulation2018,
  title = {Effects of Cerebellar Neuromodulation in Movement Disorders: {{A}}~Systematic Review},
  shorttitle = {Effects of Cerebellar Neuromodulation in Movement Disorders},
  author = {Fran{\c c}a, Carina and {de Andrade}, Daniel Ciampi and Teixeira, Manoel Jacobsen and Galhardoni, Ricardo and Silva, Valquiria and Barbosa, Egberto Reis and Cury, Rubens Gisbert},
  year = {2018},
  journal = {Brain Stimulation},
  volume = {11},
  number = {2},
  pages = {249--260},
  issn = {1876-4754},
  doi = {10.1016/j.brs.2017.11.015},
  abstract = {BACKGROUND: The cerebellum is involved in the pathophysiology of many movement disorders and its importance in the field of neuromodulation is growing. OBJECTIVES: To review the current evidence for cerebellar modulation in movement disorders and its safety profile. METHODS: Eligible studies were identified after a systematic literature review of the effects of cerebellar modulation in cerebellar ataxia, Parkinson's disease (PD), essential tremor (ET), dystonia and progressive supranuclear palsy (PSP). Neuromodulation techniques included transcranial magnetic stimulation (TMS), transcranial direct current stimulation (tDCS) and deep brain stimulation (DBS). The changes in motor scores and the incidence of adverse events after the stimulation were reviewed. RESULTS: Thirty-four studies were included in the systematic review, comprising 431 patients. The evaluation after stimulation ranged from immediately after to 12 months after. Neuromodulation techniques improved cerebellar ataxia due to vascular or degenerative etiologies (TMS, tDCS and DBS), dyskinesias in PD patients (TMS), gross upper limb movement in PD patients (tDCS), tremor in ET (TMS and tDCS), cervical dystonia (TMS and tDCS) and dysarthria in PSP patients (TMS). All the neuromodulation techniques were safe, since only three studies reported the existence of side effects (slight headache after TMS, local skin erythema after tDCS and infectious complication after DBS). Eleven studies did not mention if adverse events occurred. CONCLUSIONS: Cerebellar modulation can improve specific symptoms in some movement disorders and is a safe and well-tolerated procedure. Further studies are needed to lay the groundwork for new researches in this promising target.},
  langid = {english},
  pmid = {29191439},
  keywords = {Cerebellum,Clinical Trials as Topic,Deep brain stimulation,Deep Brain Stimulation,Direct current stimulation,Humans,Movement disorders,Movement Disorders,Neuromodulation,Parkinson Disease,Transcranial Direct Current Stimulation,Transcranial magnetic stimulation,Transcranial Magnetic Stimulation,Treatment Outcome}
}

@article{Francis1999a,
  title = {The Cholinergic Hypothesis of {{Alzheimer}} ' s Disease : A Review of Progress},
  author = {Francis, Paul T and Palmer, Alan M and Snape, Michael and Wilcock, Gordon K},
  year = {1999},
  pages = {137--147},
  abstract = {Alzheimer's disease is one of the most common causes of mental deterioration in elderly people, accounting for around 50\%- 60\% of the overall cases of dementia among persons over 65 years of age. The past two decades have witnessed a considerable research eVort directed towards discover- ing the cause of Alzheimer's disease with the ultimate hope of developing safe and eVective pharmacological treatments. This article examines the existing scientific applicability of the original cholinergic hypothesis of Alzheimer's disease by de- scribing the biochemical and histopatho- logical changes of neurotransmitter markers that occur in the brains of patients with Alzheimer's disease both at postmor- tem and neurosurgical cerebral biopsy and the behavioural consequences of cholino- mimetic drugs and cholinergic lesions. Such studies have resulted in the discovery of an association between a decline in learning and memory, and a deficit in exci- tatory amino acid (EAA) neurotransmis- sion, together with important roles for the cholinergic system in attentional process- ing and as amodulator ofEAAneurotrans- mission. Accordingly, although there is presently no ``cure'' for Alzheimer's dis- ease, a large number of potential therapeu- tic interventions have emerged that are designed to correct loss of presynaptic cholinergic function. A few of these com- pounds have confirmed eYcacy in delaying the deterioration of symptoms of Alzheimer's disease, a valuable treatment target considering the progressive nature of the disease. Indeed, three compounds have received European approval for the treatment of the cognitive symptoms of Alzheimer's disease, first tacrine and more recently, donepezil and rivastigmine, all of which are cholinesterase inhibitors.},
  keywords = {acetylcholine,alzheimer,cholinest-,ects an estimated 15,erase inhibitors,is the leading,million people worldwide and,s disease,s disease a v,treatment},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/francis et al_1999_the cholinergic hypothesis of alzheimer ’ s disease.pdf}
}

@article{friedeSeamlessPhaseII2019,
  title = {Seamless Phase {{II}}/{{III}} Clinical Trials Using Early Outcomes for Treatment or Subgroup Selection: Methods and Aspects of Their Implementation},
  shorttitle = {Seamless Phase {{II}}/{{III}} Clinical Trials Using Early Outcomes for Treatment or Subgroup Selection},
  author = {Friede, Tim and Stallard, Nigel and Parsons, Nicholas},
  year = {2019},
  journal = {arXiv preprint arXiv:1901.08365},
  eprint = {1901.08365},
  archiveprefix = {arXiv},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/friede et al_2019_seamless phase ii-iii clinical trials using early outcomes for treatment or.pdf;/Users/zenn/Zotero/storage/9PF8KPCH/1901.html}
}

@article{frisonLinearlyDivergentTreatment1997,
  title = {Linearly Divergent Treatment Effects in Clinical Trials with Repeated Measures: Efficient Analysis Using Summary Statistics},
  shorttitle = {Linearly Divergent Treatment Effects in Clinical Trials with Repeated Measures},
  author = {Frison, Lars J. and Pocock, Stuart J.},
  year = {1997},
  month = dec,
  journal = {Statistics in Medicine},
  volume = {16},
  number = {24},
  pages = {2855--2872},
  issn = {0277-6715, 1097-0258},
  doi = {10.1002/(SICI)1097-0258(19971230)16:24<2855::AID-SIM749>3.0.CO;2-Y},
  urldate = {2023-04-14},
  abstract = {In many randomized clinical trials with repeated measures of a response variable one anticipates a linear divergence over time in the difference between treatments. This paper explores how to make an efficient choice of analysis based on individual patient summary statistics. With the objective of estimating the mean rate of treatment divergence the simplest choice of summary statistic is the regression coefficient of response on time for each subject (SLOPE). The gains in statistical efficiency imposed by adjusting for the observed pre-treatment levels, or even better the estimated intercepts, are clarified. In the process, we develop the optimal linear summary statistic for any repeated measures design with assumed known covariance structure and shape of true mean treatment difference over time. Statistical power considerations are explored and an example from an asthma trial is used to illustrate the main points. 1997 by John Wiley \& Sons, Ltd.},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/frison_pocock_1997_linearly divergent treatment effects in clinical trials with repeated measures.pdf}
}

@article{froelicher1998electrocardiographic,
  title = {The Electrocardiographic Exercise Test in a Population with Reduced Workup Bias: Diagnostic Performance, Computerized Interpretation, and Multivariable Prediction},
  author = {Froelicher, Victor F and Lehmann, Kenneth G and Thomas, Ronald and Goldman, Steven and Morrison, Douglas and Edson, Robert and Lavori, Philip and Myers, Jonathan and Dennis, Charles and Shabetai, Ralph and others},
  year = {1998},
  journal = {Annals of internal medicine},
  volume = {128},
  number = {12\_Part\_1},
  pages = {965--974},
  publisher = {American College of Physicians}
}

@misc{FrontiersReportQuality,
  title = {Frontiers {\textbar} {{Report Quality}} of {{Generalized Linear Mixed Models}} in {{Psychology}}: {{A Systematic Review}}},
  urldate = {2023-07-21},
  howpublished = {https://www.frontiersin.org/articles/10.3389/fpsyg.2021.666182/full},
  file = {/Users/zenn/Zotero/storage/47SBSQUI/full.html}
}

@article{frostAnalysisRepeatedDirect2004,
  title = {The Analysis of Repeated `Direct' Measures of Change Illustrated with an Application in Longitudinal Imaging},
  author = {Frost, Chris and Kenward, Michael G. and Fox, Nick C.},
  year = {2004},
  month = nov,
  journal = {Statistics in Medicine},
  volume = {23},
  number = {21},
  pages = {3275--3286},
  issn = {0277-6715, 1097-0258},
  doi = {10.1002/sim.1909},
  urldate = {2023-12-23},
  abstract = {Abstract             The use of repeated measures of an outcome variable to improve statistical power and precision in randomized clinical trials and cohort studies is well documented. Linear mixed models have great utility in the analysis of such studies in many medical applications including imaging. However, in imaging studies and other applications the basic outcome can be a `direct' measure of change in a variable, as opposed to a difference calculated by subtraction of one measured value from another. The correlation structure of such repeated measures of `direct' change, in particular the non-independence of within-person consecutive measures, adds complexity to the analysis. In this paper, we present a family of hierarchical mixed models for the analysis of such data and explain how to implement them using standard statistical software. We illustrate the use of our models with data from a cohort of patients with Alzheimer's disease. Copyright {\copyright} 2004 John Wiley \& Sons, Ltd.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/XCMDLHWZ/Frost et al. - 2004 - The analysis of repeated ‘direct’ measures of chan.pdf}
}

@article{frostOptimizingDesignClinical2008,
  title = {Optimizing the Design of Clinical Trials Where the Outcome Is a Rate. {{Can}} Estimating a Baseline Rate in a Run-in Period Increase Efficiency?: {{THE EFFICIENCY OF CLINICAL TRIALS WITH A RUN-IN DESIGN}}},
  shorttitle = {Optimizing the Design of Clinical Trials Where the Outcome Is a Rate. {{Can}} Estimating a Baseline Rate in a Run-in Period Increase Efficiency?},
  author = {Frost, Chris and Kenward, Michael G. and Fox, Nick C.},
  year = {2008},
  month = aug,
  journal = {Statistics in Medicine},
  volume = {27},
  number = {19},
  pages = {3717--3731},
  issn = {02776715},
  doi = {10.1002/sim.3280},
  urldate = {2023-04-14},
  abstract = {It is well known that the statistical power of randomized controlled trials with a continuous outcome can be increased by using a pre-randomization baseline measure of the outcome variable as a covariate in the analysis. For a trial where the outcome measure is a rate, for example in a therapeutic trial in Alzheimer's disease, the relevant covariate is a pre-randomization measure of that rate. Obtaining this requires separating the total follow-up period into two periods. In the first `run-in' period all patients would be `off-treatment' to facilitate the calculation of baseline atrophy rates. In the second `on-treatment' period half of the patients, selected at random, would be switched onto active treatment with the others remaining off treatment. In this paper we use linear mixed models to establish a methodological framework that is then used to assess the extent to which such designs can increase statistical power. We illustrate our methodology with two examples. The first is a design with three evenly spaced time points analysed with a standard random slopes model. The second is a model for repeated `direct' measures of changes used for the analysis of imaging studies with visits at multiple time points. We show that run-in designs can materially reduce sample size provided that true between-subject variability in rates is large relative to measurement error. Copyright q 2008 John Wiley \& Sons, Ltd.},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/frost et al_2008_optimizing the design of clinical trials where the outcome is a rate.pdf}
}

@article{frostOptimizingDesignClinical2008a,
  title = {Optimizing the Design of Clinical Trials Where the Outcome Is a Rate. {{Can}} Estimating a Baseline Rate in a Run-in Period Increase Efficiency?: {{THE EFFICIENCY OF CLINICAL TRIALS WITH A RUN-IN DESIGN}}},
  shorttitle = {Optimizing the Design of Clinical Trials Where the Outcome Is a Rate. {{Can}} Estimating a Baseline Rate in a Run-in Period Increase Efficiency?},
  author = {Frost, Chris and Kenward, Michael G. and Fox, Nick C.},
  year = {2008},
  month = aug,
  journal = {Statistics in Medicine},
  volume = {27},
  number = {19},
  pages = {3717--3731},
  issn = {02776715},
  doi = {10.1002/sim.3280},
  urldate = {2023-08-31},
  abstract = {It is well known that the statistical power of randomized controlled trials with a continuous outcome can be increased by using a pre-randomization baseline measure of the outcome variable as a covariate in the analysis. For a trial where the outcome measure is a rate, for example in a therapeutic trial in Alzheimer's disease, the relevant covariate is a pre-randomization measure of that rate. Obtaining this requires separating the total follow-up period into two periods. In the first `run-in' period all patients would be `off-treatment' to facilitate the calculation of baseline atrophy rates. In the second `on-treatment' period half of the patients, selected at random, would be switched onto active treatment with the others remaining off treatment. In this paper we use linear mixed models to establish a methodological framework that is then used to assess the extent to which such designs can increase statistical power. We illustrate our methodology with two examples. The first is a design with three evenly spaced time points analysed with a standard random slopes model. The second is a model for repeated `direct' measures of changes used for the analysis of imaging studies with visits at multiple time points. We show that run-in designs can materially reduce sample size provided that true between-subject variability in rates is large relative to measurement error. Copyright q 2008 John Wiley \& Sons, Ltd.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/KPMURX8N/Frost et al. - 2008 - Optimizing the design of clinical trials where the.pdf}
}

@misc{FullArticleEmpirical,
  title = {Full Article: {{Empirical Characteristic Function Estimation}} and {{Its Applications}}},
  urldate = {2024-05-11},
  howpublished = {https://www.tandfonline.com/doi/full/10.1081/ETC-120039605?src=recsys},
  file = {/Users/zenn/Zotero/storage/46U47CCX/ETC-120039605.html}
}

@article{fuTableExactSample1992,
  title = {A {{Table}} of {{Exact Sample Sizes}} for {{Use}} with {{Fisher}}'s {{Exact Test}} for 2 x 2 {{Tables}}},
  author = {Fu, Y. X. and Arnold, J.},
  year = {1992},
  journal = {Biometrics},
  volume = {48},
  number = {4},
  eprint = {2532702},
  eprinttype = {jstor},
  pages = {1103--1112},
  publisher = {[Wiley, International Biometric Society]},
  issn = {0006-341X},
  doi = {10.2307/2532702},
  urldate = {2023-07-21},
  abstract = {We studied systematically the problem of sample size for Fisher's exact test of independence in 2 x 2 tables, assuming that neither of the two margins is fixed. In this case, we present tables to calculate sample sizes necessary to achieve 50\% and 90\% power with the significance level equal to 1\% or 5\%. These tables can be used to determine the sample size necessary to detect gametic-phase disequilibrium between two genetic loci in a population genetics survey. A one-sided test and two double-sized tests are considered corresponding to the two most commonly used interpretations of observed significance.},
  file = {/Users/zenn/Zotero/storage/U77NW6FE/Fu and Arnold - 1992 - A Table of Exact Sample Sizes for Use with Fisher'.pdf}
}

@article{Gail2009,
  title = {Testing for {{Qualitative Interactions}} between {{Treatment Effects}} and {{Patient Subsets Published}} by : {{International Biometric Society Stable URL}} : {{http://www.jstor.org/stable/2530862}}},
  author = {Gail, Author M and Simon, R},
  year = {2009},
  journal = {Society},
  volume = {41},
  number = {2},
  pages = {361--372},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/gail_simon_2009_testing for qualitative interactions between treatment effects and patient.pdf}
}

@inproceedings{galasko1996development,
  title = {Development of a Pool of Items to Assess Activities of Daily Living in Clinical Trials for {{Alzheimer}}'s Disease},
  booktitle = {Neurology},
  author = {Galasko, D and Bennett, D and Ernesto, C and Thomas, R and Sano, M},
  year = {1996},
  volume = {46},
  pages = {3075--3075},
  publisher = {LITTLE BROWN CO 34 BEACON STREET, BOSTON, MA 02108-1493}
}

@article{galasko1997alzheimer,
  title = {The {{Alzheimer}}'s {{Disease Cooperative Study}}. {{An}} Inventory to Assess Activities of Daily Living for Clinical Trials in {{Alzheimer}}'s Disease},
  author = {Galasko, D and Bennett, D and Sano, M and Ernesto, C and Thomas, R and Grundman, M and Ferris, S},
  year = {1997},
  journal = {Alzheimer disease and associated disorders},
  volume = {11},
  number = {Suppl 2},
  pages = {S33--S39}
}

@inproceedings{galasko1997csf,
  title = {{{CSF}} Levels of {{A}} {{ beta}} 432 and Tau as Aids to Diagnosing {{Alzheimer}}'s Disease},
  booktitle = {Neurology},
  author = {Galasko, D and Seubert, P and Motter, R and Schenk, D and Kholodenko, D and Lieberburg, I and Chang, L and Miller, B and Clark, C and Kaye, J and others},
  year = {1997},
  volume = {48},
  pages = {63008--63008},
  publisher = {LIPPINCOTT-RAVEN PUBL 227 EAST WASHINGTON SQ, PHILADELPHIA, PA 19106}
}

@article{galasko1997inventory,
  title = {An Inventory to Assess Activities of Daily Living for Clinical Trials in {{Alzheimer}}'s Disease.},
  author = {Galasko, Douglas and Bennett, David and Sano, Mary and Ernesto, Chris and Thomas, Ronald and Grundman, Michael and Ferris, Steven},
  year = {1997},
  journal = {Alzheimer disease and associated disorders},
  publisher = {Lippincott Williams \& Wilkins}
}

@article{galasko1998high,
  title = {High Cerebrospinal Fluid Tau and Low Amyloid Beta42 Levels in the Clinical Diagnosis of {{Alzheimer}} Disease and Relation to Apolipoprotein {{E}} Genotype},
  author = {Galasko, D and Chang, L and Motter, R and Clark, {\relax CM} and Kaye, J and Knopman, D and Thomas, R and Kholodenko, D and Schenk, D and Lieberburg, I and others},
  year = {1998},
  journal = {Archives of neurology},
  volume = {55},
  number = {7},
  pages = {937--945},
  publisher = {American Medical Association}
}

@inproceedings{galasko1999beneficial,
  title = {The Beneficial Effects of Vitamin {{E}} and Selegiline in a Controlled Trial in {{Alzheimer}}'s {{Disease}} Are Independent of the Apolipoprotein {{E}} E4 Allele},
  booktitle = {{{NEUROLOGY}}},
  author = {Galasko, {\relax DR} and Sano, M and Berg, J and Thomas, {\relax RG} and Grundman, M and Thal, {\relax LJ}},
  year = {1999},
  volume = {52},
  pages = {A397--A397},
  publisher = {LIPPINCOTT WILLIAMS \& WILKINS 530 WALNUT ST, PHILADELPHIA, PA 19106-3621 USA}
}

@article{galasko2004p1,
  title = {P1-003 {{ADCS Prevention}} Instrument Project: Assessment of Activities of Daily Living ({{ADL}})},
  author = {Galasko, Douglas and Bennett, David and Sano, Mary and Marson, Daniel and Jin, Shelia and Thomas, Ronald},
  year = {2004},
  journal = {Neurobiology of Aging},
  number = {25},
  pages = {S94}
}

@article{galasko2005detailed,
  title = {Detailed Assessment of Activities of Daily Living in Moderate to Severe {{Alzheimer}}'s Disease},
  author = {Galasko, D and Schmitt, F and Thomas, R and Jin, S and Bennett, D and Ferris, S},
  year = {2005},
  journal = {Journal of the International Neuropsychological Society},
  volume = {11},
  number = {4},
  pages = {446--453},
  publisher = {Cambridge University Press}
}

@article{galasko2008o2,
  title = {O2-04--06: {{Randomized}} Clinical Trial of Antioxidant Treatment in {{Alzheimer}}'s Disease with {{CSF}} Biomarker Measures},
  author = {Galasko, Douglas and Peskind, Elaine and Clark, Christopher M and Quinn, Joseph and Ringman, John and Jicha, Gregory A and Cottrell, Barbara and Thomas, Ronald G},
  year = {2008},
  journal = {Alzheimer's \& Dementia},
  volume = {4},
  pages = {T139--T139}
}

@article{galasko2012alzheimer,
  title = {Alzheimer's {{Disease Cooperative Study}}. {{Antioxidants}} for {{Alzheimer}} Disease: {{A}} Randomized Clinical Trial with Cerebrospinal Fluid Biomarker Measures},
  author = {Galasko, {\relax DR} and Peskind, E and Clark, {\relax CM} and Quinn, {\relax JF} and Ringman, {\relax JM} and Jicha, {\relax GA} and Cotman, C and Cottrell, B and Montine, {\relax TJ} and Thomas, {\relax RG} and others},
  year = {2012},
  journal = {Archives of neurology},
  volume = {69},
  number = {7},
  pages = {836--841}
}

@article{galasko2012antioxidants,
  title = {Antioxidants for {{Alzheimer}} Disease: A Randomized Clinical Trial with Cerebrospinal Fluid Biomarker Measures},
  author = {Galasko, Douglas R and Peskind, Elaine and Clark, Christopher M and Quinn, Joseph F and Ringman, John M and Jicha, Gregory A and Cotman, Carl and Cottrell, Barbara and Montine, Thomas J and Thomas, Ronald G and others},
  year = {2012},
  journal = {Archives of neurology},
  volume = {69},
  number = {7},
  pages = {836--841},
  publisher = {American Medical Association}
}

@article{galasko2014clinical,
  title = {Clinical Trial of an Inhibitor of {{RAGE-A}}{{ beta}} Interactions in {{Alzheimer}} Disease},
  author = {Galasko, Douglas and Bell, Joanne and Mancuso, Jessica Y and Kupiec, James W and Sabbagh, Marwan N and Van Dyck, Christopher and Thomas, Ronald G and Aisen, Paul S and others},
  year = {2014},
  journal = {Neurology},
  volume = {82},
  number = {17},
  pages = {1536--1542},
  publisher = {Wolters Kluwer Health, Inc. on behalf of the American Academy of Neurology}
}

@inproceedings{gamst2000description,
  title = {Description of Behaviors Emerging in Community-Dwelling Persons with {{Alzheimer}}'s Disease over 12 Months},
  booktitle = {Annals of Neurology},
  author = {Gamst, A and Thomas, {\relax RG} and Patterson, M and Schneider, L},
  year = {2000},
  volume = {48},
  pages = {419--420},
  publisher = {LIPPINCOTT WILLIAMS \& WILKINS 530 WALNUT ST, PHILADELPHIA, PA 19106-3621 USA}
}

@article{garnseyensignOptimalStratifiedSimon1994,
  title = {An Optimal Stratified {{Simon}} Two-stage Design},
  author = {Garnsey Ensign, Lisa and Gehan, Edmund A and Kamen, Douglas S and Thall, Peter F},
  year = {1994},
  journal = {Wiley Online Library},
  volume = {13},
  pages = {1727--1736},
  urldate = {2022-01-31},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/garnsey ensign et al_1994_an optimal stratified simon two‐stage design.pdf}
}

@article{garnseyensignOptimalThreeStage1994,
  title = {An Optimal Three-stage Design for Phase {{II}} Clinical Trials},
  author = {Garnsey Ensign, Lisa and Gehan, Edmund A and Kamen, Douglas S and Thall, Peter F},
  year = {1994},
  journal = {Wiley Online Library},
  volume = {13},
  pages = {1727--1736},
  urldate = {2022-01-31},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/garnsey ensign et al_1994_an optimal three‐stage design for phase ii clinical trials.pdf}
}

@article{gaspariniMixedeffectsModelsHealth2020,
  title = {Mixed-Effects Models for Health Care Longitudinal Data with an Informative Visiting Process: {{A Monte Carlo}} Simulation Study},
  shorttitle = {Mixed-Effects Models for Health Care Longitudinal Data with an Informative Visiting Process},
  author = {Gasparini, Alessandro and Abrams, Keith R. and Barrett, Jessica K. and Major, Rupert W. and Sweeting, Michael J. and Brunskill, Nigel J. and Crowther, Michael J.},
  year = {2020},
  journal = {Statistica Neerlandica},
  volume = {74},
  number = {1},
  pages = {5--23},
  publisher = {Wiley Online Library},
  keywords = {electronic health records,informative visiting process,inverse intensity of visiting weighting,longitudinal data,mixed-effects models,Monte Carlo simulation,recurrent-events models,selection bias},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/gasparini et al_2020_mixed-effects models for health care longitudinal data with an informative.pdf;/Users/zenn/Zotero/storage/8FICPZGM/stan.html}
}

@inproceedings{gelmont2015safety,
  title = {Safety of Intravenous Immunoglobulin Therapy in Patients with Probable Alzheimer's Disease: {{A}} Randomized, Placebo-Controlled Clinical Study},
  booktitle = {Annals of Allergy Asthma \& Immunology},
  author = {Gelmont, D and Thomas, {\relax RG} and {Dyck-Jones}, {\relax JA} and Fritsch, S and Aisen, P and Relkin, N},
  year = {2015},
  volume = {115},
  pages = {A113--A113},
  publisher = {ELSEVIER SCIENCE INC 360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA}
}

@article{gelmont2016demonstration,
  title = {Demonstration of Safety of Intravenous Immunoglobulin in Geriatric Patients in a Long-Term, Placebo-Controlled Study of {{Alzheimer}}'s Disease},
  author = {Gelmont, David and Thomas, Ronald G and Britt, Jonathan and {Dyck-Jones}, Jacqueline A and Doralt, Jennifer and Fritsch, Sandor and Brewer, James B and Rissman, Robert A and Aisen, Paul},
  year = {2016},
  journal = {Alzheimer's \& Dementia: Translational Research \& Clinical Interventions},
  volume = {2},
  number = {2},
  pages = {131--139},
  publisher = {No longer published by Elsevier}
}

@article{ghisays2020pet,
  title = {{{PET}} Evidence of Preclinical Cerebellar Amyloid Plaque Deposition in Autosomal Dominant {{Alzheimer}}'s Disease: {{Neuroimaging}}/Imaging and Genetics},
  author = {Ghisays, Valentina and Lopera, Francisco and Goradia, Dhruman D and Protas, Hillary D and {Malek-Ahmadi}, Michael H and Chen, Yinghua and Devadas, Vivek and Luo, Ji and Lee, Wendy and Brown, Christopher T and others},
  year = {2020},
  journal = {Alzheimer's \& Dementia},
  volume = {16},
  pages = {e039051}
}

@inproceedings{ghisays2020pet,
  title = {{{PET}} Evidence of Preclinical Cerebellar Amyloid Plaque Deposition in Autosomal Dominant {{Alzheimer}}'s Disease},
  booktitle = {2020 Alzheimer's Association International Conference},
  author = {Ghisays, Valentina and Lopera, Francisco and Goradia, Dhruman D and Protas, Hillary D and {Malek-Ahmadi}, Michael H and Chen, Yinghua and Devadas, Vivek and Luo, Ji and Lee, Wendy and Brown, Christopher T and others},
  year = {2020},
  publisher = {ALZ}
}

@article{ghisays2021pet,
  title = {{{PET}} Evidence of Preclinical Cerebellar Amyloid Plaque Deposition in Autosomal Dominant {{Alzheimer}}'s Disease-Causing {{Presenilin-1 E280A}} Mutation Carriers},
  author = {Ghisays, Valentina and Lopera, Francisco and Goradia, Dhruman D and Protas, Hillary D and {Malek-Ahmadi}, Michael H and Chen, Yinghua and Devadas, Vivek and Luo, Ji and Lee, Wendy and Baena, Ana and others},
  year = {2021},
  journal = {NeuroImage: Clinical},
  volume = {31},
  pages = {102749},
  publisher = {Elsevier}
}

@article{ghoshStatisticalPowerSample2022,
  title = {Statistical Power and Sample Size Requirements to Detect an Intervention by Time Interaction in Four-level Longitudinal Cluster Randomized Trials},
  author = {Ghosh, Samiran and Mukhopadhyay, Siuli and Majumder, Priyanka and Wang, Bo},
  year = {2022},
  month = jun,
  journal = {Statistics in Medicine},
  volume = {41},
  number = {14},
  pages = {2542--2556},
  issn = {0277-6715, 1097-0258},
  doi = {10.1002/sim.9369},
  urldate = {2022-11-04},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/ghosh et al_2022_statistical power and sample size requirements to detect an intervention by.pdf}
}

@article{giagkouEmergingDrugsProgressive2019,
  title = {Emerging Drugs for Progressive Supranuclear Palsy},
  author = {Giagkou, Nikolaos and Stamelou, Maria},
  year = {2019},
  month = jun,
  journal = {Expert Opinion on Emerging Drugs},
  volume = {24},
  number = {2},
  pages = {83--92},
  issn = {1744-7623},
  doi = {10.1080/14728214.2019.1609450},
  abstract = {Introduction: Progressive supranuclear palsy (PSP) is a common cause of atypical parkinsonism and a rapidly progressive disease that greatly burdens both patients and caregivers. Drugs with disease-modifying potential, targeting mechanisms implicated in the disease's pathogenesis are currently tested in Phase 1 and 2 trials. If proven efficacious, these compounds might provide substantial benefits not only to patients with PSP but to patients with other tauopathies as well. Areas covered: Drugs in Phase 1 and 2 trials in PSP, and Phase 2 trials in other tauopathies (Alzheimer's disease) are reviewed. Expert opinion: The rationale behind the currently tested compounds as well as the tools available to document a treatment effect offer hope for a therapeutic breakthrough in PSP. The current lack of sufficiently validated biomarkers remains a hurdle that needs to be overcome, in order to facilitate both clinical trials and the accurate prescription of future treatments.},
  langid = {english},
  pmid = {31007097},
  keywords = {Alzheimer Disease,Animals,Antibodies Monoclonal,Antiparkinson Agents,Cholinesterase Inhibitors,Clinical trials,Drug Discovery,Humans,Mice,Neuroprotective Agents,parkinsonism,Progressive supranuclear palsy,Randomized Controlled Trials as Topic,Supranuclear Palsy Progressive,Tau immunotherapy,tau Proteins,tau targeted therapeutics,tauopathies,treatment,Treatment Outcome},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/giagkou_stamelou_2019_emerging drugs for progressive supranuclear palsy2.pdf}
}

@article{giagkouEmergingDrugsProgressive2019a,
  title = {Emerging Drugs for Progressive Supranuclear Palsy},
  author = {Giagkou, Nikolaos and Stamelou, Maria},
  year = {2019},
  month = jun,
  journal = {Expert Opinion on Emerging Drugs},
  volume = {24},
  number = {2},
  pages = {83--92},
  issn = {1744-7623},
  doi = {10.1080/14728214.2019.1609450},
  abstract = {Introduction: Progressive supranuclear palsy (PSP) is a common cause of atypical parkinsonism and a rapidly progressive disease that greatly burdens both patients and caregivers. Drugs with disease-modifying potential, targeting mechanisms implicated in the disease's pathogenesis are currently tested in Phase 1 and 2 trials. If proven efficacious, these compounds might provide substantial benefits not only to patients with PSP but to patients with other tauopathies as well. Areas covered: Drugs in Phase 1 and 2 trials in PSP, and Phase 2 trials in other tauopathies (Alzheimer's disease) are reviewed. Expert opinion: The rationale behind the currently tested compounds as well as the tools available to document a treatment effect offer hope for a therapeutic breakthrough in PSP. The current lack of sufficiently validated biomarkers remains a hurdle that needs to be overcome, in order to facilitate both clinical trials and the accurate prescription of future treatments.},
  langid = {english},
  pmid = {31007097},
  keywords = {Alzheimer Disease,Animals,Antibodies Monoclonal,Antiparkinson Agents,Cholinesterase Inhibitors,Clinical trials,Drug Discovery,Humans,Mice,Neuroprotective Agents,parkinsonism,Progressive supranuclear palsy,Randomized Controlled Trials as Topic,Supranuclear Palsy Progressive,Tau immunotherapy,tau Proteins,tau targeted therapeutics,tauopathies,treatment,Treatment Outcome},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/giagkou_stamelou_2019_emerging drugs for progressive supranuclear palsy.pdf}
}

@article{giagkouEmergingDrugsProgressive2019b,
  title = {Emerging Drugs for Progressive Supranuclear Palsy},
  author = {Giagkou, Nikolaos and Stamelou, Maria},
  year = {2019},
  month = jun,
  journal = {Expert Opinion on Emerging Drugs},
  volume = {24},
  number = {2},
  pages = {83--92},
  issn = {1744-7623},
  doi = {10.1080/14728214.2019.1609450},
  abstract = {Introduction: Progressive supranuclear palsy (PSP) is a common cause of atypical parkinsonism and a rapidly progressive disease that greatly burdens both patients and caregivers. Drugs with disease-modifying potential, targeting mechanisms implicated in the disease's pathogenesis are currently tested in Phase 1 and 2 trials. If proven efficacious, these compounds might provide substantial benefits not only to patients with PSP but to patients with other tauopathies as well. Areas covered: Drugs in Phase 1 and 2 trials in PSP, and Phase 2 trials in other tauopathies (Alzheimer's disease) are reviewed. Expert opinion: The rationale behind the currently tested compounds as well as the tools available to document a treatment effect offer hope for a therapeutic breakthrough in PSP. The current lack of sufficiently validated biomarkers remains a hurdle that needs to be overcome, in order to facilitate both clinical trials and the accurate prescription of future treatments.},
  langid = {english},
  pmid = {31007097},
  keywords = {Alzheimer Disease,Animals,Antibodies Monoclonal,Antiparkinson Agents,Cholinesterase Inhibitors,Clinical trials,Drug Discovery,Humans,Mice,Neuroprotective Agents,parkinsonism,Progressive supranuclear palsy,Randomized Controlled Trials as Topic,Supranuclear Palsy Progressive,Tau immunotherapy,tau Proteins,tau targeted therapeutics,tauopathies,treatment,Treatment Outcome}
}

@article{giagkouEmergingDrugsProgressive2019c,
  title = {Emerging Drugs for Progressive Supranuclear Palsy},
  author = {Giagkou, Nikolaos and Stamelou, Maria},
  year = {2019},
  month = apr,
  journal = {Expert Opinion on Emerging Drugs},
  volume = {24},
  number = {2},
  pages = {83--92},
  issn = {1472-8214, 1744-7623},
  doi = {10.1080/14728214.2019.1609450},
  urldate = {2024-06-05},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/NJNUYDMH/Giagkou and Stamelou - 2019 - Emerging drugs for progressive supranuclear palsy.pdf}
}

@article{giovagnoliBayesianDesignAdaptive2021,
  title = {The {{Bayesian Design}} of {{Adaptive Clinical Trials}}},
  author = {Giovagnoli, Alessandra},
  year = {2021},
  month = jan,
  journal = {International Journal of Environmental Research and Public Health},
  volume = {18},
  number = {2},
  pages = {530},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {1660-4601},
  doi = {10.3390/ijerph18020530},
  urldate = {2024-03-20},
  abstract = {This paper presents a brief overview of the recent literature on adaptive design of clinical trials from a Bayesian perspective for statistically not so sophisticated readers. Adaptive designs are attracting a keen interest in several disciplines, from a theoretical viewpoint and also---potentially---from a practical one, and Bayesian adaptive designs, in particular, have raised high expectations in clinical trials. The main conceptual tools are highlighted here, with a mention of several trial designs proposed in the literature that use these methods, including some of the registered Bayesian adaptive trials to this date. This review aims at complementing the existing ones on this topic, pointing at further interesting reading material.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {adaptive designs,adaptive randomization,Bayesian designs,clinical trials,predictive power,target allocation},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/giovagnoli_2021_the bayesian design of adaptive clinical trials.pdf}
}

@article{glimmHierarchicalTestingMultiple2009,
  title = {Hierarchical Testing of Multiple Endpoints in Group-Sequential Trials},
  author = {Glimm, Ekkehard and Maurer, Willi and Bretz, Frank},
  year = {2009},
  journal = {Statistics in Medicine},
  pages = {n/a-n/a},
  issn = {02776715},
  doi = {10.1002/sim.3748},
  urldate = {2018-09-01},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/glimm et al_2009_hierarchical testing of multiple endpoints in group-sequential trials.pdf}
}

@article{goepfertPeriodontalDiseaseUpper2004,
  title = {Periodontal {{Disease}} and {{Upper Genital Tract Inflammation}} in {{Early Spontaneous Preterm Birth}}:},
  shorttitle = {Periodontal {{Disease}} and {{Upper Genital Tract Inflammation}} in {{Early Spontaneous Preterm Birth}}},
  author = {Goepfert, Alice R. and Jeffcoat, Marjorie K. and Andrews, William W. and {Faye-Petersen}, Ona and Cliver, Suzanne P. and Goldenberg, Robert L. and Hauth, John C.},
  year = {2004},
  month = oct,
  journal = {Obstetrics \& Gynecology},
  volume = {104},
  number = {4},
  pages = {777--783},
  issn = {0029-7844},
  doi = {10.1097/01.AOG.0000139836.47777.6d},
  urldate = {2024-02-29},
  abstract = {OBJECTIVE: To estimate the relationship between maternal periodontal disease and both early spontaneous preterm birth and selected markers of upper genital tract inflammation. METHODS: In this case-control study, periodontal assessment was performed in 59 women who experienced an early spontaneous preterm birth at less than 32 weeks of gestation, in a control population of 36 women who experienced an early indicated preterm birth at less than 32 weeks of gestation, and in 44 women with an uncomplicated birth at term ({$>$} 37 weeks). Periodontal disease was defined by the degree of attachment loss. Cultures of the placenta and umbilical cord blood, cord interleukin-6 levels, and histopathologic examination of the placenta were performed for all women. RESULTS: Severe periodontal disease was more common in the spontaneous preterm birth group (49\%) than in the indicated preterm (25\%, P ؍ .02) and term control groups (30\%, P ؍ .045). Multivariable analyses, controlling for possible confounders, supported the association between severe periodontal disease and spontaneous preterm birth (odds ratio 3.4, 95\% confidence interval 1.5--7.7). Neither histologic chorioamnionitis, a positive placental culture, nor an elevated cord plasma interleukin-6 level was significantly associated with periodontal disease (80\% power to detect a 50\% difference in rate of histological chorioamnionitis, ␣ ؍ 0.05). CONCLUSION: Women with early spontaneous preterm birth were more likely to have severe periodontal disease},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/GVXU2E6W/Goepfert et al. - 2004 - Periodontal Disease and Upper Genital Tract Inflam.pdf}
}

@article{goepfertPeriodontalDiseaseUpper2004a,
  title = {Periodontal {{Disease}} and {{Upper Genital Tract Inflammation}} in {{Early Spontaneous Preterm Birth}}},
  author = {Goepfert, Alice R. and Jeffcoat, Marjorie K. and Andrews, William W. and {Faye-Petersen}, Ona and Cliver, Suzanne P. and Goldenberg, Robert L. and Hauth, John C.},
  year = {2004},
  month = oct,
  journal = {Obstetrics \& Gynecology},
  volume = {104},
  number = {4},
  pages = {777},
  issn = {0029-7844},
  doi = {10.1097/01.AOG.0000139836.47777.6d},
  urldate = {2024-02-27},
  abstract = {OBJECTIVE:~           To estimate the relationship between maternal periodontal disease and both early spontaneous preterm birth and selected markers of upper genital tract inflammation.           METHODS:~           In this case-control study, periodontal assessment was performed in 59 women who experienced an early spontaneous preterm birth at less than 32 weeks of gestation, in a control population of 36 women who experienced an early indicated preterm birth at less than 32 weeks of gestation, and in 44 women with an uncomplicated birth at term ({$\geq$} 37 weeks). Periodontal disease was defined by the degree of attachment loss. Cultures of the placenta and umbilical cord blood, cord interleukin-6 levels, and histopathologic examination of the placenta were performed for all women.           RESULTS:~           Severe periodontal disease was more common in the spontaneous preterm birth group (49\%) than in the indicated preterm (25\%, P = .02) and term control groups (30\%, P = .045). Multivariable analyses, controlling for possible confounders, supported the association between severe periodontal disease and spontaneous preterm birth (odds ratio 3.4, 95\% confidence interval 1.5--7.7). Neither histologic chorioamnionitis, a positive placental culture, nor an elevated cord plasma interleukin-6 level was significantly associated with periodontal disease (80\% power to detect a 50\% difference in rate of histological chorioamnionitis, {$\alpha$} = 0.05).           CONCLUSION:~           Women with early spontaneous preterm birth were more likely to have severe periodontal disease than women with indicated preterm birth or term birth. Periodontal disease was not associated with selected markers of upper genital tract inflammation.           LEVEL OF EVIDENCE:~           II-2},
  langid = {american},
  file = {/Users/zenn/Zotero/storage/55WGZKAH/periodontal_disease_and_upper_genital_tract.22.html}
}

@article{goetzProgressionGaitSpeech2003,
  title = {Progression of Gait, Speech and Swallowing Deficits in Progressive Supranuclear Palsy},
  author = {Goetz, Christopher G. and Leurgans, Sue and Lang, Anthony E. and Litvan, Irene},
  year = {2003},
  month = mar,
  journal = {Neurology},
  volume = {60},
  number = {6},
  pages = {917--922},
  issn = {1526-632X},
  doi = {10.1212/01.wnl.0000052686.97625.27},
  abstract = {OBJECTIVE: To identify outcome measures for clinical trials in progressive supranuclear palsy (PSP), the authors determined the time to key motor impairments in a well-defined patient cohort. METHODS: The records of consecutive patients with probable PSP, defined by National Institute of Neurological Disorders and Stroke-Society for Progressive Supranuclear Palsy workshop criteria on first visit to a tertiary care center, were selected for study if the patients were seen regularly at 3- to 6-month intervals, had at least 24 months of care at the Rush movement disorder center, and were originally seen in the movement disorder center before any of the following key motor impairments developed: unintelligible speech, no independent walking, inability to stand unassisted, wheelchair-bound, or recommendation for feeding tube placement. Using standardized criteria from the Unified Parkinson's Disease Rating Scale and Hoehn and Yahr stages taken at each clinic visit, the authors recorded the time that each patient reached the key motor impairments and death. Median months from first symptom onset and from first consultation at the movement disorder center to each motor impairment were derived from Kaplan-Meier curves. RESULTS: Fifty subjects, mean age at study entry 64.2 years, were followed to death (n = 21, mean duration of surveillance 53.6 months) or in ongoing fashion (n = 29, mean duration of surveillance 46.2 months). Eighty-eight percent of the sample met at least one milestone. The median time from disease onset to the first key motor impairment was 48 months, 24 months after first consultation. The three gait items occurred temporally close, and the authors considered them thereafter as a single milestone, occurring at a median disease duration of 57 months, 34 months after first consultation. Unintelligible speech occurred at a median disease duration of 71 months, median 44 months after first consultation. As a composite end point, speech/gait accounted for 98\% of the sample's first key motor impairment. Need for nasogastric tube was rarely the first milestone (8\%). CONCLUSIONS: Gait impairment and unintelligible speech are milestones that occur rapidly in PSP and can be monitored with standardized rating scales. The authors suggest that clinical trials use these indices to assess how interventions alter anticipated progression of clinical deterioration in PSP.},
  langid = {english},
  pmid = {12654953},
  keywords = {Adult,Aged,Cause of Death,Clinical Trials as Topic,Cohort Studies,Deglutition Disorders,Disease Progression,Female,Gait Disorders Neurologic,Humans,Life Tables,Male,Middle Aged,Outcome Assessment Health Care,Speech Disorders,Supranuclear Palsy Progressive}
}

@article{goetzProgressionGaitSpeech2003a,
  title = {Progression of Gait, Speech and Swallowing Deficits in Progressive Supranuclear Palsy},
  author = {Goetz, Christopher G. and Leurgans, Sue and Lang, Anthony E. and Litvan, Irene},
  year = {2003},
  month = mar,
  journal = {Neurology},
  volume = {60},
  number = {6},
  pages = {917--922},
  issn = {1526-632X},
  doi = {10.1212/01.wnl.0000052686.97625.27},
  abstract = {OBJECTIVE: To identify outcome measures for clinical trials in progressive supranuclear palsy (PSP), the authors determined the time to key motor impairments in a well-defined patient cohort. METHODS: The records of consecutive patients with probable PSP, defined by National Institute of Neurological Disorders and Stroke-Society for Progressive Supranuclear Palsy workshop criteria on first visit to a tertiary care center, were selected for study if the patients were seen regularly at 3- to 6-month intervals, had at least 24 months of care at the Rush movement disorder center, and were originally seen in the movement disorder center before any of the following key motor impairments developed: unintelligible speech, no independent walking, inability to stand unassisted, wheelchair-bound, or recommendation for feeding tube placement. Using standardized criteria from the Unified Parkinson's Disease Rating Scale and Hoehn and Yahr stages taken at each clinic visit, the authors recorded the time that each patient reached the key motor impairments and death. Median months from first symptom onset and from first consultation at the movement disorder center to each motor impairment were derived from Kaplan-Meier curves. RESULTS: Fifty subjects, mean age at study entry 64.2 years, were followed to death (n = 21, mean duration of surveillance 53.6 months) or in ongoing fashion (n = 29, mean duration of surveillance 46.2 months). Eighty-eight percent of the sample met at least one milestone. The median time from disease onset to the first key motor impairment was 48 months, 24 months after first consultation. The three gait items occurred temporally close, and the authors considered them thereafter as a single milestone, occurring at a median disease duration of 57 months, 34 months after first consultation. Unintelligible speech occurred at a median disease duration of 71 months, median 44 months after first consultation. As a composite end point, speech/gait accounted for 98\% of the sample's first key motor impairment. Need for nasogastric tube was rarely the first milestone (8\%). CONCLUSIONS: Gait impairment and unintelligible speech are milestones that occur rapidly in PSP and can be monitored with standardized rating scales. The authors suggest that clinical trials use these indices to assess how interventions alter anticipated progression of clinical deterioration in PSP.},
  langid = {english},
  pmid = {12654953},
  keywords = {Adult,Aged,Cause of Death,Clinical Trials as Topic,Cohort Studies,Deglutition Disorders,Disease Progression,Female,Gait Disorders Neurologic,Humans,Life Tables,Male,Middle Aged,Outcome Assessment Health Care,Speech Disorders,Supranuclear Palsy Progressive}
}

@article{golbeClinicalRatingScale2007,
  title = {A Clinical Rating Scale for Progressive Supranuclear Palsy},
  author = {Golbe, Lawrence I. and {Ohman-Strickland}, Pamela A.},
  year = {2007},
  month = jun,
  journal = {Brain},
  volume = {130},
  number = {6},
  pages = {1552--1565},
  issn = {0006-8950},
  doi = {10.1093/brain/awm032},
  urldate = {2024-04-23},
  abstract = {We devised a Progressive Supranuclear Palsy (PSP) Rating Scale comprising 28 items in six categories: daily activities (by history), behaviour, bulbar, ocular motor, limb motor and gait/midline. Scores range from 0 to 100, each item graded 0--2 (six items) or 0--4 (22 items). Inter-rater reliability is good, with intra-class correlation coefficient for the overall scale of 0.86 (95\% CI 0.65--0.98). A single examiner applied the PSPRS at every visit for 162 patients. Mean rate of progression was 11.3 ({\textpm}11.0) points per year. Neither onset age nor gender correlated well with rate of progression. Median actuarially corrected survival was 7.3 years. The PSPRS score was a good independent predictor of subsequent survival (P \&lt; 0.0001). For example, for patients with scores from 40 to 49, 3-year survival was 41.9\% (95\% CI 31.0--56.6) but 4-year survival was only 17.9\% (95\% CI 10.2--31.5). For those patients, likelihood or retaining some gait function was 51.7\% (40.0--66.9) at 1 year but only 6.5\% (1.8--23.5) at 3 years. We conclude that the PSPRS is a practical measure that is sensitive to disease progression and could be useful as a dependent variable in observational or interventional trials and as an indicator of prognosis in clinical practice.},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/golbe_ohman-strickland_2007_a clinical rating scale for progressive supranuclear palsy.pdf;/Users/zenn/Zotero/storage/2YKCF9L2/293321.html}
}

@article{golbeClinicalRatingScale2007a,
  title = {A Clinical Rating Scale for Progressive Supranuclear Palsy},
  author = {Golbe, Lawrence I. and {Ohman-Strickland}, Pamela A.},
  year = {2007},
  journal = {Brain},
  volume = {130},
  number = {6},
  pages = {1552--1565},
  publisher = {Oxford University Press},
  urldate = {2024-04-23},
  file = {/Users/zenn/Zotero/storage/6VBS77QN/293321.html}
}

@book{golbeClinicianGuideProgressive2019,
  title = {A {{Clinician}}'s {{Guide}} to {{Progressive Supranuclear Palsy}}},
  author = {Golbe, Lawrence I.},
  year = {2019},
  eprint = {j.ctvbtzpj2},
  eprinttype = {jstor},
  publisher = {Rutgers University Press},
  doi = {10.2307/j.ctvbtzpj2},
  urldate = {2024-06-05},
  abstract = {This brief, clinically-focused volume is informed by Lawrence I. Golbe's three decades of research and tertiary clinical care in progressive supranuclear palsy, a complex disorder with rapidly changing diagnostic and therapeutic approaches. It is an ideal source for the general neurologist seeking a refresher and the primary care provider, neurological nurse, or physical, occupational or speech therapist who must address their patients' specialized needs.     \emph{A Clinician's Guide to Progressive Supranuclear Palsy}  emphasizes early diagnostic signs, medication options, non-pharmacologic management and palliative care. It offers a quick overview of the complications of PSP most likely to prompt an ER visit; a widening spectrum of PSP variants; and ample description of the genetics, epidemiology, natural history, pathology, molecular biology and neurochemistry of PSP. The PSP Rating Scale used in the book is a convenient tool for clinicians in routine practice and the leading PSP clinical measure world-wide. Golbe provides a practical and useful guidebook to help all clinicians learn and battle this complex disorder.},
  isbn = {978-1-978803-20-6}
}

@article{goldberg2002psychosocial,
  title = {Psychosocial and Functional Parameters in Patients with Age Related Macular Degeneration and Choroidal Neovascularization with and without Photodynamic Therapy},
  author = {Goldberg, {\relax DE} and {Roch-Levecq}, {\relax AC} and Maclean, {\relax KK} and Brody, {\relax BL} and McGuire, {\relax DE} and Goldbaum, {\relax MH} and Thomas, {\relax RG} and Brown, {\relax SI} and Freeman, {\relax WR}},
  year = {2002},
  journal = {Investigative Ophthalmology \& Visual Science},
  volume = {43},
  number = {13},
  pages = {597--597},
  publisher = {{The Association for Research in Vision and Ophthalmology}}
}

@article{Goldenshluger2021,
  title = {Density {{Deconvolution}} with {{Non-Standard Error Distributions}}: {{Rates}} of {{Convergence}} and {{Adaptive Estimation}}},
  author = {Goldenshluger, Alexander and Kim, Taeho},
  year = {2021},
  eprint = {2101.02491},
  abstract = {It is a typical standard assumption in the density deconvolution problem that the characteristic function of the measurement error distribution is non-zero on the real line. While this condition is assumed in the majority of existing works on the topic, there are many problem instances of interest where it is violated. In this paper we focus on non--standard settings where the characteristic function of the measurement errors has zeros, and study how zeros multiplicity affects the estimation accuracy. For a prototypical problem of this type we demonstrate that the best achievable estimation accuracy is determined by the multiplicity of zeros, the rate of decay of the error characteristic function, as well as by the smoothness and the tail behavior of the estimated density. We derive lower bounds on the minimax risk and develop optimal in the minimax sense estimators. In addition, we consider the problem of adaptive estimation and propose a data-driven estimator that automatically adapts to unknown smoothness and tail behavior of the density to be estimated.},
  archiveprefix = {arXiv},
  keywords = {and phrases,characteristic function,density deconvolution,laplace transform,minimax risk,non-standard measurement error,zero multiplicity},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/goldenshluger_kim_2021_density deconvolution with non-standard error distributions.pdf}
}

@article{goldPrefaceSpecialIssue2012,
  title = {Preface for the Special Issue of Imaging Brain Aging and Neurodegenerative Disease},
  author = {Gold, Brian T. and Keller, Jeffrey N.},
  year = {2012},
  journal = {Biochimica et Biophysica Acta (BBA) - Molecular Basis of Disease},
  volume = {1822},
  number = {3},
  pages = {315--316},
  issn = {09254439},
  doi = {10.1016/j.bbadis.2012.01.001},
  urldate = {2016-10-22},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/gold_keller_2012_preface for the special issue of imaging brain aging and neurodegenerative.pdf}
}

@article{gomarUtilityCombinationsBiomarkers2011,
  title = {Utility of {{Combinations}} of {{Biomarkers}}, {{Cognitive Markers}}, and {{Risk Factors}} to {{Predict Conversion From Mild Cognitive Impairment}} to {{Alzheimer Disease}} in {{Patients}} in the {{Alzheimer}}'s {{Disease Neuroimaging Initiative}}},
  author = {Gomar, Jesus J. and {Bobes-Bascaran}, Maria T. and {Conejero-Goldberg}, Concepcion and Davies, Peter and Goldberg, Terry E. and Initiative, for the Alzheimer's Disease Neuroimaging},
  year = {2011},
  month = sep,
  journal = {Archives of General Psychiatry},
  volume = {68},
  number = {9},
  pages = {961},
  publisher = {American Medical Association},
  issn = {0003-990X},
  doi = {10.1001/archgenpsychiatry.2011.96},
  urldate = {2017-07-14},
  abstract = {{$<$}h3{$>$}Context{$<$}/h3{$>$}Biomarkers have become increasingly important in understanding neurodegenerative processes associated with Alzheimer disease. Markers include regional brain volumes, cerebrospinal fluid measures of pathological A{$\beta$}1-42 and total tau, cognitive measures, and individual risk factors.{$<$}h3{$>$}Objective{$<$}/h3{$>$}To determine the discriminative utility of different classes of biomarkers and cognitive markers by examining their ability to predict a change in diagnostic status from mild cognitive impairment to Alzheimer disease.{$<$}h3{$>$}Design{$<$}/h3{$>$}Longitudinal study.{$<$}h3{$>$}Participants{$<$}/h3{$>$}We analyzed the Alzheimer's Disease Neuroimaging Initiative database to study patients with mild cognitive impairment who converted to Alzheimer disease (n~=~116) and those who did not convert (n~=~204) within a 2-year period. We determined the predictive utility of 25 variables from all classes of markers, biomarkers, and risk factors in a series of logistic regression models and effect size analyses.{$<$}h3{$>$}Setting{$<$}/h3{$>$}The Alzheimer's Disease Neuroimaging Initiative public database.{$<$}h3{$>$}Outcome Measures{$<$}/h3{$>$}Primary outcome measures were odds ratios, pseudo- R\textsuperscript{2}s, and effect sizes.{$<$}h3{$>$}Results{$<$}/h3{$>$}In comprehensive stepwise logistic regression models that thus included variables from all classes of markers, the following baseline variables predicted conversion within a 2-year period: 2 measures of delayed verbal memory and middle temporal lobe cortical thickness. In an effect size analysis that examined rates of decline, change scores for biomarkers were modest for 2 years, but a change in an everyday functional activities measure (Functional Assessment Questionnaire) was considerably larger. Decline in scores on the Functional Assessment Questionnaire and Trail Making Test, part B, accounted for approximately 50\% of the predictive variance in conversion from mild cognitive impairment to Alzheimer disease.{$<$}h3{$>$}Conclusions{$<$}/h3{$>$}Cognitive markers at baseline were more robust predictors of conversion than most biomarkers. Longitudinal analyses suggested that conversion appeared to be driven less by changes in the neurobiologic trajectory of the disease than by a sharp decline in functional ability and, to a lesser extent, by declines in executive function.},
  keywords = {alzheimer's disease,biological markers,minimal cognitive impairment,neuroimaging,recombinant colony-stimulating factors},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/gomar et al_2011_utility of combinations of biomarkers, cognitive markers, and risk factors to.pdf}
}

@article{gormanEcologicalSexualDimorphism2014,
  title = {Ecological Sexual Dimorphism and Environmental Variability within a Community of {{Antarctic}} Penguins (Genus {{Pygoscelis}})},
  author = {Gorman, Kristen B. and Williams, Tony D. and Fraser, William R.},
  year = {2014},
  journal = {PloS one},
  volume = {9},
  number = {3},
  pages = {e90081},
  publisher = {Public Library of Science San Francisco, USA},
  urldate = {2024-06-28},
  file = {/Users/zenn/Zotero/storage/8MBCSF94/Gorman et al. - 2014 - Ecological sexual dimorphism and environmental var.pdf}
}

@article{gouletPowerReplicatedMeasures2019,
  title = {The {{Power}} of {{Replicated Measures}} to {{Increase Statistical Power}}},
  author = {Goulet, Marc-Andr{\'e} and Cousineau, Denis},
  year = {2019},
  month = sep,
  journal = {Advances in Methods and Practices in Psychological Science},
  volume = {2},
  number = {3},
  pages = {199--213},
  issn = {2515-2459, 2515-2467},
  doi = {10.1177/2515245919849434},
  urldate = {2023-12-23},
  abstract = {When running statistical tests, researchers can commit a Type II error, that is, fail to reject the null hypothesis when it is false. To diminish the probability of committing a Type II error ({$\beta$}), statistical power must be augmented. Typically, this is done by increasing sample size, as more participants provide more power. When the estimated effect size is small, however, the sample size required to achieve sufficient statistical power can be prohibitive. To alleviate this lack of power, a common practice is to measure participants multiple times under the same condition. Here, we show how to estimate statistical power by taking into account the benefit of such replicated measures. To that end, two additional parameters are required: the correlation between the multiple measures within a given condition and the number of times the measure is replicated. An analysis of a sample of 15 studies (total of 298 participants and 38,404 measurements) suggests that in simple cognitive tasks, the correlation between multiple measures is approximately .14. Although multiple measurements increase statistical power, this effect is not linear, but reaches a plateau past 20 to 50 replications (depending on the correlation). Hence, multiple measurements do not replace the added population representativeness provided by additional participants.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/FSL3W8WN/Goulet and Cousineau - 2019 - The Power of Replicated Measures to Increase Stati.pdf}
}

@article{gozesSurprisingSexDifferences2023,
  title = {Surprising Sex Differences Indicate Davunetide-Mediated Brain Protection and Clinical Efficacy in Women Suffering from Progressive Supranuclear Palsy},
  author = {Gozes, Illana and Shapira, Guy and Lobyntseva, Alexandra and Shomron, Noam},
  year = {2023},
  urldate = {2024-06-05},
  file = {/Users/zenn/Zotero/storage/CF6DZL88/Gozes et al. - 2023 - Surprising sex differences indicate davunetide-med.pdf}
}

@article{gozesUnexpectedGenderDifferences2023,
  title = {Unexpected Gender Differences in Progressive Supranuclear Palsy Reveal Efficacy for Davunetide in Women},
  author = {Gozes, Illana and Shapira, Guy and Lobyntseva, Alexandra and Shomron, Noam},
  year = {2023},
  journal = {Translational Psychiatry},
  volume = {13},
  number = {1},
  pages = {319},
  publisher = {Nature Publishing Group UK London},
  urldate = {2024-06-05},
  file = {/Users/zenn/Zotero/storage/I3TU7UAL/Gozes et al. - 2023 - Unexpected gender differences in progressive supra.pdf}
}

@article{graffelmanExactInferenceHardyWeinberg2015,
  title = {Exact {{Inference}} for {{Hardy-Weinberg Proportions}} with {{Missing Genotypes}}: {{Single}} and {{Multiple Imputation}}},
  shorttitle = {Exact {{Inference}} for {{Hardy-Weinberg Proportions}} with {{Missing Genotypes}}},
  author = {Graffelman, Jan and Nelson, S. and Gogarten, S. M. and Weir, B. S.},
  year = {2015},
  journal = {G3 : genes - genomes - genetics},
  volume = {5},
  number = {11},
  pages = {2365--2373},
  publisher = {Genetics Society of America},
  address = {United States},
  issn = {2160-1836},
  doi = {10.1534/g3.115.022111},
  abstract = {This paper addresses the issue of exact-test based statistical inference for Hardy-Weinberg equilibrium in the presence of missing genotype data. Missing genotypes often are discarded when markers are tested for Hardy-Weinberg equilibrium, which can lead to bias in the statistical inference about equilibrium. Single and multiple imputation can improve inference on equilibrium. We develop tests for equilibrium in the presence of missingness by using both inbreeding coefficients (or, equivalently, {$\chi$}(2) statistics) and exact p-values. The analysis of a set of markers with a high missing rate from the GENEVA project on prematurity shows that exact inference on equilibrium can be altered considerably when missingness is taken into account. For markers with a high missing rate ({$>$}5\%), we found that both single and multiple imputation tend to diminish evidence for Hardy-Weinberg disequilibrium. Depending on the imputation method used, 6-13\% of the test results changed qualitatively at the 5\% level.},
  langid = {english},
  keywords = {Algorithms,Arees tematiques de la UPC,Biometry,Data Accuracy,Estadistica medica,exact test,Genetics Population - methods,Genomics,HardyWeinberg equilibrium,imputation,Inbreeding,Investigations,Linkage Disequilibrium,Matematiques i estadistica,missing data,Models Genetic,Quantitative Biology},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/graffelman et al_2015_exact inference for hardy-weinberg proportions with missing genotypes.pdf}
}

@article{graffelmanMidPvalueExact2013,
  title = {The Mid P-Value in Exact Tests for {{Hardy-Weinberg}} Equilibrium},
  author = {Graffelman, Jan and Moreno, Victor},
  year = {2013},
  month = aug,
  journal = {Statistical Applications in Genetics and Molecular Biology},
  volume = {12},
  number = {4},
  pages = {433--448},
  publisher = {De Gruyter},
  issn = {1544-6115},
  doi = {10.1515/sagmb-2012-0039},
  urldate = {2023-02-09},
  abstract = {Objective: Exact tests for Hardy-Weinberg equilibrium are widely used in genetic association studies. We evaluate the mid p -value, unknown in the genetics literature, as an alternative for the standard p -value in the exact test. Method: The type 1 error rate and the power of the exact test are calculated for different sample sizes, sigificance levels, minor allele counts and degrees of deviation from equilibrium. Three different p -value are considered: the standard two-sided p -value, the doubled one-sided p -value and the mid p -value. Practical implications of using the mid p -value are discussed with HapMap datasets and a data set on colon cancer. Results: The mid p -value is shown to have a type 1 error rate that is always closer to the nominal level, and to have better power. Differences between the standard p -value and the mid p -value can be large for insignificant results, and are smaller for significant results. The analysis of empirical databases shows that the mid p -value uncovers more significant markers, and that the equilibrium null distribution is not tenable for both databases. Conclusion: The standard exact p -value is overly conservative, in particular for small minor allele frequencies. The mid p -value ameliorates this problem by bringing the rejection rate closer to the nominal level, at the price of ocasionally exceeding the nominal level.},
  langid = {english},
  keywords = {Levene-Haldane distribution,power,single nucleotide polymorphism,type I error rate},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/graffelman_moreno_2013_the mid p-value in exact tests for hardy-weinberg equilibrium.pdf}
}

@article{graffelmanMultiAllelicExact2018,
  title = {Multi-allelic Exact Tests for {{Hardy}}--{{Weinberg}} Equilibrium That Account for Gender},
  author = {Graffelman, Jan and Weir, Bruce S.},
  year = {2018},
  journal = {Molecular Ecology Resources},
  volume = {18},
  number = {3},
  pages = {461--473},
  publisher = {Wiley Subscription Services, Inc},
  address = {England},
  issn = {1755-098X},
  doi = {10.1111/1755-0998.12748},
  abstract = {Statistical tests for Hardy--Weinberg equilibrium are important elementary tools in genetic data analysis. X-chromosomal variants have long been tested by applying autosomal test procedures to females only, and gender is usually not considered when testing autosomal variants for equilibrium. Recently, we proposed specific X-chromosomal exact test procedures for bi-allelic variants that include the hemizygous males, as well as autosomal tests that consider gender. In this study, we present the extension of the previous work for variants with multiple alleles. A full enumeration algorithm is used for the exact calculations of tri-allelic variants. For variants with many alternate alleles, we use a permutation test. Some empirical examples with data from the 1,000 genomes project are discussed.},
  langid = {english},
  keywords = {Algorithms,Alleles,Arees tematiques de la UPC,Chromosomes Human Pair 7 - chemistry,Chromosomes Human X - chemistry,Chromosomes Human X - genetics,Computer Simulation,Cromosomes,Data analysis,Data processing,Empirical analysis,Enumeration,Equilibrium,Estadistica matematica,Female,Females,Gender,Gene Frequency,Genetic analysis,Genetic Variation,Genetica,Genetics,Genomes,Genotype,Humans,Indel,Male,Males,Matematiques i estadistica,Mathematical statistics,microsatellite,Models estadistics,Models Genetic,Molecular,permutation test,Permutations,Resource,Resource Article,RESOURCE ARTICLES,Sex Factors,Statistical Advances,Statistical analysis,Statistical tests,X chromosome},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/graffelman_weir_2018_multi‐allelic exact tests for hardy–weinberg equilibrium that account for gender.pdf}
}

@book{granjonOutstandingUserInterfaces2022,
  title = {Outstanding {{User Interfaces}} with {{Shiny}}},
  author = {Granjon, David},
  year = {2022},
  month = aug,
  publisher = {CRC Press},
  abstract = {Outstanding User Interfaces with Shiny provides the reader with necessary knowledge to develop beautiful and highly interactive user interfaces. It gives the minimum requirements in HTML/JavaScript and CSS to be able to extend already existing Shiny layouts or develop new templates from scratch. Suitable for anyone with some experience of Shiny, package development and software engineering best practices, this book is an ideal guide for graduates and professionals who wish to bring their app design to the next level. Key Features:  Provides a survival kit in web development to seamlessly get started with HTML/CSS/JavaScript Leverage CSS and Sass and higher-level tools like \{bslib\} to substantially enhance the design of your app in no time A comprehensive guide to the \{htmltools\} package to seamlessly customize existing layouts Describes in detail how Shiny inputs work and how R and JavaScript communicate Details all the necessary steps to create a production-grade custom template from scratch: packaging, shiny tags creation, validating and testing R components and JavaScript Expose common web development debugging technics Provides a list of existing templates, resources to get started and to explore},
  googlebooks = {NjZ9EAAAQBAJ},
  isbn = {978-1-00-058708-1},
  langid = {english},
  keywords = {Business & Economics / Statistics,Mathematics / Probability & Statistics / General}
}

@article{Grassi2019,
  title = {A Novel Ensemble-Based Machine Learning Algorithm to Predict the Conversion from Mild Cognitive Impairment to {{Alzheimer}}'s Disease Using Socio-Demographic Characteristics, Clinical Information, and Neuropsychological Measures},
  author = {Grassi, Massimiliano and Rouleaux, Nadine and Caldirola, Daniela and Loewenstein, David and Schruers, Koen and Perna, Giampaolo and Dumontier, Michel},
  year = {2019},
  journal = {Frontiers in Neurology},
  volume = {10},
  number = {JUL},
  pages = {1--15},
  issn = {16642295},
  doi = {10.3389/fneur.2019.00756},
  abstract = {Background: Despite the increasing availability in brain health related data, clinically translatable methods to predict the conversion from Mild Cognitive Impairment (MCI) to Alzheimer's disease (AD) are still lacking. Although MCI typically precedes AD, only a fraction of 20-40\% of MCI individuals will progress to dementia within 3 years following the initial diagnosis. As currently available and emerging therapies likely have the greatest impact when provided at the earliest disease stage, the prompt identification of subjects at high risk for conversion to AD is of great importance in the fight against this disease. In this work, we propose a highly predictive machine learning algorithm, based only on non-invasively and easily in-the-clinic collectable predictors, to identify MCI subjects at risk for conversion to AD. Methods: The algorithm was developed using the open dataset from the Alzheimer's Disease Neuroimaging Initiative (ADNI), employing a sample of 550 MCI subjects whose diagnostic follow-up is available for at least 3 years after the baseline assessment. A restricted set of information regarding sociodemographic and clinical characteristics, neuropsychological test scores was used as predictors and several different supervised machine learning algorithms were developed and ensembled in final algorithm. A site-independent stratified train/test split protocol was used to provide an estimate of the generalized performance of the algorithm. Results: The final algorithm demonstrated an AUROC of 0.88, sensitivity of 77.7\%, and a specificity of 79.9\% on excluded test data. The specificity of the algorithm was 40.2\% for 100\% sensitivity. Conclusions: The algorithm we developed achieved sound and high prognostic performance to predict AD conversion using easily clinically derived information that makes the algorithm easy to be translated into practice. This indicates beneficial application to improve recruitment in clinical trials and to more selectively prescribe new and newly emerging early interventions to high AD risk patients.},
  keywords = {adni,Alzheimer's disease,Clinical prediction rule,machine learning,Machine learning,Mild cognitive impairment,Neuropsychological tests,Personalized medicine,Precision medicine},
  file = {/Users/zenn/Zotero/storage/ZDHW4RL8/grassi et al_2019_a novel ensemble-based machine learning algorithm to predict the conversion.pdf}
}

@article{gratuzeHuntingtonDiseaseTauopathy2016,
  title = {Is {{Huntington}}'s Disease a Tauopathy?},
  author = {Gratuze, Maud and Cisbani, Giulia and Cicchetti, Francesca and Planel, Emmanuel},
  year = {2016},
  month = apr,
  journal = {Brain: A Journal of Neurology},
  volume = {139},
  number = {Pt 4},
  pages = {1014--1025},
  issn = {1460-2156},
  doi = {10.1093/brain/aww021},
  abstract = {Tauopathies are a subclass of neurodegenerative diseases typified by the deposition of abnormal microtubule-associated tau protein within the cerebral tissue. Alzheimer's disease, progressive supranuclear palsy, chronic traumatic encephalopathy and some fronto-temporal dementias are examples of the extended family of tauopathies. In the last decades, intermittent reports of cerebral tau pathology in individuals afflicted with Huntington's disease-an autosomal dominant neurodegenerative disorder that manifests by severe motor, cognitive and psychiatric problems in adulthood-have also begun to surface. These observations remained anecdotal until recently when a series of publications brought forward compelling evidence that this monogenic disorder may, too, be a tauopathy. Collectively, these studies reported that: (i) patients with Huntington's disease present aggregated tau inclusions within various structures of the brain; (ii) tau haplotype influences the cognitive function of Huntington's disease patients; and (iii) that the genetic product of the disease, the mutant huntingtin protein, could alter tau splicing, phosphorylation, oligomerization and subcellular localization. Here, we review the past and current evidence in favour of the postulate that Huntington's disease is a new member of the family of tauopathies.},
  langid = {english},
  pmid = {26969684},
  keywords = {Animals,Brain,Clinical Trials as Topic,Humans,Huntington Disease,Huntington's disease,Phosphorylation,tau,tau Proteins,Tauopathies},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/gratuze et al_2016_is huntington's disease a tauopathy.pdf}
}

@article{greenSIMRPackagePower2016,
  title = {{{SIMR}}: {{An R}} Package for Power Analysis of Generalized Linear Mixed Models by Simulation},
  shorttitle = {{{SIMR}}},
  author = {Green, Peter and MacLeod, Catriona J.},
  year = {2016},
  journal = {Methods in Ecology and Evolution},
  volume = {7},
  number = {4},
  pages = {493--498},
  urldate = {2024-03-11},
  file = {/Users/zenn/Zotero/storage/EM863CUC/Green and MacLeod - 2016 - SIMR An R package for power analysis of generaliz.pdf}
}

@article{grootDiagnosticPrognosticPerformance2022,
  title = {Diagnostic and Prognostic Performance to Detect {{Alzheimer}}'s Disease and Clinical Progression of a Novel Assay for Plasma p-Tau217},
  author = {Groot, Colin and Cicognola, Claudia and Bali, Divya and {Triana-Baltzer}, Gallen and Dage, Jeffrey L. and Pontecorvo, Michael J. and Kolb, Hartmuth C. and Ossenkoppele, Rik and Janelidze, Shorena and Hansson, Oskar},
  year = {2022},
  month = may,
  journal = {Alzheimer's Research \& Therapy},
  volume = {14},
  number = {1},
  pages = {67},
  issn = {1758-9193},
  doi = {10.1186/s13195-022-01005-8},
  urldate = {2023-08-10},
  abstract = {Recent advances in disease-modifying treatments highlight the need for accurately identifying individuals in early Alzheimer's disease (AD) stages and for monitoring of treatment effects. Plasma measurements of phosphorylated tau (p-tau) are a promising biomarker for AD, but different assays show varying diagnostic and prognostic accuracies. The objective of this study was to determine the clinical performance of a novel plasma p-tau217 (p-tau217) assay, p-tau217+Janssen, and perform a head-to-head comparison to an established assay, plasma p-tau217Lilly, within two independent cohorts.},
  keywords = {Alzheimer's disease,Assay,Mild cognitive impairment,p-tau,Plasma biomarkers},
  file = {/Users/zenn/Zotero/storage/25HR2XVQ/Groot et al. - 2022 - Diagnostic and prognostic performance to detect Al.pdf;/Users/zenn/Zotero/storage/4J2HYU6G/s13195-022-01005-8.html}
}

@article{grundman1996alzheimer,
  title = {Alzheimer's Disease Cooperative Study},
  author = {Grundman, Michael and Thomas, Ronald G},
  year = {1996},
  journal = {Alzheimer Disease: From Molecular Biology to Theraphy},
  pages = {425},
  publisher = {Springer Science \& Business Media}
}

@inproceedings{grundman1996rate,
  title = {Rate of Dementia of the {{Alzheimer}} Type ({{DAT}}) in Subjects with Mild Cognitive Impairment},
  booktitle = {Neurology},
  author = {Grundman, Michael and Petersen, Ronald C and Morris, {\relax JC} and Ferris, S and Sano, Mary and Farlow, Martin R and Doody, Rachel S and Galasko, D and Ernesto, C and Thomas, {\relax RG} and others},
  year = {1996},
  volume = {46},
  pages = {50003--50003},
  publisher = {LITTLE BROWN CO 34 BEACON STREET, BOSTON, MA 02108-1493}
}

@article{grundman2000use,
  title = {Use of Brain {{MRI}} Volumetric Analysis in a Mild Cognitive Impairment Trial to Delay the Diagnosis of {{Alzheimer}}'s Disease},
  author = {Grundman, Michael and Sencakova, Drahomira and Jack, {\relax CR} and Fillit, H and O'Connell, A},
  year = {2000},
  journal = {Drug discovery and development for Alzheimer's disease},
  pages = {24--32}
}

@article{grundman2002brain,
  title = {Brain {{MRI}} Hippocampal Volume and Prediction of Clinical Status in a Mild Cognitive Impairment Trial},
  author = {Grundman, Michael and Sencakova, Drahomira and Jack, Clifford R and Petersen, Ronald C and Kim, Hyun T and Schultz, Arlan and Weiner, Myron F and DeCarli, Charles and DeKosky, Steven T and Van Dyck, Christopher and others},
  year = {2002},
  journal = {Journal of Molecular Neuroscience},
  volume = {19},
  number = {1},
  pages = {23--27},
  publisher = {Humana Press}
}

@article{grundman2002brain,
  title = {Brain {{MRI}} Hippocampal of Clinical Status in a Mild Volume and Prediction Cognitive Impairment Trial},
  author = {Grundman, M and Sencakova, D and Jack, {\relax CR} and Petersen, {\relax RC} and Kim, {\relax HT} and Schultz, A and Weiner, {\relax MF} and DeCarli, C and DeKosky, {\relax ST} and Van Dyck, C and others},
  year = {2002},
  journal = {Journal of Molecular Neuroscience},
  volume = {19},
  number = {1-2},
  pages = {23--27},
  publisher = {HUMANA PRESS INC 999 RIVERVIEW DRIVE SUITE 208, TOTOWA, NJ 07512 USA}
}

@inproceedings{grundman2002clinical,
  title = {Clinical Correlates of Hippocampal Atrophy in Patients with Mild Cognitive Impairment},
  booktitle = {Neurobiology of Aging},
  author = {Grundman, M and Kim, {\relax HT} and Schultz, {\relax AN} and Thomas, {\relax RG} and Thal, L and Jack, {\relax CR} and Peterson, {\relax RC}},
  year = {2002},
  volume = {23},
  pages = {S364--S364},
  publisher = {ELSEVIER SCIENCE INC 360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA}
}

@article{grundman2002phase,
  title = {A Phase {{I}} Study of {{AIT-082}} in Healthy Elderly Volunteers},
  author = {Grundman, Michael and Farlow, Martin and Peavy, Guerry and Kim, Hyun T and Capparelli, Edmund and Schultz, Arlan N and Salmon, David P and Ferris, Steven H and Mohs, Richard and Thomas, Ronald G and others},
  year = {2002},
  journal = {Journal of Molecular Neuroscience},
  volume = {18},
  number = {3},
  pages = {283--293},
  publisher = {Humana Press}
}

@article{grundman2003hippocampal,
  title = {Hippocampal Volume Is Associated with Memory but Not Nonmemory Cognitive Performance in Patients with Mild Cognitive Impairment},
  author = {Grundman, Michael and Jack, Clifford R and Petersen, Ronald C and Kim, Hyun T and Taylor, Curtis and Datvian, Marina and Weiner, Myron F and DeCarli, Charles and DeKosky, Steven T and Van Dyck, Christopher and others},
  year = {2003},
  journal = {Journal of Molecular Neuroscience},
  volume = {20},
  number = {3},
  pages = {241--248},
  publisher = {Humana Press}
}

@article{grundman2003multicenter,
  title = {A Multicenter, Randomized, Placebo Controlled, Multiple-Dose, Safety and Pharmacokinetic Study of {{AIT-082}} ({{Neotrofin}}™) in Mild {{Alzheimer}}'s Disease Patients},
  author = {Grundman, M and Capparelli, E and Kim, {\relax HT} and Morris, {\relax JC} and Farlow, M and Rubin, {\relax EH} and Heidebrink, J and Hake, A and Ho, G and Schultz, {\relax AN} and others},
  year = {2003},
  journal = {Life sciences},
  volume = {73},
  number = {5},
  pages = {539--553},
  publisher = {Pergamon}
}

@article{grundman2004mild,
  title = {Mild Cognitive Impairment Can Be Distinguished from {{Alzheimer}} Disease and Normal Aging for Clinical Trials},
  author = {Grundman, Michael and Petersen, Ronald C and Ferris, Steven H and Thomas, Ronald G and Aisen, Paul S and Bennett, David A and Foster, Norman L and Jack Jr, Clifford R and Galasko, Douglas R and Doody, Rachelle and others},
  year = {2004},
  journal = {Archives of neurology},
  volume = {61},
  number = {1},
  pages = {59--66},
  publisher = {American Medical Association}
}

@article{gulmezsevimEvaluationRetinalChanges2018,
  title = {Evaluation of {{Retinal Changes}} in {{Progressive Supranuclear Palsy}} and {{Parkinson Disease}}},
  author = {Gulmez Sevim, Duygu and Unlu, Metin and Gultekin, Murat and Karaca, Cagatay and Mirza, Meral and Mirza, Galip Ertugrul},
  year = {2018},
  month = jun,
  journal = {Journal of Neuro-Ophthalmology: The Official Journal of the North American Neuro-Ophthalmology Society},
  volume = {38},
  number = {2},
  pages = {151--155},
  issn = {1536-5166},
  doi = {10.1097/WNO.0000000000000591},
  abstract = {BACKGROUND: Differentiating Parkinson disease (PD) from progressive supranuclear palsy (PSP) can be challenging early in the clinical course. The aim of our study was to see if specific retinal changes could serve as a distinguishing feature. METHODS: We used spectral domain optical coherence tomography (SD-OCT) with automatic segmentation to measure peripapillary nerve fiber layer thickness and the thickness and volume of retinal layers at the macula. RESULTS: Thicknesses of superior peripapillary retinal nerve fiber layer (pRNFL), macular ganglion cell layer, inner plexiform layer, inner nuclear layer, and macular volume were more affected in PSP compared with PD (P {$<$} 0.05). Thicker inferotemporal pRNFL and lower macular volume were detected in levodopa users compared with nonusers in patients with PD. CONCLUSIONS: PD and PSP are associated with distinct changes in retinal morphology, which can be assessed with SD-OCT.},
  langid = {english},
  pmid = {29240574},
  keywords = {Aged,Antiparkinson Agents,Female,Humans,Levodopa,Male,Middle Aged,Nerve Fibers,Non-Randomized Controlled Trials as Topic,Optic Disk,Parkinson Disease,Prospective Studies,Retinal Diseases,Retinal Ganglion Cells,Supranuclear Palsy Progressive,Tomography Optical Coherence}
}

@article{gulmezsevimEvaluationRetinalChanges2018a,
  title = {Evaluation of {{Retinal Changes}} in {{Progressive Supranuclear Palsy}} and {{Parkinson Disease}}},
  author = {Gulmez Sevim, Duygu and Unlu, Metin and Gultekin, Murat and Karaca, Cagatay and Mirza, Meral and Mirza, Galip Ertugrul},
  year = {2018},
  month = jun,
  journal = {Journal of Neuro-Ophthalmology: The Official Journal of the North American Neuro-Ophthalmology Society},
  volume = {38},
  number = {2},
  pages = {151--155},
  issn = {1536-5166},
  doi = {10.1097/WNO.0000000000000591},
  abstract = {BACKGROUND: Differentiating Parkinson disease (PD) from progressive supranuclear palsy (PSP) can be challenging early in the clinical course. The aim of our study was to see if specific retinal changes could serve as a distinguishing feature. METHODS: We used spectral domain optical coherence tomography (SD-OCT) with automatic segmentation to measure peripapillary nerve fiber layer thickness and the thickness and volume of retinal layers at the macula. RESULTS: Thicknesses of superior peripapillary retinal nerve fiber layer (pRNFL), macular ganglion cell layer, inner plexiform layer, inner nuclear layer, and macular volume were more affected in PSP compared with PD (P {$<$} 0.05). Thicker inferotemporal pRNFL and lower macular volume were detected in levodopa users compared with nonusers in patients with PD. CONCLUSIONS: PD and PSP are associated with distinct changes in retinal morphology, which can be assessed with SD-OCT.},
  langid = {english},
  pmid = {29240574},
  keywords = {Aged,Antiparkinson Agents,Female,Humans,Levodopa,Male,Middle Aged,Nerve Fibers,Non-Randomized Controlled Trials as Topic,Optic Disk,Parkinson Disease,Prospective Studies,Retinal Diseases,Retinal Ganglion Cells,Supranuclear Palsy Progressive,Tomography Optical Coherence}
}

@article{Gumpertz2017,
  title = {A {{Simple Approach}} to {{Inference}} in {{Random Coefficient Models Author}} ( s ): {{Marcia Gumpertz}} and {{Sastry G}} . {{Pantula Source}} : {{The American Statistician}} , {{Vol}} . 43 , {{No}} . 4 ( {{Nov}} ., 1989 ), Pp . 203-210 {{Published}} by : {{Taylor}} \& {{Francis}} , {{Ltd}} . on Behalf of The},
  author = {Gumpertz, Marcia and Pantula, Sastry G},
  year = {2017},
  volume = {43},
  number = {4},
  pages = {203--210},
  keywords = {asymptotic inference,estimated general-,growth curve,ized least squares,repeated-measures},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/gumpertz_pantula_2017_a simple approach to inference in random coefficient models author ( s ).pdf}
}

@article{gumpertzSimpleApproachInference1989,
  title = {A Simple Approach to Inference in Random Coefficient Models},
  author = {Gumpertz, Marcia and Pantula, Sastry G.},
  year = {1989},
  journal = {American Statistician},
  volume = {43},
  number = {4},
  pages = {203--210},
  issn = {15372731},
  doi = {10.1080/00031305.1989.10475659},
  abstract = {Random coefficient regression models have been used to analyze cross-sectional and longitudinal data in economics and growth-curve data from biological and agricultural experiments. In the literature several estimators, including the ordinary least squares and the estimated generalized least squares (EGLS), have been considered for estimating the parameters of the mean model. Based on the asymptotic properties of the EGLS estimators, test statistics have been proposed for testing linear hypotheses involving the parameters of the mean model. An alternative estimator, the simple mean of the individual regression coefficients, provides estimation and hypothesis-testing procedures that are simple to compute and teach. The large sample properties of this simple estimator are shown to be similar to that of the EGLS estimator. The performance of the proposed estimator is compared with that of the existing estimators by Monte Carlo simulation. {\copyright} 1989 American Statistical Association.},
  keywords = {Asymptotic inference,Estimated generalized least squares,Growth curve,Repeated-measures regression},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/gumpertz_pantula_1989_a simple approach to inference in random coefficient models.pdf}
}

@article{guoDynamicsPlasmaBiomarkers2023,
  title = {The Dynamics of Plasma Biomarkers across the {{Alzheimer}}'s Continuum},
  author = {Guo, Yu and Shen, Xue-Ning and Wang, Hui-Fu and Chen, Shi-Dong and Zhang, Ya-Ru and Chen, Shu-Fen and Cui, Mei and Cheng, Wei and Dong, Qiang and Ma, Tao and Yu, Jin-Tai},
  year = {2023},
  month = feb,
  journal = {Alzheimer's Research \& Therapy},
  volume = {15},
  number = {1},
  pages = {31},
  issn = {1758-9193},
  doi = {10.1186/s13195-023-01174-0},
  urldate = {2023-02-13},
  abstract = {Failures in drug trials strengthen the necessity to further determine the neuropathological events during the development of Alzheimer's disease (AD). We sought to investigate the dynamic changes and performance of plasma biomarkers across the entire Alzheimer's continuum in the Chinese population.},
  keywords = {Alzheimer's continuum,Biomarker,Glial fibrillary acidic protein,Plasma,Trajectory},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/guo et al_2023_the dynamics of plasma biomarkers across the alzheimer’s continuum.pdf;/Users/zenn/Zotero/storage/MF5SI8WU/s13195-023-01174-0.html}
}

@article{guoSelectingSampleSize2013,
  title = {Selecting a Sample Size for Studies with Repeated Measures},
  author = {Guo, Yi and Logan, Henrietta L and Glueck, Deborah H and Muller, Keith E},
  year = {2013},
  month = dec,
  journal = {BMC Medical Research Methodology},
  volume = {13},
  number = {1},
  pages = {100},
  issn = {1471-2288},
  doi = {10.1186/1471-2288-13-100},
  urldate = {2024-05-08},
  copyright = {http://creativecommons.org/licenses/by/2.0},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/guo et al_2013_selecting a sample size for studies with repeated measures.pdf;/Users/zenn/Zotero/storage/3UJSKGYH/1471-2288-13-100.html}
}

@article{haass-kofflerTreatedDoxazosin2018,
  title = {Treated with Doxazosin},
  author = {{Haass-koffler}, Carolina L and Goodyear, Kimberly and Zywiak, William H and Magill, Molly and Eltinge, Sarah E and Wallace, Paul M and Long, Victoria M and {Jayaram-lindstr{\"o}m}, Nitya and Swift, M and Kenna, George A and Leggio, Lorenzo},
  year = {2018},
  pages = {23--28},
  doi = {10.1016/j.drugalcdep.2017.03.016.Higher},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/haass-koffler et al_2018_treated with doxazosin.pdf}
}

@article{haberExactUnconditionalTest1994,
  title = {An {{Exact Unconditional}} Test for the {{Hardy-Weinberg Equilibrium}}},
  author = {Haber, Michael},
  year = {1994},
  journal = {Biometrical Journal},
  volume = {36},
  number = {6},
  pages = {741--749},
  issn = {1521-4036},
  doi = {10.1002/bimj.4710360614},
  urldate = {2023-02-05},
  abstract = {An exact test based on the unconditional distribution of a test statistic for the Hardy-Weinberg equilibrium is introduced. This test is usually more powerful and requires less extensive tabulations compared with the (ordinary) exact conditional test. Tables of critical values are given for N = 5(1)100 and {$\alpha$} ={$\cdot$}10, {$\cdot$}05, {$\cdot$}01. Sample sizes required to attain a given power with the unconditional and conditional exact tests are provided.},
  langid = {english},
  keywords = {Genotypic frequencies,Goodness of fit,Inbreeding coefficient,Power,Sample size},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/haber_1994_an exact unconditional test for the hardy-weinberg equilibrium.pdf;/Users/zenn/Zotero/storage/LLZSQP2B/bimj.html}
}

@article{habermanWarningUseChiSquared1988,
  title = {A {{Warning}} on the {{Use}} of {{Chi-Squared Statistics}} with {{Frequency Tables}} with {{Small Expected Cell Counts}}},
  author = {Haberman, Shelby J.},
  year = {1988},
  month = jun,
  journal = {Journal of the American Statistical Association},
  volume = {83},
  number = {402},
  pages = {555--560},
  publisher = {Taylor \& Francis},
  issn = {0162-1459},
  doi = {10.1080/01621459.1988.10478632},
  urldate = {2024-02-09},
  abstract = {When applied to frequency tables with small expected cell counts, Pearson chi-squared test statistics may be asymptotically inconsistent even in cases in which a satisfactory chi-squared approximation exists for the distribution under the null hypothesis. This problem is particularly important in cases in which the number of cells is large and the expected cell counts are quite variable. To illustrate this bias of the chi-squared test, this article considers the Pearson chi-squared test of the hypothesis that the cell probabilities for a multinomial frequency table have specified values. In this case, the expected value and variance of the Pearson chi-square may be evaluated under both the null and alternative hypotheses. When the number of cells is large, normal approximations and discrete Edgeworth expansions may also be used to assess the size and power of the Pearson chi-squared test. These analyses show that unless all cell probabilities are equal, it is possible to select a significance level and cell probabilities under the alternative hypothesis such that the power is less than the size of the test. As shown by exact calculations, the difference may be substantial even in cases in which all expected cell sizes are at least 5 under the null hypothesis. The use of moments shows that given any minimum expected cell size under the null hypothesis and given any significance level, it is possible to make the power arbitrarily close to 0 by the selection of a large enough number of cells in the table and suitable cell probabilities for the null and alternative hypotheses. The normal approximations for the distribution of the Pearson chi-squared statistic permit the size of this bias to be assessed in less-extreme cases involving tables with many cells. These results imply that caution must be exercised in the application of Pearson chi-squared statistics to sparse contingency tables with many cells. An alternative to the Pearson chi-square, proposed by Zelterman (1986), avoids some of the problems. Exact calculation, however, shows that the alternative statistic does not eliminate all problems of bias. The problems described in this article clearly extend to more general applications of the Pearson chi-squared statistic.},
  keywords = {Asymptotic bias,Consistency},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/haberman_1988_a warning on the use of chi-squared statistics with frequency tables with small.pdf}
}

@article{habermanWarningUseChiSquared1988a,
  title = {A {{Warning}} on the {{Use}} of {{Chi-Squared Statistics}} with {{Frequency Tables}} with {{Small Expected Cell Counts}}},
  author = {Haberman, Shelby J.},
  year = {1988},
  month = jun,
  journal = {Journal of the American Statistical Association},
  volume = {83},
  number = {402},
  pages = {555--560},
  issn = {0162-1459, 1537-274X},
  doi = {10.1080/01621459.1988.10478632},
  urldate = {2024-02-09},
  langid = {english}
}

@article{hale1989effect,
  title = {Effect of Zinc Supplementation on the Development of Cardiovascular Disease in the Elderly},
  author = {Hale, William E and May, Franklin E and Thomas, Ronald G and Moore, Mary T and Stewart, Ronald B},
  year = {1989},
  journal = {Journal of Nutrition for the Elderly},
  volume = {8},
  number = {2},
  pages = {49--58},
  publisher = {Taylor \& Francis}
}

@article{hallerSimulationStudyEstimating2018,
  title = {A Simulation Study on Estimating Biomarker--Treatment Interaction Effects in Randomized Trials with Prognostic Variables},
  author = {Haller, Bernhard and Ulm, Kurt},
  year = {2018},
  month = dec,
  journal = {Trials},
  volume = {19},
  number = {1},
  pages = {128},
  issn = {1745-6215},
  doi = {10.1186/s13063-018-2491-0},
  urldate = {2024-04-11},
  abstract = {Background: To individualize treatment decisions based on patient characteristics, identification of an interaction between a biomarker and treatment is necessary. Often such potential interactions are analysed using data from randomized clinical trials intended for comparison of two treatments. Tests of interactions are often lacking statistical power and we investigated if and how a consideration of further prognostic variables can improve power and decrease the bias of estimated biomarker--treatment interactions in randomized clinical trials with time-to-event outcomes. Methods: A simulation study was performed to assess how prognostic factors affect the estimate of the biomarker--treatment interaction for a time-to-event outcome, when different approaches, like ignoring other prognostic factors, including all available covariates or using variable selection strategies, are applied. Different scenarios regarding the proportion of censored observations, the correlation structure between the covariate of interest and further potential prognostic variables, and the strength of the interaction were considered. Results: The simulation study revealed that in a regression model for estimating a biomarker--treatment interaction, the probability of detecting a biomarker--treatment interaction can be increased by including prognostic variables that are associated with the outcome, and that the interaction estimate is biased when relevant prognostic variables are not considered. However, the probability of a false-positive finding increases if too many potential predictors are included or if variable selection is performed inadequately. Conclusions: We recommend undertaking an adequate literature search before data analysis to derive information about potential prognostic variables and to gain power for detecting true interaction effects and pre-specifying analyses to avoid selective reporting and increased false-positive rates.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/WYHV6LQC/13063_2018_Article_2491.pdf}
}

@article{hallPrevalenceRatesDementia2009,
  title = {Prevalence Rates for Dementia and {{Alzheimer}} ' s Disease in {{African Americans}} : 1992 versus 2001},
  author = {Hall, Kathleen S and Gao, Sujuan and Baiyewu, Olusegun and Lane, Kathleen A and Gureje, Oye and Shen, Jianzhao and Ogunniyi, Adesola and Murrell, Jill R and Unverzagt, Frederick W and Dickens, Jeanne and {Smith-gamble}, Valerie and Hendrie, Hugh C},
  year = {2009},
  journal = {Alzheimer's \& Dementia},
  volume = {5},
  number = {3},
  pages = {227--233},
  publisher = {Elsevier Ltd},
  issn = {1552-5260},
  doi = {10.1016/j.jalz.2009.01.026},
  isbn = {3172741249},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/hall et al_2009_prevalence rates for dementia and alzheimer ’ s disease in african americans.pdf}
}

@article{hamasakiDesignDataMonitoring2018,
  title = {Design, Data Monitoring, and Analysis of Clinical Trials with Co-Primary Endpoints: {{A}} Review},
  author = {Hamasaki, Toshimitsu and Evans, Scott R. and Asakura, Koko},
  year = {2018},
  month = jan,
  journal = {Journal of Biopharmaceutical Statistics},
  volume = {28},
  number = {1},
  pages = {28--51},
  publisher = {{Taylor and Francis Inc.}},
  issn = {15205711},
  doi = {10.1080/10543406.2017.1378668},
  urldate = {2022-01-30},
  abstract = {We review the design, data monitoring, and analyses of clinical trials with co-primary endpoints. Recently developed methods for fixed-sample and group-sequential settings are described. Practical considerations are discussed, and guidance for the application of these methods is provided.},
  pmid = {29083951},
  keywords = {Co-primary endpoints (CPE),fixed-sample designs,group-sequential designs,intersection-union test (IUT),multiple primary endpoints (MPE),type II error adjustment},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/hamasaki et al_2018_design, data monitoring, and analysis of clinical trials with co-primary.pdf}
}

@inproceedings{hamilton2002correlates,
  title = {Correlates of Weight Change in {{Huntington}}'s Disease},
  booktitle = {{{NEUROLOGY}}},
  author = {Hamilton, {\relax JM} and {Corey-Bloom}, J and Thomas, {\relax RG} and Peavy, G and Jacobson, {\relax MW}},
  year = {2002},
  volume = {58},
  pages = {A309--A310},
  publisher = {LIPPINCOTT WILLIAMS \& WILKINS 530 WALNUT ST, PHILADELPHIA, PA 19106-3621 USA}
}

@article{hamilton2004comparison,
  title = {A Comparison of Episodic Memory Deficits in Neuropathologically-Confirmed {{Dementia}} with {{Lewy}} Bodies and {{Alzheimer}}'s Disease},
  author = {Hamilton, Joanne M and Salmon, David P and Galasko, Douglas and Delis, Dean C and Hansen, Lawrence A and Masliah, Eliezer and Thomas, Ronald G and Thal, Leon J},
  year = {2004},
  journal = {Journal of the International Neuropsychological Society},
  volume = {10},
  number = {5},
  pages = {689--697},
  publisher = {Cambridge University Press}
}

@article{Hansson2021,
  title = {Biomarkers for Neurodegenerative Diseases},
  author = {Hansson, Oskar},
  year = {2021},
  journal = {Nature Medicine},
  volume = {27},
  number = {6},
  pages = {954--963},
  publisher = {Springer US},
  issn = {1546170X},
  doi = {10.1038/s41591-021-01382-x},
  abstract = {Biomarkers for neurodegenerative diseases are needed to improve the diagnostic workup in the clinic but also to facilitate the development and monitoring of effective disease-modifying therapies. Positron emission tomography methods detecting amyloid-{$\beta$} and tau pathology in Alzheimer's disease have been increasingly used to improve the design of clinical trials and observational studies. In recent years, easily accessible and cost-effective blood-based biomarkers detecting the same Alzheimer's disease pathologies have been developed, which might revolutionize the diagnostic workup of Alzheimer's disease globally. Relevant biomarkers for {$\alpha$}-synuclein pathology in Parkinson's disease are also emerging, as well as blood-based markers of general neurodegeneration and glial activation. This review presents an overview of the latest advances in the field of biomarkers for neurodegenerative diseases. Future directions are discussed regarding implementation of novel biomarkers in clinical practice and trials.},
  pmid = {34083813},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/hansson_2021_biomarkers for neurodegenerative diseases.pdf}
}

@article{haoHypergraphConvolutionalNetwork2024,
  title = {Hypergraph Convolutional Network for Longitudinal Data Analysis in {{Alzheimer}}'s Disease},
  author = {Hao, Xiaoke and Li, Jiawang and Ma, Mingming and Qin, Jing and Zhang, Daoqiang and Liu, Feng},
  year = {2024},
  month = jan,
  journal = {Computers in Biology and Medicine},
  volume = {168},
  pages = {107765},
  issn = {00104825},
  doi = {10.1016/j.compbiomed.2023.107765},
  urldate = {2024-03-17},
  abstract = {Alzheimer's disease (AD) is an irreversible and progressive neurodegenerative disease. Longitudinal structural magnetic resonance imaging (sMRI) data have been widely used for tracking AD pathogenesis and diagnosis. However, existing methods tend to treat each time point equally without considering the temporal characteristics of longitudinal data. In this paper, we propose a weighted hypergraph convolution network (WHGCN) to use the internal correlations among different time points and leverage high-order relationships between subjects for AD detection. Specifically, we construct hypergraphs for sMRI data at each time point using the K-nearest neighbor (KNN) method to represent relationships between subjects, and then fuse the hypergraphs according to the importance of the data at each time point to obtain the final hypergraph. Subsequently, we use hypergraph convolution to learn high-order information between subjects while performing feature dimensionality reduc\- tion. Finally, we conduct experiments on 518 subjects selected from the Alzheimer's disease neuroimaging initiative (ADNI) database, and the results show that the WHGCN can get higher AD detection performance and has the potential to improve our understanding of the pathogenesis of AD.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/KPE7KXNU/1-s2.0-S0010482523012301-main.pdf}
}

@article{haoHypergraphConvolutionalNetwork2024a,
  title = {Hypergraph Convolutional Network for Longitudinal Data Analysis in {{Alzheimer}}'s Disease},
  author = {Hao, Xiaoke and Li, Jiawang and Ma, Mingming and Qin, Jing and Zhang, Daoqiang and Liu, Feng},
  year = {2024},
  month = jan,
  journal = {Computers in Biology and Medicine},
  volume = {168},
  pages = {107765},
  issn = {0010-4825},
  doi = {10.1016/j.compbiomed.2023.107765},
  urldate = {2024-03-17},
  abstract = {Alzheimer's disease (AD) is an irreversible and progressive neurodegenerative disease. Longitudinal structural magnetic resonance imaging (sMRI) data have been widely used for tracking AD pathogenesis and diagnosis. However, existing methods tend to treat each time point equally without considering the temporal characteristics of longitudinal data. In this paper, we propose a weighted hypergraph convolution network (WHGCN) to use the internal correlations among different time points and leverage high-order relationships between subjects for AD detection. Specifically, we construct hypergraphs for sMRI data at each time point using the K-nearest neighbor (KNN) method to represent relationships between subjects, and then fuse the hypergraphs according to the importance of the data at each time point to obtain the final hypergraph. Subsequently, we use hypergraph convolution to learn high-order information between subjects while performing feature dimensionality reduction. Finally, we conduct experiments on 518 subjects selected from the Alzheimer's disease neuroimaging initiative (ADNI) database, and the results show that the WHGCN can get higher AD detection performance and has the potential to improve our understanding of the pathogenesis of AD.},
  keywords = {Alzheimer's disease,Hypergraph convolutional network,Longitudinal data,Structural magnetic resonance imaging,Weighted fusion},
  file = {/Users/zenn/Zotero/storage/SPPKBET6/S0010482523012301.html}
}

@article{haoHypergraphConvolutionalNetwork2024b,
  title = {Hypergraph Convolutional Network for Longitudinal Data Analysis in {{Alzheimer}}'s Disease},
  author = {Hao, Xiaoke and Li, Jiawang and Ma, Mingming and Qin, Jing and Zhang, Daoqiang and Liu, Feng},
  year = {2024},
  month = jan,
  journal = {Computers in Biology and Medicine},
  volume = {168},
  pages = {107765},
  issn = {0010-4825},
  doi = {10.1016/j.compbiomed.2023.107765},
  urldate = {2024-03-17},
  abstract = {Alzheimer's disease (AD) is an irreversible and progressive neurodegenerative disease. Longitudinal structural magnetic resonance imaging (sMRI) data have been widely used for tracking AD pathogenesis and diagnosis. However, existing methods tend to treat each time point equally without considering the temporal characteristics of longitudinal data. In this paper, we propose a weighted hypergraph convolution network (WHGCN) to use the internal correlations among different time points and leverage high-order relationships between subjects for AD detection. Specifically, we construct hypergraphs for sMRI data at each time point using the K-nearest neighbor (KNN) method to represent relationships between subjects, and then fuse the hypergraphs according to the importance of the data at each time point to obtain the final hypergraph. Subsequently, we use hypergraph convolution to learn high-order information between subjects while performing feature dimensionality reduction. Finally, we conduct experiments on 518 subjects selected from the Alzheimer's disease neuroimaging initiative (ADNI) database, and the results show that the WHGCN can get higher AD detection performance and has the potential to improve our understanding of the pathogenesis of AD.},
  keywords = {Alzheimer's disease,Hypergraph convolutional network,Longitudinal data,Structural magnetic resonance imaging,Weighted fusion},
  file = {/Users/zenn/Zotero/storage/4HGPW5P8/S0010482523012301.html}
}

@article{harringtonISPYGlimpseFuture2016,
  title = {I-{{SPY}} 2 --- {{A Glimpse}} of the {{Future}} of {{Phase}} 2 {{Drug Development}}?},
  author = {Harrington, David and Parmigiani, Giovanni},
  year = {2016},
  month = jul,
  journal = {New England Journal of Medicine},
  volume = {375},
  number = {1},
  pages = {7--9},
  issn = {0028-4793, 1533-4406},
  doi = {10.1056/NEJMp1602256},
  urldate = {2022-10-20},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/harrington_parmigiani_2016_i-spy 2 — a glimpse of the future of phase 2 drug development.pdf}
}

@article{harrisonBriefIntroductionMixed2018,
  title = {A Brief Introduction to Mixed Effects Modelling and Multi-Model Inference in Ecology},
  author = {Harrison, Xavier A. and Donaldson, Lynda and {Correa-Cano}, Maria Eugenia and Evans, Julian and Fisher, David N. and Goodwin, Cecily E. D. and Robinson, Beth S. and Hodgson, David J. and Inger, Richard},
  year = {2018},
  month = may,
  journal = {PeerJ},
  volume = {6},
  pages = {e4794},
  publisher = {PeerJ Inc.},
  issn = {2167-8359},
  doi = {10.7717/peerj.4794},
  urldate = {2022-10-31},
  abstract = {The use of linear mixed effects models (LMMs) is increasingly common in the analysis of biological data. Whilst LMMs offer a flexible approach to modelling a broad range of data types, ecological data are often complex and require complex model structures, and the fitting and interpretation of such models is not always straightforward. The ability to achieve robust biological inference requires that practitioners know how and when to apply these tools. Here, we provide a general overview of current methods for the application of LMMs to biological data, and highlight the typical pitfalls that can be encountered in the statistical modelling process. We tackle several issues regarding methods of model selection, with particular reference to the use of information theory and multi-model inference in ecology. We offer practical solutions and direct the reader to key references that provide further technical detail for those seeking a deeper understanding. This overview should serve as a widely accessible code of best practice for applying LMMs to complex biological problems and model structures, and in doing so improve the robustness of conclusions drawn from studies investigating ecological and evolutionary questions.},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/harrison et al_2018_a brief introduction to mixed effects modelling and multi-model inference in.pdf;/Users/zenn/Zotero/storage/A28CPZPM/4794.html}
}

@article{harrisonNeuroimagingGeneticRisk2015,
  title = {Neuroimaging {{Genetic Risk}} for {{Alzheimer}}'s {{Disease}} in {{Preclinical Individuals}}: {{From Candidate Genes}} to {{Polygenic Approaches}}},
  author = {Harrison, Theresa M and Bookheimer, Susan Y},
  year = {2015},
  journal = {Biological Psychiatry: Cognitive Neuroscience and Neuroimaging},
  volume = {1},
  pages = {14--23},
  doi = {10.1016/j.bpsc.2015.09.003},
  abstract = {Better characterization of the preclinical phase of Alzheimer's disease (AD) is needed to develop effective interventions. Neuropathologic changes in AD, including neuronal loss and the formation of proteinaceous deposits, can begin 20 years before the onset of clinical symptoms. As such, the emergence of cognitive impairment should not be the sole basis used to diagnose AD or to evaluate individuals for enrollment in clinical trials for preventive AD treatments. Instead, early preclinical biomarkers of disease and genetic risk should be used to determine the most likely prognosis and to enroll individuals in appropriate clinical trials. Neuroimaging-based biomarkers and genetic analysis together present a powerful system for classifying preclinical pathology in patients. Disease-modifying interventions are more likely to produce positive outcomes when administered early in the course of AD. This review examines the utility of the neuroimaging genetics field as it applies to AD and early detection during the preclinical phase. Neuroimaging studies focused on single genetic risk factors are summarized. Particular focus is on the recent increased interest in polygenic methods, and the benefits and disadvantages of these approaches are discussed. Challenges in the neuroimaging genetics field, including limitations of statistical power arising from small effect sizes and the overuse of cross-sectional designs, are also discussed. Despite the limitations, neuroimaging genetics has already begun to influence clinical trial design and is expected to play a major role in the prevention of AD. A long prodrome precedes the emergence of the clinical symptoms of Alzheimer's disease (AD) (1--3). Increasingly, the time between the first silent pathologic changes in the brain and the earliest stages of cognitive impairment is understood to be a critical window during which prevention and treatment strategies may be most effective (4). This preclinical phase of AD pathogenesis that occurs before clinical symptoms emerge is not well characterized. By definition, individuals with preclinical AD are unaware that they are affected by any neurologic pathology, and their deficits are not detectable with cognitive testing. Preclinical AD is distinct from mild cognitive impairment, which is characterized by subtle cognitive decline and sometimes can progress to a clinical diagnosis of AD (5,6). In the absence of detectable cognitive decline, investigators have access to a limited set of research tools to explore preclinical AD in humans. These tools include neuroimaging, genetic testing, and biochemical assays of the blood and cerebrospinal fluid. Neuroimaging genetics research is poised to play a critical role in improving the characterization of the earliest phases of AD pathophysiology. In this article, we discuss the important role of neuroimaging genetics in AD prevention and treatment with a particular focus on the preclinical phase of the disease. Specifically, we review findings resulting from candidate gene and polygenic approaches to neuroimaging genetics studies in AD. The goal of this review is to educate readers on the status of the field, including its many limitations, and to argue that neuroimaging genetics research using polygenic approaches will lead to better characterization of preclinical AD, which is necessary to achieve effective AD prevention.},
  keywords = {Alzheimer's disease,Clinical trials,Genetics,Neuroimaging,Polygenic risk score,Preclinical},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/harrison_bookheimer_2015_neuroimaging genetic risk for alzheimer's disease in preclinical individuals.pdf}
}

@article{haughtonPackagesEstimatingFinite2012,
  title = {Packages for {{Estimating Finite Mixtures}} : {{A Review Packages}} for {{Estimating Finite Mixtures}} : {{A Review}}},
  author = {Haughton, Dominique and Haughton, Dominique},
  year = {2012},
  volume = {1305},
  number = {1997},
  keywords = {em algorithm,finite mixtures,maxi-,mum likelihood,weibull regressions},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/haughton_haughton_2012_packages for estimating finite mixtures.pdf}
}

@article{Haulcy2021,
  title = {Classifying {{Alzheimer}}'s {{Disease Using Audio}} and {{Text-Based Representations}} of {{Speech}}},
  author = {Haulcy, R'mani and Glass, James},
  year = {2021},
  journal = {Frontiers in Psychology},
  volume = {11},
  number = {January},
  pages = {1--13},
  issn = {16641078},
  doi = {10.3389/fpsyg.2020.624137},
  abstract = {Alzheimer's Disease (AD) is a form of dementia that affects the memory, cognition, and motor skills of patients. Extensive research has been done to develop accessible, cost-effective, and non-invasive techniques for the automatic detection of AD. Previous research has shown that speech can be used to distinguish between healthy patients and afflicted patients. In this paper, the ADReSS dataset, a dataset balanced by gender and age, was used to automatically classify AD from spontaneous speech. The performance of five classifiers, as well as a convolutional neural network and long short-term memory network, was compared when trained on audio features (i-vectors and x-vectors) and text features (word vectors, BERT embeddings, LIWC features, and CLAN features). The same audio and text features were used to train five regression models to predict the Mini-Mental State Examination score for each patient, a score that has a maximum value of 30. The top-performing classification models were the support vector machine and random forest classifiers trained on BERT embeddings, which both achieved an accuracy of 85.4\% on the test set. The best-performing regression model was the gradient boosting regression model trained on BERT embeddings and CLAN features, which had a root mean squared error of 4.56 on the test set. The performance on both tasks illustrates the feasibility of using speech to classify AD and predict neuropsychological scores.},
  keywords = {Alzheimer's disease,BERT,dementia detection,i-vectors,MMSE prediction,speech,word vectors,x-vectors},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/haulcy_glass_2021_classifying alzheimer's disease using audio and text-based representations of.pdf}
}

@article{hawthorneImputingCrossSectionalMissing2005,
  title = {Imputing {{Cross-Sectional Missing Data}}: {{Comparison}} of {{Common Techniques}}},
  shorttitle = {Imputing {{Cross-Sectional Missing Data}}},
  author = {Hawthorne, Graeme and Hawthorne, Graeme and Elliott, Peter},
  year = {2005},
  month = jul,
  journal = {Australian \& New Zealand Journal of Psychiatry},
  volume = {39},
  number = {7},
  pages = {583--590},
  publisher = {SAGE Publications Ltd},
  issn = {0004-8674},
  doi = {10.1080/j.1440-1614.2005.01630.x},
  urldate = {2023-09-29},
  abstract = {Objective: Increasing awareness of how missing data affects the analysis of clinical and public health interventions has led to increasing numbers of missing data procedures. There is little advice regarding which procedures should be selected under different circumstances. This paper compares six popular procedures: listwise deletion, item mean substitution, person mean substitution at two levels, regression imputation and hot deck imputation. Method: Using a complete dataset, each was examined under a variety of sample sizes and differing levels ofmissing data. The criteria were the true t-values for the entire sample. Results: The results suggest important differences. Ifmissing data are from a scale where about half the items are present, hot deck imputation or person mean substitution are best. Because person mean substitution is computationally simpler, similar in its efficiency, advocated by other researchers and more likely to be an option on statistical software packages, it is the method of choice. If the missing data are from a scale where more than half the items are missing, or with single-item measures, then hot deck imputation is recommended. The findings also showed that listwise deletion and item mean substitution performed poorly. Conclusions: Person mean and hot deck imputation are preferred. Since listwise deletion and item mean substitution performed poorly, yet are the most widely reported methods, the findings have broad implications.},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/hawthorne et al_2005_imputing cross-sectional missing data.pdf}
}

@article{hedayatOptimalEfficientCrossover2003,
  title = {Optimal and Efficient Crossover Designs under Different Assumptions about the Carryover Effects},
  author = {Hedayat, {\relax AS} and Statistics, J Stufken - Journal of Biopharmaceutical and 2003, undefined},
  year = {2003},
  journal = {Taylor \& Francis},
  volume = {13},
  number = {3},
  pages = {10016},
  issn = {1520-5711},
  doi = {10.1081/BIP-120022771},
  urldate = {2021-11-06},
  abstract = {In certain studies it is desirable or necessary that a subject, such as a patient in a medical trial, receive a treatment in each period. This facilitates a within-subject comparison of the treatments. Designs for studies of this type are called crossover designs or repeated measurements designs. If there are s subjects in p periods, the design should specify which of the t treatments is assigned to subject j in period i, i {$\frac{1}{4}$} 1;. . .; p; j {$\frac{1}{4}$} 1;. . .; s: Equivalently we may think of a design as assigning each subject to one of the t p possible treatment sequences. The choice of a design will clearly depend on the values of p, s, and t, to which we will refer as the design parameters. But for any set of design parameters, we will typically still have many design choices. To distinguish between different designs for the same design parameters, we will compare the designs under criteria that are related to the objective of the study. Often the objective is a comparison of the treatments, and we would choose a design that, in some sense, provides good estimates of the treatment differences. For these criteria, a design that is optimal under one statistical model may not be optimal under another. It is therefore also of interest to identify designs that are efficient (relative to an optimal design) for more than one model. The main difference in the models that we will consider is in how the possible first-order carryover effects are modeled. This is a controversial issue, and it is by no means our intent to resolve this here. But a design that is efficient under a variety of plausible models is preferable to one that performs well under one model but poorly under another. Our main focus will be on two models. One of these models has been considered extensively in the literature, while the other is relatively new. For selected design parameters, we will compare selected designs under these models.},
  keywords = {Modeling carryover,Optimal design,Repeated measurements,Washout periods},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/hedayat et al_2003_optimal and efficient crossover designs under different assumptions about the.pdf}
}

@article{hedayatOptimalEfficientCrossover2006,
  title = {Optimal and Efficient Crossover Designs When Subject Effects Are Random},
  author = {Hedayat, {\relax AS} and Stufken, J and Statistical, M Yang - Journal of the American and 2006, undefined},
  year = {2006},
  month = sep,
  journal = {Taylor \& Francis},
  volume = {101},
  number = {475},
  pages = {1031--1038},
  issn = {0162-1459},
  doi = {10.1198/016214505000001384},
  urldate = {2021-11-06},
  abstract = {Most studies on optimal crossover designs are based on models that assume subject effects to be fixed effects. In this article we identify and study optimal and efficient designs for a model with random subject effects. With the number of periods not exceeding the number of treatments, we find that totally balanced designs are universally optimal for treatment effects in a large subclass of competing designs. However, in the entire class of designs, totally balanced designs are in general not optimal, and their efficiency depends on the ratio of the subject effects variance and the error variance. We develop tools to study the efficiency of totally balanced designs and to identify designs with higher efficiency.},
  keywords = {Fisher information matrix,Mixed-effects model,Totally balanced design,Universal optimality},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/hedayat et al_2006_optimal and efficient crossover designs when subject effects are random.pdf}
}

@article{heddenComparisonMissingData2008,
  title = {A Comparison of Missing Data Methods for Hypothesis Tests of the Treatment Effect in Substance Abuse Clinical Trials: A {{Monte-Carlo}} Simulation Study},
  shorttitle = {A Comparison of Missing Data Methods for Hypothesis Tests of the Treatment Effect in Substance Abuse Clinical Trials},
  author = {Hedden, Sarra L. and Woolson, Robert F. and Malcolm, Robert J.},
  year = {2008},
  month = jun,
  journal = {Substance Abuse Treatment, Prevention, and Policy},
  volume = {3},
  number = {1},
  pages = {13},
  issn = {1747-597X},
  doi = {10.1186/1747-597X-3-13},
  urldate = {2023-08-12},
  abstract = {Missing data due to attrition are rampant in substance abuse clinical trials. However, missing data are often ignored in the presentation of substance abuse clinical trials. This paper demonstrates missing data methods which may be used for hypothesis testing.},
  langid = {english},
  keywords = {Longitudinal Data Analysis,Miss Data Mechanism,Miss Data Pattern,Miss Data Rate,Outpatient Substance Abuse Treatment},
  file = {/Users/zenn/Zotero/storage/UQX3JQ3Y/Hedden et al. - 2008 - A comparison of missing data methods for hypothesi.pdf}
}

@techreport{heEFFECTDIGOXINMORTALITY1997,
  title = {{{THE EFFECT OF DIGOXIN ON MORTALITY AND MORBIDITY IN PATIENTS WITH HEART FAILURE}}},
  author = {He, T and Igitalis, D and Nvestigation, I and Roup, G},
  year = {1997},
  volume = {336},
  pages = {525},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/he et al_1997_the effect of digoxin on mortality and morbidity in patients with heart failure.pdf}
}

@article{hendrickson2020optimizing,
  title = {Optimizing Aggregated N-of-1 Trial Designs for Predictive Biomarker Validation: Statistical Methods and Theoretical Findings},
  author = {Hendrickson, Rebecca C and Thomas, Ronald G and Schork, Nicholas J and Raskind, Murray A},
  year = {2020},
  journal = {Frontiers in Digital Health},
  pages = {13},
  publisher = {Frontiers}
}

@inproceedings{hendrickson2021longitudinal,
  title = {Longitudinal Effects of {{COVID-19}} Related Occupational Stressors on Health Care Workers and First Responders: {{Implications}} for Wellbeing, Workplace Retention, Suicidality, and the Relationship of Acute Stress Symptoms to {{PTSD}}},
  booktitle = {{{NEUROPSYCHOPHARMACOLOGY}}},
  author = {Hendrickson, Rebecca and Slevin, Roisin and Hoerster, Katherine and Chang, Bernard and Sano, Ellen and McCalle, Catherine and Monty, Gillian and Thomas, Ronald G and Raskind, Murray},
  year = {2021},
  volume = {46},
  pages = {121--122},
  publisher = {SPRINGERNATURE CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND}
}

@article{hendrickson2022impact,
  title = {The Impact of the {{COVID-19}} Pandemic on Mental Health, Occupational Functioning, and Professional Retention among Health Care Workers and First Responders},
  author = {Hendrickson, Rebecca C and Slevin, Rois{\'i}n A and Hoerster, Katherine D and Chang, Bernard P and Sano, Ellen and McCall, Catherine A and Monty, Gillian R and Thomas, Ronald G and Raskind, Murray A},
  year = {2022},
  journal = {Journal of general internal medicine},
  volume = {37},
  number = {2},
  pages = {397--408},
  publisher = {Springer International Publishing}
}

@article{hendricksonImpactCOVID19Pandemic2022,
  title = {The {{Impact}} of the {{COVID-19 Pandemic}} on {{Mental Health}}, {{Occupational Functioning}}, and {{Professional Retention Among Health Care Workers}} and {{First Responders}}},
  author = {Hendrickson, Rebecca C. and Slevin, Rois{\'i}n A. and Hoerster, Katherine D. and Chang, Bernard P. and Sano, Ellen and McCall, Catherine A. and Monty, Gillian R. and Thomas, Ronald G. and Raskind, Murray A.},
  year = {2022},
  month = feb,
  journal = {Journal of General Internal Medicine},
  volume = {37},
  number = {2},
  pages = {397--408},
  publisher = {Springer},
  issn = {15251497},
  doi = {10.1007/S11606-021-07252-Z/FIGURES/4},
  urldate = {2022-04-10},
  abstract = {Background: The COVID-19 pandemic has greatly affected front-line health care workers (HCW) and first responders (FR). The specific components of COVID-19 related occupational stressors (CROS) associated with psychiatric symptoms and reduced occupational functioning or retention remain poorly understood. Objectives: Examine the relationships between total and factored CROS, psychiatric symptoms, and occupational outcomes. Design: Observational, self-report, single time-point online assessment. Participants: A total of 510 US HCW (N = 301) and FR (N = 200) with occupational duties affected by the COVID-19 pandemic. Main Outcomes and Measures: CROS were assessed using a custom 17-item questionnaire. Post-traumatic stress disorder (PTSD), depression, insomnia, and generalized anxiety symptoms were assessed using the PTSD Checklist-5 (PCL5), Patient Health Questionnaire-9 (PHQ9), Insomnia Severity Index (ISI), and General Anxiety Disorder-7 (GAD7). Respondents' likelihood of leaving current field and occupational functioning were assessed with 2-item PROMIS subscales. Relationships were modeled using multivariable regression. Open-ended responses were coded using rapid template analysis. Results: CROS total scores correlated significantly with all four psychiatric symptom domains (R's =.42--.53), likelihood of leaving one's current occupation (R =.18), and trouble doing usual work (R =.28), all p's {$<$}.001. Half of HCW indicated a decreased likelihood of staying in their current occupation as a result of the pandemic. CROS were fit to a 3-factor model consisting of risk, demoralization, and volume factors. All CROS factors were associated with psychiatric symptom burden, but demoralization was most prominently associated with psychiatric symptoms and negative occupational outcomes. Among psychiatric symptoms, PTSD symptoms were most strongly associated with negative occupational outcomes. Open-ended statements emphasized lack of protection and support, increased occupational demands, and emotional impact of work duties. Conclusions and Relevance: These results demonstrate potentially treatable psychiatric symptoms in HCW and FR experiencing CROS, impacting both wellbeing and the health care system. Mitigating CROS, particularly by addressing factors driving demoralization, may improve HCW and FR mental health, occupational functioning, and retention.},
  pmid = {34918181},
  keywords = {COVID-19,Insomnia,Occupational trauma,Professional retention,PTSD},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/hendrickson et al_2022_the impact of the covid-19 pandemic on mental health, occupational functioning,.pdf}
}

@article{hendricksonOptimizingAggregatedNOf12020,
  title = {Optimizing {{Aggregated N-Of-1 Trial Designs}} for {{Predictive Biomarker Validation}}: {{Statistical Methods}} and {{Theoretical Findings}}},
  author = {Hendrickson, Rebecca C. and Thomas, Ronald G. and Schork, Nicholas J. and Raskind, Murray A.},
  year = {2020},
  month = aug,
  journal = {Frontiers in Digital Health},
  volume = {2},
  publisher = {Frontiers Media SA},
  doi = {10.3389/FDGTH.2020.00013/FULL},
  urldate = {2021-11-06},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/hendrickson et al_2020_optimizing aggregated n-of-1 trial designs for predictive biomarker validation.pdf}
}

@article{heoSampleSizeRequirement2010,
  title = {Sample Size Requirement to Detect an Intervention Effect at the End of Follow-up in a Longitudinal Cluster Randomized Trial},
  author = {Heo, Moonseong and Kim, Yongman and Xue, Xiaonan and Kim, Mimi Y.},
  year = {2010},
  month = feb,
  journal = {Statistics in Medicine},
  volume = {29},
  number = {3},
  pages = {382--390},
  issn = {02776715},
  doi = {10.1002/sim.3806},
  urldate = {2022-11-04},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/heo et al_2010_sample size requirement to detect an intervention effect at the end of.pdf}
}

@article{herbstHowManyDigits2024,
  title = {How {{Many Digits}} Are {{Needed}}?},
  author = {Herbst, Ira W. and M{\o}ller, Jesper and Svane, Anne Marie},
  year = {2024},
  month = feb,
  journal = {Methodology and Computing in Applied Probability},
  volume = {26},
  number = {1},
  pages = {5},
  issn = {1573-7713},
  doi = {10.1007/s11009-024-10073-2},
  urldate = {2024-02-26},
  abstract = {Let \$\$X\_1,X\_2,...\$\$be the digits in the base-q expansion of a random variable X defined on [0,~1) where \$\$q{\textbackslash}ge 2\$\$is an integer. For \$\$n=1,2,...\$\$, we study the probability distribution \$\$P\_n\$\$of the (scaled) remainder \$\$T{\textasciicircum}n(X)={\textbackslash}sum \_\{k=n+1\}{\textasciicircum}{\textbackslash}infty X\_k q{\textasciicircum}\{n-k\}\$\$: If X has an absolutely continuous CDF then \$\$P\_n\$\$converges in the total variation metric to the Lebesgue measure \$\${\textbackslash}mu \$\$on the unit interval. Under weak smoothness conditions we establish first a coupling between X and a non-negative integer valued random variable N so that \$\$T{\textasciicircum}N(X)\$\$follows \$\${\textbackslash}mu \$\$and is independent of \$\$(X\_1,...,X\_N)\$\$, and second exponentially fast convergence of \$\$P\_n\$\$and its PDF \$\$f\_n\$\$. We discuss how many digits are needed and show examples of our results.},
  langid = {english},
  keywords = {37A50,60F25,62E17,Asymptotic distribution,Coupling,Exponential convergence rate,Extended Newcomb-Benford law,Remainder of a digit expansion,Total variation distance},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/herbst et al_2024_how many digits are needed.pdf}
}

@article{Hernan2016,
  title = {Using {{Big Data}} to {{Emulate}} a {{Target Trial When}} a {{Randomized Trial Is Not Available}}},
  author = {Hern{\'a}n, Miguel A. and Robins, James M.},
  year = {2016},
  journal = {American Journal of Epidemiology},
  volume = {183},
  number = {8},
  pages = {758--764},
  issn = {14766256},
  doi = {10.1093/aje/kwv254},
  abstract = {Ideally, questions about comparative effectiveness or safety would be answered using an appropriately designed and conducted randomized experiment. When we cannot conduct a randomized experiment, we analyze observational data. Causal inference from large observational databases (big data) can be viewed as an attempt to emulate a randomized experiment - the target experiment or target trial - that would answer the question of interest. When the goal is to guide decisions among several strategies, causal analyses of observational data need to be evaluated with respect to how well they emulate a particular target trial. We outline a framework for comparative effectiveness research using big data that makes the target trial explicit. This framework channels counterfactual theory for comparing the effects of sustained treatment strategies, organizes analytic approaches, provides a structured process for the criticism of observational studies, and helps avoid common methodologic pitfalls.},
  pmid = {26994063},
  keywords = {big data,causal inference,comparative effectiveness research,target trial},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/hernán_robins_2016_using big data to emulate a target trial when a randomized trial is not.pdf}
}

@article{hernanPerProtocolAnalysesPragmatic2017,
  title = {Per-{{Protocol Analyses}} of {{Pragmatic Trials}}},
  author = {Hern{\'a}n, Miguel A. and Robins, James M.},
  year = {2017},
  month = oct,
  journal = {New England Journal of Medicine},
  volume = {377},
  number = {14},
  pages = {1391--1398},
  issn = {0028-4793, 1533-4406},
  doi = {10.1056/NEJMsm1605385},
  urldate = {2023-03-02},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/hernán_robins_2017_per-protocol analyses of pragmatic trials.pdf}
}

@article{herschtalEffectDichotomizationSkewed2023,
  title = {The Effect of Dichotomization of Skewed Adjustment Covariates in the Analysis of Clinical Trials},
  author = {Herschtal, Alan},
  year = {2023},
  month = mar,
  journal = {BMC Medical Research Methodology},
  volume = {23},
  number = {1},
  pages = {60},
  issn = {1471-2288},
  doi = {10.1186/s12874-023-01878-9},
  urldate = {2023-05-06},
  abstract = {Baseline imbalance in covariates associated with the primary outcome in clinical trials leads to bias in the reporting of results. Standard practice is to mitigate that bias by stratifying by those covariates in the randomization. Additionally, for continuously valued outcome variables, precision of estimates can be (and should be) improved by controlling for those covariates in analysis. Continuously valued covariates are commonly thresholded for the purpose of performing stratified randomization, with participants being allocated to arms such that balance between arms is achieved within each stratum. Often the thresholding consists of a simple dichotomization. For simplicity, it is also common practice to dichotomize the covariate when controlling for it at the analysis stage. This latter dichotomization is unnecessary, and has been shown in the literature to result in a loss of precision when compared with controlling for the covariate in its raw, continuous form. Analytic approaches to quantifying the magnitude of the loss of precision are generally confined to the most convenient case of a normally distributed covariate. This work generalises earlier findings, examining the effect on treatment effect estimation of dichotomizing skew-normal covariates, which are characteristic of a far wider range of real-world scenarios than their normal equivalents.},
  keywords = {Adjustment,Clinical trials,Covariates,Linear regression,Skewness,Stratification},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/herschtal_2023_the effect of dichotomization of skewed adjustment covariates in the analysis.pdf}
}

@article{heussenRandomizationBasedInferenceClinical2023,
  title = {Randomization-{{Based Inference}} for {{Clinical Trials}} with {{Missing Outcome Data}}},
  author = {Heussen, Nicole and Hilgers, Ralf-Dieter and Rosenberger, William F. and Tan, Xiao and Uschner, Diane},
  year = {2023},
  month = sep,
  journal = {Statistics in Biopharmaceutical Research},
  pages = {1--12},
  issn = {1946-6315},
  doi = {10.1080/19466315.2023.2250119},
  urldate = {2023-12-15},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/VG5KAYVM/Heussen et al. - 2023 - Randomization-Based Inference for Clinical Trials .pdf}
}

@article{heWalkingPaceHandgrip2023,
  title = {Walking Pace, Handgrip Strength, Age, {{APOE}} Genotypes, and New-Onset Dementia: The {{UK Biobank}} Prospective Cohort Study},
  shorttitle = {Walking Pace, Handgrip Strength, Age, {{APOE}} Genotypes, and New-Onset Dementia},
  author = {He, Panpan and Zhou, Chun and Ye, Ziliang and Liu, Mengyi and Zhang, Yuanyuan and Wu, Qimeng and Zhang, Yanjun and Yang, Sisi and Xiaoqin, Gan and Qin, Xianhui},
  year = {2023},
  month = jan,
  journal = {Alzheimer's Research \& Therapy},
  volume = {15},
  number = {1},
  pages = {9},
  issn = {1758-9193},
  doi = {10.1186/s13195-022-01158-6},
  urldate = {2023-01-16},
  abstract = {The independent and additive associations of walking pace and grip strength on dementia risk and the potential modifying effects of age, APOE phenotypes, and other dementia risk factors on the walking pace and dementia relationships demand further clarification. We aimed to investigate the independent and additive relationships of walking pace and handgrip strength on the risk of new-onset dementia and examine the potentially modifying effects of age, APOE phenotypes, lifestyle factors, and family history of dementia in the relationships.},
  keywords = {Age,APOE 4 dosage,Dementia,Handgrip strength,Walking pace},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/he et al_2023_walking pace, handgrip strength, age, apoe genotypes, and new-onset dementia.pdf;/Users/zenn/Zotero/storage/9MRQ3Y4Z/s13195-022-01158-6.html}
}

@article{hewerMinimalClinicallyImportant2016,
  title = {Minimal Clinically Important Worsening on the Progressive Supranuclear {{Palsy Rating Scale}}},
  author = {Hewer, Sarah and Varley, Sue and Boxer, Adam L. and Paul, Eldho and Williams, David R. and {AL-108-231 Investigators}},
  year = {2016},
  month = oct,
  journal = {Movement Disorders: Official Journal of the Movement Disorder Society},
  volume = {31},
  number = {10},
  pages = {1574--1577},
  issn = {1531-8257},
  doi = {10.1002/mds.26694},
  abstract = {BACKGROUND: Despite the widespread use of the Progressive Supranuclear Palsy Rating Scale (PSPRS), it is not known what change in this scale is meaningful for patients. METHODS: We analyzed data from a large clinical trial in PSP-Richardson's syndrome (AL-108-231) to calculate minimal clinically important worsening. This was defined as the difference in mean change of PSPRS in subjects rated "a little worse" and those rated "unchanged" on the Clinicians' Global Impression of Change Scale. A multivariate analysis using logistic regression assessed the relationship between clinical worsening, PSPRS, depression, and activities of daily living. RESULTS: The minimal clinically important worsening on the PSPRS was 5.7 points, corresponding to the mean decline over 6 months in the trial. Changes in activities of daily living and PSPRS were significantly associated with clinical worsening. CONCLUSIONS: Clinically meaningful change is measurable on the PSPRS over 6 months. {\copyright} 2016 International Parkinson and Movement Disorder Society.},
  langid = {english},
  pmcid = {PMC5215805},
  pmid = {27324431},
  keywords = {Aged,Disease Progression,Female,Humans,Male,Middle Aged,minimal clinically important change (MCIC),Minimal Clinically Important Difference,Oligopeptides,progressive supranuclear palsy (PSP),progressive supranuclear palsy rating scale (PSPRS),Severity of Illness Index,Supranuclear Palsy Progressive},
  file = {/Users/zenn/Zotero/storage/C649GXP2/Hewer et al. - 2016 - Minimal clinically important worsening on the prog.pdf}
}

@article{hewerMinimalClinicallyImportant2016a,
  title = {Minimal Clinically Important Worsening on the Progressive Supranuclear {{Palsy Rating Scale}}},
  author = {Hewer, Sarah and Varley, Sue and Boxer, Adam L. and Paul, Eldho and Williams, David R and Investigators, on behalf of the AL-108-231},
  year = {2016},
  journal = {Movement Disorders},
  volume = {31},
  number = {10},
  pages = {1574--1577},
  issn = {1531-8257},
  doi = {10.1002/mds.26694},
  urldate = {2024-06-05},
  abstract = {Background Despite the widespread use of the Progressive Supranuclear Palsy Rating Scale (PSPRS), it is not known what change in this scale is meaningful for patients. Methods We analyzed data from a large clinical trial in PSP-Richardson's syndrome (AL-108-231) to calculate minimal clinically important worsening. This was defined as the difference in mean change of PSPRS in subjects rated ``a little worse'' and those rated ``unchanged'' on the Clinicians' Global Impression of Change Scale. A multivariate analysis using logistic regression assessed the relationship between clinical worsening, PSPRS, depression, and activities of daily living. Results The minimal clinically important worsening on the PSPRS was 5.7 points, corresponding to the mean decline over 6 months in the trial. Changes in activities of daily living and PSPRS were significantly associated with clinical worsening. Conclusions Clinically meaningful change is measurable on the PSPRS over 6 months. {\copyright} 2016 International Parkinson and Movement Disorder Society},
  copyright = {{\copyright} 2016 2016 International Parkinson and Movement Disorder Society},
  langid = {english},
  keywords = {minimal clinically important change (MCIC),progressive supranuclear palsy (PSP),progressive supranuclear palsy rating scale (PSPRS)},
  file = {/Users/zenn/Zotero/storage/Q8YWKY6P/Hewer et al. - 2016 - Minimal clinically important worsening on the prog.pdf;/Users/zenn/Zotero/storage/AXFGF8XS/mds.html}
}

@article{hewerMinimalClinicallyImportant2016b,
  title = {Minimal Clinically Important Worsening on the Progressive Supranuclear {{Palsy Rating Scale}}},
  author = {Hewer, Sarah and Varley, Sue and Boxer, Adam L. and Paul, Eldho and Williams, David R and Investigators, on behalf of the AL-108-231},
  year = {2016},
  journal = {Movement Disorders},
  volume = {31},
  number = {10},
  pages = {1574--1577},
  issn = {1531-8257},
  doi = {10.1002/mds.26694},
  urldate = {2024-06-05},
  abstract = {Background Despite the widespread use of the Progressive Supranuclear Palsy Rating Scale (PSPRS), it is not known what change in this scale is meaningful for patients. Methods We analyzed data from a large clinical trial in PSP-Richardson's syndrome (AL-108-231) to calculate minimal clinically important worsening. This was defined as the difference in mean change of PSPRS in subjects rated ``a little worse'' and those rated ``unchanged'' on the Clinicians' Global Impression of Change Scale. A multivariate analysis using logistic regression assessed the relationship between clinical worsening, PSPRS, depression, and activities of daily living. Results The minimal clinically important worsening on the PSPRS was 5.7 points, corresponding to the mean decline over 6 months in the trial. Changes in activities of daily living and PSPRS were significantly associated with clinical worsening. Conclusions Clinically meaningful change is measurable on the PSPRS over 6 months. {\copyright} 2016 International Parkinson and Movement Disorder Society},
  langid = {english},
  keywords = {minimal clinically important change (MCIC),progressive supranuclear palsy (PSP),progressive supranuclear palsy rating scale (PSPRS)},
  file = {/Users/zenn/Zotero/storage/7XDT9SFI/Hewer et al. - 2016 - Minimal clinically important worsening on the prog.pdf}
}

@article{HHSPublicAccess2015,
  title = {{{HHS Public Access}}},
  year = {2015},
  volume = {2},
  number = {2},
  pages = {128--135},
  doi = {10.14283/jpad.2015.55.Endpoints},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/2015_hhs public access.pdf}
}

@article{higginbothamIntegratedProteomicsReveals2019,
  title = {Integrated {{Proteomics Reveals Brain-Based Cerebrospinal Fluid Biomarkers}} in {{Asymptomatic}} and {{Symptomatic Alzheimer}} ' s {{Disease}}},
  author = {Higginbotham, Lenora and Ping, Lingyan and Dammer, Eric B and Duong, Duc M},
  year = {2019},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/higginbotham et al_2019_integrated proteomics reveals brain-based cerebrospinal fluid biomarkers in.pdf}
}

@article{hilgersDesignAnalysisStratified2020,
  title = {Design and Analysis of Stratified Clinical Trials in the Presence of Bias},
  author = {Hilgers, Ralf-Dieter and Manolov, Martin and Heussen, Nicole and Rosenberger, William F},
  year = {2020},
  month = jun,
  journal = {Statistical Methods in Medical Research},
  volume = {29},
  number = {6},
  pages = {1715--1727},
  issn = {0962-2802, 1477-0334},
  doi = {10.1177/0962280219846146},
  urldate = {2023-12-15},
  abstract = {Background               Among various design aspects, the choice of randomization procedure have to be agreed on, when planning a clinical trial stratified by center. The aim of the paper is to present a methodological approach to evaluate whether a randomization procedure mitigates the impact of bias on the test decision in clinical trial stratified by center.                                         Methods               We use the weighted t test to analyze the data from a clinical trial stratified by center with a two-arm parallel group design, an intended 1:1 allocation ratio, aiming to prove a superiority hypothesis with a continuous normal endpoint without interim analysis and no adaptation in the randomization process. The derivation is based on the weighted t test under misclassification, i.e. ignoring bias. An additive bias model combing selection bias and time-trend bias is linked to different stratified randomization procedures.                                         Results               Various aspects to formulate stratified versions of randomization procedures are discussed. A formula for sample size calculation of the weighted t test is derived and used to specify the tolerated imbalance allowed by some randomization procedures. The distribution of the weighted t test under misclassification is deduced, taking the sequence of patient allocation to treatment, i.e. the randomization sequence into account. An additive bias model combining selection bias and time-trend bias at strata level linked to the applied randomization sequence is proposed. With these before mentioned components, the potential impact of bias on the type one error probability depending on the selected randomization sequence and thus the randomization procedure is formally derived and exemplarily calculated within a numerical evaluation study.                                         Conclusion               The proposed biasing policy and test distribution are necessary to conduct an evaluation of the comparative performance of (stratified) randomization procedure in multi-center clinical trials with a two-arm parallel group design. It enables the choice of the best practice procedure. The evaluation stimulates the discussion about the level of evidence resulting in those kind of clinical trials.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/YZ9RVSHI/Hilgers et al. - 2020 - Design and analysis of stratified clinical trials .pdf;/Users/zenn/Zotero/storage/4IEPU8UT/0962280219846146.html}
}

@misc{hinzShapeDerivativeApproach2023,
  title = {A Shape Derivative Approach to Domain Simplification},
  author = {Hinz, Jochen and Chanon, Ondine and Arrigoni, Alessandra and Buffa, Annalisa},
  year = {2023},
  month = jun,
  number = {arXiv:2306.05384},
  eprint = {2306.05384},
  primaryclass = {cs, math},
  publisher = {arXiv},
  urldate = {2023-06-09},
  abstract = {The objective of this study is to address the difficulty of simplifying the geometric model in which a differential problem is formulated, also called defeaturing, while simultaneously ensuring that the accuracy of the solution is maintained under control. This enables faster and more efficient simulations, without sacrificing accuracy. More precisely, we consider an isogeometric discretisation of an elliptic model problem defined on a two-dimensional hierarchical B-spline computational domain with a complex boundary. Starting with an oversimplification of the geometry, we build a goal-oriented adaptive strategy that adaptively reintroduces continuous geometrical features in regions where the analysis suggests a large impact on the quantity of interest. This strategy is driven by an a posteriori estimator of the defeaturing error based on first-order shape sensitivity analysis, and it profits from the local refinement properties of hierarchical B-splines. The adaptive algorithm is described together with a procedure to generate (partially) simplified hierarchical B-spline geometrical domains. Numerical experiments are presented to illustrate the proposed strategy and its limitations.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Mathematics - Numerical Analysis},
  file = {/Users/zenn/Zotero/storage/BBCIPUX9/Hinz et al. - 2023 - A shape derivative approach to domain simplificati.pdf}
}

@misc{hinzShapeDerivativeApproach2023a,
  title = {A Shape Derivative Approach to Domain Simplification},
  author = {Hinz, Jochen and Chanon, Ondine and Arrigoni, Alessandra and Buffa, Annalisa},
  year = {2023},
  month = jun,
  number = {arXiv:2306.05384},
  eprint = {2306.05384},
  primaryclass = {cs, math},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2306.05384},
  urldate = {2023-06-09},
  abstract = {The objective of this study is to address the difficulty of simplifying the geometric model in which a differential problem is formulated, also called defeaturing, while simultaneously ensuring that the accuracy of the solution is maintained under control. This enables faster and more efficient simulations, without sacrificing accuracy. More precisely, we consider an isogeometric discretisation of an elliptic model problem defined on a two-dimensional hierarchical B-spline computational domain with a complex boundary. Starting with an oversimplification of the geometry, we build a goal-oriented adaptive strategy that adaptively reintroduces continuous geometrical features in regions where the analysis suggests a large impact on the quantity of interest. This strategy is driven by an a posteriori estimator of the defeaturing error based on first-order shape sensitivity analysis, and it profits from the local refinement properties of hierarchical B-splines. The adaptive algorithm is described together with a procedure to generate (partially) simplified hierarchical B-spline geometrical domains. Numerical experiments are presented to illustrate the proposed strategy and its limitations.},
  archiveprefix = {arXiv},
  keywords = {Mathematics - Numerical Analysis},
  file = {/Users/zenn/Zotero/storage/QHSMRFQK/Hinz et al. - 2023 - A shape derivative approach to domain simplificati.pdf;/Users/zenn/Zotero/storage/R2DP5TJ3/2306.html}
}

@article{hirjiComparisonAlgorithmsExact1996,
  title = {A Comparison of Algorithms for Exact Analysis of Unordered 2 {\texttimes} {{K}} Contingency Tables},
  author = {Hirji, Karim F. and Johnson, Timothy D.},
  year = {1996},
  month = apr,
  journal = {Computational Statistics \& Data Analysis},
  volume = {21},
  number = {4},
  pages = {419--429},
  issn = {01679473},
  doi = {10.1016/0167-9473(94)00021-2},
  urldate = {2023-07-10},
  abstract = {We present a comparison of two efficient algorithms for exact analysis of an unordered 2 x K table. First, by considering conditional generating functions, we show that both the network algorithm of Mehta and Patel (J. Amer. Statist. Assoc. 78 (1983)) and the fast Fourier transform (FFT) algorithm of Baglivo et al. (J. Amer. Statist. Assoc. 82 (1992)) rest on the same foundation. This foundation is a recursive polynomial relation. We further show that the network algorithm is equivalent to a stage-wise implementation of this recursion while the FFT algorithm is based on performing the same recursion at complex roots of unity. Our empirical results for the Pearson X 2, likelihood ratio, and Freeman-Halton statistics show that the network algorithm, or equivalently, the recursive polynomial multiplication algorithm is superior to the FFT algorithm with respect to computing speed and accuracy.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/2IAEMKB5/Hirji and Johnson - 1996 - A comparison of algorithms for exact analysis of u.pdf}
}

@article{hirjiComparisonAlgorithmsExact1997,
  title = {A Comparison of Algorithms for Exact Goodness-of-Fit Tests for Multinomial Data},
  author = {Hirji, Karim F.},
  year = {1997},
  month = jan,
  journal = {Communications in Statistics - Simulation and Computation},
  volume = {26},
  number = {3},
  pages = {1197--1227},
  issn = {0361-0918},
  doi = {10.1080/03610919708813435},
  urldate = {2018-04-07},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/hirji_1997_a comparison of algorithms for exact goodness-of-fit tests for multinomial data.pdf}
}

@article{hirtzComparisonUltrasensitiveMass2023,
  title = {Comparison of Ultrasensitive and Mass Spectrometry Quantification of Blood-Based Amyloid Biomarkers for {{Alzheimer}}'s Disease Diagnosis in a Memory Clinic Cohort},
  author = {Hirtz, Christophe and Busto, Germain U. and Bennys, Karim and Kindermans, Jana and Navucet, Sophie and Tiers, Laurent and Lista, Simone and Vialaret, J{\'e}r{\^o}me and Gutierrez, Laure-Anne and Dauvilliers, Yves and Berr, Claudine and Lehmann, Sylvain and Gabelle, Audrey},
  year = {2023},
  month = feb,
  journal = {Alzheimer's Research \& Therapy},
  volume = {15},
  number = {1},
  pages = {34},
  issn = {1758-9193},
  doi = {10.1186/s13195-023-01188-8},
  urldate = {2023-02-21},
  abstract = {Alzheimer's disease (AD) is a complex neurodegenerative disorder with {$\beta$}-amyloid pathology as a key underlying process. The relevance of cerebrospinal fluid (CSF) and brain imaging biomarkers is validated in clinical practice for early diagnosis. Yet, their cost and perceived invasiveness are a limitation for large-scale implementation. Based on positive amyloid profiles, blood-based biomarkers should allow to detect people at risk for AD and to monitor patients under therapeutics strategies. Thanks to the recent development of innovative proteomic tools, the sensibility and specificity of blood biomarkers have been considerably improved. However, their diagnosis and prognosis relevance for daily clinical practice is still incomplete.},
  keywords = {Alzheimer's disease,Biomarkers,Diagnosis,IPMS,Plasma,Simoa},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/hirtz et al_2023_comparison of ultrasensitive and mass spectrometry quantification of.pdf;/Users/zenn/Zotero/storage/DPCRQYKT/s13195-023-01188-8.html}
}

@article{hobart2009p1,
  title = {P1-270: {{The ADAS-cog}}'s Performance as a Measure-Lessons from the {{ADNI}} Study: {{Part}} 3-Do the Scale Modifications Add Value?},
  author = {Hobart, Jeremy and Posner, Holly and Aisen, Paul and Selnes, Ola and Stern, Yaakov and Thomas, Ronald and Weiner, Michael and Zajicek, John and Zeger, Scott and Cano, Stefan},
  year = {2009},
  journal = {Alzheimer's \& Dementia},
  volume = {5},
  number = {4S\_Part\_9},
  pages = {P256--P256}
}

@article{hobart2013putting,
  title = {Putting the Alzheimer's Cognitive Test to the Test {{II}}: {{Rasch}} Measurement Theory},
  author = {Hobart, Jeremy and Cano, Stefan and Posner, Holly and Selnes, Ola and Stern, Yaakov and Thomas, Ronald and Zajicek, John and Initiative, Alzheimer's Disease Neuroimaging and others},
  year = {2013},
  journal = {Alzheimer's \& dementia},
  volume = {9},
  number = {1},
  pages = {S10--S20},
  publisher = {No longer published by Elsevier}
}

@article{hochbergMultiplicityProblemsMultiple2000,
  title = {4 {{On}} Some Multiplicity Problems and Multiple Comparison Procedures in Biostatistics},
  author = {Hochberg, Yosef and Westfall, Peter H.},
  year = {2000},
  journal = {Handbook of statistics},
  volume = {18},
  pages = {75--113},
  publisher = {Elsevier},
  urldate = {2024-03-12},
  file = {/Users/zenn/Zotero/storage/SSX9GZZ9/openurl.html}
}

@article{hochbergSharperBonferroniProcedure1988,
  title = {A Sharper {{Bonferroni}} Procedure for Multiple Tests of Significance},
  author = {HOCHBERG, {\relax YOSEF}},
  year = {1988},
  month = dec,
  journal = {Biometrika},
  volume = {75},
  number = {4},
  pages = {800--802},
  issn = {0006-3444},
  doi = {10.1093/biomet/75.4.800},
  urldate = {2024-03-12},
  abstract = {A simple procedure for multiple tests of significance based on individual p-values is derived. This simple procedure is sharper than Holm's (1979) sequentially rejective procedure. Both procedures contrast the ordered p- values with the same set of critical values. Holm's procedure rejects an hypothesis only if its p-value and each of the smaller p-values are less than their corresponding critical-values. The new procedure rejects all hypotheses with smaller or equal p-values to that of any one found less than its critical value.},
  file = {/Users/zenn/Zotero/storage/ZRVNAJ8W/HOCHBERG - 1988 - A sharper Bonferroni procedure for multiple tests .pdf;/Users/zenn/Zotero/storage/G2K5NBNB/423177.html}
}

@article{hochbergSharperBonferroniProcedure1988a,
  title = {A Sharper {{Bonferroni}} Procedure for Multiple Tests of Significance},
  author = {Hochberg, Yosef},
  year = {1988},
  journal = {Biometrika},
  volume = {75},
  number = {4},
  pages = {800--802},
  publisher = {Oxford University Press},
  urldate = {2024-03-12}
}

@article{hoglingerLongitudinalMagneticResonance2017,
  title = {Longitudinal Magnetic Resonance Imaging in Progressive Supranuclear Palsy: {{A}} New Combined Score for Clinical Trials},
  shorttitle = {Longitudinal Magnetic Resonance Imaging in Progressive Supranuclear Palsy},
  author = {H{\"o}glinger, G{\"u}nter U. and Sch{\"o}pe, Jakob and Stamelou, Maria and Kassubek, Jan and Del Ser, Teodoro and Boxer, Adam L. and Wagenpfeil, Stefan and Huppertz, Hans-J{\"u}rgen and {AL-108-231 Investigators} and {Tauros MRI Investigators} and {Movement Disorder Society-Endorsed PSP Study Group}},
  year = {2017},
  month = jun,
  journal = {Movement Disorders: Official Journal of the Movement Disorder Society},
  volume = {32},
  number = {6},
  pages = {842--852},
  issn = {1531-8257},
  doi = {10.1002/mds.26973},
  abstract = {BACKGROUND: Two recent, randomized, placebo-controlled phase II/III trials (clinicaltrials.gov: NCT01110720, NCT01049399) of davunetide and tideglusib in progressive supranuclear palsy (PSP) generated prospective, 1-year longitudinal datasets of high-resolution T1-weighted three-dimensional MRI. OBJECTIVE: The objective of this study was to develop a quantitative MRI disease progression measurement for clinical trials. METHODS: The authors performed a fully automated quantitative MRI analysis employing atlas-based volumetry and provide sample size calculations based on data collected in 99 PSP patients assigned to placebo in these trials. Based on individual volumes of 44 brain compartments and structures at baseline and 52 weeks of follow-up, means and standard deviations of annualized percentage volume changes were used to estimate standardized effect sizes and the required sample sizes per group for future 2-armed, placebo-controlled therapeutic trials. RESULTS: The highest standardized effect sizes were found for midbrain, frontal lobes, and the third ventricle. Using the annualized percentage volume change of these structures to detect a 50\% change in the 1-year progression (80\% power, significance level 5\%) required lower numbers of patients per group (third ventricle, n = 32; midbrain, n = 37; frontal lobe, n = 43) than the best clinical scale (PSP rating scale total score, n = 58). A combination of volume changes in these 3 structures reduced the number of required patients to only 20 and correlated best with the progression in the clinical scales. CONCLUSIONS: We propose the 1-year change in the volumes of third ventricle, midbrain, and frontal lobe as combined imaging read-out for clinical trials in PSP that require the least number of patients for detecting efficacy to reduce brain atrophy. {\copyright} 2017 International Parkinson and Movement Disorder Society.},
  langid = {english},
  pmcid = {PMC5808453},
  pmid = {28436538},
  keywords = {Aged,clinical trials,Clinical Trials as Topic,Disease Progression,Female,Frontal Lobe,Humans,Longitudinal Studies,magnetic resonance imaging,Magnetic Resonance Imaging,Male,Mesencephalon,Middle Aged,power calculation,progressive supranuclear palsy,Supranuclear Palsy Progressive,Third Ventricle,volumetry},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/höglinger et al_2017_longitudinal magnetic resonance imaging in progressive supranuclear palsy3.pdf}
}

@article{hoglingerLongitudinalMagneticResonance2017a,
  title = {Longitudinal Magnetic Resonance Imaging in Progressive Supranuclear Palsy: {{A}} New Combined Score for Clinical Trials},
  shorttitle = {Longitudinal Magnetic Resonance Imaging in Progressive Supranuclear Palsy},
  author = {H{\"o}glinger, G{\"u}nter U. and Sch{\"o}pe, Jakob and Stamelou, Maria and Kassubek, Jan and Del Ser, Teodoro and Boxer, Adam L. and Wagenpfeil, Stefan and Huppertz, Hans-J{\"u}rgen and {AL-108-231 Investigators} and {Tauros MRI Investigators} and {Movement Disorder Society-Endorsed PSP Study Group}},
  year = {2017},
  month = jun,
  journal = {Movement Disorders: Official Journal of the Movement Disorder Society},
  volume = {32},
  number = {6},
  pages = {842--852},
  issn = {1531-8257},
  doi = {10.1002/mds.26973},
  abstract = {BACKGROUND: Two recent, randomized, placebo-controlled phase II/III trials (clinicaltrials.gov: NCT01110720, NCT01049399) of davunetide and tideglusib in progressive supranuclear palsy (PSP) generated prospective, 1-year longitudinal datasets of high-resolution T1-weighted three-dimensional MRI. OBJECTIVE: The objective of this study was to develop a quantitative MRI disease progression measurement for clinical trials. METHODS: The authors performed a fully automated quantitative MRI analysis employing atlas-based volumetry and provide sample size calculations based on data collected in 99 PSP patients assigned to placebo in these trials. Based on individual volumes of 44 brain compartments and structures at baseline and 52 weeks of follow-up, means and standard deviations of annualized percentage volume changes were used to estimate standardized effect sizes and the required sample sizes per group for future 2-armed, placebo-controlled therapeutic trials. RESULTS: The highest standardized effect sizes were found for midbrain, frontal lobes, and the third ventricle. Using the annualized percentage volume change of these structures to detect a 50\% change in the 1-year progression (80\% power, significance level 5\%) required lower numbers of patients per group (third ventricle, n = 32; midbrain, n = 37; frontal lobe, n = 43) than the best clinical scale (PSP rating scale total score, n = 58). A combination of volume changes in these 3 structures reduced the number of required patients to only 20 and correlated best with the progression in the clinical scales. CONCLUSIONS: We propose the 1-year change in the volumes of third ventricle, midbrain, and frontal lobe as combined imaging read-out for clinical trials in PSP that require the least number of patients for detecting efficacy to reduce brain atrophy. {\copyright} 2017 International Parkinson and Movement Disorder Society.},
  langid = {english},
  pmcid = {PMC5808453},
  pmid = {28436538},
  keywords = {Aged,clinical trials,Clinical Trials as Topic,Disease Progression,Female,Frontal Lobe,Humans,Longitudinal Studies,magnetic resonance imaging,Magnetic Resonance Imaging,Male,Mesencephalon,Middle Aged,power calculation,progressive supranuclear palsy,Supranuclear Palsy Progressive,Third Ventricle,volumetry},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/höglinger et al_2017_longitudinal magnetic resonance imaging in progressive supranuclear palsy2.pdf}
}

@article{hoglingerLongitudinalMagneticResonance2017b,
  title = {Longitudinal Magnetic Resonance Imaging in Progressive Supranuclear Palsy: {{A}} New Combined Score for Clinical Trials},
  shorttitle = {Longitudinal Magnetic Resonance Imaging in Progressive Supranuclear Palsy},
  author = {H{\"o}glinger, G{\"u}nter U. and Sch{\"o}pe, Jakob and Stamelou, Maria and Kassubek, Jan and Del Ser, Teodoro and Boxer, Adam L. and Wagenpfeil, Stefan and Huppertz, Hans-J{\"u}rgen and {AL-108-231 Investigators} and {Tauros MRI Investigators} and {Movement Disorder Society-Endorsed PSP Study Group}},
  year = {2017},
  month = jun,
  journal = {Movement Disorders: Official Journal of the Movement Disorder Society},
  volume = {32},
  number = {6},
  pages = {842--852},
  issn = {1531-8257},
  doi = {10.1002/mds.26973},
  abstract = {BACKGROUND: Two recent, randomized, placebo-controlled phase II/III trials (clinicaltrials.gov: NCT01110720, NCT01049399) of davunetide and tideglusib in progressive supranuclear palsy (PSP) generated prospective, 1-year longitudinal datasets of high-resolution T1-weighted three-dimensional MRI. OBJECTIVE: The objective of this study was to develop a quantitative MRI disease progression measurement for clinical trials. METHODS: The authors performed a fully automated quantitative MRI analysis employing atlas-based volumetry and provide sample size calculations based on data collected in 99 PSP patients assigned to placebo in these trials. Based on individual volumes of 44 brain compartments and structures at baseline and 52 weeks of follow-up, means and standard deviations of annualized percentage volume changes were used to estimate standardized effect sizes and the required sample sizes per group for future 2-armed, placebo-controlled therapeutic trials. RESULTS: The highest standardized effect sizes were found for midbrain, frontal lobes, and the third ventricle. Using the annualized percentage volume change of these structures to detect a 50\% change in the 1-year progression (80\% power, significance level 5\%) required lower numbers of patients per group (third ventricle, n = 32; midbrain, n = 37; frontal lobe, n = 43) than the best clinical scale (PSP rating scale total score, n = 58). A combination of volume changes in these 3 structures reduced the number of required patients to only 20 and correlated best with the progression in the clinical scales. CONCLUSIONS: We propose the 1-year change in the volumes of third ventricle, midbrain, and frontal lobe as combined imaging read-out for clinical trials in PSP that require the least number of patients for detecting efficacy to reduce brain atrophy. {\copyright} 2017 International Parkinson and Movement Disorder Society.},
  langid = {english},
  pmcid = {PMC5808453},
  pmid = {28436538},
  keywords = {Aged,clinical trials,Clinical Trials as Topic,Disease Progression,Female,Frontal Lobe,Humans,Longitudinal Studies,magnetic resonance imaging,Magnetic Resonance Imaging,Male,Mesencephalon,Middle Aged,power calculation,progressive supranuclear palsy,Supranuclear Palsy Progressive,Third Ventricle,volumetry},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/höglinger et al_2017_longitudinal magnetic resonance imaging in progressive supranuclear palsy.pdf}
}

@article{hoglingerSafetyEfficacyTilavonemab2021,
  title = {Safety and Efficacy of Tilavonemab in Progressive Supranuclear Palsy: A Phase 2, Randomised, Placebo-Controlled Trial},
  shorttitle = {Safety and Efficacy of Tilavonemab in Progressive Supranuclear Palsy},
  author = {H{\"o}glinger, G{\"u}nter U. and Litvan, Irene and Mendonca, Nuno and Wang, Deli and Zheng, Hui and {Rendenbach-Mueller}, Beatrice and Lon, Hoi-Kei and Jin, Ziyi and Fisseha, Nahome and Budur, Kumar and Gold, Michael and Ryman, Davis and Florian, Hana and Ahmed, Anwar and Aiba, Ikuko and Albanese, Alberto and Bertram, Kelly and Bordelon, Yvette and Bower, James and Brosch, Jared and Claassen, Daniel and Colosimo, Carlo and Corvol, Jean-Christophe and Cudia, Paola and Daniele, Antonio and Defebvre, Luc and {Driver-Dunckley}, Erika and Duquette, Antoine and Eleopra, Roberto and Eusebio, Alexandre and Fung, Victor and Geldmacher, David and Golbe, Lawrence and Grandas, Francisco and Hall, Deborah and Hatano, Taku and H{\"o}glinger, G{\"u}nter U. and Honig, Lawrence and Hui, Jennifer and Kerwin, Diana and Kikuchi, Akio and Kimber, Thomas and Kimura, Takashi and Kumar, Rajeev and Litvan, Irene and Ljubenkov, Peter and Lorenzl, Stefan and Ludolph, Albert and Mari, Zoltan and McFarland, Nikolaus and Meissner, Wassilios and Rivera, Pablo Mir and Mochizuki, Hidek and Morgan, John and Munhoz, Renato and Nishikawa, Noriko and O`Sullivan, John and Oeda, Tomoko and Oizumi, Hideki and Onodera, Osamu and {Ory-Magne}, Fabienne and Peckham, Elizabeth and Postuma, Ronald and Quattrone, Aldo and Quinn, Joseph and Ruggieri, Stefano and Sarna, Justyna and Schulz, Paul E. and Slevin, John and Tagliati, Michele and Wile, Daryl and Wszolek, Zbigniew and Xie, Tao and Zesiewicz, Theresa},
  year = {2021},
  month = mar,
  journal = {The Lancet Neurology},
  volume = {20},
  number = {3},
  pages = {182--192},
  publisher = {Elsevier},
  issn = {1474-4422, 1474-4465},
  doi = {10.1016/S1474-4422(20)30489-0},
  urldate = {2024-04-23},
  langid = {english},
  pmid = {33609476},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/höglinger et al_2021_safety and efficacy of tilavonemab in progressive supranuclear palsy.pdf}
}

@inproceedings{hohl1997diagnostic,
  title = {Diagnostic Accuracy of Dementia with {{Lewy}} Bodies: {{A}} Prospective Evaluation},
  booktitle = {Neurology},
  author = {Hohl, U and CoreyBloom, J and Hansen, {\relax LA} and Thomas, {\relax RG} and Thal, {\relax LJ}},
  year = {1997},
  volume = {48},
  pages = {2032--2032},
  publisher = {LIPPINCOTT-RAVEN PUBL 227 EAST WASHINGTON SQ, PHILADELPHIA, PA 19106}
}

@article{hohl1999mini,
  title = {Mini-Mental State Examination and Mattis Dementia Rating Scale Performance Differs in Hispanic and Non-{{Hispanic}} Alzheimer's Disease Patients},
  author = {Hohl, Ursula and Grundman, Michael and Salmon, David P and Thomas, Ronald G and Thal, Leon J},
  year = {1999},
  journal = {Journal of the International Neuropsychological Society},
  volume = {5},
  number = {4},
  pages = {301--307},
  publisher = {Cambridge University Press}
}

@article{howellComputingExactProbability1976,
  title = {Computing the Exact Probability of an r by c Contingency Table with Fixed Marginal Totals},
  author = {Howell, David C. and Gordon, Lawrence R.},
  year = {1976},
  journal = {Behavior Research Methods \& Instrumentation},
  volume = {8},
  number = {3},
  pages = {317--317},
  publisher = {Springer-Verlag New York}
}

@misc{HttpProceedingsMlr,
  title = {{{http://proceedings.mlr.press/v28/ross13a.pdf}}},
  urldate = {2024-03-30},
  howpublished = {http://proceedings.mlr.press/v28/ross13a.pdf}
}

@article{hu2021power,
  title = {Power and Sample Size for Random Coefficient Regression Models in Randomized Experiments with Monotone Missing Data},
  author = {Hu, Nan and Mackey, Howard and Thomas, Ronald},
  year = {2021},
  journal = {Biometrical Journal},
  volume = {63},
  number = {4},
  pages = {806--824}
}

@article{Hubbard,
  title = {Spontaneous {{Isomerization}} of {{Asp387}} in {{Tau}} Is {{Diagnostic}} for {{Alzheimer}}'s {{Disease}}: {{An Endogenous Indicator}} of {{Reduced Autophagic Flux}}},
  author = {Hubbard, Evan E and Heil, Lilian and Merrihew, Gennifer E and Chhatwal, Jasmeer P and Farlow, Martin R and Mclean, Catriona A and Ghetti, Bernardino and Newell, Kathy L and Frosch, Matthew P and Bateman, Randall J and Larson, Eric B and Keene, C Dirk and Montine, Thomas J and Maccoss, Michael and Julian, Ryan R},
  doi = {10.1101/2021.04.21.440819},
  urldate = {2021-04-23},
  abstract = {Amino acid isomerization is a spontaneous chemical modification potentially related to the underlying causes of Alzheimer's disease (AD). We demonstrate that data-independent acquisition mass spectrometry can be used to characterize isomerization in complex protein mixtures. Examination of a large cohort of brain tissue samples revealed a striking relationship between isomerization of tau and AD status. Surprisingly, isomerization was found to be more abundant in both autosomal dominant and sporadic AD samples relative to controls. We hypothesize that lower autophagic flux in AD brains accounts for these results. Additional data, including quantitative analysis of proteins related to autophagy, strongly support this hypothesis. For example, isomerization of tau is positively correlated with levels of p62, a recognized indicator of autophagic inhibition. In sum, the data suggest strong ties between isomerization and autophagic flux, which may therefore represent a promising target for future investigations into the therapy and prevention of AD.},
  keywords = {age-related neurodegenerative disease,amyloid,amyloid-beta,aspartic acid,hippocampus,lysosome,neurofibrillary tangle,post-translational modification,proteomics,proteostasis},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/hubbard et al_spontaneous isomerization of asp387 in tau is diagnostic for alzheimer's disease.pdf}
}

@article{huberMonteCarloAlgorithms2006,
  title = {Monte {{Carlo Algorithms}} for {{Hardy}}--{{Weinberg Proportions}}},
  author = {Huber, Mark and Chen, Yuguo and Dinwoodie, Ian and Dobra, Adrian and Nicholas, Mike},
  year = {2006},
  journal = {Biometrics},
  volume = {62},
  number = {1},
  pages = {49--53},
  issn = {1541-0420},
  doi = {10.1111/j.1541-0420.2005.00418.x},
  urldate = {2022-11-05},
  abstract = {The Hardy--Weinberg law is among the most important principles in the study of biological systems (Crow, 1988, Genetics119, 473--476). Given its importance, many tests have been devised to determine whether a finite population follows Hardy--Weinberg proportions. Because asymptotic tests can fail, Guo and Thompson (1992, Biometrics48, 361--372) developed an exact test; unfortunately, the Monte Carlo method they proposed to evaluate their test has a running time that grows linearly in the size of the population N. Here, we propose a new algorithm whose expected running time is linear in the size of the table produced, and completely independent of N. In practice, this new algorithm can be considerably faster than the original method.},
  langid = {english},
  keywords = {Direct sampling,Exact p-value,Hardy-Weinberg,Monte Carlo},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/huber et al_2006_monte carlo algorithms for hardy–weinberg proportions.pdf;/Users/zenn/Zotero/storage/LFEGT4B7/j.1541-0420.2005.00418.html}
}

@misc{huisa2018memantine,
  title = {Memantine and Cholinesterase Inhibitor Use in Alzheimer Disease Trials: {{Potential}} for Confounding by Indication (P6. 178)},
  author = {Huisa, Branko and Thomas, Ronald and Jin, Shelia and Oltersdorf, Tilman and Taylor, Curtis and Feldman, Howard},
  year = {2018},
  publisher = {Wolters Kluwer Health, Inc. on behalf of the American Academy of Neurology}
}

@article{huisa2019memantine,
  title = {Memantine and Acetylcholinesterase Inhibitor Use in {{Alzheimer}}'s Disease Clinical Trials: {{Potential}} for Confounding by Indication},
  author = {Huisa, Branko N and Thomas, Ronald G and Jin, Shelia and Oltersdorf, Tilman and Taylor, Curtis and Feldman, Howard H},
  year = {2019},
  journal = {Journal of Alzheimer's Disease},
  volume = {67},
  number = {2},
  pages = {707--713},
  publisher = {IOS Press}
}

@article{hungControversialMultipleTesting2009,
  title = {Some Controversial Multiple Testing Problems in Regulatory Applications},
  author = {Hung, H. M.James and Wang, Sue Jane},
  year = {2009},
  month = jan,
  journal = {Journal of Biopharmaceutical Statistics},
  volume = {19},
  number = {1},
  pages = {1--11},
  issn = {10543406},
  doi = {10.1080/10543400802541693},
  urldate = {2022-01-30},
  abstract = {Multiple testing problems in regulatory applications are often more challenging than the problems of handling a set of mathematical symbols representing multiple null hypotheses under testing. In the union-intersection setting, it is important to define a family of null hypotheses relevant to the clinical questions at issue. The distinction between primary endpoint and secondary endpoint needs to be considered properly in different clinical applications. Without proper consideration, the widely used sequential gate keeping strategies often impose too many logical restrictions to make sense, particularly to deal with the problem of testing multiple doses and multiple endpoints, the problem of testing a composite endpoint and its component endpoints, and the problem of testing superiority and noninferiority in the presence of multiple endpoints. Partitioning the null hypotheses involved in closed testing into clinical relevant orderings or sets can be a viable alternative to resolving the illogical problems requiring more attention from clinical trialists in defining the clinical hypotheses or clinical question(s) at the design stage. In the intersection-union setting there is little room for alleviating the stringency of the requirement that each endpoint must meet the same intended alpha level, unless the parameter space under the null hypothesis can be substantially restricted. Such restriction often requires insurmountable justification and usually cannot be supported by the internal data. Thus, a possible remedial approach to alleviate the possible conservatism as a result of this requirement is a group-sequential design strategy that starts with a conservative sample size planning and then utilizes an alpha spending function to possibly reach the conclusion early. Copyright {\copyright} Taylor \& Francis Group, LLC.},
  pmid = {19127460},
  keywords = {Composite endpoint,Group-sequential,Intersection-union,Noninferiority,Sequential gate keeping,Studywise,Superiority,Union-intersection},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/hung_wang_2009_some controversial multiple testing problems in regulatory applications.pdf}
}

@misc{huntReviewContainerizationInteractive2021,
  title = {A {{Review}} of {{Containerization}} for {{Interactive}} and {{Reproducible Analysis}}},
  author = {Hunt, Gregory J. and {Gagnon-Bartsch}, Johann A.},
  year = {2021},
  month = aug,
  number = {arXiv:2103.16004},
  eprint = {2103.16004},
  primaryclass = {stat},
  publisher = {arXiv},
  urldate = {2023-06-22},
  abstract = {In recent decades the analysis of data has become increasingly computational. Correspondingly, this has changed how scientific and statistical work is shared. For example, it is now commonplace for underlying analysis code and data to be proffered alongside journal publications and conference talks. Unfortunately, sharing code faces several challenges. First, it is often difficult to take code from one computer and run it on another. Code configuration, version, and dependency issues often make this challenging. Secondly, even if the code runs, it is often hard to understand or interact with the analysis. This makes it difficult to assess the code and its findings, for example, in a peer review process. In this review we describe the combination of two computing technologies that help make analyses shareable, interactive, and completely reproducible. These technologies are (1) analysis containerization, which leverages virtualization to fully encapsulate analysis, data, code and dependencies into an interactive and shareable format, and (2) code notebooks, a literate programming format for interacting with analyses. The fusion of these two technologies offers significant advantages over using either individually. This review surveys how the combination enhances the accessibility and reproducibility of code, analyses, and ideas.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Statistics - Other Statistics},
  file = {/Users/zenn/Zotero/storage/593IHVVJ/2103.16004.pdf}
}

@article{huqueComparisonMultipleImputation2018,
  title = {A Comparison of Multiple Imputation Methods for Missing Data in Longitudinal Studies 01 {{Mathematical Sciences}}},
  author = {Huque, Md Hamidul and Carlin, John B. and Simpson, Julie A. and Lee, Katherine J.},
  year = {2018},
  month = dec,
  journal = {BMC Medical Research Methodology},
  volume = {18},
  number = {1},
  publisher = {BioMed Central Ltd.},
  issn = {14712288},
  doi = {10.1186/s12874-018-0615-6},
  abstract = {Background: Multiple imputation (MI) is now widely used to handle missing data in longitudinal studies. Several MI techniques have been proposed to impute incomplete longitudinal covariates, including standard fully conditional specification (FCS-Standard) and joint multivariate normal imputation (JM-MVN), which treat repeated measurements as distinct variables, and various extensions based on generalized linear mixed models. Although these MI approaches have been implemented in various software packages, there has not been a comprehensive evaluation of the relative performance of these methods in the context of longitudinal data. Method: Using both empirical data and a simulation study based on data from the six waves of the Longitudinal Study of Australian Children (N = 4661), we investigated the performance of a wide range of MI methods available in standard software packages for investigating the association between child body mass index (BMI) and quality of life using both a linear regression and a linear mixed-effects model. Results: In this paper, we have identified and compared 12 different MI methods for imputing missing data in longitudinal studies. Analysis of simulated data under missing at random (MAR) mechanisms showed that the generally available MI methods provided less biased estimates with better coverage for the linear regression model and around half of these methods performed well for the estimation of regression parameters for a linear mixed model with random intercept. With the observed data, we observed an inverse association between child BMI and quality of life, with available data as well as multiple imputation. Conclusion: Both FCS-Standard and JM-MVN performed well for the estimation of regression parameters in both analysis models. More complex methods that explicitly reflect the longitudinal structure for these analysis models may only be needed in specific circumstances such as irregularly spaced data.},
  pmid = {30541455},
  keywords = {FCS,Joint modelling,Linear mixed model,Longitudinal missing data,MICE,Multilevel multiple imputation,Multiple imputation},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/huque et al_2018_a comparison of multiple imputation methods for missing data in longitudinal.pdf}
}

@article{iasonosAdaptiveDoseFindingStudies2014,
  title = {Adaptive {{Dose-Finding Studies}}: {{A Review}} of {{Model-Guided Phase I Clinical Trials}}},
  shorttitle = {Adaptive {{Dose-Finding Studies}}},
  author = {Iasonos, Alexia and O'Quigley, John},
  year = {2014},
  month = aug,
  journal = {Journal of Clinical Oncology},
  volume = {32},
  number = {23},
  pages = {2505--2511},
  issn = {0732-183X},
  doi = {10.1200/JCO.2013.54.6051},
  urldate = {2024-03-19},
  abstract = {Purpose We provide a comprehensive review of adaptive phase I clinical trials in oncology that used a statistical model to guide dose escalation to identify the maximum-tolerated dose (MTD). We describe the clinical setting, practical implications, and safety of such applications, with the aim of understanding how these designs work in practice. Methods We identified 53 phase I trials published between January 2003 and September 2013 that used the continual reassessment method (CRM), CRM using escalation with overdose control, or time-to-event CRM for late-onset toxicities. Study characteristics, design parameters, dose-limiting toxicity (DLT) definition, DLT rate, patient-dose allocation, overdose, underdose, sample size, and trial duration were abstracted from each study. In addition, we examined all studies in terms of safety, and we outlined the reasons why escalations occur and under what circumstances. Results On average, trials accrued 25 to 35 patients over a 2-year period and tested five dose levels. The average DLT rate was 18\%, which is lower than in previous reports, whereas all levels above the MTD had an average DLT rate of 36\%. On average, 39\% of patients were treated at the MTD, and 74\% were treated at either the MTD or an adjacent level (one level above or below). Conclusion This review of completed phase I studies confirms the safety and generalizability of model-guided, adaptive dose-escalation designs, and it provides an approach for using, interpreting, and understanding such designs to guide dose escalation in phase I trials.},
  pmcid = {PMC4121508},
  pmid = {24982451},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/iasonos_o'quigley_2014_adaptive dose-finding studies.pdf}
}

@article{iddiPowerSampleSize2022,
  title = {Power and {{Sample Size}} for {{Longitudinal Models}} in {{R}}--{{The}} Longpower {{Package}} and {{Shiny App}}},
  author = {Iddi, Samuel and Donohue, Michael C.},
  year = {2022},
  journal = {The R Journal},
  volume = {14},
  pages = {264--282},
  urldate = {2023-12-23},
  file = {/Users/zenn/Zotero/storage/IIMXM48B/Iddi and Donohue - 2022 - Power and Sample Size for Longitudinal Models in R.pdf}
}

@article{imaiVarianceIdentificationEfficiency2008,
  title = {Variance Identification and Efficiency Analysis in Randomized Experiments under the Matched-Pair Design},
  author = {Imai, Kosuke},
  year = {2008},
  month = oct,
  journal = {Statistics in Medicine},
  volume = {27},
  number = {24},
  pages = {4857--4873},
  issn = {02776715, 10970258},
  doi = {10.1002/sim.3337},
  urldate = {2022-11-04},
  abstract = {In his 1923 landmark article, Neyman introduced randomization-based inference to estimate average treatment effects from experiments under the completely randomized design. Under this framework, Neyman considered the statistical estimation of the sample average treatment effect and derived the variance of the standard estimator using the treatment assignment mechanism as the sole basis of inference. In this paper, I extend Neyman's analysis to randomized experiments under the matched-pair design where experimental units are paired based on their pre-treatment characteristics and the randomization of treatment is subsequently conducted within each matched pair. I study the variance identification for the standard estimator of average treatment effects and analyze the relative efficiency of the matched-pair design over the completely randomized design. I also show how to empirically evaluate the relative efficiency of the two designs using experimental data obtained under the matched-pair design. My randomization-based analysis differs from previous studies in that it avoids modeling and other assumptions as much as possible. Finally, the analytical results are illustrated with numerical and empirical examples. Copyright q 2008 John Wiley \& Sons, Ltd.},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/imai_2008_variance identification and efficiency analysis in randomized experiments under.pdf}
}

@techreport{imbensCommentsUnderstandingMisunderstanding2018,
  title = {Comments {{On}}: {{Understanding}} and {{Misunderstanding Randomized Controlled Trails}} by {{Cartwright}} and {{Deaton}}},
  shorttitle = {Comments {{On}}},
  author = {Imbens, Guido W.},
  year = {2018},
  file = {/Users/zenn/Zotero/storage/PHY5QHI7/3648.html}
}

@article{imLeastSquarestypeDensity2020,
  title = {A Least Squares-Type Density Estimator Using a Polynomial Function},
  author = {Im, Jongho and Morikawa, Kosuke and Ha, Hyung-Tae},
  year = {2020},
  month = apr,
  journal = {Computational Statistics \& Data Analysis},
  volume = {144},
  pages = {106882},
  issn = {0167-9473},
  doi = {10.1016/j.csda.2019.106882},
  urldate = {2023-03-01},
  abstract = {Higher-order density approximation and estimation methods using orthogonal series expansion have been extensively discussed in statistical literature and its various fields of application. This study proposes least squares-type estimation for series expansion via minimizing the weighted square difference of series distribution expansion and a benchmarking distribution estimator. As the least squares-type estimator has an explicit expression, similar to the classical moment-matching technique, its asymptotic properties are easily obtained under certain regularity conditions. In addition, we resolve the non-negativity issue of the series expansion using quadratic programming. Numerical examples with various simulated and real datasets demonstrate the superiority of the proposed estimator.},
  langid = {english},
  keywords = {Asymptotic distribution,Density estimation,Orthogonal polynomials,Quadratic programming,Series expansion},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/im et al_2020_a least squares-type density estimator using a polynomial function.pdf}
}

@misc{ImputingCrossSectionalMissing,
  title = {Imputing {{Cross-Sectional Missing Data}}: {{Comparison}} of {{Common Techniques}}},
  shorttitle = {Imputing {{Cross-Sectional Missing Data}}},
  issn = {1440-1614},
  urldate = {2023-09-29},
  howpublished = {https://journals.sagepub.com/doi/epub/10.1080/j.1440-1614.2005.01630.x},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/YBLQUQS3/j.1440-1614.2005.01630.html}
}

@misc{inaoExactSequentialSinglearm2023,
  title = {Exact Sequential Single-Arm Trial Design with Curtailment for Binary Endpoint},
  author = {Inao, Tasuku and Yokota, Isao},
  year = {2023},
  month = mar,
  number = {arXiv:2303.17091},
  eprint = {2303.17091},
  primaryclass = {stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2303.17091},
  urldate = {2023-07-21},
  abstract = {Due to ethical and economical reasons, sequential single-arm trial designs are used for assessing the therapeutic efficacy of new treatments in phase II trials. Simon's 2-stage design and Lan-DeMets' \${\textbackslash}alpha\$-spending function method with O'Brien-Fleming type are widely recognized as the traditional methods for futility stopping and efficacy stopping, respectively. These methods have two practical problems, which are the difficulty of interpretation for stopping under staggered entry and the inflation of error rate due to a small-sample trial. In this research, we propose the exact sequential design making the threshold value for efficacy fixed, and compare with traditional designs in sample size. Since the maximum sample size and average sample number of the proposed design are generally smaller than those of traditional designs containing fixed design, the proposed design is expected to be enrolled fewer subjects. In addition, we evaluate several kinds of point estimators and confidence intervals at the end of trials in the proposed design. If one is concerned with bias, the bias-adjusted estimator may be better. As for a confidence interval, the mid-p approach will be a good choice.},
  archiveprefix = {arXiv},
  keywords = {Statistics - Methodology},
  file = {/Users/zenn/Zotero/storage/X98IFCK9/Inao and Yokota - 2023 - Exact sequential single-arm trial design with curt.pdf;/Users/zenn/Zotero/storage/L7EZG3NI/2303.html}
}

@misc{IntroductionLinearMixedEffects,
  title = {An {{Introduction}} to {{Linear Mixed-Effects Modeling}} in {{R}}},
  doi = {10.1177/2515245920960351},
  urldate = {2023-02-14},
  howpublished = {https://journals.sagepub.com/doi/epub/10.1177/2515245920960351},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/an introduction to linear mixed-effects modeling in r.pdf;/Users/zenn/Zotero/storage/9F9NXBPH/2515245920960351.html}
}

@misc{InvitationTeachingReproducible,
  title = {An {{Invitation}} to {{Teaching Reproducible Research}}: {{Lessons}} from a {{Symposium}}},
  shorttitle = {An {{Invitation}} to {{Teaching Reproducible Research}}},
  issn = {2693-9169},
  urldate = {2023-06-22},
  howpublished = {https://www.tandfonline.com/doi/epub/10.1080/26939169.2022.2099489?needAccess=true\&role=button},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/42CY9SAN/26939169.2022.html}
}

@article{Iometopane123BetaCIT2003,
  title = {Iometopane: (123){{I}} Beta-{{CIT}}, Dopascan Injection, {{GPI}} 200, {{RTI}} 55},
  shorttitle = {Iometopane},
  year = {2003},
  journal = {Drugs in R\&D},
  volume = {4},
  number = {5},
  pages = {320--322},
  issn = {1174-5886},
  doi = {10.2165/00126839-200304050-00008},
  abstract = {Iometopane [(123)I beta-CIT, GPI 200, RTI 55], a tropane derivative labelled with iodine-123, is a dopamine imaging agent that was under development with Guilford Pharmaceuticals (as Dopascan Injection) for the early diagnosis of Parkinson's disease. Neurochemical imaging with iometopane using conventional single photon emission computerised tomography (SPECT) provided images of the brain for the distinguished diagnosis of Parkinson's disease. The ability of iometopane to bind to the dopamine transporter on presynaptic dopaminergic nerve terminal in the striatum (caudate nucleus and putamen) has been used to differentiate the uptake of the agent by the neurons in the striatum in patients with a Parkinsonian disorder (Parkinson's disease and progressive supranuclear palsy) from patients without a Parkinsonian disorder (essential tremor and healthy controls) with high sensitivity and specificity. The diminished uptake of iometopane in the striatum on the SPECT images of patients with a Parkinsonian disorder can be applied to assess both disease trait and disease state (severity) reflected by the severity of the brain dopamine neuron loss. The rate of clinical progression of Parkinson's disease varies greatly and is currently unpredictable. Imaging with iometopane provides the opportunity to evaluate patients longitudinally from early to late disease using an objective biomarker for dopamine nerve cell degeneration. Diagnostic imaging with Dopascan Injection is thought to differentiate Parkinson's disease from other forms of tremor, eliminate tests such as MRI and CT scans, unnecessary and inappropriate medications (psychotropics), and significantly reduce the number of people remaining on Parkinson's disease medications for life, despite not having Parkinson's disease. Guilford Pharmaceuticals acquired the licence for iometopane from the Research Triangle Institute, US, and sub-licensed it to Daiichi Radioisotope Laboratories for marketing, sales and distribution in Japan, Korea and Taiwan. In July 2003, Daiichi Radioisotope Laboratories paid a milestone payment of \$0.55 million to Guilford after filing an application for approval in Japan. In January 2002, Guilford signed an exclusive European development, marketing and sales and distribution agreement for iometopane with MAP Medical Technologies of Finland. Under the terms of the agreement, MAP Medical Technologies will assume responsibility for regulatory approvals, manufacturing, marketing and selling the agent in all member states of the EU and other selected markets. In return, Guilford will receive an upfront payment, milestone payments and royalties on future sales in these territories. In July 2002, MAP Medical Technologies become a subsidiary of Schering AG. In March 2002, Guilford Pharmaceuticals sublicensed iometopane to Molecular Neuroimaging LLC (MNI) of Connecticut, USA. Under the terms of the agreement, MNI will pay a royalty for each administration of iometopane, and also provide Guilford Pharmaceuticals with favourable pricing for the services (including administration of iometopane) for any clinical trials of Guilford's product candidates. This agreement will be terminated upon the US FDA's approval of the product candidate for marketing and sale in the US. Guilford has retained commercial rights to Dopascan Injection in the US. MAP Medical Technologies (Schering AG) submitted a Marketing Authorisation Application (MAA) in Finland for European approval of iometopane for the diagnosis of Parkinson's disease in April 2002. Daiichi Radioisotope Laboratories filed an application for approval of iometopane (Dopascan Injection) for the diagnosis of Parkinson's disease in Japan in July 2003. Guilford Pharmaceuticals is conducting a phase II clinical trial in 200 patients with Parkinson's disease where iometopane imaging is used to assess the effectiveness of GPI 1485, an investigational drug candidate, at baseline and at one year and two years after treatment with either GPI 1485 or placebo. The enrolment is expected to be completed in Q3 of 2003. Guint with either GPI 1485 or placebo. The enrolment is expected to be completed in Q3 of 2003. Guilford Pharmaceuticals decided not to proceed with phase III clinical trials and further development of iometopane due to its inability to contract a suitable manufacturer for the clinical and commercial supply of iometopane on acceptable conditions in the US. Guilford Pharmaceuticals obtained the patent coverage for iometopane in the US, Australia and Europe (Austria, Belgium, Switzerland, Liechtenstein, Germany, Denmark, Spain, France, the United Kingdom, Italy, Luxembourg, the Netherlands, Sweden and Greece). Separate filings were made in Finland, Norway, Japan, Canada and Korea. The manufacturing methods of Dopascan are protected by patents in the US and Europe. Dopascan is a registered trademark in the US, Canada, Europe and Asia.},
  langid = {english},
  pmid = {12952503},
  keywords = {Clinical Trials Phase II as Topic,Cocaine,Dopamine Plasma Membrane Transport Proteins,Humans,Injections Intravenous,Iodine Radioisotopes,Membrane Glycoproteins,Membrane Transport Proteins,Nerve Tissue Proteins,Paralysis,Parkinson Disease,Radionuclide Imaging,Radiopharmaceuticals}
}

@article{irizarry2009plasma,
  title = {Plasma Urate and Progression of Mild Cognitive Impairment},
  author = {Irizarry, Michael C and Raman, Rema and Schwarzschild, Michael A and Becerra, Lida M and Thomas, Ronald G and Peterson, Ronald C and Ascherio, Alberto and Aisen, Paul S},
  year = {2009},
  journal = {Neurodegenerative Diseases},
  volume = {6},
  number = {1-2},
  pages = {23--28},
  publisher = {Karger Publishers}
}

@article{irizarry2012incidence,
  title = {Incidence of New-Onset Seizures in Mild to Moderate {{Alzheimer}} Disease},
  author = {Irizarry, Michael C and Jin, Shelia and He, Feng and Emond, Jennifer A and Raman, Rema and Thomas, Ronald G and Sano, Mary and Quinn, Joseph F and Tariot, Pierre N and Galasko, Douglas R and others},
  year = {2012},
  journal = {Archives of neurology},
  volume = {69},
  number = {3},
  pages = {368--372},
  publisher = {American Medical Association}
}

@article{irving1994drug,
  title = {Drug and Alcohol Abuse Inpatients' Attitudes about Smoking Cessation},
  author = {Irving, Lori M and Seidner, Andrea L and Burling, Thomas A and Thomas, Ronald G and Brenner, Gail F},
  year = {1994},
  journal = {Journal of Substance Abuse},
  volume = {6},
  number = {3},
  pages = {267--278},
  publisher = {JAI}
}

@article{iyerConcomitantMedicationsProgressive2024,
  title = {Concomitant {{Medications}} for {{Progressive Supranuclear Palsy}}: {{A Secondary Analysis}} of a {{Randomized Clinical Trial}}},
  shorttitle = {Concomitant {{Medications}} for {{Progressive Supranuclear Palsy}}},
  author = {Iyer, Jay M. and Gunzler, Douglas and Lang, Anthony E. and Golbe, Lawrence I. and Pantelyat, Alexander and Boxer, Adam L. and Wills, Anne-Marie and Group, AL-108-231 Study},
  year = {2024},
  journal = {JAMA neurology},
  urldate = {2024-06-05},
  file = {/Users/zenn/Zotero/storage/3K28FC7Q/Iyer et al. - 2024 - Concomitant Medications for Progressive Supranucle.pdf}
}

@article{iyerConcomitantMedicationsProgressive2024a,
  title = {Concomitant {{Medications}} for {{Progressive Supranuclear Palsy}}: {{A Secondary Analysis}} of a {{Randomized Clinical Trial}}},
  shorttitle = {Concomitant {{Medications}} for {{Progressive Supranuclear Palsy}}},
  author = {Iyer, Jay M. and Gunzler, Douglas and Lang, Anthony E. and Golbe, Lawrence I. and Pantelyat, Alexander and Boxer, Adam L. and Wills, Anne-Marie and {AL-108-231 Study Group}},
  year = {2024},
  month = mar,
  journal = {JAMA Neurology},
  volume = {81},
  number = {3},
  pages = {295},
  issn = {2168-6149},
  doi = {10.1001/jamaneurol.2023.5215},
  urldate = {2024-06-05},
  abstract = {This secondary analysis of a randomized clinical trial examines changes in the progression of progressive supranuclear palsy (PSP) associated with 31 concomitant medication classes used by study participants over 1 year.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/86N3MG65/Iyer et al. - 2024 - Concomitant Medications for Progressive Supranucle.pdf}
}

@article{jacobs2018p3,
  title = {P3-032: {{SCREENING-TO-BASELINE COGNITIVE VARIABILITY DOES NOT PREDICT RATE OF DECLINE IN A CLINICAL TRIAL OF MILD-TO-MODERATE AD}}},
  author = {Jacobs, Diane M and Thomas, Ronald G and Salmon, David P and Huisa, Branko N and Feldman, Howard H and Schneider, Lon S},
  year = {2018},
  journal = {Alzheimer's \& Dementia},
  volume = {14},
  number = {7S\_Part\_20},
  pages = {P1076--P1077}
}

@article{jacobs2020development,
  title = {Development of a Novel Cognitive Composite Outcome to Assess Therapeutic Effects of Exercise in the {{EXERT}} Trial for Adults with {{MCI}}: {{The ADAS-Cog-Exec}}},
  author = {Jacobs, Diane M and Thomas, Ronald G and Salmon, David P and Jin, Shelia and Feldman, Howard H and Cotman, Carl W and Baker, Laura D and Group, Alzheimer's Disease Cooperative Study EXERT Study and Initiative, Alzheimer's Disease Neuroimaging},
  year = {2020},
  journal = {Alzheimer's \& Dementia: Translational Research \& Clinical Interventions},
  volume = {6},
  number = {1},
  pages = {e12059}
}

@article{jaegerDevelopmentCognitiveComposite2021,
  title = {Development of a Cognitive Composite for Measuring Change in Progressive Supranuclear Palsy},
  author = {Jaeger, Judith and Yang, Lili and Li, Yumeng and {Castrillo-Viguera}, Carmen and Haeberlein, Samantha Budd and Dam, Tien and O'Gorman, John},
  year = {2021},
  month = nov,
  journal = {Parkinsonism \& Related Disorders},
  volume = {92},
  pages = {94--100},
  issn = {1873-5126},
  doi = {10.1016/j.parkreldis.2021.10.007},
  abstract = {INTRODUCTION: Individuals with progressive supranuclear palsy (PSP) experience cognitive changes that are challenging to follow without a validated neuropsychological test battery to measure progression. This study describes a composite measure to evaluate cognition in individuals with PSP. METHODS: Baseline cognitive test data from 486 participants with PSP in the PASSPORT (NCT03068468) study included the Repeatable Battery for Assessment of Neuropsychological Status (RBANS), Color Trails Test (CTT) parts 1 and 2, letter-number sequencing, and letter fluency. Data were analyzed using summary statistics and a matrix of Pearson correlations. A hypothetical factor structure was constructed and validated. RESULTS: Observed correlations were highest for scores between story memory and story recall (correlation coefficient~=~0.78) and lowest for scores between letter fluency and picture naming (correlation coefficient~=~0.11), and picture naming and figure copy (correlation coefficient~=~0.12). After excluding picture naming and Color Trails Test (CTT) parts 1 and 2, a 3-factor structure was hypothesized for the remaining 13 tests. Confirmatory factor analysis demonstrated goodness of fit within acceptable limits (comparative fit index and Tucker-Lewis index~=~0.98, standardized root-mean-square residual and root-mean-square error of approximation~=~0.05-0.06). Mixed-model repeated-measures analysis of change from baseline to week 52 in RBANS and PSP cognitive composite score produced mean-to-standard-deviation ratios of 0.418 and 0.780, respectively. CONCLUSIONS: This novel composite endpoint, based on RBANS and designed to account for motor impairments in PSP, improves on current cognitive assessments PSP.},
  langid = {english},
  pmid = {34736158},
  keywords = {Adult,Aged,Aged 80 and over,Antibodies Monoclonal Humanized,Cognition,Cognitive composite,Double-Blind Method,Factor Analysis Statistical,Female,Humans,Male,Memory,Memory and Learning Tests,Middle Aged,Neuropsychological status,Neuropsychological Tests,Progressive supranuclear palsy,Randomized Controlled Trials as Topic,RBANS,Reproducibility of Results,Supranuclear Palsy Progressive,Trail Making Test,Treatment Outcome}
}

@article{jaegerDevelopmentCognitiveComposite2021a,
  title = {Development of a Cognitive Composite for Measuring Change in Progressive Supranuclear Palsy},
  author = {Jaeger, Judith and Yang, Lili and Li, Yumeng and {Castrillo-Viguera}, Carmen and Haeberlein, Samantha Budd and Dam, Tien and O'Gorman, John},
  year = {2021},
  month = nov,
  journal = {Parkinsonism \& Related Disorders},
  volume = {92},
  pages = {94--100},
  issn = {1873-5126},
  doi = {10.1016/j.parkreldis.2021.10.007},
  abstract = {INTRODUCTION: Individuals with progressive supranuclear palsy (PSP) experience cognitive changes that are challenging to follow without a validated neuropsychological test battery to measure progression. This study describes a composite measure to evaluate cognition in individuals with PSP. METHODS: Baseline cognitive test data from 486 participants with PSP in the PASSPORT (NCT03068468) study included the Repeatable Battery for Assessment of Neuropsychological Status (RBANS), Color Trails Test (CTT) parts 1 and 2, letter-number sequencing, and letter fluency. Data were analyzed using summary statistics and a matrix of Pearson correlations. A hypothetical factor structure was constructed and validated. RESULTS: Observed correlations were highest for scores between story memory and story recall (correlation coefficient~=~0.78) and lowest for scores between letter fluency and picture naming (correlation coefficient~=~0.11), and picture naming and figure copy (correlation coefficient~=~0.12). After excluding picture naming and Color Trails Test (CTT) parts 1 and 2, a 3-factor structure was hypothesized for the remaining 13 tests. Confirmatory factor analysis demonstrated goodness of fit within acceptable limits (comparative fit index and Tucker-Lewis index~=~0.98, standardized root-mean-square residual and root-mean-square error of approximation~=~0.05-0.06). Mixed-model repeated-measures analysis of change from baseline to week 52 in RBANS and PSP cognitive composite score produced mean-to-standard-deviation ratios of 0.418 and 0.780, respectively. CONCLUSIONS: This novel composite endpoint, based on RBANS and designed to account for motor impairments in PSP, improves on current cognitive assessments PSP.},
  langid = {english},
  pmid = {34736158},
  keywords = {Adult,Aged,Aged 80 and over,Antibodies Monoclonal Humanized,Cognition,Cognitive composite,Double-Blind Method,Factor Analysis Statistical,Female,Humans,Male,Memory,Memory and Learning Tests,Middle Aged,Neuropsychological status,Neuropsychological Tests,Progressive supranuclear palsy,Randomized Controlled Trials as Topic,RBANS,Reproducibility of Results,Supranuclear Palsy Progressive,Trail Making Test,Treatment Outcome}
}

@article{jagerBenchmarkDataImputation2021,
  title = {A {{Benchmark}} for {{Data Imputation Methods}}},
  author = {J{\"a}ger, Sebastian and Allhorn, Arndt and Bie{\ss}mann, Felix},
  year = {2021},
  journal = {Frontiers in Big Data},
  volume = {4},
  issn = {2624-909X},
  urldate = {2023-04-15},
  abstract = {With the increasing importance and complexity of data pipelines, data quality became one of the key challenges in modern software applications. The importance of data quality has been recognized beyond the field of data engineering and database management systems (DBMSs). Also, for machine learning (ML) applications, high data quality standards are crucial to ensure robust predictive performance and responsible usage of automated decision making. One of the most frequent data quality problems is missing values. Incomplete datasets can break data pipelines and can have a devastating impact on downstream ML applications when not detected. While statisticians and, more recently, ML researchers have introduced a variety of approaches to impute missing values, comprehensive benchmarks comparing classical and modern imputation approaches under fair and realistic conditions are underrepresented. Here, we aim to fill this gap. We conduct a comprehensive suite of experiments on a large number of datasets with heterogeneous data and realistic missingness conditions, comparing both novel deep learning approaches and classical ML imputation methods when either only test or train and test data are affected by missing data. Each imputation method is evaluated regarding the imputation quality and the impact imputation has on a downstream ML task. Our results provide valuable insights into the performance of a variety of imputation methods under realistic conditions. We hope that our results help researchers and engineers to guide their data preprocessing method selection for automated data quality improvement.},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/jäger et al_2021_a benchmark for data imputation methods.pdf}
}

@article{jahanshiriDevelopingWebbasedData2014,
  title = {Developing Web-Based Data Analysis Tools for Precision Farming Using {{R}} and {{Shiny}}},
  author = {Jahanshiri, Ebrahim and Shariff, Abdul Rashid Mohd},
  year = {2014},
  month = jun,
  journal = {IOP Conference Series: Earth and Environmental Science},
  volume = {20},
  pages = {012014},
  issn = {1755-1315},
  doi = {10.1088/1755-1315/20/1/012014},
  urldate = {2023-12-15},
  abstract = {Technologies that are set to increase the productivity of agricultural practices require more and more data. Nevertheless, farming data is also being increasingly cheap to collect and maintain. Bulk of data that are collected by the sensors and samples need to be analysed in an efficient and transparent manner. Web technologies have long being used to develop applications that can assist the farmers and managers. However until recently, analysing the data in an online environment has not been an easy task especially in the eyes of data analysts. This barrier is now overcome by the availability of new application programming interfaces that can provide real-time web based data analysis. In this paper developing a prototype web based application for data analysis using new facilities in R statistical package and its web development facility, Shiny is explored. The pros and cons of this type of data analysis environment for precision farming are enumerated and future directions in web application development for agricultural data are discussed.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/HQMF2YW4/Jahanshiri and Shariff - 2014 - Developing web-based data analysis tools for preci.pdf}
}

@inproceedings{james2002indomethacin,
  title = {Indomethacin Reduces {{Helicobacter}} Pylori-Induced Interleukin-8 ({{IL-8}}) Production by the Gastric Epithelial Cell Line, {{AGS}}.},
  booktitle = {{{GASTROENTEROLOGY}}},
  author = {James, {\relax MW} and Argent, {\relax RH} and Thomas, R and Hawkey, C and Atherton, J},
  year = {2002},
  volume = {122},
  pages = {A227--A227},
  publisher = {WB SAUNDERS CO INDEPENDENCE SQUARE WEST CURTIS CENTER, STE 300, PHILADELPHIA {\dots}}
}

@article{Janelidze2020,
  title = {Plasma {{P-tau181}} in {{Alzheimer}}'s Disease: Relationship to Other Biomarkers, Differential Diagnosis, Neuropathology and Longitudinal Progression to {{Alzheimer}}'s Dementia},
  author = {Janelidze, Shorena and Mattsson, Niklas and Palmqvist, Sebastian and Smith, Ruben and Beach, Thomas G. and Serrano, Geidy E. and Chai, Xiyun and Proctor, Nicholas K. and Eichenlaub, Udo and Zetterberg, Henrik and Blennow, Kaj and Reiman, Eric M. and Stomrud, Erik and Dage, Jeffrey L. and Hansson, Oskar},
  year = {2020},
  journal = {Nature Medicine},
  volume = {26},
  number = {3},
  pages = {379--386},
  publisher = {Springer US},
  issn = {1546170X},
  doi = {10.1038/s41591-020-0755-1},
  abstract = {Plasma phosphorylated tau181 (P-tau181) might be increased in Alzheimer's disease (AD), but its usefulness for differential diagnosis and prognosis is unclear. We studied plasma P-tau181 in three cohorts, with a total of 589 individuals, including cognitively unimpaired participants and patients with mild cognitive impairment (MCI), AD dementia and non-AD neurodegenerative diseases. Plasma P-tau181 was increased in preclinical AD and further increased at the MCI and dementia stages. It correlated with CSF P-tau181 and predicted positive Tau positron emission tomography (PET) scans (area under the curve (AUC) = 0.87--0.91 for different brain regions). Plasma P-tau181 differentiated AD dementia from non-AD neurodegenerative diseases with an accuracy similar to that of Tau PET and CSF P-tau181 (AUC = 0.94--0.98), and detected AD neuropathology in an autopsy-confirmed cohort. High plasma P-tau181 was associated with subsequent development of AD dementia in cognitively unimpaired and MCI subjects. In conclusion, plasma P-tau181 is a noninvasive diagnostic and prognostic biomarker of AD, which may be useful in clinical practice and trials.},
  pmid = {32123385},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/janelidze et al_2020_plasma p-tau181 in alzheimer’s disease.pdf}
}

@article{janelidzePhosphotau217Phosphotau181Plasma2020,
  title = {Phospho-Tau217 and Phospho-Tau181 in Plasma and {{CSF}} as Biomarkers for {{Alzheimer}}'s Disease},
  author = {Janelidze, Shorena and Palmqvist, Sebastian and Quiroz, Yakeel T. and Lopera, Francisco and Stomrud, Erik and Su, Yi and Chen, Yinghua and Serrano, Geidy E and Leuzy, Antoine and Mattsson, Niklas and Strandberg, Olof and Smith, Ruben and Villegas, Andres and Sepulveda, Diego and Chai, Xiyun and Proctor, Nicholas and Zetterberg, Henrik and Beach, Thomas G. and Blennow, Kaj and Reiman, Eric M. and Dage, Jeffrey L. and Hansson, Oskar},
  year = {2020},
  journal = {Alzheimer's \& Dementia},
  volume = {16},
  number = {S5},
  pages = {e037520},
  issn = {1552-5279},
  doi = {10.1002/alz.037520},
  urldate = {2023-03-22},
  abstract = {Background Cerebrospinal fluid (CSF) p-tau181 (tau phosphorylated at threonine 181) is an established biomarker of Alzheimer's disease (AD) reflecting abnormal tau metabolism in the brain. We have recently shown that also plasma p-tau181 is a promising biomarker for AD (Janelidze et al, Nature Medicine, 2020). We now evaluate whether CSF p-tau217 or plasma p-tau217 are even better biomarkers. Methods We compared CSF p-tau217 to CSF p-tau181 in the Swedish BioFINDER-1 cohort (n=194). We next evaluated plasma p-tau217 and plasma p-tau181 in three cohorts with 1,438 participants: an Arizona-based neuropathology cohort, including 34 AD and 47 non-AD participants; the Swedish BioFINDER-2 cohort, including cognitively unimpaired (n=312) participants, and clinically diagnosed patients with mild cognitive impairment (MCI, n=188), AD dementia (n=126), and other non-AD neurodegenerative diseases (n=109); a Colombian autosomal-dominant AD kindred, including 365 PSEN1E280A-carriers and 257 non-mutation carriers. Results CSF p-tau217 had stronger correlations with the tau-PET tracer, and more accurately identified individuals with abnormal tau-PET scans (AUC=0.93) than CSF P-tau181. CSF P-tau217 correlated better than p-tau181 with CSF and PET measures of neocortical amyloid-{$\beta$} burden and more accurately distinguished AD dementia from non-AD neurodegenerative disorders. Antemortem plasma P-tau217 differentiated individuals with intermediate-to-high likelihood of AD according to neuropathology from those without AD (AUC=0.89) and performed significantly better than plasma P-tau181. Plasma P-tau217 also differentiated clinical AD dementia from non-AD neurodegenerative diseases (AUC=0.96) significantly better than plasma P-tau181, plasma neurofilament light, and established MRI measures, and similar to CSF P-tau217, CSF P-tau181, CSF A{$\beta$}42/40, and tau-PET. Increased plasma P-tau217 was observed already in the pre-symptomatic stages of AD. In PSEN1 mutation carriers the increase started at age 25, about 20 years prior to estimated onset of MCI. Plasma P-tau217 correlated with cerebral tau tangle densities in subjects with neuritic plaques (r=0.64). It predicted abnormal tau-PET scans (AUC=0.95) significantly better than plasma P-tau181, plasma neurofilament light, CSF P-tau181 and CSF A{$\beta$}42/A{$\beta$}40, and similar to CSF P-tau217. Conclusions Plasma and CSF P-tau217 reflect brain tau burden, increases early in AD, and differentiates AD from other neurodegenerative diseases.},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/janelidze et al_2020_phospho-tau217 and phospho-tau181 in plasma and csf as biomarkers for.pdf;/Users/zenn/Zotero/storage/9R256ALL/alz.html}
}

@article{jankovicControlledTrialPergolide1983,
  title = {Controlled Trial of Pergolide Mesylate in {{Parkinson}}'s Disease and Progressive Supranuclear Palsy},
  author = {Jankovic, J.},
  year = {1983},
  month = apr,
  journal = {Neurology},
  volume = {33},
  number = {4},
  pages = {505--507},
  issn = {0028-3878},
  doi = {10.1212/wnl.33.4.505},
  abstract = {We evaluated pergolide in 22 patients with Parkinson's disease and 3 with progressive supranuclear palsy (PSP). After achieving an optimal dose of pergolide and Sinemet, a matching placebo was substituted in double-blind manner. The mean dose of levodopa (in Sinemet) was reduced by 68\%; in eight patients, pergolide completely replaced levodopa. In parkinsonian patients, the mean Hoehn-Yahr stage decreased from 3.2 to 1.6, and the mean total disability score decreased from 48.3 to 17.8. In 10 patients with on-off phenomenon, the time on increased 174\% with pergolide. There was little effect in PSP. Postural light-headedness and reversible mental changes were seen.},
  langid = {english},
  pmid = {6339985},
  keywords = {Adult,Aged,Antiparkinson Agents,Bulbar Palsy Progressive,Clinical Trials as Topic,Double-Blind Method,Ergolines,Female,Humans,Levodopa,Male,Middle Aged,Parkinson Disease,Pergolide,Placebos}
}

@article{jansenAnalyzingIncompleteDiscrete2006,
  title = {Analyzing Incomplete Discrete Longitudinal Clinical Trial Data},
  author = {Jansen, Ivy and Beunckens, Caroline and Molenberghs, Geert and Verbeke, Geert and Mallinckrodt, Craig},
  year = {2006},
  file = {/Users/zenn/Zotero/storage/MTPBCUPI/Jansen et al. - 2006 - Analyzing incomplete discrete longitudinal clinica.pdf;/Users/zenn/Zotero/storage/GFNPZGRC/088342305000000322.html}
}

@article{Jansson2022,
  title = {Markers of {{Cerebrovascular Injury}}, {{Inflammation}}, and {{Plasma Lipids Are Associated}} with {{Alzheimer}}'s {{Disease Cerebrospinal Fluid Biomarkers}} in {{Cognitively Normal Persons}}},
  author = {Jansson, Deidre and Wang, Marie and Thomas, Ronald G. and Erickson, Michelle A. and Peskind, Elaine R. and Li, Ge and Iliff, Jeffrey},
  editor = {Quinn, Joseph},
  year = {2022},
  month = mar,
  journal = {Journal of Alzheimer's Disease},
  volume = {86},
  number = {2},
  pages = {813--826},
  issn = {13872877},
  doi = {10.3233/JAD-215400},
  abstract = {Background: Alzheimer's disease (AD) is a multifactorial process that takes years to manifest clinically. We propose that brain-derived indicators of cerebrovascular dysfunction and inflammation would inform on AD-related pathological processes early in, and perhaps prior to neurodegenerative disease development. Objective: Define the relationship between cerebrospinal fluid (CSF) markers of cerebrovascular dysfunction and neuroinflammation with AD CSF biomarkers in cognitively normal individuals. Methods: Analytes were measured from CSF and plasma collected at baseline from two randomized control trials. We performed Pearson correlation analysis (adjusting for age, sex, APOE haplotype, and education) between markers of central nervous system (CNS) barrier disruption, cerebrovascular dysfunction, CSF inflammatory cytokines and chemokines, and plasma lipid levels. We then developed a statistical prediction model using machine learning to test the ability of measured CSF analytes and blood lipid profiles to predict CSF AD biomarkers (total tau, phospho-tau (181), A{$\beta$}42) in this clinical population. Results: Our analysis revealed a significant association between markers of CNS barrier dysfunction and markers of cerebrovascular dysfunction, acute inflammatory responses, and CSF inflammatory cytokines. There was a significant association of blood lipid profiles with cerebrovascular injury markers, and CSF inflammatory cytokine levels. Using machine learning, we show that combinations of blood lipid profiles, CSF markers of CNS barrier disruption, cerebrovascular dysfunction and CSF inflammatory cytokines predict CSF total tau, p-tau, and, to a lesser extent, A{$\beta$}42 in cognitively normal subjects. Conclusion: This suggests that these parallel pathological processes may contribute to the development of AD-related neuropathology in the absence of clinical manifestations.},
  keywords = {biomarkers,blood-brain barrier,cerebrospinal fluid,hdl,ldl,ptau,tau},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/jansson et al_2022_markers of cerebrovascular injury, inflammation, and plasma lipids are.pdf}
}

@article{Jansson2022,
  title = {Markers of Cerebrovascular Injury, Inflammation, and Plasma Lipids Are Associated with Alzheimer's Disease Cerebrospinal Fluid Biomarkers in Cognitively Normal Persons},
  author = {Jansson, Deidre and Wang, Marie and Thomas, Ronald G. and Erickson, Michelle A. and Peskind, Elaine R. and Li, Ge and Iliff, Jeffrey},
  year = {2022},
  journal = {Journal of Alzheimer's Disease},
  volume = {86},
  number = {2},
  pages = {813--826},
  issn = {13872877},
  doi = {10.3233/jad-215400},
  keywords = {biomarkers,blood-brain barrier,cerebrospinal fluid,hdl,ldl,ptau,tau}
}

@article{jaredPeriodontalDiseasesAdverse2008,
  title = {Periodontal {{Diseases}} and {{Adverse Pregnancy Outcomes}}: {{A Review}} of the {{Evidence}} and {{Implications}} for {{Clinical Practice}}},
  author = {Jared, Heather and Boggess, Kim A},
  year = {2008},
  journal = {Journal of Dental Hygiene},
  volume = {82},
  number = {3},
  abstract = {Periodontal diseases affect the majority of the population either as gingivitis or periodontitis. Recently there have been many studies that link or seek to find a relationship between periodontal disease and other systemic diseases including, cardiovascular disease, diabetes, stroke, and adverse pregnancy outcomes. For adverse pregnancy outcomes, the literature is inconclusive and the magnitude of the relationship between these 2 has not been fully decided. The goal of this paper is to review the literature regarding periodontal diseases and adverse pregnancy outcomes, and provide oral health care providers with resources to educate their patients. Alternatively, this paper will also discuss what is occurring to help increase the availability of care for pregnant women and what oral health care providers can do to help improve these issues.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/S6UQ4LT8/Jared and Boggess - 2008 - Periodontal Diseases and Adverse Pregnancy Outcome.pdf}
}

@article{jDiseaseModellingCognitive2021,
  title = {Disease {{Modelling}} of {{Cognitive Outcomes}} and {{Biomarkers}} in the {{European Prevention}} of {{Alzheimer}}'s {{Dementia Longitudinal Cohort}}},
  author = {J, Howlett and SM, Hill and CW, Ritchie and BDM, Tom},
  year = {2021},
  month = aug,
  journal = {Frontiers in big data},
  volume = {4},
  publisher = {Front Big Data},
  issn = {2624-909X},
  doi = {10.3389/FDATA.2021.676168},
  urldate = {2021-10-02},
  abstract = {A key challenge for the secondary prevention of Alzheimer's dementia is the need to identify individuals early on in the disease process through sensitive cognitive tests and biomarkers. The European Prevention of Alzheimer's Dementia (EPAD) consortium recruited participants into a longitudinal cohort study with the aim of building a readiness cohort for a proof-of-concept clinical trial and also to generate a rich longitudinal data-set for disease modelling. Data have been collected on a wide range of measurements including cognitive outcomes, neuroimaging, cerebrospinal fluid biomarkers, genetics and other clinical and environmental risk factors, and are available for 1,828 eligible participants at baseline, 1,567 at 6~months, 1,188 at one-year follow-up, 383 at 2~years, and 89 participants at three-year follow-up visit. We novelly apply state-of-the-art longitudinal modelling and risk stratification approaches to these data in order to characterise disease progression and biological heterogeneity within the cohort. Specifically, we use longitudinal class-specific mixed effects models to characterise the different clinical disease trajectories and a semi-supervised Bayesian clustering approach to explore whether participants can be stratified into homogeneous subgroups that have different patterns of cognitive functioning evolution, while also having subgroup-specific profiles in terms of baseline biomarkers and longitudinal rate of change in biomarkers.},
  pmid = {34490422},
  keywords = {Brian D M Tom,doi:10.3389/fdata.2021.676168,James Howlett,MEDLINE,National Center for Biotechnology Information,National Institutes of Health,National Library of Medicine,NCBI,NIH,NLM,PMC8417903,pmid:34490422,PubMed Abstract,Review,Steven M Hill},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/j et al_2021_disease modelling of cognitive outcomes and biomarkers in the european.pdf}
}

@article{jeffriesDetectingTreatmentDifferences2018,
  title = {Detecting Treatment Differences in Group Sequential Longitudinal Studies with Covariate Adjustment},
  author = {Jeffries, Neal O. and Troendle, James F. and Geller, Nancy L.},
  year = {2018},
  journal = {Biometrics},
  volume = {74},
  number = {3},
  pages = {1072--1081},
  issn = {1541-0420},
  doi = {10.1111/biom.12837},
  urldate = {2024-03-30},
  abstract = {In longitudinal studies comparing two treatments over a series of common follow-up measurements, there may be interest in determining if there is a treatment difference at any follow-up period when there may be a non-monotone treatment effect over time. To evaluate this question, Jeffries and Geller (2015) examined a number of clinical trial designs that allowed adaptive choice of the follow-up time exhibiting the greatest evidence of treatment difference in a group sequential testing setting with Gaussian data. The methods are applicable when a few measurements were taken at prespecified follow-up periods. Here, we test the intersection null hypothesis of no difference at any follow-up time versus the alternative that there is a difference for at least one follow-up time. Results of Jeffries and Geller (2015) are extended by considering a broader range of modeled data and the inclusion of covariates using generalized estimating equations. Testing procedures are developed to determine a set of follow-up times that exhibit a treatment difference that accounts for multiplicity in follow-up times and interim analyses.},
  copyright = {Published 2017. This article is a U.S. Government work and is in the public domain in the USA.},
  langid = {english},
  keywords = {Generalized estimating equations,Generalized linear models,Group sequential design,Longitudinal analysis},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/jeffries et al_2018_detecting treatment differences in group sequential longitudinal studies with2.pdf;/Users/zenn/Zotero/storage/YL2SQIDU/biom.html}
}

@article{jeffriesDetectingTreatmentDifferences2018a,
  title = {Detecting {{Treatment Differences}} in {{Group Sequential Longitudinal Studies}} with {{Covariate Adjustment}}},
  author = {Jeffries, Neal O. and Troendle, James F. and Geller, Nancy L.},
  year = {2018},
  month = sep,
  journal = {Biometrics},
  volume = {74},
  number = {3},
  pages = {1072--1081},
  issn = {0006-341X, 1541-0420},
  doi = {10.1111/biom.12837},
  urldate = {2024-03-20},
  abstract = {Summary             In longitudinal studies comparing two treatments over a series of common follow-up measurements, there may be interest in determining if there is a treatment difference at any follow-up period when there may be a non-monotone treatment effect over time. To evaluate this question, Jeffries and Geller (2015) examined a number of clinical trial designs that allowed adaptive choice of the follow-up time exhibiting the greatest evidence of treatment difference in a group sequential testing setting with Gaussian data. The methods are applicable when a few measurements were taken at prespecified follow-up periods. Here, we test the intersection null hypothesis of no difference at any follow-up time versus the alternative that there is a difference for at least one follow-up time. Results of Jeffries and Geller (2015) are extended by considering a broader range of modeled data and the inclusion of covariates using generalized estimating equations. Testing procedures are developed to determine a set of follow-up times that exhibit a treatment difference that accounts for multiplicity in follow-up times and interim analyses.},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/jeffries et al_2018_detecting treatment differences in group sequential longitudinal studies with.pdf;/Users/zenn/Zotero/storage/5EI7N4PA/PMC7515605.html}
}

@article{jeffriesEvaluatingTreatmentEffects2023,
  title = {Evaluating Treatment Effects in Group Sequential Multivariate Longitudinal Studies with Covariate Adjustment},
  author = {Jeffries, Neal O. and Troendle, James F. and Geller, Nancy L.},
  year = {2023},
  journal = {Biometrics},
  volume = {79},
  number = {2},
  pages = {1496--1506},
  issn = {1541-0420},
  doi = {10.1111/biom.13659},
  urldate = {2024-03-30},
  abstract = {Jeffries et al. (2018) investigated testing for a treatment difference in the setting of a randomized clinical trial with a single outcome measured longitudinally over a series of common follow-up times while adjusting for covariates. That paper examined the null hypothesis of no difference at any follow-up time versus the alternative of a difference for at least one follow-up time. We extend those results here by considering multivariate outcome measurements, where each individual outcome is examined at common follow-up times. We consider the case where there is interest in first testing for a treatment difference in a global function of the outcomes (e.g., weighted average or sum) with subsequent interest in examining the individual outcomes, should the global function show a treatment difference. Testing is conducted for each follow-up time and may be performed in the setting of a group sequential trial. Testing procedures are developed to determine follow-up times for which a global treatment difference exists and which individual combinations of outcome and follow-up time show evidence of a difference while controlling for multiplicity in outcomes, follow-up, and interim analyses. These approaches are examined in a study evaluating the effects of tissue plasminogen activator on longitudinally obtained stroke severity measurements.},
  copyright = {Published 2022. This article is a U.S. Government work and is in the public domain in the USA.},
  langid = {english},
  keywords = {familywise error,generalized estimating equations,global tests,longitudinal analysis,parallel gatekeeper},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/jeffries et al_2023_evaluating treatment effects in group sequential multivariate longitudinal2.pdf;/Users/zenn/Zotero/storage/TZ73W7KE/biom.html}
}

@article{jeffriesEvaluatingTreatmentEffects2023a,
  title = {Evaluating Treatment Effects in Group Sequential Multivariate Longitudinal Studies with Covariate Adjustment},
  author = {Jeffries, Neal O. and Troendle, James F. and Geller, Nancy L.},
  year = {2023},
  journal = {Biometrics},
  volume = {79},
  number = {2},
  pages = {1496--1506},
  issn = {1541-0420},
  doi = {10.1111/biom.13659},
  urldate = {2024-03-20},
  abstract = {Jeffries et al. (2018) investigated testing for a treatment difference in the setting of a randomized clinical trial with a single outcome measured longitudinally over a series of common follow-up times while adjusting for covariates. That paper examined the null hypothesis of no difference at any follow-up time versus the alternative of a difference for at least one follow-up time. We extend those results here by considering multivariate outcome measurements, where each individual outcome is examined at common follow-up times. We consider the case where there is interest in first testing for a treatment difference in a global function of the outcomes (e.g., weighted average or sum) with subsequent interest in examining the individual outcomes, should the global function show a treatment difference. Testing is conducted for each follow-up time and may be performed in the setting of a group sequential trial. Testing procedures are developed to determine follow-up times for which a global treatment difference exists and which individual combinations of outcome and follow-up time show evidence of a difference while controlling for multiplicity in outcomes, follow-up, and interim analyses. These approaches are examined in a study evaluating the effects of tissue plasminogen activator on longitudinally obtained stroke severity measurements.},
  langid = {english},
  keywords = {familywise error,generalized estimating equations,global tests,longitudinal analysis,parallel gatekeeper},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/jeffries et al_2023_evaluating treatment effects in group sequential multivariate longitudinal.pdf;/Users/zenn/Zotero/storage/CUG4INBE/biom.html}
}

@article{jeffriesLongitudinalClinicalTrials2015,
  title = {Longitudinal {{Clinical Trials}} with {{Adaptive Choice}} of {{Follow-Up Time}}},
  author = {Jeffries, Neal and Geller, Nancy L.},
  year = {2015},
  month = jun,
  journal = {Biometrics},
  volume = {71},
  number = {2},
  pages = {469--477},
  issn = {0006-341X, 1541-0420},
  doi = {10.1111/biom.12287},
  urldate = {2024-04-04},
  abstract = {In longitudinal studies comparing two treatments with a maximum follow-up time there may be interest in examining treatment effects for intermediate follow-up times. One motivation may be to identify the time period with greatest treatment difference when there is a non-monotone treatment effect over time; another motivation may be to make the trial more efficient in terms of time to reach a decision on whether a new treatment is efficacious or not. Here, we test the composite null hypothesis of no difference at any follow-up time versus the alternative that there is a difference at at least one follow-up time. The methods are applicable when a few measurements are taken over time, such as in early longitudinal trials or in ancillary studies. Suppose the test statistic Ztk will be used to test the hypothesis of no treatment effect at a fixed follow-up time tk. In this context a common approach is to perform a pilot study on N1 subjects, and evaluate the treatment effect at the fixed time points t1, . . . , tK and choose t{$\ast$} as the value of tk for which Ztk is maximized. Having chosen t{$\ast$} a second trial can be designed. In a setting with group sequential testing we consider several adaptive alternatives to this approach that treat the pilot and second trial as a seamless, combined entity and evaluate Type I error and power characteristics. The adaptive designs we consider typically have improved power over the common, separate trial approach.},
  copyright = {https://academic.oup.com/journals/pages/open\_access/funder\_policies/chorus/standard\_publication\_model},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/IGJFUGCV/biometrics_71_2_469.pdf}
}

@article{jeffriesLongitudinalClinicalTrials2015a,
  title = {Longitudinal {{Clinical Trials}} with {{Adaptive Choice}} of {{Follow-Up Time}}},
  author = {Jeffries, Neal and Geller, Nancy L.},
  year = {2015},
  month = jun,
  journal = {Biometrics},
  volume = {71},
  number = {2},
  pages = {469--477},
  issn = {0006-341X, 1541-0420},
  doi = {10.1111/biom.12287},
  urldate = {2024-03-20},
  abstract = {Summary             In longitudinal studies comparing two treatments with a maximum follow-up time there may be interest in examining treatment effects for intermediate follow-up times. One motivation may be to identify the time period with greatest treatment difference when there is a non-monotone treatment effect over time; another motivation may be to make the trial more efficient in terms of time to reach a decision on whether a new treatment is efficacious or not. Here, we test the composite null hypothesis of no difference at any follow-up time versus the alternative that there is a difference at at least one follow-up time. The methods are applicable when a few measurements are taken over time, such as in early longitudinal trials or in ancillary studies. Suppose the test statistic will be used to test the hypothesis of no treatment effect at a fixed follow-up time . In this context a common approach is to perform a pilot study on subjects, and evaluate the treatment effect at the fixed time points and choose as the value of for which is maximized. Having chosen a second trial can be designed. In a setting with group sequential testing we consider several adaptive alternatives to this approach that treat the pilot and second trial as a seamless, combined entity and evaluate Type I error and power characteristics. The adaptive designs we consider typically have improved power over the common, separate trial approach.},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/jeffries_geller_2015_longitudinal clinical trials with adaptive choice of follow-up time.pdf;/Users/zenn/Zotero/storage/KLLW6IQH/PMC4480157.html}
}

@article{jeong199753,
  title = {53 {{Power}} Comparisons among Different Number of Categories under Ordered Polytomous Logistic Regression Model},
  author = {Jeong, Jong-Hyeon and Klauber, Melville R and Thomas, Ronald G and Grundman, Michael and Thal, Leon J},
  year = {1997},
  journal = {Controlled Clinical Trials},
  volume = {3},
  number = {18},
  pages = {S74}
}

@article{jiCurrentStatusClinical2021,
  title = {Current {{Status}} of {{Clinical Trials}} on {{Tau Immunotherapies}}},
  author = {Ji, Changyi and Sigurdsson, Einar M.},
  year = {2021},
  month = jul,
  journal = {Drugs},
  volume = {81},
  number = {10},
  pages = {1135--1152},
  issn = {1179-1950},
  doi = {10.1007/s40265-021-01546-6},
  abstract = {Tau immunotherapies have advanced from proof-of-concept studies to over a dozen clinical trials for Alzheimer's disease (AD) and other tauopathies. Mechanistic studies in animal and culture models have provided valuable insight into how these therapies may work but multiple pathways are likely involved. Different groups have emphasized the importance of intracellular vs extracellular antibody-mediated clearance of the tau protein and there is no consensus on which pool of tau should ideally be targeted. Likewise, various normal and disease-selective epitopes are being targeted, and the antibody isotypes either favor phagocytosis of the tau-antibody complex or are neutral in that aspect. Most of the clinical trials are in early stages, thus their efficacy is not yet known, but all have been without any major adverse effects and some have reported target engagement. A few have been discontinued. One in phase I, presumably because of a poor pharmacokinetic profile, and three in phase II for a lack of efficacy although this trial stage is not well powered for efficacy measures. In these phase II studies, trials with two antibodies in patients with progressive supranuclear palsy or other primary tauopathies were halted but are continuing in patients with AD, and one antibody trial was stopped in early-stage AD but is continuing in moderate AD. These three antibodies have been reported to only work extracellularly and tau is not increased in the cerebrospinal fluid of primary tauopathies, which may explain the failures of two of them. In the discontinued AD trial, there are some concerns about how much of extracellular tau contains the N-terminal epitope that is being targeted. In addition, extracellular tau is only a small part of total tau, compared to intracellular tau. Targeting only the former may not be sufficient for functional benefits. Given these outcomes, decision makers within the pharmaceutical companies who green light these trials should attempt to target tau not only extracellularly but also intracellularly to increase their chances of success. Hopefully, some of the ongoing trials will provide some functional benefits to the large number of patients with tauopathies.},
  langid = {english},
  pmcid = {PMC8752054},
  pmid = {34101156},
  keywords = {Alzheimer Disease,Animals,Clinical Trials as Topic,Humans,Immunotherapy,tau Proteins,Tauopathies,Vaccines},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/ji_sigurdsson_2021_current status of clinical trials on tau immunotherapies2.pdf}
}

@article{jiCurrentStatusClinical2021a,
  title = {Current {{Status}} of {{Clinical Trials}} on {{Tau Immunotherapies}}},
  author = {Ji, Changyi and Sigurdsson, Einar M.},
  year = {2021},
  month = jul,
  journal = {Drugs},
  volume = {81},
  number = {10},
  pages = {1135--1152},
  issn = {1179-1950},
  doi = {10.1007/s40265-021-01546-6},
  abstract = {Tau immunotherapies have advanced from proof-of-concept studies to over a dozen clinical trials for Alzheimer's disease (AD) and other tauopathies. Mechanistic studies in animal and culture models have provided valuable insight into how these therapies may work but multiple pathways are likely involved. Different groups have emphasized the importance of intracellular vs extracellular antibody-mediated clearance of the tau protein and there is no consensus on which pool of tau should ideally be targeted. Likewise, various normal and disease-selective epitopes are being targeted, and the antibody isotypes either favor phagocytosis of the tau-antibody complex or are neutral in that aspect. Most of the clinical trials are in early stages, thus their efficacy is not yet known, but all have been without any major adverse effects and some have reported target engagement. A few have been discontinued. One in phase I, presumably because of a poor pharmacokinetic profile, and three in phase II for a lack of efficacy although this trial stage is not well powered for efficacy measures. In these phase II studies, trials with two antibodies in patients with progressive supranuclear palsy or other primary tauopathies were halted but are continuing in patients with AD, and one antibody trial was stopped in early-stage AD but is continuing in moderate AD. These three antibodies have been reported to only work extracellularly and tau is not increased in the cerebrospinal fluid of primary tauopathies, which may explain the failures of two of them. In the discontinued AD trial, there are some concerns about how much of extracellular tau contains the N-terminal epitope that is being targeted. In addition, extracellular tau is only a small part of total tau, compared to intracellular tau. Targeting only the former may not be sufficient for functional benefits. Given these outcomes, decision makers within the pharmaceutical companies who green light these trials should attempt to target tau not only extracellularly but also intracellularly to increase their chances of success. Hopefully, some of the ongoing trials will provide some functional benefits to the large number of patients with tauopathies.},
  langid = {english},
  pmcid = {PMC8752054},
  pmid = {34101156},
  keywords = {Alzheimer Disease,Animals,Clinical Trials as Topic,Humans,Immunotherapy,tau Proteins,Tauopathies,Vaccines},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/ji_sigurdsson_2021_current status of clinical trials on tau immunotherapies.pdf}
}

@article{jimenez2012p3,
  title = {P3-364: {{ADCS EDC}}},
  author = {{Jimenez-Maggiora}, Gustavo and Thomas, Ronald and Hong, Phuoc and Aisen, Paul},
  year = {2012},
  journal = {Alzheimer's \& Dementia},
  volume = {8},
  number = {4S\_Part\_16},
  pages = {P584--P584}
}

@article{jimenez2013p4,
  title = {P4--184: {{ADCS}} Electronic Data Capture: {{Integrated}} Image Management},
  author = {{Jimenez-Maggiora}, Gustavo and Thomas, Ronald and Brewer, Jim and Bruschi, Stefania and Hong, Phuoc and Aisen, Paul},
  year = {2013},
  journal = {Alzheimer's \& Dementia},
  volume = {9},
  pages = {P773--P773}
}

@article{jimenez2013p4,
  title = {P4--157: {{Adcs}} Electronic Data Capture: {{Collaborative}} Development and Management of Clinical Trial Databases},
  author = {{Jimenez-Maggiora}, Gustavo and Thomas, Ronald and Bruschi, Stefania and Qiu, Hongmei and Hong, Phuoc and Aisen, Paul},
  year = {2013},
  journal = {Alzheimer's \& Dementia},
  volume = {9},
  pages = {P763--P764}
}

@article{jimenez2014p1,
  title = {P1-358: {{ADCS EDC}}: {{DATA EXCHANGE AND PROCESSING PLATFORM}}},
  author = {{Jimenez-Maggiora}, Gustavo Adolfo and Thomas, Ronald G and Qiu, Hongmei and Bruschi, Stefania and So, Jia-Shing and Hong, Phuoc and Aisen, Paul S},
  year = {2014},
  journal = {Alzheimer's \& Dementia},
  volume = {10},
  pages = {P445--P445},
  publisher = {The Alzheimer's Association}
}

@article{jimenez2014p1,
  title = {P1-357: {{ADCS EDC}}: {{INVESTIGATIONAL PRODUCT MANAGEMENT SYSTEM}}},
  author = {{Jimenez-Maggiora}, Gustavo Adolfo and Thomas, Ronald G and Qiu, Hongmei and Hong, Phuoc and Aisen, Paul S},
  year = {2014},
  journal = {Alzheimer's \& Dementia},
  volume = {10},
  pages = {P444--P445},
  publisher = {The Alzheimer's Association}
}

@article{jin1998dynamic,
  title = {Dynamic Measurement Scale Development for Clinical Trials in Targeted Populations},
  author = {Jin, Shelia and Thomas, Ronald G and Galasko, Douglas and Thal, Leon J},
  year = {1998},
  journal = {Controlled Clinical Trials},
  volume = {19},
  number = {3},
  pages = {S58},
  publisher = {Elsevier}
}

@article{jinAlgorithmsMinimizationRandomization2021,
  title = {Algorithms for Minimization Randomization and the Implementation with an {{R}} Package},
  author = {Jin, Man and Polis, Adam and Hartzel, Jonathan},
  year = {2021},
  month = oct,
  journal = {Communications in Statistics - Simulation and Computation},
  volume = {50},
  number = {10},
  pages = {3077--3087},
  issn = {0361-0918, 1532-4141},
  doi = {10.1080/03610918.2019.1619765},
  urldate = {2023-12-15},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/TEBHRX74/Jin et al. - 2021 - Algorithms for minimization randomization and the .pdf}
}

@article{joeOrderingDependenceContingency1985,
  title = {An Ordering of Dependence for Contingency Tables},
  author = {Joe, Harry},
  year = {1985},
  month = oct,
  journal = {Linear Algebra and its Applications},
  volume = {70},
  pages = {89--103},
  issn = {0024-3795},
  doi = {10.1016/0024-3795(85)90045-X},
  urldate = {2023-07-29},
  abstract = {A majorization ordering is defined on matrices with the same row and column sums. This ordering is used as an ordering of dependence for contingency tables. Results are derived for maximal and minimal matrices with respect to the majorization ordering. This theory can be used to maximize and minimize Schur concave functions defined over matrices, when there are row and column sum constraints; in this paper, it is applied to the algorithm of Mehta and Patel (1983) for finding the P-value of Fisher's exact test.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/AFFSPAVK/Joe - 1985 - An ordering of dependence for contingency tables.pdf;/Users/zenn/Zotero/storage/64AF9YRL/002437958590045X.html}
}

@article{johanssonJournalComputationalGraphical2020,
  title = {Journal of {{Computational}} and {{Graphical Statistics Rerandomization Strategies}} for {{Balancing Covariates Using Pre-Experimental Longitudinal Data Rerandomization Strategies}} for {{Balancing Covariates Using Pre-Experimental Longitudinal Data}}},
  author = {Johansson, Per and Schultzberg, M{\aa}rten},
  year = {2020},
  journal = {JOURNAL OF COMPUTATIONAL AND GRAPHICAL STATISTICS},
  volume = {2020},
  number = {4},
  pages = {798--813},
  issn = {1537-2715},
  doi = {10.1080/10618600.2020.1753531},
  abstract = {This article considers experimental design based on the strategy of rerandomization to increase the efficiency in experiments. Two aspects of rerandomization are addressed. First, we propose a two-stage allocation sample scheme for randomization inference to the units in experiments that guarantees that the difference-in-mean estimator is an unbiased estimator of the sample average treatment effect for any experiment, conserves the exactness of randomization inference, and halves the time consumption of the rerandomization design. Second, we propose a rank-based covariate-balance measure which can take into account the estimated relative weight of each covariate. Several strategies for estimating these weights using pre-experimental data are proposed. Using Monte Carlo simulations, the proposed strategies are compared to complete randomization and Mahalanobis-based rerandomization. An empirical example is given where the power of a mean difference test of electricity consumption of 54 households is increased by 99\%, in comparison to complete randomization, using one of the proposed designs based on high frequency longitudinal electricity consumption data.},
  keywords = {Experimental design,Fisher exact test,High frequency longitudinal data,Mahalanobis distance criterion,Mirror allocation sampling,Rerandomization},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/johansson_schultzberg_2020_journal of computational and graphical statistics rerandomization strategies.pdf}
}

@article{johnsonPowerAnalysisGeneralized2015,
  title = {Power Analysis for Generalized Linear Mixed Models in Ecology and Evolution},
  author = {Johnson, Paul C. D. and Barry, Sarah J. E. and Ferguson, Heather M. and M{\"u}ller, Pie},
  year = {2015},
  journal = {Methods in Ecology and Evolution},
  volume = {6},
  number = {2},
  pages = {133--142},
  issn = {2041-210X},
  doi = {10.1111/2041-210X.12306},
  urldate = {2022-11-16},
  abstract = {`Will my study answer my research question?' is the most fundamental question a researcher can ask when designing a study, yet when phrased in statistical terms -- `What is the power of my study?' or `How precise will my parameter estimate be?' -- few researchers in ecology and evolution (EE) try to answer it, despite the detrimental consequences of performing under- or over-powered research. We suggest that this reluctance is due in large part to the unsuitability of simple methods of power analysis (broadly defined as any attempt to quantify prospectively the `informativeness' of a study) for the complex models commonly used in EE research. With the aim of encouraging the use of power analysis, we present simulation from generalized linear mixed models (GLMMs) as a flexible and accessible approach to power analysis that can account for random effects, overdispersion and diverse response distributions. We illustrate the benefits of simulation-based power analysis in two research scenarios: estimating the precision of a survey to estimate tick burdens on grouse chicks and estimating the power of a trial to compare the efficacy of insecticide-treated nets in malaria mosquito control. We provide a freely available R function, sim.glmm, for simulating from GLMMs. Analysis of simulated data revealed that the effects of accounting for realistic levels of random effects and overdispersion on power and precision estimates were substantial, with correspondingly severe implications for study design in the form of up to fivefold increases in sampling effort. We also show the utility of simulations for identifying scenarios where GLMM-fitting methods can perform poorly. These results illustrate the inadequacy of standard analytical power analysis methods and the flexibility of simulation-based power analysis for GLMMs. The wider use of these methods should contribute to improving the quality of study design in EE.},
  langid = {english},
  keywords = {experimental design,generalized linear mixed model,long-lasting insecticidal net,overdispersion,precision,random effects,sample size,simulation},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/johnson et al_2015_power analysis for generalized linear mixed models in ecology and evolution.pdf;/Users/zenn/Zotero/storage/H9HMFE5C/2041-210X.html}
}

@article{johnsonPowerAnalysisGeneralized2015a,
  title = {Power Analysis for Generalized Linear Mixed Models in Ecology and Evolution},
  author = {Johnson, Paul C. D. and Barry, Sarah J. E. and Ferguson, Heather M. and M{\"u}ller, Pie},
  editor = {Schielzeth, Holger},
  year = {2015},
  month = feb,
  journal = {Methods in Ecology and Evolution},
  volume = {6},
  number = {2},
  pages = {133--142},
  issn = {2041-210X, 2041-210X},
  doi = {10.1111/2041-210X.12306},
  urldate = {2024-03-11},
  abstract = {Summary                                                                                     `Will my study answer my research question?' is the most fundamental question a researcher can ask when designing a study, yet when phrased in statistical terms -- `What is the power of my study?' or `How precise will my parameter estimate be?' -- few researchers in ecology and evolution (                     EE                     ) try to answer it, despite the detrimental consequences of performing under- or over-powered research. We suggest that this reluctance is due in large part to the unsuitability of simple methods of power analysis (broadly defined as any attempt to quantify prospectively the `informativeness' of a study) for the complex models commonly used in                     EE                     research. With the aim of encouraging the use of power analysis, we present simulation from generalized linear mixed models (                     GLMM                     s) as a flexible and accessible approach to power analysis that can account for random effects, overdispersion and diverse response distributions.                                                                                             We illustrate the benefits of simulation-based power analysis in two research scenarios: estimating the precision of a survey to estimate tick burdens on grouse chicks and estimating the power of a trial to compare the efficacy of insecticide-treated nets in malaria mosquito control. We provide a freely available                     R                     function,                     sim.glmm                     , for simulating from                     GLMM                     s.                                                                                             Analysis of simulated data revealed that the effects of accounting for realistic levels of random effects and overdispersion on power and precision estimates were substantial, with correspondingly severe implications for study design in the form of up to fivefold increases in sampling effort. We also show the utility of simulations for identifying scenarios where                     GLMM                     -fitting methods can perform poorly.                                                                                             These results illustrate the inadequacy of standard analytical power analysis methods and the flexibility of simulation-based power analysis for                     GLMM                     s. The wider use of these methods should contribute to improving the quality of study design in                     EE                     .},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/JJMFKHWP/Johnson et al. - 2015 - Power analysis for generalized linear mixed models.pdf}
}

@article{jonesCombinedTheoreticalEmpirical2018,
  title = {A Combined Theoretical and Empirical Approach to Evidence Quality Evaluation: {{A}} Commentary on {{Deaton}} and {{Cartwright}}},
  shorttitle = {A Combined Theoretical and Empirical Approach to Evidence Quality Evaluation},
  author = {Jones, Andrew and Steel, Daniel},
  year = {2018},
  journal = {Social Science \& Medicine},
  volume = {210},
  pages = {74--76},
  publisher = {Elsevier},
  file = {/Users/zenn/Zotero/storage/RHGTXL9H/S0277953618302028.html}
}

@article{jovicExactMethodAnalysis2010,
  title = {An Exact Method for Analysis Following a Two-Stage Phase {{II}} Cancer Clinical Trial},
  author = {Jovic, Gordana and Whitehead, John},
  year = {2010},
  month = dec,
  journal = {Statistics in Medicine},
  volume = {29},
  number = {30},
  pages = {3118--3125},
  issn = {02776715},
  doi = {10.1002/sim.3837},
  urldate = {2023-08-18},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/ITKXLKPU/Jovic and Whitehead - 2010 - An exact method for analysis following a two-stage.pdf}
}

@article{jungNoteSampleSize2007,
  title = {A {{Note}} on {{Sample Size Calculation Based}} on {{Propensity Analysis}} in {{Nonrandomized Trials}}},
  author = {Jung, Sin-Ho and Chow, Shein-Chung and Chi, Eric M.},
  year = {2007},
  month = jan,
  journal = {Journal of Biopharmaceutical Statistics},
  volume = {17},
  number = {1},
  pages = {35--41},
  publisher = {Taylor \& Francis},
  issn = {1054-3406},
  doi = {10.1080/10543400601044790},
  urldate = {2023-08-18},
  abstract = {In nonrandomized trials, patients are not randomly assigned to treatment groups with equal probability. Instead, the probability of assignment varies from patient to patient depending on patients baseline covariates. This often results in a non-comparable treatment groups due to treatment imbalance. As a result, the United States Food and Drug Administration (FDA) recommended that the method of propensity score analysis be employed to overcome this problem. In this note, a formula for sample size calculation is developed based on a proposed weighted Mantel--Haenszel test on the strata defined by the propensity score analysis. It was shown that the sample size formula derived by Nam (1998) based on the test statistic proposed by Gart (1985) is a special case of the sample size formula derived in this note.},
  pmid = {17219754},
  keywords = {Nonrandomized trials,Propensity score analysis,Weighted Mantel-Haenszel test},
  file = {/Users/zenn/Zotero/storage/DIV5ZSIC/Jung et al. - 2007 - A Note on Sample Size Calculation Based on Propens.pdf}
}

@article{jungStratifiedFisherExact2014,
  title = {Stratified {{Fisher}}'s Exact Test and Its Sample Size Calculation},
  author = {Jung, Sin-Ho},
  year = {2014},
  journal = {Biometrical Journal},
  volume = {56},
  number = {1},
  pages = {129--140},
  issn = {1521-4036},
  doi = {10.1002/bimj.201300048},
  urldate = {2023-07-21},
  abstract = {Chi-squared test has been a popular approach to the analysis of a 2 {\texttimes} 2 table when the sample sizes for the four cells are large. When the large sample assumption does not hold, however, we need an exact testing method such as Fisher's test. When the study population is heterogeneous, we often partition the subjects into multiple strata, so that each stratum consists of homogeneous subjects and hence the stratified analysis has an improved testing power. While Mantel--Haenszel test has been widely used as an extension of the chi-squared test to test on stratified 2 {\texttimes} 2 tables with a large-sample approximation, we have been lacking an extension of Fisher's test for stratified exact testing. In this paper, we discuss an exact testing method for stratified 2 {\texttimes} 2 tables that is simplified to the standard Fisher's test in single 2 {\texttimes} 2 table cases, and propose its sample size calculation method that can be useful for designing a study with rare cell frequencies.},
  copyright = {{\copyright} 2013 WILEY-VCH Verlag GmbH \& Co. KGaA, Weinheim},
  langid = {english},
  keywords = {Conditional type I error,Exact test,Hypergeometric distribution,Many 2  2 tables,Odds ratio},
  file = {/Users/zenn/Zotero/storage/PDMMMABU/Jung - 2014 - Stratified Fisher's exact test and its sample size.pdf;/Users/zenn/Zotero/storage/94N4NAU4/bimj.html}
}

@article{justPartitionEisensteinSeries2021,
  title = {Partition {{Eisenstein}} Series and Semi-Modular Forms},
  author = {Just, Matthew and Schneider, Robert},
  year = {2021},
  month = mar,
  journal = {arXiv:2103.06239 [math]},
  eprint = {2103.06239},
  primaryclass = {math},
  urldate = {2021-03-13},
  abstract = {We identify a class of "semi-modular" forms invariant on special subgroups of \$GL\_2({\textbackslash}mathbb Z)\$, which includes classical modular forms together with complementary classes of functions that are also nice in a specific sense. We define an Eisenstein-like series summed over integer partitions, and use it to construct families of semi-modular forms.},
  archiveprefix = {arXiv},
  keywords = {Mathematics - Combinatorics,Mathematics - Number Theory},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/just_schneider_2021_partition eisenstein series and semi-modular forms.pdf;/Users/zenn/Zotero/storage/2CU2EDF4/2103.html}
}

@article{juttenWhyClinicalTrial2023,
  title = {Why a Clinical Trial Is as Good as Its Outcome Measure: {{A}} Framework for the Selection and Use of Cognitive Outcome Measures for Clinical Trials of {{Alzheimer}}'s Disease},
  shorttitle = {Why a Clinical Trial Is as Good as Its Outcome Measure},
  author = {Jutten, Roos J. and Papp, Kathryn V. and Hendrix, Suzanne and Ellison, Noel and Langbaum, Jessica B. and Donohue, Michael C. and Hassenstab, Jason and Maruff, Paul and Rentz, Dorene M. and Harrison, John and Cummings, Jeffrey and Scheltens, Philip and Sikkes, Sietske A. M.},
  year = {2023},
  journal = {Alzheimer's \& Dementia},
  volume = {19},
  number = {2},
  pages = {708--720},
  issn = {1552-5279},
  doi = {10.1002/alz.12773},
  urldate = {2024-01-18},
  abstract = {A crucial aspect of any clinical trial is using the right outcome measure to assess treatment efficacy. Compared to the rapidly evolved understanding and measurement of pathophysiology in preclinical and early symptomatic stages of Alzheimer's disease (AD), relatively less progress has been made in the evolution of clinical outcome assessments (COAs) for those stages. The current paper aims to provide a benchmark for the design and evaluation of COAs for use in early AD trials. We discuss lessons learned on capturing cognitive changes in predementia stages of AD, including challenges when validating novel COAs for those early stages and necessary evidence for their implementation in clinical trials. Moving forward, we propose a multi-step framework to advance the use of more effective COAs to assess clinically meaningful changes in early AD, which will hopefully contribute to the much-needed consensus around more appropriate outcome measures to assess clinical efficacy of putative treatments. Highlights We discuss lessons learned on capturing cognitive changes in predementia stages of AD. We propose a framework for the design and evaluation of performance based cognitive tests for use in early AD trials. We provide recommendations to facilitate the implementation of more effective cognitive outcome measures in AD trials.},
  langid = {english},
  keywords = {Alzheimer's disease,clinical outcome assessments,clinical trial,cognition,preclinical,prodromal},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/jutten et al_2023_why a clinical trial is as good as its outcome measure.pdf;/Users/zenn/Zotero/storage/NPAJ3KMT/alz.html}
}

@article{kahanAccountingCentreeffectsMulticentre2014,
  title = {Accounting for Centre-Effects in Multicentre Trials with a Binary Outcome -- When, Why, and How?},
  author = {Kahan, Brennan C.},
  year = {2014},
  month = feb,
  journal = {BMC Medical Research Methodology},
  volume = {14},
  number = {1},
  pages = {20},
  issn = {1471-2288},
  doi = {10.1186/1471-2288-14-20},
  urldate = {2023-08-11},
  abstract = {It is often desirable to account for centre-effects in the analysis of multicentre randomised trials, however it is unclear which analysis methods are best in trials with a binary outcome.},
  keywords = {Binary outcomes,Fixed-effects,Generalised estimating equations,Mantel-Haenszel,Multicentre trials,Random effects,Randomised controlled trial},
  file = {/Users/zenn/Zotero/storage/J5EYM9NE/Kahan - 2014 - Accounting for centre-effects in multicentre trial.pdf;/Users/zenn/Zotero/storage/YPI4QLVE/1471-2288-14-20.html}
}

@article{kahanAccountingCentreeffectsMulticentre2014a,
  title = {Accounting for Centre-Effects in Multicentre Trials with a Binary Outcome -- When, Why, and How?},
  author = {Kahan, Brennan C.},
  year = {2014},
  month = feb,
  journal = {BMC Medical Research Methodology},
  volume = {14},
  number = {1},
  pages = {20},
  issn = {1471-2288},
  doi = {10.1186/1471-2288-14-20},
  urldate = {2024-06-15},
  abstract = {It is often desirable to account for centre-effects in the analysis of multicentre randomised trials, however it is unclear which analysis methods are best in trials with a binary outcome.},
  langid = {english},
  keywords = {Binary outcomes,Fixed-effects,Generalised estimating equations,Mantel-Haenszel,Multicentre trials,Random effects,Randomised controlled trial},
  file = {/Users/zenn/Zotero/storage/4A48VYWU/Kahan - 2014 - Accounting for centre-effects in multicentre trial.pdf}
}

@article{kahanAdjustingMultiplePrognostic2013,
  title = {Adjusting for Multiple Prognostic Factors in the Analysis of Randomised Trials},
  author = {Kahan, Brennan C. and Morris, Tim P.},
  year = {2013},
  month = jul,
  journal = {BMC Medical Research Methodology},
  volume = {13},
  number = {1},
  pages = {99},
  issn = {1471-2288},
  doi = {10.1186/1471-2288-13-99},
  urldate = {2024-06-15},
  abstract = {When multiple prognostic factors are adjusted for in the analysis of a randomised trial, it is unclear (1) whether it is necessary to account for each of the strata, formed by all combinations of the prognostic factors (stratified analysis), when randomisation has been balanced within each stratum (stratified randomisation), or whether adjusting for the main effects alone will suffice, and (2) the best method of adjustment in terms of type I error rate and power, irrespective of the randomisation method.},
  langid = {english},
  keywords = {Covariate adjusted analysis,Randomised controlled trial,Restricted randomisation,Stratified analysis,Stratified randomisation},
  file = {/Users/zenn/Zotero/storage/QW8XKPT4/Kahan and Morris - 2013 - Adjusting for multiple prognostic factors in the a.pdf}
}

@article{kahanImproperAnalysisTrials2012,
  title = {Improper Analysis of Trials Randomised Using Stratified Blocks or Minimisation},
  author = {Kahan, Brennan C. and Morris, Tim P.},
  year = {2012},
  journal = {Statistics in medicine},
  volume = {31},
  number = {4},
  pages = {328--340},
  publisher = {Blackwell Publishing Ltd},
  address = {England},
  issn = {0277-6715},
  doi = {10.1002/sim.4431},
  abstract = {Many clinical trials restrict randomisation using stratified blocks or minimisation to balance prognostic factors across treatment groups. It is widely acknowledged in the statistical literature that the subsequent analysis should reflect the design of the study, and any stratification or minimisation variables should be adjusted for in the analysis. However, a review of recent general medical literature showed only 14 of 41 eligible studies reported adjusting their primary analysis for stratification or minimisation variables. We show that balancing treatment groups using stratification leads to correlation between the treatment groups. If this correlation is ignored and an unadjusted analysis is performed, standard errors for the treatment effect will be biased upwards, resulting in 95\% confidence intervals that are too wide, type I error rates that are too low and a reduction in power. Conversely, an adjusted analysis will give valid inference. We explore the extent of this issue using simulation for continuous, binary and time-to-event outcomes where treatment is allocated using stratified block randomisation or minimisation. Copyright {\copyright} 2011 John Wiley \& Sons, Ltd.},
  langid = {english},
  keywords = {adjustment,Analysis,Antineoplastic Agents - therapeutic use,Back Injuries - rehabilitation,Back Injuries - surgery,Bias,Breast Neoplasms - drug therapy,Breast Neoplasms - mortality,Carcinoma - drug therapy,Carcinoma - mortality,Clinical outcomes,Clinical trials,Computer Simulation - statistics & numerical data,Confidence intervals,covariates,Data Interpretation Statistical,Deoxyribonucleases - therapeutic use,Drug Therapy Combination - statistics & numerical data,Female,Fibrinolytic Agents - therapeutic use,Humans,Interferon-alpha - therapeutic use,Kidney Neoplasms - drug therapy,Kidney Neoplasms - mortality,Liver Cirrhosis Biliary - drug therapy,Male,Medical statistics,Medroxyprogesterone Acetate - therapeutic use,minimisation,Penicillamine - therapeutic use,Pleural Effusion - drug therapy,Pleural Effusion - mortality,Randomized Controlled Trials as Topic - statistics & numerical data,Simulation,stratification,Survival Analysis,Tamoxifen - therapeutic use,Tissue Plasminogen Activator - therapeutic use,Treatment Outcome,unadjusted analysis},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/kahan_morris_2012_improper analysis of trials randomised using stratified blocks or minimisation.pdf}
}

@article{kahanImproperAnalysisTrials2012a,
  title = {Improper Analysis of Trials Randomised Using Stratified Blocks or Minimisation},
  author = {Kahan, Brennan C. and Morris, Tim P.},
  year = {2012},
  journal = {Statistics in Medicine},
  volume = {31},
  number = {4},
  pages = {328--340},
  issn = {1097-0258},
  doi = {10.1002/sim.4431},
  urldate = {2024-06-15},
  abstract = {Many clinical trials restrict randomisation using stratified blocks or minimisation to balance prognostic factors across treatment groups. It is widely acknowledged in the statistical literature that the subsequent analysis should reflect the design of the study, and any stratification or minimisation variables should be adjusted for in the analysis. However, a review of recent general medical literature showed only 14 of 41 eligible studies reported adjusting their primary analysis for stratification or minimisation variables. We show that balancing treatment groups using stratification leads to correlation between the treatment groups. If this correlation is ignored and an unadjusted analysis is performed, standard errors for the treatment effect will be biased upwards, resulting in 95\% confidence intervals that are too wide, type I error rates that are too low and a reduction in power. Conversely, an adjusted analysis will give valid inference. We explore the extent of this issue using simulation for continuous, binary and time-to-event outcomes where treatment is allocated using stratified block randomisation or minimisation. Copyright {\copyright} 2011 John Wiley \& Sons, Ltd.},
  copyright = {Copyright {\copyright} 2011 John Wiley \& Sons, Ltd.},
  langid = {english},
  keywords = {adjustment,clinical trials,covariates,minimisation,stratification,unadjusted analysis},
  file = {/Users/zenn/Zotero/storage/TASJT2DR/Kahan and Morris - 2012 - Improper analysis of trials randomised using strat.pdf}
}

@article{kang1997genetic,
  title = {Genetic Association of the Low-Density Lipoprotein Receptor-Related Protein Gene ({{LRP}}), and Apolipoprotein {{E}} Receptor, with Late-Onset {{Alzheimer}}'s Disease},
  author = {Kang, {\relax DE} and Saitoh, T and Chen, X and Xia, Y and Masliah, E and Hansen, {\relax LA} and Thomas, {\relax RG} and Thal, {\relax LJ} and Katzman, R},
  year = {1997},
  journal = {Neurology},
  volume = {49},
  number = {1},
  pages = {56--61},
  publisher = {Wolters Kluwer Health, Inc. on behalf of the American Academy of Neurology}
}

@article{kaplanSimpleBayesianModels,
  title = {Simple {{Bayesian}} Models for Missing Binary Outcomes in Randomized Controlled Trials},
  author = {Kaplan, Adam and Nelson, David},
  journal = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.9866},
  urldate = {2023-08-25},
  abstract = {Missing outcomes are commonly encountered in randomized controlled trials (RCT) involving human subjects and present a risk for substantial bias in the results of a complete case analysis. While response rates for RCTs are typically high there is no agreed upon universal threshold under which the amount of missing data is deemed to not be a threat to inference. We focus here on binary outcomes that are possibly missing not at random, that is, the value of the outcome influences its possibility of being observed. Salient information that can assist in addressing these missing outcomes in such situations is the anticipated response rate in each study arm; these can often be anticipated based on prior research in similar populations using similar designs and outcomes. Further, in some areas of human subjects research, we are often confident or we suspect that response rates among RCT participants with successful treatment outcomes will be at least as great as those among participants without successful treatment outcomes. In other settings we may suspect the opposite relationship. This direction of the differential response between those with successful and unsuccessful outcomes can further aid in addressing the missing outcomes. We present simple Bayesian pattern-mixture models that incorporate this information on response rates to analyze the relationship between a binary outcome and an intervention while addressing the missing outcomes. We assess the performance of this method in simulation studies and apply this method to the results of an RCT of a smoking abstinence intervention.},
  langid = {english},
  keywords = {missing data,nonignorable missing data,pattern mixture models},
  file = {/Users/zenn/Zotero/storage/GT8PB9MK/Kaplan and Nelson - Simple Bayesian models for missing binary outcomes.pdf;/Users/zenn/Zotero/storage/NHU72EX8/sim.html}
}

@article{Katabathula2021,
  title = {Predict {{Alzheimer}} ' s Disease Using Hippocampus {{MRI}} Data : A Lightweight {{3D}} Deep Convolutional Network Model with Visual and Global Shape Representations},
  author = {Katabathula, Sreevani and Wang, Qinyong and Xu, Rong},
  year = {2021},
  volume = {0},
  pages = {1--9},
  publisher = {Alzheimer's Research \& Therapy},
  keywords = {3d convolutional neural network,alzheimer,Alzheimer's diseaseHippocampusMagnetic resonance,hippocampus,magnetic resonance imaging,s disease},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/katabathula et al_2021_predict alzheimer ’ s disease using hippocampus mri data.pdf}
}

@article{katzman1997effects,
  title = {Effects of Apolipoprotein {{E}} on Dementia and Aging in the {{Shanghai Survey}} of {{Dementia}}},
  author = {Katzman, R and Zhang, M-Y and Chen, {\relax PJ} and Gu, N and Jiang, S and Saitoh, T and Chen, X and Klauber, M and Thomas, {\relax RG} and Liu, {\relax WT} and others},
  year = {1997},
  journal = {Neurology},
  volume = {49},
  number = {3},
  pages = {779--785},
  publisher = {Wolters Kluwer Health, Inc. on behalf of the American Academy of Neurology}
}

@article{katzman1998interaction,
  title = {Interaction of Apolipoprotein {{E}} Epsilon 4 with Other Genetic and Non-Genetic Risk Factors in Late Onset {{Alzheimer}} Disease: Problems Facing the Investigator},
  author = {Katzman, R and Kang, D and Thomas, R},
  year = {1998},
  journal = {Neurochemical research},
  volume = {23},
  number = {3},
  pages = {369--376},
  publisher = {Kluwer Academic Publishers-Plenum Publishers}
}

@article{kean1998power,
  title = {Power Calculation for Randomized Start Design},
  author = {Kean, Yin M and Thomas, Ronald G and Thal, Leon J},
  year = {1998},
  journal = {Controlled Clinical Trials},
  volume = {19},
  number = {3},
  pages = {S38},
  publisher = {Elsevier}
}

@article{keane1998utility,
  title = {Utility of Psychophysiological Measurement in the Diagnosis of Posttraumatic Stress Disorder: Results from a {{Department}} of {{Veterans Affairs Cooperative Study}}.},
  author = {Keane, Terence M and Kolb, Lawrence C and Kaloupek, Danny G and Orr, Scott P and Blanchard, Edward B and Thomas, Ronald G and Hsieh, Frank Y and Lavori, Philip W},
  year = {1998},
  journal = {Journal of consulting and clinical psychology},
  volume = {66},
  number = {6},
  pages = {914},
  publisher = {American Psychological Association}
}

@misc{kedlaya2021frobenius,
  title = {Frobenius Structures on Hypergeometric Equations},
  author = {Kedlaya, Kiran S.},
  year = {2021},
  eprint = {1912.13073},
  primaryclass = {math.NT},
  archiveprefix = {arXiv}
}

@misc{kedlayaFrobeniusStructuresHypergeometric2021,
  title = {Frobenius Structures on Hypergeometric Equations},
  author = {Kedlaya, Kiran S.},
  year = {2021},
  month = dec,
  number = {arXiv:1912.13073},
  eprint = {1912.13073},
  primaryclass = {math},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1912.13073},
  urldate = {2023-06-08},
  abstract = {We give an exposition of Dwork's construction of Frobenius structures associated to generalized hypergeometric equations via the interpretation of the latter due to Gelfand-Kapranov-Zelevinsky in the language of A-hypergeometric systems. As a consequence, we extract some explicit formulas for the degeneration at 0 in terms of the Morita p-adic gamma function.},
  archiveprefix = {arXiv},
  keywords = {33C20 12H25,Mathematics - Algebraic Geometry,Mathematics - Number Theory},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/kedlaya_2021_frobenius structures on hypergeometric equations.pdf;/Users/zenn/Zotero/storage/69NRNV72/1912.html}
}

@misc{kedlayaFrobeniusStructuresHypergeometric2021a,
  title = {Frobenius Structures on Hypergeometric Equations},
  author = {Kedlaya, Kiran S.},
  year = {2021},
  month = dec,
  number = {arXiv:1912.13073},
  eprint = {1912.13073},
  primaryclass = {math},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1912.13073},
  urldate = {2023-07-29},
  abstract = {We give an exposition of Dwork's construction of Frobenius structures associated to generalized hypergeometric equations via the interpretation of the latter due to Gelfand-Kapranov-Zelevinsky in the language of A-hypergeometric systems. As a consequence, we extract some explicit formulas for the degeneration at 0 in terms of the Morita p-adic gamma function.},
  archiveprefix = {arXiv},
  keywords = {33C20 12H25,Mathematics - Algebraic Geometry,Mathematics - Number Theory},
  file = {/Users/zenn/Zotero/storage/PRKHV6C2/Kedlaya - 2021 - Frobenius structures on hypergeometric equations.pdf;/Users/zenn/Zotero/storage/6P6AA5Y9/1912.html}
}

@article{kellyAdaptiveGroupSequential2005,
  title = {An Adaptive Group Sequential Design for Phase {{II}}/{{III}} Clinical Trials That Select a Single Treatment from Several},
  author = {Kelly, Patrick J. and Stallard, Nigel and Todd, Susan},
  year = {2005},
  journal = {Journal of Biopharmaceutical Statistics},
  volume = {15},
  number = {4},
  pages = {641--658},
  publisher = {Taylor \& Francis},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/kelly et al_2005_an adaptive group sequential design for phase ii-iii clinical trials that.pdf;/Users/zenn/Zotero/storage/5NT8ZALL/BIP-200062857.html}
}

@article{kellyPracticalComparisonGroupSequential2005,
  title = {A {{Practical Comparison}} of {{Group-Sequential}} and {{Adaptive Designs}}},
  author = {Kelly, Patrick J. and Roshini Sooriyarachchi, M. and Stallard, Nigel and Todd, Susan},
  year = {2005},
  month = jul,
  journal = {Journal of Biopharmaceutical Statistics},
  volume = {15},
  number = {4},
  pages = {719--738},
  issn = {1054-3406, 1520-5711},
  doi = {10.1081/BIP-200062859},
  urldate = {2022-10-20},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/kelly et al_2005_a practical comparison of group-sequential and adaptive designs.pdf}
}

@article{kennaHHSPublicAccess2017,
  title = {{{HHS Public Access}}},
  author = {Kenna, George A and {Haass-koffler}, Carolina L and Zywiak, William H and Edwards, Steven M and Brickley, Michael B and Swift, Robert M and Leggio, Lorenzo},
  year = {2017},
  volume = {21},
  number = {4},
  pages = {904--914},
  doi = {10.1111/adb.12275.Role},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/kenna et al_2017_hhs public access.pdf}
}

@article{keoghSimulatingLongitudinalData2021,
  title = {Simulating Longitudinal Data from Marginal Structural Models Using the Additive Hazard Model},
  author = {Keogh, Ruth H. and Seaman, Shaun R. and Gran, Jon Michael and Vansteelandt, Stijn},
  year = {2021},
  journal = {Biometrical Journal},
  volume = {63},
  number = {7},
  pages = {1526--1541},
  publisher = {Wiley Online Library},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/keogh et al_2021_simulating longitudinal data from marginal structural models using the additive.pdf;/Users/zenn/Zotero/storage/QTNGDFWJ/bimj.html}
}

@article{kerns1992concave,
  title = {Concave Hymenal Variations in Suspected Child Sexual Abuse Victims},
  author = {Kerns, David L and Ritter, Mary L and Thomas, Ronald G},
  year = {1992},
  journal = {Pediatrics},
  volume = {90},
  number = {2},
  pages = {265--272},
  publisher = {American Academy of Pediatrics}
}

@article{khachaturian2008roadmap,
  title = {A Roadmap for the Prevention of Dementia: The Inaugural {{Leon Thal Symposium}}},
  author = {Khachaturian, Zaven S and Petersen, Ronald C and Gauthier, Serge and Buckholtz, Neil and {Corey-Bloom}, Jodey P and Evans, Bill and Fillit, Howard and Foster, Norman and Greenberg, Barry and Grundman, Michael and others},
  year = {2008},
  journal = {Alzheimer's \& dementia: the journal of the Alzheimer's Association},
  volume = {4},
  number = {3},
  pages = {156},
  publisher = {NIH Public Access}
}

@article{kimAnalysisMulticenterClinical2020,
  title = {Analysis of Multicenter Clinical Trials with Very Low Event Rates},
  author = {Kim, Jiyu and Troxel, Andrea B. and Halpern, Scott D. and Volpp, Kevin G. and Kahan, Brennan C. and Morris, Tim P. and Harhay, Michael O.},
  year = {2020},
  month = nov,
  journal = {Trials},
  volume = {21},
  number = {1},
  pages = {917},
  issn = {1745-6215},
  doi = {10.1186/s13063-020-04801-5},
  urldate = {2023-05-06},
  abstract = {In a five-arm randomized clinical trial (RCT) with stratified randomization across 54 sites, we encountered low primary outcome event proportions, resulting in multiple sites with zero events either overall or in one or more study arms. In this paper, we systematically evaluated different statistical methods of accounting for center in settings with low outcome event proportions.},
  langid = {english},
  keywords = {Binary outcomes,GEE,Low event rate,Mantel-Haenszel,Multicenter trial,Random effects,Randomized clinical trial,Small sample adjustment,Stratified randomization},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/kim et al_2020_analysis of multicenter clinical trials with very low event rates.pdf}
}

@article{Kiuchi1996,
  title = {A {{World Wide Web-based}} User Interface for a Data Management System for Use in Multi-Institutional Clinical Trials--Development and Experimental Operation of an Automated Patient Registration and Random Allocation System.},
  author = {Kiuchi, T and Ohashi, Y and Konishi, M and Bandai, Y and Kosuge, T and Kakizoe, T},
  year = {1996},
  month = dec,
  journal = {Controlled clinical trials},
  volume = {17},
  number = {6},
  eprint = {8974208},
  eprinttype = {pubmed},
  pages = {476--93},
  issn = {0197-2456},
  abstract = {We have employed the Hypertext Transfer Protocol (HTTP) and Hypertext Markup Language (HTML) to develop an automated patient registration and random allocation system for use in a multi-institutional clinical trial. We made it available on-line to World Wide Web clients in each hospital through a user friendly graphical user interface. During experimental operation, the physicians found it satisfactory from the viewpoint of both ease of operation and response time. For the development of a graphical user interface in network-based information system for use in multi-institutional clinical trials, HTTP/HTML has several advantages over an ordinary client-server model. Therefore, we concluded that we would adopt HTP/HTML for the construction of user interfaces for physicians in each spital and for data managers in our coordinating center.},
  pmid = {8974208},
  keywords = {Chemotherapy Adjuvant,Computer Communication Networks,Computer Security,Forms and Records Control,Forms and Records Control: methods,Humans,Hypermedia,Management Information Systems,Multicenter Studies as Topic,Pancreatic Neoplasms,Pancreatic Neoplasms: drug therapy,Random Allocation,Randomized Controlled Trials as Topic,User-Computer Interface},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/kiuchi et al_1996_a world wide web-based user interface for a data management system for use in.pdf}
}

@article{kiwamukudoNeurophysiologicalTrajectoriesAlzheimer2023,
  title = {Neurophysiological Trajectories in {{Alzheimer}}'s Disease Progression},
  author = {{Kiwamu Kudo} and {Kamalini G Ranasinghe} and {Hirofumi Morise} and {Faatimah Syed} and {Kensuke Sekihara} and {Katherine P. Rankin} and {Bruce L Miller} and {Joel Kramer} and {Gil Rabinovici} and {Keith Vossel} and {Heidi E Kirsch} and {Srikantan Nagarajan}},
  year = {2023},
  month = jan,
  journal = {bioRxiv},
  pages = {2023.05.18.541379},
  doi = {10.1101/2023.05.18.541379},
  abstract = {Alzheimer's disease (AD) is characterized by accumulation of amyloid-{$B$} and misfolded tau proteins causing synaptic dysfunction and progressive neurodegeneration and cognitive decline. Altered neural oscillations have been consistently demonstrated in AD. However, the trajectories of abnormal neural oscillations in AD progression and their relationship to neurodegeneration and cognitive decline are unknown. Here, we deployed robust event-based sequencing models (EBMs) to investigate the trajectories of long-range and local neural synchrony across AD stages, estimated from resting-state magnetoencephalography. Increases in neural synchrony in the delta-theta band and decreases in the alpha and beta bands showed progressive changes along the EBM stages. Decreases in alpha and beta-band synchrony preceded both neurodegeneration and cognitive decline, indicating that frequency-specific neuronal synchrony abnormalities are early manifestations of AD pathophysiology. The long-range synchrony effects were greater than the local synchrony, indicating a greater sensitivity of connectivity metrics involving multiple regions of the brain. These results demonstrate the evolution of functional neuronal deficits along the sequence of AD progression.Competing Interest StatementK.K. and H.M. are employees of Ricoh Company, Ltd.}
}

@article{Klein2019,
  title = {Gantenerumab Reduces Amyloid- {$\beta$} Plaques in Patients with Prodromal to Moderate {{Alzheimer}} ' s Disease : A {{PET}} Substudy Interim Analysis},
  author = {Klein, Gregory and Delmar, Paul and Voyle, Nicola and Rehal, Sunita and Hofmann, Carsten and {Abi-saab}, Danielle and Andjelkovic, Mirjana and Ristic, Smiljana and Wang, Guoqiao and Bateman, Randall and Kerchner, Geoffrey A and Baudler, Monika and Fontoura, Paulo and Doody, Rachelle},
  year = {2019},
  journal = {Alzheimer's Research and Therapy},
  pages = {1--12},
  publisher = {Alzheimer's Research \& Therapy},
  keywords = {alzheimer,Alzheimer's disease,amyloid-  plaque,Amyloid- plaque,centiloid,Centiloid,com,correspondence,disease-modification therapies,Disease-modification therapies,florbetapir,Florbetapir,gantenerumab,Gantenerumab,gregory,klein,open-label extension,Open-label extension,positron emission tomography,Positron emission tomography,roche,s disease},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/klein et al_2019_gantenerumab reduces amyloid- β plaques in patients with prodromal to moderate.pdf}
}

@inproceedings{knopman1998relationship,
  title = {The Relationship between {{Nursing}} Home Placement and Measures of Change in {{Alzheimer}}'s Disease},
  booktitle = {Neurology},
  author = {Knopman, {\relax DS} and Sano, M and Berg, {\relax JD} and Thomas, {\relax RG}},
  year = {1998},
  volume = {50},
  pages = {A251--A251},
  publisher = {LIPPINCOTT WILLIAMS \& WILKINS 227 EAST WASHINGTON SQ, PHILADELPHIA, PA 19106 USA}
}

@article{knopman1999nursing,
  title = {Nursing Home Placement Is Related to Dementia Progression: Experience from a Clinical Trial},
  author = {Knopman, David S and Berg, {\relax JD} and Thomas, R and Grundman, M and Thal, {\relax LJ} and Sano, M and others},
  year = {1999},
  journal = {Neurology},
  volume = {52},
  number = {4},
  pages = {714--714},
  publisher = {Wolters Kluwer Health, Inc. on behalf of the American Academy of Neurology}
}

@article{kochStatisticalConsiderationsMultiplicity1996,
  title = {Statistical {{Considerations}} for {{Multiplicity}} in {{Confirmatory Protocols}}},
  author = {Koch, Gary G. and Gansky, Stuart A.},
  year = {1996},
  month = apr,
  journal = {Drug Information Journal},
  volume = {30},
  number = {2},
  pages = {523--534},
  publisher = {SAGE Publications},
  issn = {0092-8615},
  doi = {10.1177/009286159603000228},
  urldate = {2024-03-12},
  abstract = {Statistical issues concerning multiple response criteria, multiple treatment groups, and multiple subgroups in clinical trials require careful attention in order to avoid an inappropriately high prevalence of chance findings, as well as to avoid unsatisfactorily low power to detect real treatment differences. An underlying goal is using a 0.050 significance level as often as possible for separate assessments while maintaining a 0.050 level for all assessments taken together, so statistical power is not compromised. For multiple response criteria, a useful assessment strategy is composite ranking as a single criterion first and then its individual components. Multiple treatment comparisons can often be effectively addressed with closed testing procedures with hierarchical evaluation. This hierarchy must be well specified since significance at its first stage is required before testing is allowed at the next stage. In most clinical trials, subgroups are of supportive interest after statistical significance for all patients is shown. A subgroup hierarchy, however, permits primary evaluation in conjunction with all patients through significance level spending function methods as in interim analyses, for example, the O'Brien-Fleming method. The rationale is the analogy between a subgroup hierarchy and the patient hierarchy at successive interim analyses. With this method, the significance level for all patients' evaluation typically ranges between 0.040 and 0.045 and that for subgroups ranges from 0.005-0.020. The methods outlined here for multiple response criteria, multiple treatment groups, and subgroups, or related counterparts, should be prespecified in the protocol for a clinical trial. If not in the protocol, they should be incorporated in the analysis plan prior to study unmasking.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/J5NXZE96/Koch and Gansky - 1996 - Statistical Considerations for Multiplicity in Con.pdf}
}

@article{koehlerEmpiricalInvestigationGoodnessofFit1980,
  title = {An {{Empirical Investigation}} of {{Goodness-of-Fit Statistics}} for {{Sparse Multinomials}}},
  author = {Koehler, Kenneth J. and Larntz, Kinley},
  year = {1980},
  month = jun,
  journal = {Journal of the American Statistical Association},
  volume = {75},
  number = {370},
  pages = {336--344},
  issn = {0162-1459, 1537-274X},
  doi = {10.1080/01621459.1980.10477473},
  urldate = {2024-02-09},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/koehler_larntz_1980_an empirical investigation of goodness-of-fit statistics for sparse multinomials.pdf}
}

@article{kolamunnage-donaModellingVariableDropout2016,
  title = {Modelling Variable Dropout in Randomised Controlled Trials with Longitudinal Outcomes: Application to the {{MAGNETIC}} Study},
  shorttitle = {Modelling Variable Dropout in Randomised Controlled Trials with Longitudinal Outcomes},
  author = {{Kolamunnage-Dona}, Ruwanthi and Powell, Colin and Williamson, Paula Ruth},
  year = {2016},
  month = dec,
  journal = {Trials},
  volume = {17},
  number = {1},
  pages = {222},
  issn = {1745-6215},
  doi = {10.1186/s13063-016-1342-0},
  urldate = {2024-05-08},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/kolamunnage-dona et al_2016_modelling variable dropout in randomised controlled trials with longitudinal.pdf;/Users/zenn/Zotero/storage/YBC4JSUK/s13063-016-1342-0.html}
}

@article{korosInterventionsProgressiveSupranuclear2016,
  title = {Interventions in Progressive Supranuclear Palsy},
  author = {Koros, Christos and Stamelou, Maria},
  year = {2016},
  month = jan,
  journal = {Parkinsonism \& Related Disorders},
  volume = {22 Suppl 1},
  pages = {S93-95},
  issn = {1873-5126},
  doi = {10.1016/j.parkreldis.2015.09.033},
  abstract = {Progressive supranuclear palsy (PSP) an atypical parkinsonian with a common phenotype comprising early falls, the characteristic slowing of vertical saccades and a frontal syndrome with marked apathy (Richardson's syndrome). Currently, no effective symptomatic or neuroprotective treatment is available for PSP. Current medical have a limited role in PSP. Novel experimental treatments include davunetide or tideglusib, both inhibitors of glycogen synthase kinase-3 (GSK-3) that failed to improve the clinical outcome of PSP patients in two recent studies. Future interventions aiming at tau dysfunction and passive or active immunization are ongoing or underway.},
  langid = {english},
  pmid = {26459661},
  keywords = {Animals,Brain,Clinical Trials as Topic,Davunetide,Glycogen Synthase Kinase 3,Glycogen synthase kinase-3 inhibitors,Humans,Immunization,Progressive supranuclear palsy,Richardson's syndrome,Supranuclear Palsy Progressive,Thiadiazoles,Tideglusib,Treatment}
}

@article{korosInterventionsProgressiveSupranuclear2016a,
  title = {Interventions in Progressive Supranuclear Palsy},
  author = {Koros, Christos and Stamelou, Maria},
  year = {2016},
  month = jan,
  journal = {Parkinsonism \& Related Disorders},
  volume = {22 Suppl 1},
  pages = {S93-95},
  issn = {1873-5126},
  doi = {10.1016/j.parkreldis.2015.09.033},
  abstract = {Progressive supranuclear palsy (PSP) an atypical parkinsonian with a common phenotype comprising early falls, the characteristic slowing of vertical saccades and a frontal syndrome with marked apathy (Richardson's syndrome). Currently, no effective symptomatic or neuroprotective treatment is available for PSP. Current medical have a limited role in PSP. Novel experimental treatments include davunetide or tideglusib, both inhibitors of glycogen synthase kinase-3 (GSK-3) that failed to improve the clinical outcome of PSP patients in two recent studies. Future interventions aiming at tau dysfunction and passive or active immunization are ongoing or underway.},
  langid = {english},
  pmid = {26459661},
  keywords = {Animals,Brain,Clinical Trials as Topic,Davunetide,Glycogen Synthase Kinase 3,Glycogen synthase kinase-3 inhibitors,Humans,Immunization,Progressive supranuclear palsy,Richardson's syndrome,Supranuclear Palsy Progressive,Thiadiazoles,Tideglusib,Treatment}
}

@article{korosInterventionsProgressiveSupranuclear2016b,
  title = {Interventions in Progressive Supranuclear Palsy},
  author = {Koros, Christos and Stamelou, Maria},
  year = {2016},
  month = jan,
  journal = {Parkinsonism \& Related Disorders},
  volume = {22 Suppl 1},
  pages = {S93-95},
  issn = {1873-5126},
  doi = {10.1016/j.parkreldis.2015.09.033},
  abstract = {Progressive supranuclear palsy (PSP) an atypical parkinsonian with a common phenotype comprising early falls, the characteristic slowing of vertical saccades and a frontal syndrome with marked apathy (Richardson's syndrome). Currently, no effective symptomatic or neuroprotective treatment is available for PSP. Current medical have a limited role in PSP. Novel experimental treatments include davunetide or tideglusib, both inhibitors of glycogen synthase kinase-3 (GSK-3) that failed to improve the clinical outcome of PSP patients in two recent studies. Future interventions aiming at tau dysfunction and passive or active immunization are ongoing or underway.},
  langid = {english},
  pmid = {26459661},
  keywords = {Animals,Brain,Clinical Trials as Topic,Davunetide,Glycogen Synthase Kinase 3,Glycogen synthase kinase-3 inhibitors,Humans,Immunization,Progressive supranuclear palsy,Richardson's syndrome,Supranuclear Palsy Progressive,Thiadiazoles,Tideglusib,Treatment}
}

@article{koss1997assessing,
  title = {Assessing Patterns of Agitation in Alzheimer's Disease Patients with the Cohen-Mansfield Agitation Inventory. {{The}} Alzheimer's Disease Cooperative Study.},
  author = {Koss, Elisabeth and Weiner, Myron and Ernesto, Christopher and {Cohen-Mansfield}, Jiska and Ferris, Steven H and Grundman, Michael and Schafer, Kimberly and Sano, Mary and Thal, Leon J and Thomas, Ronald and others},
  year = {1997},
  journal = {Alzheimer Disease and Associated Disorders},
  volume = {11},
  pages = {S45--50}
}

@article{koudelovaSimulationFacialGrowth2019,
  title = {Simulation of Facial Growth Based on Longitudinal Data: {{Age}} Progression and Age Regression between 7 and 17 Years of Age Using {{3D}} Surface Data},
  shorttitle = {Simulation of Facial Growth Based on Longitudinal Data},
  author = {Koudelov{\'a}, Jana and Hoffmannov{\'a}, Eva and Dupej, J{\'a}n and Velem{\'i}nsk{\'a}, Jana},
  editor = {Sforza, Chiarella},
  year = {2019},
  month = feb,
  journal = {PLOS ONE},
  volume = {14},
  number = {2},
  pages = {e0212618},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0212618},
  urldate = {2023-02-12},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/koudelová et al_2019_simulation of facial growth based on longitudinal data.pdf}
}

@article{koyamaRigidityEulerProducts2021,
  title = {Rigidity of {{Euler Products}}},
  author = {Koyama, Shin-ya and Kurokawa, Nobushige},
  year = {2021},
  month = mar,
  journal = {arXiv:2103.06464 [math]},
  eprint = {2103.06464},
  primaryclass = {math},
  urldate = {2021-03-13},
  abstract = {We report a simple rigidicy theorem for certain Euler products.},
  archiveprefix = {arXiv},
  keywords = {11M06 11M41,Mathematics - Number Theory},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/koyama_kurokawa_2021_rigidity of euler products.pdf;/Users/zenn/Zotero/storage/ECY6Y5EY/2103.html}
}

@article{krajewska2005analysis,
  title = {Analysis of Apoptosis Protein Expression in Early-Stage Colorectal Cancer Suggests Opportunities for New Prognostic Biomarkers},
  author = {Krajewska, Maryla and Kim, Hoguen and Kim, Chul and Kang, Haeyoun and Welsh, Kate and Matsuzawa, Shu-ichi and Tsukamoto, Michelle and Thomas, Ronald G and {Assa-Munt}, Nuria and Piao, Zhe and others},
  year = {2005},
  journal = {Clinical Cancer Research},
  volume = {11},
  number = {15},
  pages = {5451--5461},
  publisher = {American Association for Cancer Research}
}

@article{kronmalEstimationProbabilityDensities1968,
  title = {The {{Estimation}} of {{Probability Densities}} and {{Cumulatives}} by {{Fourier Series Methods}}},
  author = {Kronmal, R. and Tarter, M.},
  year = {1968},
  journal = {Journal of the American Statistical Association},
  volume = {63},
  number = {323},
  eprint = {2283885},
  eprinttype = {jstor},
  pages = {925--952},
  publisher = {[American Statistical Association, Taylor \& Francis, Ltd.]},
  issn = {0162-1459},
  doi = {10.2307/2283885},
  urldate = {2023-03-01},
  abstract = {A class of estimators (referred to as the Fourier estimators {\^f}\textsubscript{m} and {\^F}\textsubscript{m}) of the probability density function f and the associated cumulative distribution function F are considered. Here {\^f}\textsubscript{m} = {$\sum$}\textsubscript{k = 0}\textsuperscript{m} {\^a}\textsubscript{k} {$\psi$}\textsubscript{k} and {\^F}\textsubscript{m} = {$\sum$}\textsuperscript{m}\textsubscript{k = 0} {\^A}\textsubscript{k} {$\psi$}\textsubscript{k} where the functions \{{$\psi\vphantom\}$}\textsubscript{k}\vphantom\{\} comprise an orthogonal set with respect to weight function w(x), and the statistics {\^a}\textsubscript{k} and {\^A}\textsubscript{k} are formed from the n unordered observations. Simple expressions are found for the mean integrated square errors, M.I.S.E., of the estimators {\^f}\textsubscript{m} and {\^F}\textsubscript{m}, i.e., E {$\int$} \{f(x) - {\^f}\vphantom\}\textsubscript{m}(x)\vphantom\{\}\textsuperscript{2w}(x)dx and E{$\int$} \{F(x) - {\^F}\vphantom\}\textsubscript{m}(x)\vphantom\{\}\textsuperscript{2w}(x)dx in terms of the variances of {\^a}\textsubscript{k} and {\^A}\textsubscript{k} and the Fourier coefficients of f and F. For Fourier estimators based upon the trigonometric orthogonal functions the {\^a}\textsubscript{k} are the sample trigonometric moments. The variances and covariances of the statistics {\^a}\textsubscript{k} and {\^A}\textsubscript{k} for these special cases are shown to be linear functions of the density f's Fourier coefficients. Therefore, simple expressions are obtained which relate the M.I.S.E. of the Fourier estimators {\^F}\textsubscript{m} and {\^f}\textsubscript{m} to the Fourier coefficients of the density f. These M.I.S.E. expressions both facilitate the evaluation of error for specific densities and specific truncation points m and make it possible for an optimal value of m to be estimated from the sample. The simplicity of the M.I.S.E. expressions in the trigonometric case does not seem to be paralleled by simple expressions for Var {\^a}\textsubscript{k}, and hence M.I.S.E., for other orthogonal systems, notably those based upon Hermite polynomials. A procedure for choosing the optimal number of terms of {\^F}\textsubscript{m} and {\^f}\textsubscript{m} is derived and the M.I.S.E. of {\^f}\textsubscript{m} is compared to that of several alternative estimators of the population density. It is shown that for almost all cumulatives there exists a finite m such that {\^F}\textsubscript{m} has smaller M.I.S.E. than the sample cumulative, i.e., the step function.},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/kronmal_tarter_1968_the estimation of probability densities and cumulatives by fourier series.pdf}
}

@misc{kudoNeurophysiologicalTrajectoriesAlzheimer2023,
  title = {Neurophysiological Trajectories in {{Alzheimer}}'s Disease Progression},
  author = {Kudo, Kiwamu and Ranasinghe, Kamalini G. and Morise, Hirofumi and Syed, Faatimah and Sekihara, Kensuke and Rankin, Katherine P. and Miller, Bruce L. and Kramer, Joel and Rabinovici, Gil and Vossel, Keith and Kirsch, Heidi E. and Nagarajan, Srikantan},
  year = {2023},
  month = nov,
  primaryclass = {New Results},
  pages = {2023.05.18.541379},
  publisher = {bioRxiv},
  doi = {10.1101/2023.05.18.541379},
  urldate = {2023-11-09},
  abstract = {Alzheimer's disease (AD) is characterized by accumulation of amyloid-{$B$} and misfolded tau proteins causing synaptic dysfunction and progressive neurodegeneration and cognitive decline. Altered neural oscillations have been consistently demonstrated in AD. However, the trajectories of abnormal neural oscillations in AD progression and their relationship to neurodegeneration and cognitive decline are unknown. Here, we deployed robust event-based sequencing models (EBMs) to investigate the trajectories of long-range and local neural synchrony across AD stages, estimated from resting-state magnetoencephalography. Increases in neural synchrony in the delta-theta band and decreases in the alpha and beta bands showed progressive changes along the EBM stages. Decreases in alpha and beta-band synchrony preceded both neurodegeneration and cognitive decline, indicating that frequency-specific neuronal synchrony abnormalities are early manifestations of AD pathophysiology. The long-range synchrony effects were greater than the local synchrony, indicating a greater sensitivity of connectivity metrics involving multiple regions of the brain. These results demonstrate the evolution of functional neuronal deficits along the sequence of AD progression.},
  archiveprefix = {bioRxiv},
  chapter = {New Results},
  copyright = {{\copyright} 2023, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NoDerivs 4.0 International), CC BY-ND 4.0, as described at http://creativecommons.org/licenses/by-nd/4.0/},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/H98IVMXT/Kudo et al. - 2023 - Neurophysiological trajectories in Alzheimer's dis.pdf}
}

@article{kumleEstimatingPowerGeneralized2021,
  title = {Estimating Power in (Generalized) Linear Mixed Models: {{An}} Open Introduction and Tutorial in {{R}}},
  shorttitle = {Estimating Power in (Generalized) Linear Mixed Models},
  author = {Kumle, Levi and V{\~o}, Melissa L.-H. and Draschkow, Dejan},
  year = {2021},
  month = dec,
  journal = {Behavior Research Methods},
  volume = {53},
  number = {6},
  pages = {2528--2543},
  issn = {1554-3528},
  doi = {10.3758/s13428-021-01546-0},
  urldate = {2024-03-11},
  abstract = {Abstract                            Mixed-effects models are a powerful tool for modeling fixed and random effects simultaneously, but do not offer a feasible analytic solution for estimating the probability that a test correctly rejects the null hypothesis. Being able to estimate this probability, however, is critical for sample size planning, as power is closely linked to the reliability and replicability of empirical findings. A flexible and very intuitive alternative to               analytic               power solutions are               simulation-based               power analyses. Although various tools for conducting simulation-based power analyses for mixed-effects models are available, there is lack of guidance on how to appropriately use them. In this tutorial, we discuss how to estimate power for mixed-effects models in different use cases: first, how to use models that were fit on available (e.g. published) data to determine sample size; second, how to determine the number of stimuli required for sufficient power; and finally, how to conduct sample size planning without available data. Our examples cover both linear and generalized linear models and we provide code and resources for performing simulation-based power analyses on openly accessible data sets. The present work therefore helps researchers to navigate sound research design when using mixed-effects models, by summarizing resources, collating available knowledge, providing solutions and tools, and applying them to real-world problems in sample sizing planning when sophisticated analysis procedures like mixed-effects models are outlined as inferential procedures.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/UU7IQHJ6/Kumle et al. - 2021 - Estimating power in (generalized) linear mixed mod.pdf;/Users/zenn/Zotero/storage/DUFG3AKG/s13428-021-01546-0.html}
}

@article{Kunert2008,
  title = {Optimal Crossover Designs for Two Treatments in the Presence of Mixed and Self-Carryover Effects},
  author = {Kunert, J and Stufken, J.},
  year = {2008},
  month = dec,
  journal = {Journal of the American Statistical Association},
  volume = {103},
  number = {484},
  pages = {1641--1647},
  issn = {01621459},
  doi = {10.1198/016214508000000760},
  urldate = {2021-11-06},
  abstract = {The main purpose of this article is to identify optimal crossover designs for two treatments under a model that includes mixed and self carryover effects. In addition, results are reported for optimal two-treatment crossover designs under several closely related models, and the performance of various designs for three and four periods is studied under the different models. {\copyright} 2008 American Statistical Association.},
  keywords = {Design optimality,Direct treatment effect,Interaction model,Traditional model},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/kunert_stufken_2008_optimal crossover designs for two treatments in the presence of mixed and.pdf}
}

@article{kunzBlindedUnblindedEstimation2017,
  title = {Blinded versus Unblinded Estimation of a Correlation Coefficient to Inform Interim Design Adaptations: {{Blinded}} versus Unblinded Interim Correlation Estimation},
  shorttitle = {Blinded versus Unblinded Estimation of a Correlation Coefficient to Inform Interim Design Adaptations},
  author = {Kunz, Cornelia U. and Stallard, Nigel and Parsons, Nicholas and Todd, Susan and Friede, Tim},
  year = {2017},
  month = mar,
  journal = {Biometrical Journal},
  volume = {59},
  number = {2},
  pages = {344--357},
  issn = {03233847},
  doi = {10.1002/bimj.201500233},
  urldate = {2022-10-20},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/kunz et al_2017_blinded versus unblinded estimation of a correlation coefficient to inform.pdf}
}

@article{kunzComparisonMethodsTreatment2015,
  title = {A Comparison of Methods for Treatment Selection in Seamless Phase {{II}}/{{III}} Clinical Trials Incorporating Information on Short-Term Endpoints},
  author = {Kunz, Cornelia Ursula and Friede, Tim and Parsons, Nicholas and Todd, Susan and Stallard, Nigel},
  year = {2015},
  journal = {Journal of Biopharmaceutical Statistics},
  volume = {25},
  number = {1},
  pages = {170--189},
  publisher = {Taylor \& Francis},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/kunz et al_2015_a comparison of methods for treatment selection in seamless phase ii-iii.pdf;/Users/zenn/Zotero/storage/DJXZNNDA/10543406.2013.html}
}

@article{lachinApplicationsWeiLachinMultivariate2014,
  title = {Applications of the {{Wei-Lachin}} Multivariate One-Sided Test for Multiple Outcomes on Possibly Different Scales},
  author = {Lachin, John M.},
  year = {2014},
  journal = {PLoS ONE},
  volume = {9},
  number = {10},
  issn = {19326203},
  doi = {10.1371/journal.pone.0108784},
  abstract = {Many studies aim to assess whether a therapy has a beneficial effect on multiple outcomes simultaneously relative to a control. Often the joint null hypothesis of no difference for the set of outcomes is tested using separate tests with a correction for multiple tests, or using a multivariate T2-like MANOVA or global test. However, a more powerful test in this case is a multivariate one-sided or one-directional test directed at detecting a simultaneous beneficial treatment effect on each outcome, though not necessarily of the same magnitude. The Wei-Lachin test is a simple 1 df test obtained from a simple sum of the component statistics that was originally described in the context of a multivariate rank analysis. Under mild conditions this test provides a maximin efficient test of the null hypothesis of no difference between treatment groups for all outcomes versus the alternative hypothesis that the experimental treatment is better than control for some or all of the component outcomes, and not worse for any. Herein applications are described to a simultaneous test for multiple differences in means, proportions or life-times, and combinations thereof, all on potentially different scales. The evaluation of sample size and power for such analyses is also described. For a test of means of two outcomes with a common unit variance and correlation 0.5, the sample size needed to provide 90\% power for two separate one-sided tests at the 0.025 level is 64\% greater than that needed for the single Wei-Lachin multivariate one-directional test at the 0.05 level. Thus, a Wei-Lachin test with these operating characteristics is 39\% more efficient than two separate tests. Likewise, compared to a T2-like omnibus test on 2 df, the Wei-Lachin test is 32\% more efficient. An example is provided in which the Wei-Lachin test of multiple components has superior power to a test of a composite outcome.},
  pmid = {25329662},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/lachin_2014_applications of the wei-lachin multivariate one-sided test for multiple.pdf}
}

@article{lafitSelectionNumberParticipants2021,
  title = {Selection of the {{Number}} of {{Participants}} in {{Intensive Longitudinal Studies}}: {{A User-Friendly Shiny App}} and {{Tutorial}} for {{Performing Power Analysis}} in {{Multilevel Regression Models That Account}} for {{Temporal Dependencies}}},
  shorttitle = {Selection of the {{Number}} of {{Participants}} in {{Intensive Longitudinal Studies}}},
  author = {Lafit, Ginette and Adolf, Janne K. and Dejonckheere, Egon and {Myin-Germeys}, Inez and Viechtbauer, Wolfgang and Ceulemans, Eva},
  year = {2021},
  month = jan,
  journal = {Advances in Methods and Practices in Psychological Science},
  volume = {4},
  number = {1},
  pages = {251524592097873},
  issn = {2515-2459, 2515-2467},
  doi = {10.1177/2515245920978738},
  urldate = {2024-03-11},
  abstract = {In recent years, the popularity of procedures for collecting intensive longitudinal data, such as the experience-sampling method, has increased greatly. The data collected using such designs allow researchers to study the dynamics of psychological functioning and how these dynamics differ across individuals. To this end, the data are often modeled with multilevel regression models. An important question that arises when researchers design intensive longitudinal studies is how to determine the number of participants needed to test specific hypotheses regarding the parameters of these models with sufficient power. Power calculations for intensive longitudinal studies are challenging because of the hierarchical data structure in which repeated observations are nested within the individuals and because of the serial dependence that is typically present in these data. We therefore present a user-friendly application and step-by-step tutorial for performing simulation-based power analyses for a set of models that are popular in intensive longitudinal research. Because many studies use the same sampling protocol (i.e., a fixed number of at least approximately equidistant observations) within individuals, we assume that this protocol is fixed and focus on the number of participants. All included models explicitly account for the temporal dependencies in the data by assuming serially correlated errors or including autoregressive effects.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/IFRI35XB/Lafit et al. - 2021 - Selection of the Number of Participants in Intensi.pdf}
}

@article{lairdEstimatingRatesChange1990,
  title = {Estimating Rates of Change in Randomized Clinical Trials},
  author = {Laird, Nan M. and {Fong Wang}},
  year = {1990},
  month = dec,
  journal = {Controlled Clinical Trials},
  volume = {11},
  number = {6},
  pages = {405--419},
  issn = {01972456},
  doi = {10.1016/0197-2456(90)90018-W},
  urldate = {2023-04-14},
  abstract = {This article deals with the extension of the pretest-posttest clinical trial to the longitudinal data setting. We assume that a baseline (or pretest) measurement is taken on all individuals, who are then randomized, without regard to baseline values, to a treatment group. Repeated measurements are taken postrandomization at specified times. Our objective is to estimate the average rate of change (or slope) in the experimental groups and the differences in the slopes. Our focus is on the optimal use of the baseline measurements in the analysis. We contrast two different approaches:-a multivariate one that regards the entire vector of responses (including the baseline) as random outcomes and a univariate one that uses each individual's least squares slope as an outcome. Our multivariate approach is essentially a generalization of Stanek's Seemingly Unrelated Regression (SUR) estimator for the pretest-posttest design (Am Stat 42:178-183, 1988). The multivariate approach is natural to apply in this setting, and optimal if the assumed model is correct. However, the most efficient estimator requires assuming that the baseline mean parameters are the same for all experimental groups. Although this assumption is reasonable in the randomized setting, the resulting multivariate estimator uses postrandomization data as a covariate; if the assumed linear model is not correct, this can lead to distortions in the estimated treatment effect. We propose instead a reduced form multivariate estimator that may be somewhat less efficient, but protects against model misspecification.},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/laird_fong wang_1990_estimating rates of change in randomized clinical trials.pdf}
}

@article{lairdlRandomEffectsModelsLongitudinal2023,
  title = {Random-{{Effects Models}} for {{Longitudinal Data}}},
  author = {Lairdl, Nan M and Warel, James H},
  year = {2023},
  abstract = {Models for the analysis of longitudinal data must recogrlize the relationship between serial observations on the same unit. Multivariate models with general covariance structure are often difficult to apply to highly unbalanced data, whereas two-stage random-effects models can be used easily. In two-stage models, the probability distributions for the response vectors of different individuals belong to a single family, but some random-effects parameters vary across individuals, with a distribution specified at the second stage. A general family of models is discussed, which includes both growth models and repeated-measures models as special cases. A unified approach to fitting these models, based on a combination of empirical Bayes and maximum likelihood estimation of model parameters and using the EM algorithm, is discussed. Two examples are taken from a current epidemiological study of the health effects of air pollution.},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/lairdl_warel_2023_random-effects models for longitudinal data.pdf}
}

@article{lanDiscreteSequentialBoundaries1983,
  title = {Discrete Sequential Boundaries for Clinical Trials},
  author = {Lan, {\relax KKG} and DeMets, {\relax DL}},
  year = {1983},
  journal = {Biometrika},
  urldate = {2016-11-02},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/lan_demets_1983_discrete sequential boundaries for clinical trials.pdf}
}

@article{langbaum2020alzheimer,
  title = {The Alzheimer's Prevention Initiative Composite Cognitive Test: A Practical Measure for Tracking Cognitive Decline in Preclinical Alzheimer's Disease},
  author = {Langbaum, Jessica B and Ellison, Noel N and Caputo, Angelika and Thomas, Ronald G and Langlois, Carolyn and Riviere, Marie-Emmanuelle and Graf, Ana and Lopez Lopez, Cristina and Reiman, Eric M and Tariot, Pierre N and others},
  year = {2020},
  journal = {Alzheimer's Research \& Therapy},
  volume = {12},
  number = {1},
  pages = {1--11},
  publisher = {BioMed Central}
}

@article{lange2002decline,
  title = {Decline in Verbal Memory during Preclinical {{Alzheimer}}'s Disease: Examination of the Effect of {{APOE}} Genotype},
  author = {Lange, Kelly L and Bondi, Mark W and Salmon, David P and Galasko, Douglas and Delis, Dean C and Thomas, Ronald G and Thal, Leon J},
  year = {2002},
  journal = {Journal of the International Neuropsychological Society},
  volume = {8},
  number = {7},
  pages = {943--955},
  publisher = {Cambridge University Press}
}

@article{laske2014phase,
  title = {Phase 3 Trials of Solanezumab and Bapineuzumab for {{Alzheimer}}'s Disease},
  author = {Laske, Christoph},
  year = {2014},
  journal = {The New England journal of medicine},
  volume = {370},
  number = {15},
  pages = {1459}
}

@article{lauzonEvaluationStatisticalProperties2020,
  title = {Evaluation of the {{Statistical Properties}} of {{Minimal Sufficient Balance}} as a {{Method}} for {{Controlling Baseline Covariate Imbalance}} for {{Sequential Clinical Trials}} with a {{Binary Endpoint}}},
  author = {Lauzon, Steven Daniel},
  year = {2020},
  urldate = {2023-12-15}
}

@article{lauzonImpactMinimalSufficient2022,
  title = {Impact of Minimal Sufficient Balance, Minimization, and Stratified Permuted Blocks on Bias and Power in the Estimation of Treatment Effect in Sequential Clinical Trials with a Binary Endpoint},
  author = {Lauzon, Steven D and Zhao, Wenle and Nietert, Paul J and Ciolino, Jody D and Hill, Michael D and Ramakrishnan, Viswanathan},
  year = {2022},
  month = jan,
  journal = {Statistical Methods in Medical Research},
  volume = {31},
  number = {1},
  pages = {184--204},
  issn = {0962-2802, 1477-0334},
  doi = {10.1177/09622802211055856},
  urldate = {2023-12-15},
  abstract = {Minimization is among the most common methods for controlling baseline covariate imbalance at the randomization phase of clinical trials. Previous studies have found that minimization does not preserve allocation randomness as well as other methods, such as minimal sufficient balance, making it more vulnerable to allocation predictability and selection bias. Additionally, minimization has been shown in simulation studies to inadequately control serious covariate imbalances when modest biased coin probabilities ({$\leq$}0.65) are used. This current study extends the investigation of randomization methods to the analysis phase, comparing the impact of treatment allocation methods on power and bias in estimating treatment effects on a binary outcome using logistic regression. Power and bias in the estimation of treatment effect was found to be comparable across complete randomization, minimization, and minimal sufficient balance in unadjusted analyses. Further, minimal sufficient balance was found to have the most modest impact on power and the least bias in covariate-adjusted analyses. The minimal sufficient balance method is recommended for use in clinical trials as an alternative to minimization when covariate-adaptive subject randomization takes place.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/9S92ZM4G/Lauzon et al. - 2022 - Impact of minimal sufficient balance, minimization.pdf}
}

@article{lauzonStatisticalPropertiesMinimal2020,
  title = {Statistical Properties of Minimal Sufficient Balance and Minimization as Methods for Controlling Baseline Covariate Imbalance at the Design Stage of Sequential Clinical Trials},
  author = {Lauzon, Steven D. and Ramakrishnan, Viswanathan and Nietert, Paul J. and Ciolino, Jody D. and Hill, Michael D. and Zhao, Wenle},
  year = {2020},
  month = aug,
  journal = {Statistics in Medicine},
  volume = {39},
  number = {19},
  pages = {2506--2517},
  issn = {0277-6715, 1097-0258},
  doi = {10.1002/sim.8552},
  urldate = {2023-12-15},
  abstract = {When the number of baseline covariates whose imbalance needs to be controlled in a sequential randomized controlled trial is large, minimization is the most commonly used method for randomizing treatment assignments. The lack of allocation randomness associated with the minimization method has been the source of controversy, and the need to reduce even minor imbalances inherent in the minimization method has been challenged. The minimal sufficient balance (MSB) method is an alternative to the minimization method. It prevents serious imbalance from a large number of covariates while maintaining a high level of allocation randomness. In this study, the two treatment allocation methods are compared with regards to the effectiveness of balancing covariates across treatment arms and allocation randomness in equal allocation clinical trials. The MSB method proves to be equal or superior in both respects. In addition, type I error rate is preserved in analyses for both balancing methods, when using a binary endpoint.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/VNP594CF/Lauzon et al. - 2020 - Statistical properties of minimal sufficient balan.pdf}
}

@article{lawStochasticallyCurtailedTwo2021,
  title = {A Stochastically Curtailed Two-arm Randomised Phase {{{\textsc{II}}}} Trial Design for Binary Outcomes},
  shorttitle = {A Stochastically Curtailed Two-arm Randomised Phase},
  author = {Law, Martin and Grayling, Michael J. and Mander, Adrian P.},
  year = {2021},
  month = mar,
  journal = {Pharmaceutical Statistics},
  volume = {20},
  number = {2},
  pages = {212--228},
  issn = {1539-1604, 1539-1612},
  doi = {10.1002/pst.2067},
  urldate = {2023-11-15},
  abstract = {Randomised controlled trials are considered the gold standard in trial design. However, phase II oncology trials with a binary outcome are often single-arm. Although a number of reasons exist for choosing a single-arm trial, the primary reason is that single-arm designs require fewer participants than their randomised equivalents. Therefore, the development of novel methodology that makes randomised designs more efficient is of value to the trials community. This article introduces a randomised two-arm binary outcome trial design that includes stochastic curtailment (SC), allowing for the possibility of stopping a trial before the final conclusions are known with certainty. In addition to SC, the proposed design involves the use of a randomised block design, which allows investigators to control the number of interim analyses. This approach is compared with existing designs that also use early stopping, through the use of a loss function comprised of a weighted sum of design characteristics. Comparisons are also made using an example from a real trial. The comparisons show that for many possible loss functions, the proposed design is superior to existing designs. Further, the proposed design may be more practical, by allowing a flexible number of interim analyses. One existing design produces superior design realisations when the anticipated response rate is low. However, when using this design, the probability of rejecting the null hypothesis is sensitive to misspecification of the null response rate. Therefore, when considering randomised designs in phase II, we recommend the proposed approach be preferred over other sequential designs.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/PGLRZV8X/Law et al. - 2021 - A stochastically curtailed two‐arm randomised phas.pdf}
}

@misc{LecanemabEarlyAlzheimer,
  title = {Lecanemab in {{Early Alzheimer}}'s {{Disease}} {\textbar} {{New England Journal}} of {{Medicine}}},
  urldate = {2024-04-15},
  howpublished = {https://www.nejm.org/doi/full/10.1056/NEJMoa2212948},
  file = {/Users/zenn/Zotero/storage/VHWHFWBF/NEJMoa2212948.html}
}

@article{ledwinaTestingHardyWeinbergEquilibrium1980,
  title = {Testing for {{Hardy-Weinberg}} Equilibrium},
  author = {Ledwina, Teresa and Gnot, Stanis{\textbackslash}law},
  year = {1980},
  journal = {Biometrics},
  pages = {161--165},
  publisher = {JSTOR},
  file = {/Users/zenn/Zotero/storage/2NIK36SR/Ledwina and Gnot - 1980 - Testing for Hardy-Weinberg equilibrium.pdf;/Users/zenn/Zotero/storage/EGQE3NNF/2530507.html}
}

@article{lee1990p,
  title = {˙ {{P-59 Conditional}} Power Calculations through Computer Simulation: {{An}} Aid to Data Monitoring},
  author = {Lee, Kelvin K and Thomas, Ronald G},
  year = {1990},
  journal = {Controlled Clinical Trials},
  volume = {11},
  number = {4},
  pages = {302},
  publisher = {Elsevier}
}

@article{leprevostBestPracticesDevelopment2014,
  title = {On Best Practices in the Development of Bioinformatics Software},
  author = {Leprevost, Felipe da Veiga and Barbosa, Valmir C. and Francisco, Eduardo L. and {Perez-Riverol}, Yasset and Carvalho, Paulo C.},
  year = {2014},
  journal = {Frontiers in Genetics},
  volume = {5},
  number = {JUL},
  publisher = {Frontiers Research Foundation},
  issn = {16648021},
  doi = {10.3389/FGENE.2014.00199},
  urldate = {2022-06-09},
  keywords = {Best practices,Bioinformatics,Repository,Source control,Test},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/leprevost et al_2014_on best practices in the development of bioinformatics software.pdf}
}

@article{lerchDistributionOptimizationEvolutionary2020,
  title = {Distribution {{Optimization}}: {{An}} Evolutionary Algorithm to Separate {{Gaussian}} Mixtures},
  shorttitle = {Distribution {{Optimization}}},
  author = {Lerch, Florian and Ultsch, Alfred and L{\"o}tsch, J{\"o}rn},
  year = {2020},
  month = jan,
  journal = {Scientific Reports},
  volume = {10},
  number = {1},
  pages = {648},
  publisher = {Nature Publishing Group},
  issn = {2045-2322},
  doi = {10.1038/s41598-020-57432-w},
  urldate = {2024-03-30},
  abstract = {Finding subgroups in biomedical data is a key task in biomedical research and precision medicine. Already one-dimensional data, such as many different readouts from cell experiments, preclinical or human laboratory experiments or clinical signs, often reveal a more complex distribution than a single mode. Gaussian mixtures play an important role in the multimodal distribution of one-dimensional data. However, although fitting of Gaussian mixture models (GMM) is often aimed at obtaining the separate modes composing the mixture, current technical implementations, often using the Expectation Maximization (EM) algorithm, are not optimized for this task. This occasionally results in poorly separated modes that are unsuitable for determining a distinguishable group structure in the data. Here, we introduce ``Distribution Optimization'' an evolutionary algorithm to GMM fitting that uses an adjustable error function that is based on chi-square statistics and the probability density. The algorithm can be directly targeted at the separation of the modes of the mixture by employing additional criterion for the degree by which single modes overlap. The obtained GMM fits were comparable with those obtained with classical EM based fits, except for data sets where the EM algorithm produced unsatisfactory results with overlapping Gaussian modes. There, the proposed algorithm successfully separated the modes, providing a basis for meaningful group separation while fitting the data satisfactorily. Through its optimization toward mode separation, the evolutionary algorithm proofed particularly suitable basis for group separation in multimodally distributed data, outperforming alternative EM based methods.},
  copyright = {2020 The Author(s)},
  langid = {english},
  keywords = {Data processing,Functional clustering},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/lerch et al_2020_distribution optimization.pdf}
}

@article{leroyDigitalHealthTechnologies2023,
  title = {Digital Health Technologies and {{Alzheimer}}'s Disease Clinical Trials: Might Decentralized Clinical Trials Increase Participation by People with Cognitive Impairment?},
  shorttitle = {Digital Health Technologies and {{Alzheimer}}'s Disease Clinical Trials},
  author = {Leroy, Victoire and Gana, Wassim and A{\"i}doud, Amal and N'kodo, Jacques-Alexis and Balageas, Anna-Chlo{\'e} and Blanc, Pascal and Bomia, Dominique and Debacq, Camille and Foug{\`e}re, Bertrand},
  year = {2023},
  month = apr,
  journal = {Alzheimer's Research \& Therapy},
  volume = {15},
  number = {1},
  pages = {87},
  issn = {1758-9193},
  doi = {10.1186/s13195-023-01227-4},
  urldate = {2023-05-02},
  abstract = {Background{\enspace} Therapeutic trials in Alzheimer's disease (AD) face many obstacles---particularly with regard to screen-ing and recruitment. Discussion{\enspace} Decentralized clinical trials (DCTs) are being developed in other diseases and appear to be of value for overcoming these difficulties. The use of remote visits offers hope of broader recruitment and thus a reduction in inequalities due to age, geography, and ethnicity. Furthermore, it might be easier to involve primary care providers and caregivers in DCTs. However, further studies are needed to determine the feasibility of DCTs in AD. Summary{\enspace} A mixed-model DCT might constitute the first step towards completely remote trials in AD and should be assessed first.},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/leroy et al_2023_digital health technologies and alzheimer’s disease clinical trials.pdf}
}

@article{leveneMatchingProblemArising1949,
  title = {On a {{Matching Problem Arising}} in {{Genetics}}},
  author = {Levene, Howard},
  year = {1949},
  journal = {The Annals of Mathematical Statistics},
  volume = {20},
  number = {1},
  eprint = {2236806},
  eprinttype = {jstor},
  pages = {91--94},
  publisher = {Institute of Mathematical Statistics},
  issn = {0003-4851},
  urldate = {2023-08-11},
  abstract = {A statistic useful for detecting deviations from the Hardy-Weinberg equilibrium in population genetics is discussed. Both exact and asymptotic distributions are given and a special case where there is misclassification is discussed. The distribution obtained also arises from a certain card matching problem.},
  file = {/Users/zenn/Zotero/storage/HQR4HWM2/Levene - 1949 - On a Matching Problem Arising in Genetics.pdf}
}

@misc{LeveragingContainersReproducible,
  title = {Leveraging {{Containers}} for {{Reproducible Psychological Research}}},
  doi = {10.1177/25152459211017853},
  urldate = {2024-02-08},
  howpublished = {https://journals.sagepub.com/doi/epub/10.1177/25152459211017853},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/IKBHVZXZ/Leveraging Containers for Reproducible Psychologic.pdf;/Users/zenn/Zotero/storage/2IAWMZLU/25152459211017853.html}
}

@article{levinHolmSimesHochberg1996,
  title = {On the {{Holm}}, {{Simes}}, and {{Hochberg}} Multiple Test Procedures.},
  author = {Levin, B},
  year = {1996},
  month = may,
  journal = {American Journal of Public Health},
  volume = {86},
  number = {5},
  pages = {628--629},
  issn = {0090-0036, 1541-0048},
  doi = {10.2105/AJPH.86.5.628},
  urldate = {2024-03-12},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/SQGVVTLZ/Levin - 1996 - On the Holm, Simes, and Hochberg multiple test pro.pdf}
}

@article{li1995prospective,
  title = {Prospective Study of Hospitalization for Asthma: A Preliminary Risk Factor Model},
  author = {Li, Dominic and German, Donald and Lulla, Sulochina and Thomas, Ronald G and Wilson, Sandra R},
  year = {1995},
  journal = {American journal of respiratory and critical care medicine},
  volume = {151},
  number = {3\_pt\_1},
  pages = {647--655},
  publisher = {American Lung Association}
}

@article{li1997defective,
  title = {Defective Neurite Extension Is Caused by a Mutation in Amyloid Beta-{{A4}} ({{Abeta}}) Protein Precursor Found in Familial {{Alzheimer}}'s Disease},
  author = {Li, Hai Ling and Roch, Jean-Marc and Sundsmo, Mary and Otero, Deborah and Sisodia, Sangram and Thomas, Ronald and Saitoh, Tsunao},
  year = {1997},
  journal = {Journal of neurobiology},
  volume = {32},
  number = {5},
  pages = {469--480},
  publisher = {John Wiley \& Sons, Inc. New York}
}

@article{liangMultipleObjectiveResponse2013,
  title = {Multiple-objective Response-adaptive Repeated Measurement Designs in Clinical Trials for Binary Responses},
  author = {Liang, Y and Li, Y and Wang, J and in {medicine}, KC Carriere - Statistics and 2014, undefined},
  year = {2013},
  month = feb,
  journal = {Wiley Online Library},
  volume = {33},
  number = {4},
  pages = {607--617},
  doi = {10.1002/sim.5951},
  urldate = {2021-11-06},
  abstract = {A multiple-objective allocation strategy was recently proposed for constructing response-adaptive repeated measurement designs for continuous responses. We extend the allocation strategy to constructing response-adaptive repeated measurement designs for binary responses. The approach with binary responses is quite different from the continuous case, as the information matrix is a function of responses, and it involves nonlinear modeling. To deal with these problems, we first build the design on the basis of success probabilities. Then we illustrate how various models can accommodate carryover effects on the basis of logits of response profiles as well as any correlation structure. Through computer simulations, we find that the allocation strategy developed for continuous responses also works well for binary responses. As expected, design efficiency in terms of mean squared error drops sharply, as more emphasis is placed on increasing treatment benefit than estimation precision. However, we find that it can successfully allocate more patients to better treatment sequences without sacrificing much estimation precision.},
  keywords = {binary outcome,multiple-objective allocation strategy,response-adaptive repeated measurement designs},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/liang et al_2013_multiple‐objective response‐adaptive repeated measurement designs in clinical.pdf}
}

@book{liangResponseadaptiveRepeatedMeasurement2006,
  title = {Response-Adaptive Repeated Measurement Designs for Clinical Trials},
  author = {Liang, Yuanyuan and Carriere, Kimmie Chough},
  year = {2006},
  urldate = {2021-11-06},
  abstract = {In a response-adaptive design (RAD), we review and update the trial on the basis of outcomes in order to achieve a specific goal. Optimal designs for clinical trials are usually constructed under a single objective. In this paper, we develop a new adaptive allocation rule to improve the current strategies of building response adaptive designs to construct multiple-objective designs. The purpose of this new rule is to increase both estimation precision and treatment benefits by assigning more patients to a better treatment. We demonstrate that the designs constructed under the new proposed allocation rule are more efficient than fixed optimal designs in terms of both the mean squared error and improved patient care.},
  keywords = {evaluation function,multiple-objective designs,optimality criteria,response-adaptive design (RAD),self and simple mixed carryover effects model},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/liang_carriere_2006_response-adaptive repeated measurement designs for clinical trials.pdf}
}

@article{liangRoleBaselineMeasurements2010,
  title = {On the Role of Baseline Measurements for Crossover Designs under the Self and Mixed Carryover Effects Model},
  author = {Liang, Y and Biometrics, KC Carriere - and 2010, undefined},
  year = {2010},
  month = mar,
  journal = {Wiley Online Library},
  volume = {66},
  number = {1},
  pages = {140--148},
  doi = {10.1111/j.1541-0420.2009.01229.x},
  urldate = {2021-11-06},
  abstract = {It is well known that optimal designs are strongly model dependent. In this article, we apply the Lagrange multiplier approach to the optimal design problem, using a recently proposed model for carryover effects. Generally, crossover designs are not recommended when carryover effects are present and when the primary goal is to obtain an unbiased estimate of the treatment effect. In some cases, baseline measurements are believed to improve design efficiency. This article examines the impact of baselines on optimal designs using two different assumptions about carryover effects during baseline periods and employing a nontraditional crossover design model. As anticipated, baseline observations improve design efficiency considerably for two-period designs, which use the data in the first period only to obtain unbiased estimates of treatment effects, while the improvement is rather modest for three-or four-period designs. Further, we find little additional benefits for measuring baselines at each treatment period as compared to measuring baselines only in the first period. Although our study of baselines did not change the results on optimal designs that are reported in the literature, the problem of strong model dependency problem is generally recognized. The advantage of using multiperiod designs is rather evident, as we found that extending two-period designs to three-or four-period designs significantly reduced variability in estimating the direct treatment effect contrast.},
  keywords = {Baseline measurements,Lagrange multiplier,Optimal crossover design,Random subject effect,Self and mixed carryover effects model},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/liang et al_2010_on the role of baseline measurements for crossover designs under the self and.pdf}
}

@article{liCholinesteraseInhibitorsRarer2015,
  title = {Cholinesterase Inhibitors for Rarer Dementias Associated with Neurological Conditions},
  author = {Li, Ying and Hai, Shan and Zhou, Yan and Dong, Bi Rong},
  year = {2015},
  month = mar,
  journal = {The Cochrane Database of Systematic Reviews},
  volume = {2015},
  number = {3},
  pages = {CD009444},
  issn = {1469-493X},
  doi = {10.1002/14651858.CD009444.pub3},
  abstract = {BACKGROUND: Rarer dementias include Huntington's disease (HD), cerebral autosomal dominant arteriopathy with subcortical infarcts and leukoencephalopathy (CADASIL), frontotemporal dementia (FTD), dementia in multiple sclerosis (MS) and progressive supranuclear palsy (PSP). Cholinesterase inhibitors, including donepezil, galantamine and rivastigmine, are considered to be the first-line medicines for Alzheimer's disease and some other dementias, such as dementia in Parkinson's disease. Cholinesterase inhibitors are hypothesised to work by inhibiting the enzyme acetylcholinesterase (AChE) which breaks down the neurotransmitter acetylcholine. Cholinesterase inhibitors may also lead to clinical improvement for rarer dementias associated with neurological conditions. OBJECTIVES: To assess the efficacy and safety of cholinesterase inhibitors for cognitive impairment or dementia associated with neurological conditions. SEARCH METHODS: We searched the Cochrane Dementia and Cognitive Improvement Group's Specialised Register, CENTRAL, MEDLINE, EMBASE, PsycINFO, CINAHL, LILACS, several trial registries and grey literature sources in August 2013. SELECTION CRITERIA: We included randomised, double-blind, controlled trials assessing the efficacy of treatment of rarer dementias associated with neurological conditions with currently marketed cholinesterase inhibitors. DATA COLLECTION AND ANALYSIS: Two review authors independently assessed eligibility and quality of trials, and extracted data. We used the standard methodological procedures of the Cochrane Collaboration. MAIN RESULTS: We included eight RCTs involving 567 participants. Six studies used a simple parallel-group design; the other two consisted of an open-label treatment period followed by a randomised phase. All trials were well concealed for allocation and double-blind, however the sample sizes of most trials were small. All trials used placebo as control. We performed meta-analyses for some outcomes in patients with MS. For all other conditions, results are presented narratively.Two trials included patients with HD; one found that cholinesterase inhibitor use in the short-term had no statistically significant impact on the cognitive portion of the Alzheimer Disease Assessment Scale (ADAS-Cog; 1 study, WMD 1.00, 95\% CI -1.66 to 3.66, P = 0.46; low quality evidence), Unified Huntington's Disease Rating Scale (UHDRS) Verbal Fluency Test (1 study, WMD -1.20, 95\% CI -7.97 to 5.57, P = 0.73; low quality evidence), UHDRS Symbol Digit Modalities Test (SDMT; 1 study, WMD 2.70, 95\% CI -0.95 to 6.35, P = 0.15; low quality evidence) and other psychometric tests. The other study found that cholinesterase inhibitor use in the medium-term improved the results of the verbal fluency test (1 study, WMD 6.43, 95\% CI 0.66 to 12.20, P = 0.03; moderate quality evidence) and California Verbal Learning Test - Second Edition (CVLT-II) Recognition Task (1 study, WMD 2.42, 95\% CI 0.17 to 4.67, P = 0.04; moderate quality evidence). There was no statistically significant difference between groups on the SDMT (1 study, WMD -0.31, 95\% CI -7.77 to 7.15, P = 0.94; moderate quality evidence), CVLT-II trials 1-5 (1 study, WMD -2.09, 95\% CI -11.65 to 7.47, P = 0.67; moderate quality evidence), short-delay recall (1 study, WMD 0.35, 95\% CI -2.87 to 3.57, P = 0.83; moderate quality evidence), or long-delay recall (1 study, WMD -0.14, 95\% CI -3.08 to 2.80, P = 0.93; moderate quality evidence), and other psychometric tests.Four trials included patients with MS; one found no differences between the cholinesterase inhibitors (short-term) and placebo groups on the Wechsler Memory Scales general memory score (1 study, WMD 0.90, 95\% CI -0.52 to 2.32, P = 0.22; low quality evidence). The three other trials found that, in the medium-term - cholinesterase inhibitors improved the clinician's impression of cognitive change (2 studies, OR 1.96, 95\% CI 1.06 to 3.62, P = 0.03; high quality evidence). However, the treatment effect on other aspects of cognitive change were unclear, measured by the Selective Reminding Test (3 studies, WMD 1.47, 95\% CI -0.39 to 3.32, P = 0.12; high quality evidence), patient's self-reported impression of memory change (2 studies, OR 1.67, 95\% CI 0.93 to 3.00, P = 0.08; high quality evidence) and cognitive change (1 study, OR 0.95, 95\% CI 0.45 to 1.98, P = 0.89; high quality evidence), clinician's impression of memory change (1 study, OR 1.50, 95\% CI 0.59 to 3.84, P = 0.39; moderate quality evidence), other psychometric tests, and activities of daily living - patient reported impact of multiple sclerosis activities (1 study, WMD -1.18, 95\% CI -3.02 to 0.66, P = 0.21; low quality evidence).One study on patients with CADASIL found a beneficial effect of cholinesterase inhibitors on the Executive interview, and Trail Making Test parts A and B. The impact of cholinesterase inhibitors on the Vascular ADAS-Cog score (1 study, WMD 0.04, 95\% CI -1.57 to 1.65, P = 0.96; high quality evidence), the Clinical Dementia Rating Scale Sum of Boxes (1 study, WMD -0.09, 95\% CI -0.48 to 0.03, P = 0.65; high quality evidence) Disability Assessment for Dementia scale (1 study, WMD 0.58, 95\% CI -2.72 to 3.88, P = 0.73; moderate quality evidence), and other measures was unclearOne study included patients with FTD. This trial consisted of an open-label treatment period followed by a randomised, double-blind, placebo-controlled phase. No data of primary outcomes were reported in this study.In the included studies, the most common side effect was gastrointestinal symptoms. For all conditions, compared to the treatment group, the placebo group experienced significantly less nausea (6 studies, 44/257 vs. 22/246, OR 2.10, 95\% CI 1.22 to 3.62, P = 0.007; high quality evidence), diarrhoea (6 studies, 40/257 vs. 13/246, OR 3.26, 95\% CI 1.72 to 6.19, P = 0.0003; moderate quality evidence) and vomiting (3 studies, 17/192 vs. 3/182, OR 5.76, 95\% CI 1.67 to 19.87, P = 0.006; moderate quality evidence). AUTHORS' CONCLUSIONS: The sample sizes of most included trials were small, and some of the results were extracted from only one study. There were no poolable data for HD, CADASIL and FTD patients and there were no results for patients with PSP. Current evidence shows that the efficacy on cognitive function and activities of daily living of cholinesterase inhibitors in people with HD, CADASIL, MS, PSP or FTD is unclear, although cholinesterase inhibitors are associated with more gastrointestinal side effects compared with placebo.},
  langid = {english},
  pmcid = {PMC10644993},
  pmid = {25734590},
  keywords = {CADASIL,Cholinesterase Inhibitors,Cognition Disorders,Frontotemporal Dementia,Humans,Huntington Disease,Multiple Sclerosis,Nootropic Agents,Randomized Controlled Trials as Topic},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/li et al_2015_cholinesterase inhibitors for rarer dementias associated with neurological.pdf}
}

@article{liepeltTreatmentDementiaParkinsonian2008,
  title = {{[Treatment for dementia in parkinsonian syndromes. Efficacy of cholinesterase inhibitors]}},
  author = {Liepelt, I. and Maetzler, W. and Blaicher, H.-P. and Gasser, T. and Berg, D.},
  year = {2008},
  month = jan,
  journal = {Der Nervenarzt},
  volume = {79},
  number = {1},
  pages = {36--39, 42--46},
  issn = {0028-2804},
  doi = {10.1007/s00115-007-2312-2},
  abstract = {In parkinsonian syndromes dementia frequently occurs in the disease progress. The cholinergic system has been proposed as playing a key role in cognitive disturbances. Therefore the application of cholinesterase inhibitors (ChEI) is also hotly argued for dementia associated with parkinsonian syndromes. This review focuses on the specific symptoms of dementia in Parkinson's disease (PDD), dementia with Lewy bodies (DLB), progressive supranuclear palsy (PSP), and corticobasal degeneration (CBD). The effect of cholinergic treatment on cognition and behaviour is reported and critically discussed. There is evidence that medication with some ChEIs reduces cognitive disturbances and to a lesser extent improves activities of daily living in PDD. Behavioural symptoms also seem to be positively influenced by treatment with ChEIs in both PDD and DLB. The effect of treatment with cholinesterase inhibitors in PSP and CBD warrants more carefully designed studies including sufficient numbers of patients.},
  langid = {german},
  pmid = {17687535},
  keywords = {Cholinesterase Inhibitors,Dementia,Humans,Lewy Body Disease,Parkinsonian Disorders,Randomized Controlled Trials as Topic,Supranuclear Palsy Progressive,Treatment Outcome}
}

@article{liFastPrototypingCloudbased2020,
  title = {Towards Fast Prototyping of Cloud-Based Environmental Decision Support Systems for Environmental Scientists Using {{R Shiny}} and {{Docker}}},
  author = {Li, Yu},
  year = {2020},
  month = oct,
  journal = {Environmental Modelling \& Software},
  volume = {132},
  pages = {104797},
  issn = {1364-8152},
  doi = {10.1016/j.envsoft.2020.104797},
  urldate = {2023-06-22},
  abstract = {Environmental decision support systems (EDSS) have drawn an increasing attention among scientists to tackle with the growing complexity of environmental problems and to support policy makers. Yet, many EDSS reported in literature are case specific, fragmented in development strategies and under-reporting server setup, thus impeding EDSS development and knowledge sharing among the scientific community. In this work we introduce an EDSS development framework mainly based on R language, which is popular among environmental scientists, and Docker related software to lower technical hurdles for deployment in a web-based context. Using two examples, we demonstrate that the framework is able to deliver a unified and cost effective solution for setting up prototypes of modern web-based EDSS without compromising usability. A public repository is created to promote access to more examples from literature, which users can adapt for their own studies.},
  langid = {english},
  keywords = {Crop model,Docker,Free and open-source software (FOSS),Groundwater model,R shiny,Web-based EDSS},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/li_2020_towards fast prototyping of cloud-based environmental decision support systems.pdf;/Users/zenn/Zotero/storage/TTV8L9NB/S1364815220303728.html}
}

@article{liItemResponseTheory2021,
  title = {Item Response Theory Analysis of the {{Clinical Dementia Rating}}},
  author = {Li, Yan and Xiong, Chengjie and Aschenbrenner, Andrew J. and Chang, Chih-Hung and Weiner, Michael W and Nosheny, Rachel L and Mungas, Dan and Bateman, Randall J and Hassenstab, Jason and Moulder, Krista L and Morris, John C},
  year = {2021},
  month = mar,
  journal = {Alzheimer's \& Dementia},
  volume = {17},
  number = {3},
  pages = {534--542},
  issn = {1552-5260, 1552-5279},
  doi = {10.1002/alz.12210},
  urldate = {2024-01-18},
  abstract = {Abstract                            Introduction               The Clinical Dementia Rating (CDR) is widely used in Alzheimer's disease research studies and has well established reliability and validity. To facilitate the development of an online, electronic CDR (eCDR) for more efficient clinical applications, this study aims to produce a shortened version of the CDR, and to develop the statistical model for automatic scoring.                                         Methods               Item response theory (IRT) was used for item evaluation and model development. An automatic scoring algorithm was validated using existing CDR global and domain box scores as the reference standard.                                         Results               Most CDR items discriminate well at mild and very mild levels of cognitive impairment. The bi-factor IRT model fits best and the shortened CDR still demonstrates very high classification accuracy (81\%{$\sim$}92\%).                                         Discussion               The shortened version of the CDR and the automatic scoring algorithm has established a good foundation for developing an eCDR and will ultimately improve the efficiency of cognitive assessment.},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/li et al_2021_item response theory analysis of the clinical dementia rating.pdf}
}

@article{lindblad2001metabolic,
  title = {Metabolic Syndrome and Ischemic Heart Disease in Elderly Men and Women},
  author = {Lindblad, Ulf and Langer, Robert D and Wingard, Deborah L and Thomas, Ronald G and {Barrett-Connor}, Elizabeth L},
  year = {2001},
  journal = {American Journal of Epidemiology},
  volume = {153},
  number = {5},
  pages = {481--489},
  publisher = {Oxford University Press}
}

@article{lineweaver1998practice,
  title = {Practice Effects on the Modified {{Wisconsin}} Card Sorting Test in Normally Aging Adults},
  author = {Lineweaver, {\relax TT} and Bondi, {\relax MW} and Thomas, {\relax RG}},
  year = {1998},
  journal = {Archives of Clinical Neuropsychology},
  volume = {13},
  number = {1},
  pages = {41--41},
  publisher = {Elsevier}
}

@article{lineweaver1999normative,
  title = {A Normative Study of {{Nelson}}'s (1976) Modified Version of the {{Wisconsin Card Sorting Test}} in Healthy Older Adults},
  author = {Lineweaver, Tara T and Bondi, Mark W and Thomas, Ronald G and Salmon, David P},
  year = {1999},
  journal = {The Clinical Neuropsychologist},
  volume = {13},
  number = {3},
  pages = {328--347},
  publisher = {Taylor \& Francis Group}
}

@article{linschotenIncorrectlyAnalysingStratified2022,
  title = {Incorrectly Analysing Stratified and Minimised Trials May Lead to Wrongfully Rejecting Superiority of Interventions},
  author = {van Linschoten, Reinier Cornelis Anthonius and West, Rachel and van Noord, Desir{\'e}e and van Leeuwen, Nikki},
  year = {2022},
  month = may,
  journal = {Gut},
  volume = {71},
  number = {5},
  pages = {1038--1039},
  publisher = {BMJ Publishing Group},
  issn = {0017-5749, 1468-3288},
  doi = {10.1136/gutjnl-2021-324936},
  urldate = {2023-05-06},
  abstract = {It is with great interest that we read the report of Yoshida et al 1 on the effect of second-generation narrow band imaging compared to white light imaging on detecting early gastric cancer in high-risk patients. The trial was expertly designed with a large patient population and, although superiority of narrow band imaging could not be proven, has important implications for further research on this topic. However, a significant issue concerning the analyses attracted our interest and we would like to comment on it. The primary outcome, the difference in proportion of patients in whom early gastric cancer was diagnosed, failed to reach statistical significance (p=0.412). This difference in proportions was tested for significance using Fisher's exact test. This might not have been the proper method for analysis, as patients in the study were randomised using minimisation with a random component, stratified by institution, age and indication of endoscopy. Imbalance of risk factors between treatment and control arms can occur by chance {\dots}},
  chapter = {PostScript},
  copyright = {{\copyright} Author(s) (or their employer(s)) 2022. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.. http://creativecommons.org/licenses/by-nc/4.0/This is an open access article distributed in accordance with the Creative Commons Attribution Non Commercial (CC BY-NC 4.0) license, which permits others to distribute, remix, adapt, build upon this work non-commercially, and license their derivative works on different terms, provided the original work is properly cited, appropriate credit is given, any changes made indicated, and the use is non-commercial. See: http://creativecommons.org/licenses/by-nc/4.0/.},
  langid = {english},
  pmid = {34261753},
  keywords = {biostatistics,clinical trials,statistics},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/linschoten et al_2022_incorrectly analysing stratified and minimised trials may lead to wrongfully.pdf}
}

@article{liPredictedIntervalPlots2009,
  title = {Predicted {{Interval Plots}} ({{PIPS}}): {{A Graphical Tool}} for {{Data Monitoring}} of {{Clinical Trials}}},
  author = {Li, Lingling and Evans, Scott R. and Uno, Hajime and Wei, L.J.},
  year = {2009},
  month = nov,
  journal = {Statistics in Biopharmaceutical Research},
  volume = {1},
  number = {4},
  pages = {348--355},
  publisher = {Informa UK Limited},
  issn = {1946-6315},
  doi = {10.1198/SBR.2009.0041},
  urldate = {2022-01-30},
  abstract = {Group sequential designs are often used in clinical trials to evaluate efficacy and/or futility. Many methods have been developed for different types of endpoints and scenarios. However, few of these methods convey information regarding effect sizes (e.g., treatment differences) and none uses prediction to convey information regarding potential effect size estimates and associated precision, with trial continuation. To address these limitations, Evans et al. (2007) proposed to use prediction and predicted intervals as a flexible and practical tool for quantitative monitoring of clinical trials. In this article, we reaffirm the importance and usefulness of this innovative approach and introduce a graphical summary, predicted interval plots (PIPS), to display the information obtained in the prediction process in a straightforward yet comprehensive manner. We outline the construction of PIPS and apply this method in two examples. The results and the interpretations of the PIPS are discussed.},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/li et al_2009_predicted interval plots (pips).pdf}
}

@article{liTestingHardyWeinberg2009,
  title = {Testing {{Hardy}}--{{Weinberg Equilibrium}} and {{Homogeneity}} of {{Hardy}}--{{Weinberg Disequilibrium}} Using {{Complex Survey Data}}},
  author = {Li, Yan and Graubard, Barry I.},
  year = {2009},
  journal = {Biometrics},
  volume = {65},
  number = {4},
  pages = {1096--1104},
  issn = {1541-0420},
  doi = {10.1111/j.1541-0420.2009.01199.x},
  urldate = {2023-02-09},
  abstract = {For studies on population genetics, the use of representative random samples of the target population can avoid ascertainment bias. Genetic variation data from over a hundred genes were collected in a U.S. nationally representative sample in the Third National Health and Nutrition Examination Survey (NHANES III). Surveys such as the NHANES have complex stratified multistage cluster sample designs with sample weighting that can inflate variances and alter the expectations of test statistics. Thus, classical statistical tests of Hardy--Weinberg equilibrium (HWE) and homogeneity of HW disequilibrium (HHWD) for simple random samples are not suitable for data from complex samples. We propose using Wald tests for HWE and generalized score tests for HHWD that have been modified for complex samples. Monte Carlo simulation studies are used to investigate the finite sample properties of the proposed tests. Rao--Scott corrections applied to the tests were found to improve their type I error properties. Our methods are applied to the NHANES III genetic data for three loci involved in metabolizing lead in the body.},
  langid = {english},
  keywords = {Cluster sampling,Quasigeneralized score tests,Rao-Scott correction,Sample weights,Wald tests},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/li_graubard_2009_testing hardy–weinberg equilibrium and homogeneity of hardy–weinberg.pdf;/Users/zenn/Zotero/storage/6S557BEH/j.1541-0420.2009.01199.html}
}

@article{liTestingTreatmentEffect2021,
  title = {Testing for Treatment Effect in Covariate-Adaptive Randomized Trials with Generalized Linear Models and Omitted Covariates},
  author = {Li, Yang and Ma, Wei and Qin, Yichen and Hu, Feifang},
  year = {2021},
  month = oct,
  journal = {Statistical Methods in Medical Research},
  volume = {30},
  number = {9},
  pages = {2148--2164},
  issn = {0962-2802, 1477-0334},
  doi = {10.1177/09622802211008206},
  urldate = {2023-12-15},
  abstract = {Concerns have been expressed over the validity of statistical inference under covariate-adaptive randomization despite the extensive use in clinical trials. In the literature, the inferential properties under covariate-adaptive randomization have been mainly studied for continuous responses; in particular, it is well known that the usual two-sample t-test for treatment effect is typically conservative. This phenomenon of invalid tests has also been found for generalized linear models without adjusting for the covariates and are sometimes more worrisome due to inflated Type I error. The purpose of this study is to examine the unadjusted test for treatment effect under generalized linear models and covariate-adaptive randomization. For a large class of covariate-adaptive randomization methods, we obtain the asymptotic distribution of the test statistic under the null hypothesis and derive the conditions under which the test is conservative, valid, or anti-conservative. Several commonly used generalized linear models, such as logistic regression and Poisson regression, are discussed in detail. An adjustment method is also proposed to achieve a valid size based on the asymptotic results. Numerical studies confirm the theoretical findings and demonstrate the effectiveness of the proposed adjustment method.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/3LXWWYGF/Li et al. - 2021 - Testing for treatment effect in covariate-adaptive.pdf;/Users/zenn/Zotero/storage/2FQ5F8XD/09622802211008206.html}
}

@article{liTimingBiomarkerChanges2024,
  title = {Timing of {{Biomarker Changes}} in {{Sporadic Alzheimer}}'s {{Disease}} in {{Estimated Years}} from {{Symptom Onset}}},
  author = {Li, Yan and Yen, Daniel and Hendrix, Rachel D. and Gordon, Brian A. and Dlamini, Sibonginkhosi and Barth{\'e}lemy, Nicolas R. and Aschenbrenner, Andrew J. and Henson, Rachel L. and Herries, Elizabeth M. and Volluz, Katherine and Kirmess, Kristopher and Eastwood, Stephanie and Meyer, Matthew and Heller, Maren and Jarrett, Lea and McDade, Eric and Holtzman, David M. and Benzinger, Tammie L.S. and Morris, John C. and Bateman, Randall J. and Xiong, Chengjie and Schindler, Suzanne E.},
  year = {2024},
  month = feb,
  journal = {Annals of Neurology},
  pages = {ana.26891},
  issn = {0364-5134, 1531-8249},
  doi = {10.1002/ana.26891},
  urldate = {2024-03-11},
  abstract = {Objective               A clock relating amyloid positron emission tomography (PET) to time was used to estimate the timing of biomarker changes in sporadic Alzheimer disease (AD).                                         Methods               Research participants were included who underwent cerebrospinal fluid (CSF) collection within 2\,years of amyloid PET. The ages at amyloid onset and AD symptom onset were estimated for each individual. The timing of change for plasma, CSF, imaging, and cognitive measures was calculated by comparing restricted cubic splines of cross-sectional data from the amyloid PET positive and negative groups.                                         Results               The amyloid PET positive sub-cohort (n\,=\,118) had an average age of 70.4\,{\textpm}\,7.4\,years (mean\,{\textpm}\,standard deviation) and 16\% were cognitively impaired. The amyloid PET negative sub-cohort (n\,=\,277) included individuals with low levels of amyloid plaque burden at all scans who were cognitively unimpaired at the time of the scans. Biomarker changes were detected 15--19\,years before estimated symptom onset for CSF A{$\beta$}42/A{$\beta$}40, plasma A{$\beta$}42/A{$\beta$}40, CSF pT217/T217, and amyloid PET; 12--14\,years before estimated symptom onset for plasma pT217/T217, CSF neurogranin, CSF SNAP-25, CSF sTREM2, plasma GFAP, and plasma NfL; and 7--9\,years before estimated symptom onset for CSF pT205/T205, CSF YKL-40, hippocampal volumes, and cognitive measures.                                         Interpretation               The use of an amyloid clock enabled visualization and analysis of biomarker changes as a function of estimated years from symptom onset in sporadic AD. This study demonstrates that estimated years from symptom onset based on an amyloid clock can be used as a continuous staging measure for sporadic AD and aligns with findings in autosomal dominant AD. ANN NEUROL 2024},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/YDH3ESJ7/Annals of Neurology - 2024 - Li - Timing of Biomarker Changes in Sporadic Alzheimer s Disease in Estimated Years from.pdf}
}

@article{littlePreventionTreatmentMissing2012,
  title = {The {{Prevention}} and {{Treatment}} of {{Missing Data}} in {{Clinical Trials}}},
  author = {Little, Roderick J. and D'Agostino, Ralph and Cohen, Michael L. and Dickersin, Kay and Emerson, Scott S. and Farrar, John T. and Frangakis, Constantine and Hogan, Joseph W. and Molenberghs, Geert and Murphy, Susan A. and Neaton, James D. and Rotnitzky, Andrea and Scharfstein, Daniel and Shih, Weichung J. and Siegel, Jay P. and Stern, Hal},
  year = {2012},
  month = oct,
  journal = {New England Journal of Medicine},
  volume = {367},
  number = {14},
  pages = {1355--1360},
  publisher = {Massachusetts Medical Society},
  issn = {0028-4793},
  doi = {10.1056/NEJMsr1203730},
  urldate = {2023-03-02},
  abstract = {Background Missing data have seriously compromised inferences from clinical trials, yet the topic has received little attention in the clinical-trial community.1 Existing regulatory guidances2--4 on the design, conduct, and analysis of clinical trials have little specific advice on how to address the problem of missing data. A recent National Research Council (NRC) report5 on the topic seeks to address this gap, and this article summarizes some of the main findings and recommendations of that report. The authors of this article served on the panel that prepared the report. Missing data have seriously compromised inferences from clinical trials.1 For example, . . .},
  pmid = {23034025},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/little et al_2012_the prevention and treatment of missing data in clinical trials.pdf}
}

@article{liuBayesianAdaptiveTrial2022,
  title = {Bayesian Adaptive Trial Design for a Continuous Biomarker with Possibly Nonlinear or Nonmonotone Prognostic or Predictive Effects},
  author = {Liu, Yusha and Kairalla, John A. and Renfro, Lindsay A.},
  year = {2022},
  journal = {Biometrics},
  volume = {78},
  number = {4},
  pages = {1441--1453},
  issn = {1541-0420},
  doi = {10.1111/biom.13550},
  urldate = {2023-02-09},
  abstract = {As diseases like cancer are increasingly understood on a molecular level, clinical trials are being designed to reveal or validate subpopulations in which an experimental therapy has enhanced benefit. Such biomarker-driven designs, particularly ``adaptive enrichment'' designs that initially enroll an unselected population and then allow for later restriction of accrual to ``marker-positive'' patients based on interim results, are increasingly popular. Many biomarkers of interest are naturally continuous, however, and most existing design approaches either require upfront dichotomization or force monotonicity through algorithmic searches for a single marker threshold, thereby excluding the possibility that the continuous biomarker has a nondisjoint and truly nonlinear or nonmonotone prognostic relationship with outcome or predictive relationship with treatment effect. To address this, we propose a novel trial design that leverages both the actual shapes of any continuous marker effects (both prognostic and predictive) and their corresponding posterior uncertainty in an adaptive decision-making framework. At interim analyses, this marker knowledge is updated and overall or marker-driven decisions are reached such as continuing enrollment to the next interim analysis or terminating early for efficacy or futility. Using simulations and patient-level data from a multi-center Children's Oncology Group trial in Acute Lymphoblastic Leukemia, we derive the operating characteristics of our design and compare its performance to a traditional approach that identifies and applies a dichotomizing marker threshold.},
  langid = {english},
  keywords = {adaptive enrichment,Bayesian adaptive design,biomarker-driven design,continuous biomarkers,precision medicine},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/liu et al_2022_bayesian adaptive trial design for a continuous biomarker with possibly.pdf;/Users/zenn/Zotero/storage/U2ZXM828/biom.html}
}

@article{Ljubenkov2018,
  title = {Cerebrospinal Fluid Biomarkers Predict Frontotemporal Dementia Trajectory},
  author = {Ljubenkov, Peter A. and Staffaroni, Adam M. and Rojas, Julio C. and Allen, Isabel E. and Wang, Ping and Heuer, Hilary and Karydas, Anna and Kornak, John and Cobigo, Yann and Seeley, William W. and Grinberg, Lea T. and Spina, Salvatore and Fagan, Anne M. and Jerome, Gina and Knopman, David and Boeve, Brad F. and Dickerson, Bradford C. and Kramer, Joel and Miller, Bruce and Boxer, Adam L. and Rosen, Howard J.},
  year = {2018},
  month = oct,
  journal = {Annals of Clinical and Translational Neurology},
  volume = {5},
  number = {10},
  pages = {1250--1263},
  publisher = {Wiley-Blackwell},
  issn = {23289503},
  doi = {10.1002/acn3.643},
  urldate = {2021-11-08},
  abstract = {Objective: The prognostic value of cerebrospinal fluid neurofilament light chain, total tau, phosphorylated tau181, and amyloid beta1-42 was examined in frontotemporal dementia subtypes. Methods: We compared baseline biomarkers between 49 controls, 40 patients with behavioral variant frontotemporal dementia, 24 with semantic variant primary progressive aphasia, and 26 with nonfluent variant primary progressive aphasia. Linear mixed effect models were used to assess the value of baseline biomarkers in predicting clinical and radiographic change in patient cohorts over multiple yearly follow up visits. Results: Neurofilament light chain concentrations were lowest in controls. Elevated baseline neurofilament light chain predicted faster worsening in clinical severity, frontotemporal volume and frontotemporal fractional anisotropy in patients with behavioral variant frontotemporal dementia and nonfluent variant primary progressive aphasia. High total tau similarly predicted faster progression in nonfluent variant primary progressive aphasia. In behavioral variant frontotemporal dementia, higher phosphorylated tau181 predicted faster clinical progression whereas lower amyloid beta1-42 predicted faster volumetric and fractional anisotropy reduction. Neurofilament light chain and phosphorylated tau181 were of greater predictive value in patients with tau pathology as compared to TDP-43 pathology. Baseline neurofilament light chain correlated with baseline clinical severity and frontotemporal volume in behavioral variant frontotemporal dementia. Baseline total tau correlated with baseline clinical severity in semantic variant primary progressive aphasia. Interpretation: High cerebrospinal fluid neurofilament light chain predicts more aggressive disease in behavioral variant frontotemporal dementia and nonfluent variant primary progressive aphasia. Total tau, phosphorylated tau181, and amyloid beta1-42 also predict some measures of disease aggressiveness in frontotemporal dementia.},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/ljubenkov et al_2018_cerebrospinal fluid biomarkers predict frontotemporal dementia trajectory.pdf}
}

@article{lloydEXACTVALUESDISCRETE2008,
  title = {{{EXACT}} {{{\emph{P}}}} -{{VALUES FOR DISCRETE MODELS OBTAINED BY ESTIMATION AND MAXIMIZATION}}},
  author = {Lloyd, Chris J.},
  year = {2008},
  month = dec,
  journal = {Australian \& New Zealand Journal of Statistics},
  volume = {50},
  number = {4},
  pages = {329--345},
  issn = {13691473, 1467842X},
  doi = {10.1111/j.1467-842X.2008.00520.x},
  urldate = {2023-02-12},
  abstract = {In constructing exact tests from discrete data, one must deal with the possible dependence of the P-value on nuisance parameter(s) {$\psi$} as well as the discreteness of the sample space. A classical but heavy-handed approach is to maximize over {$\psi$}. We prove what has previously been understood informally, namely that maximization produces the unique and smallest possible P-value subject to the ordering induced by the underlying test statistic and test validity. On the other hand, allowing for the worst case will be more attractive when the Pvalue is less dependent on {$\psi$}. We investigate the extent to which estimating {$\psi$} under the null reduces this dependence. An approach somewhere between full maximization and estimation is partial maximization, with appropriate penalty, as introduced by Berger \& Boos (1994, P values maximized over a confidence set for the nuisance parameter. J. Amer. Statist. Assoc. 89, 1012--1016). It is argued that estimation followed by maximization is an attractive, but computationally more demanding, alternative to partial maximization. We illustrate the ideas on a range of low-dimensional but important examples for which the alternative methods can be investigated completely numerically.},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/lloyd_2008_exact ip-i -values for discrete models obtained by estimation and.pdf}
}

@article{lloydNewExactMore2008,
  title = {A {{New Exact}} and {{More Powerful Unconditional Test}} of {{No Treatment Effect}} from {{Binary Matched Pairs}}},
  author = {Lloyd, Chris J.},
  year = {2008},
  month = sep,
  journal = {Biometrics},
  volume = {64},
  number = {3},
  pages = {716--723},
  issn = {0006-341X, 1541-0420},
  doi = {10.1111/j.1541-0420.2007.00936.x},
  urldate = {2023-02-12},
  abstract = {We consider the problem of testing for a difference in the probability of success from matched binary pairs. Starting with three standard inexact tests, the nuisance parameter is first estimated and then the residual dependence is eliminated by maximization, producing what I call an E+M P-value. The E+M P-value based on McNemar's statistic is shown numerically to dominate previous suggestions, including partially maximized P-values as described in Berger and Sidik (2003, Statistical Methods in Medical Research 12, 91--108). The latter method, however, may have computational advantages for large samples.},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/lloyd_2008_a new exact and more powerful unconditional test of no treatment effect from.pdf}
}

@article{logsdon1999assessment,
  title = {Assessment of Agitation in {{Alzheimer}}'s Disease: The Agitated Behavior in Dementia Scale},
  author = {Logsdon, Rebecca G and Teri, Linda and Weiner, Myron F and Gibbons, Laura E and Raskind, Murray and Peskind, Elaine and Grundman, {\textquestiondown} Michael and Koss, Elisabeth and Thomas, Ronald G and Thai, Leon J and others},
  year = {1999},
  journal = {Journal of the American Geriatrics Society},
  volume = {47},
  number = {11},
  pages = {1354--1358},
  publisher = {Blackwell Publishing Ltd Oxford, UK}
}

@article{logsdon1999brief,
  title = {Brief Methodological Reports-Assessment of Agitation in Alzheimer's Disease: {{The}} Agitated Behavior in Dementia Scale},
  author = {Logsdon, Rebecca G and Teri, Linda and Weiner, Myron F and Gibbons, Laura E and Raskind, Murray and Peskind, Elaine and Grundman, Michael and Koss, Elisabeth and Thomas, Ronald G and Thal, Leon J},
  year = {1999},
  journal = {Journal of the American Geriatrics Society},
  volume = {47},
  number = {11},
  pages = {1354--1358},
  publisher = {Baltimore; New York: Elsevier Science Pub. Co.,[1953]-}
}

@article{lohRegressionTreeApproach2015,
  title = {A Regression Tree Approach to Identifying Subgroups with Differential Treatment Effects},
  author = {Loh, Wei-Yin and He, Xu and Man, Michael},
  year = {2015},
  journal = {Statistics in medicine},
  volume = {34},
  number = {11},
  pages = {1818--1833},
  publisher = {Wiley Online Library},
  file = {/Users/zenn/Zotero/storage/VFXZ7SKH/sim.html}
}

@article{lohRegressionTreeApproach2015a,
  title = {A Regression Tree Approach to Identifying Subgroups with Differential Treatment Effects},
  author = {Loh, Wei-Yin and He, Xu and Man, Michael},
  year = {2015},
  journal = {Statistics in Medicine},
  volume = {34},
  number = {11},
  pages = {1818--1833},
  issn = {1097-0258},
  doi = {10.1002/sim.6454},
  urldate = {2023-08-15},
  abstract = {In the fight against hard-to-treat diseases such as cancer, it is often difficult to discover new treatments that benefit all subjects. For regulatory agency approval, it is more practical to identify subgroups of subjects for whom the treatment has an enhanced effect. Regression trees are natural for this task because they partition the data space. We briefly review existing regression tree algorithms. Then, we introduce three new ones that are practically free of selection bias and are applicable to data from randomized trials with two or more treatments, censored response variables, and missing values in the predictor variables. The algorithms extend the generalized unbiased interaction detection and estimation (GUIDE) approach by using three key ideas: (i) treatment as a linear predictor, (ii) chi-squared tests to detect residual patterns and lack of fit, and (iii) proportional hazards modeling via Poisson regression. Importance scores with thresholds for identifying influential variables are obtained as by-products. A bootstrap technique is used to construct confidence intervals for the treatment effects in each node. The methods are compared using real and simulated data. Copyright {\copyright} 2015 John Wiley \& Sons, Ltd.},
  langid = {english},
  keywords = {bootstrap,missing values,proportional hazards,selection bias},
  file = {/Users/zenn/Zotero/storage/7D5AUVI9/Loh et al. - 2015 - A regression tree approach to identifying subgroup.pdf;/Users/zenn/Zotero/storage/4MCKSN2D/sim.html}
}

@misc{LongitudinalClinicalTrials,
  title = {Longitudinal Clinical Trials with Adaptive Choice of Follow-up Time - {{Jeffries}} - 2015 - {{Biometrics}} - {{Wiley Online Library}}},
  urldate = {2024-04-04},
  howpublished = {https://onlinelibrary.wiley.com/doi/full/10.1111/biom.12287},
  file = {/Users/zenn/Zotero/storage/2P32S943/biom.html}
}

@article{lopez2017alzheimer,
  title = {The Alzheimer's Prevention Initiative Generation Program: Evaluating {{CNP520}} Efficacy in the Prevention of Alzheimer's Disease},
  author = {Lopez, C Lopez and Caputo, A and Liu, F and Riviere, {\relax ME} and {Rouzade-Dominguez}, {\relax ML} and Thomas, {\relax RG} and Langbaum, {\relax JB} and Lenz, R and Reiman, {\relax EM} and Graf, A and others},
  year = {2017},
  journal = {The journal of prevention of Alzheimer's disease},
  volume = {4},
  number = {4},
  pages = {242--6}
}

@article{lopez2019alzheimer,
  title = {The {{Alzheimer}}'s {{Prevention Initiative Generation Program}}: Study Design of Two Randomized Controlled Trials for Individuals at Risk for Clinical Onset of {{Alzheimer}}'s Disease},
  author = {Lopez, Cristina Lopez and Tariot, Pierre N and Caputo, Angelika and Langbaum, Jessica B and Liu, Fonda and Riviere, Marie-Emmanuelle and Langlois, Carolyn and {Rouzade-Dominguez}, Marie-Laure and Zalesak, Martin and Hendrix, Suzanne and others},
  year = {2019},
  journal = {Alzheimer's \& Dementia: Translational Research \& Clinical Interventions},
  volume = {5},
  pages = {216--227},
  publisher = {No longer published by Elsevier}
}

@article{louisExactTestHardyWeinberg1987,
  title = {An {{Exact Test}} for {{Hardy-Weinberg}} and {{Multiple Alleles}}},
  author = {Louis, Edward J. and Dempster, Everett R.},
  year = {1987},
  journal = {Biometrics},
  volume = {43},
  number = {4},
  eprint = {2531534},
  eprinttype = {jstor},
  pages = {805--811},
  publisher = {[Wiley, International Biometric Society]},
  issn = {0006-341X},
  doi = {10.2307/2531534},
  urldate = {2023-08-11},
  abstract = {Algorithms for generating the exact distribution of a finite sample drawn from a population in Hardy-Weinberg equilibrium are given for multiple alleles. The finite sampling distribution is derived analogously to Fisher's 2 X 2 exact distribution and is equivalent to Levene's conditional finite sampling distribution for Hardy-Weinberg populations. The algorithms presented are fast computationally and allow for quick alternatives to standard methods requiring corrections and approximations. Computation time is on the order of a few seconds for three-allele examples and up to 2 minutes for four-allele examples on an IBM 3081 machine.},
  file = {/Users/zenn/Zotero/storage/T6A74E8W/Louis and Dempster - 1987 - An Exact Test for Hardy-Weinberg and Multiple Alle.pdf}
}

@article{loweGreaterPrecisionWhen2012,
  title = {Greater Precision When Measuring Dementia Severity: Establishing Item Parameters for the {{Clinical Dementia Rating Scale}}},
  shorttitle = {Greater Precision When Measuring Dementia Severity},
  author = {Lowe, Deborah A. and Balsis, Steve and Miller, Tyler M. and Benge, Jared F. and Doody, Rachelle S.},
  year = {2012},
  journal = {Dementia and geriatric cognitive disorders},
  volume = {34},
  number = {2},
  pages = {128--134},
  publisher = {S. Karger AG Basel, Switzerland},
  urldate = {2024-01-18},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/lowe et al_2012_greater precision when measuring dementia severity.pdf}
}

@book{lubanovicIntroducingPythonModern2014,
  title = {Introducing {{Python}}: {{Modern Computing}} in {{Simple Packages}}},
  shorttitle = {Introducing {{Python}}},
  author = {Lubanovic, Bill},
  year = {2014},
  month = nov,
  publisher = {"O'Reilly Media, Inc."},
  abstract = {Easy to understand and fun to read, Introducing Python is ideal for beginning programmers as well as those new to the language. Author Bill Lubanovic takes you from the basics to more involved and varied topics, mixing tutorials with cookbook-style code recipes to explain concepts in Python 3. End-of-chapter exercises help you practice what you've learned.You'll gain a strong foundation in the language, including best practices for testing, debugging, code reuse, and other development tips. This book also shows you how to use Python for applications in business, science, and the arts, using various Python tools and open source packages.Learn simple data types, and basic math and text operationsUse data-wrangling techniques with Python's built-in data structuresExplore Python code structure, including the use of functionsWrite large programs in Python, with modules and packagesDive into objects, classes, and other object-oriented featuresExamine storage from flat files to relational databases and NoSQLUse Python to build web clients, servers, APIs, and servicesManage system tasks such as programs, processes, and threadsUnderstand the basics of concurrency and network programming},
  googlebooks = {FRdOBQAAQBAJ},
  isbn = {978-1-4493-6119-8},
  langid = {english},
  keywords = {Computers / Languages / General,Computers / Languages / Python}
}

@article{luSampleSizeEstimation2008,
  title = {Sample {{Size Estimation}} for {{Repeated Measures Analysis}} in {{Randomized Clinical Trials}} with {{Missing Data}}},
  author = {Lu, Kaifeng and Luo, Xiaohui and Chen, Pei-Yun},
  year = {2008},
  month = jan,
  journal = {The International Journal of Biostatistics},
  volume = {4},
  number = {1},
  issn = {1557-4679},
  doi = {10.2202/1557-4679.1098},
  urldate = {2024-05-08},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/lu et al_2008_sample size estimation for repeated measures analysis in randomized clinical.pdf}
}

@article{lydersenPowerComparisonTwosided2003,
  title = {Power Comparison of Two-Sided Exact Tests for Association in 2 {\texttimes} 2 Contingency Tables Using Standard, Mid p and Randomized Test Versions},
  author = {Lydersen, Stian and Laake, Petter},
  year = {2003},
  journal = {Statistics in Medicine},
  volume = {22},
  number = {24},
  pages = {3859--3871},
  issn = {1097-0258},
  doi = {10.1002/sim.1671},
  urldate = {2023-02-05},
  abstract = {Exact Pearson's chi square, likelihood ratio (LR), and Fisher's tests are obtained from the conditional distribution of its test statistic, given therow and column sums of the contingency table. The power and obtained significance level of the standard, mid p, and randomized versions of these tests are compared for two-sided tests in 2 {\texttimes} 2 tables, using binomial and multinomial sampling. The mid p type I error probabilities seldom exceed thenominal significance level. The mid p and randomized test versions have approximately the same power, and higher power than the standard test version. The power of the Pearson's chi square, LR and Fisher's test differ, and they differ in approximately the same way for standard, mid p and randomized test versions for any given set of parameters. There is no general ranking between the three tests. In many cases, Pearson's chi square and Fisher's tests have almost equal power, and higher power than LR. In a few cases, perhaps characterized by poorly balanced designs, LR performs best. Fisher's test seems to be slightly more robust even if the design is poor. Copyright {\copyright} 2003 John Wiley \& Sons, Ltd.},
  langid = {english},
  keywords = {2  2 table,exact tests,mid p-value,p-value,power},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/lydersen_laake_2003_power comparison of two-sided exact tests for association in 2 × 2 contingency.pdf;/Users/zenn/Zotero/storage/9NLU3FQE/sim.html}
}

@article{lydersenRecommendedTestsAssociation2009,
  title = {Recommended Tests for Association in 2{\texttimes}2 Tables},
  author = {Lydersen, Stian and Fagerland, Morten W. and Laake, Petter},
  year = {2009},
  journal = {Statistics in Medicine},
  volume = {28},
  number = {7},
  pages = {1159--1175},
  issn = {1097-0258},
  doi = {10.1002/sim.3531},
  urldate = {2022-11-05},
  abstract = {The asymptotic Pearson's chi-squared test and Fisher's exact test have long been the most used for testing association in 2{\texttimes}2 tables. Unconditional tests preserve the significance level and generally are more powerful than Fisher's exact test for moderate to small samples, but previously were disadvantaged by being computationally demanding. This disadvantage is now moot, as software to facilitate unconditional tests has been available for years. Moreover, Fisher's exact test with mid-p adjustment gives about the same results as an unconditional test. Consequently, several better tests are available, and the choice of a test should depend only on its merits for the application involved. Unconditional tests and the mid-p approach ought to be used more than they now are. The traditional Fisher's exact test should practically never be used. Copyright {\copyright} 2009 John Wiley \& Sons, Ltd.},
  langid = {english},
  keywords = {22 tables,Fisher's exact test,mid-p-value,Pearson's chi-squared test,unconditional tests},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/lydersen et al_2009_recommended tests for association in 2×2 tables.pdf;/Users/zenn/Zotero/storage/KKTQZ77V/sim.html}
}

@article{m.horstPalmerArchipelagoPenguins2022,
  title = {Palmer {{Archipelago Penguins Data}} in the Palmerpenguins {{R Package}} - {{An Alternative}} to {{Anderson}}'s {{Irises}}},
  author = {M. Horst, Allison and Presmanes Hill, Alison and B. Gorman, Kristen},
  year = {2022},
  month = jun,
  journal = {The R Journal},
  volume = {14},
  number = {1},
  pages = {244--254},
  issn = {2073-4859},
  doi = {10.32614/RJ-2022-020},
  urldate = {2023-11-21},
  abstract = {In 1935, Edgar Anderson collected size measurements for 150 flowers from three species of Iris on the Gasp{\'e} Peninsula in Quebec, Canada. Since then, Anderson's Iris observations have become a classic dataset in statistics, machine learning, and data science teaching materials. It is included in the base R datasets package as iris, making it easy for users to access without knowing much about it. However, the lack of data documentation, presence of non-intuitive variables (e.g. ``sepal width''), and perfectly balanced groups with zero missing values make iris an inadequate and stale dataset for teaching and learning modern data science skills. Users would benefit from working with a more representative, real-world environmental dataset with a clear link to current scientific research. Importantly, Anderson's Iris data appeared in a 1936 publication by R. A. Fisher in the Annals of Eugenics (which is often the first-listed citation for the dataset), inextricably linking iris to eugenics research. Thus, a modern alternative to iris is needed. In this paper, we introduce the palmerpenguins R package (Horst et al., 2020), which includes body size measurements collected from 2007 - 2009 for three species of Pygoscelis penguins that breed on islands throughout the Palmer Archipelago, Antarctica. The penguins dataset in palmerpenguins provides an approachable, charismatic, and near drop-in replacement for iris with topical relevance for polar climate change and environmental impacts on marine predators. Since the release on CRAN in July 2020, the palmerpenguins package has been downloaded over 462,000 times, highlighting the demand and widespread adoption of this viable iris alternative. We directly compare the iris and penguins datasets for selected analyses to demonstrate that R users, in particular teachers and learners currently using iris, can switch to the Palmer Archipelago penguins for many use cases including data wrangling, visualization, linear modeling, multivariate analysis (e.g., PCA), cluster analysis and classification (e.g., by k-means).},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/54TG2578/M. Horst et al. - 2022 - Palmer Archipelago Penguins Data in the palmerpeng.pdf}
}

@article{M2013,
  title = {6 Th {{Conference Clinical Trials}} on {{Alzheimer}} ' s {{Disease}}},
  author = {M, Of Anti-tau Antibodies D and Cummings, Disease J L and Clinic, Cleveland and Ruvo, Lou},
  year = {2013},
  volume = {17},
  number = {9},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/m et al_2013_6 th conference clinical trials on alzheimer ’ s disease.pdf}
}

@article{magnussonConsequencesIgnoringTherapist2018,
  title = {The Consequences of Ignoring Therapist Effects in Trials with Longitudinal Data: {{A}} Simulation Study.},
  shorttitle = {The Consequences of Ignoring Therapist Effects in Trials with Longitudinal Data},
  author = {Magnusson, Kristoffer and Andersson, Gerhard and Carlbring, Per},
  year = {2018},
  journal = {Journal of Consulting and Clinical Psychology},
  volume = {86},
  number = {9},
  pages = {711},
  publisher = {American Psychological Association},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/magnusson et al_2018_the consequences of ignoring therapist effects in trials with longitudinal data.pdf;/Users/zenn/Zotero/storage/B7RKREQ6/2018-41322-001.html}
}

@article{mallinckrodtAccountingDropoutBias2001,
  title = {Accounting for Dropout Bias Using Mixed-Effects Models},
  author = {Mallinckrodt, Craig H. and Clark, W. Scott and David, Stacy R.},
  year = {2001},
  journal = {Journal of biopharmaceutical statistics},
  volume = {11},
  number = {1-2},
  pages = {9--21},
  publisher = {Taylor \& Francis},
  file = {/Users/zenn/Zotero/storage/2A6LJKMG/Mallinckrodt et al. - 2001 - Accounting for dropout bias using mixed-effects mo.pdf;/Users/zenn/Zotero/storage/AQUDTB2L/BIP-100104194.html}
}

@article{mallinckrodtAssessingInterpretingTreatment2003,
  title = {Assessing and Interpreting Treatment Effects in Longitudinal Clinical Trials with Missing Data},
  author = {Mallinckrodt, Craig H. and Sanger, Todd M. and Dub{\'e}, Sanjay and DeBrota, David J. and Molenberghs, Geert and Carroll, Raymond J. and Potter, William Z. and Tollefson, Gary D.},
  year = {2003},
  journal = {Biological psychiatry},
  volume = {53},
  number = {8},
  pages = {754--760},
  publisher = {Elsevier},
  file = {/Users/zenn/Zotero/storage/DYB8V97H/S000632230201867X.html}
}

@article{mallinckrodtAssessingInterpretingTreatment2003a,
  title = {Assessing and Interpreting Treatment Effects in Longitudinal Clinical Trials with Missing Data},
  author = {Mallinckrodt, Craig H and Sanger, Todd M and Dub{\'e}, Sanjay and DeBrota, David J and Molenberghs, Geert and Carroll, Raymond J and Potter, William Z and Tollefson, Gary D},
  year = {2003},
  month = apr,
  journal = {Biological Psychiatry},
  volume = {53},
  number = {8},
  pages = {754--760},
  issn = {00063223},
  doi = {10.1016/S0006-3223(02)01867-X},
  urldate = {2023-08-27},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/3F3UKHK3/Mallinckrodt et al. - 2003 - Assessing and interpreting treatment effects in lo.pdf}
}

@article{mallinckrodtAssessingResponseProfiles2003,
  title = {Assessing Response Profiles from Incomplete Longitudinal Clinical Trial Data under Regulatory Considerations},
  author = {Mallinckrodt, Craig H. and Clark, W. Scott and Carroll, Raymond J. and Molenberghs, Geert},
  year = {2003},
  journal = {Journal of biopharmaceutical statistics},
  volume = {13},
  number = {2},
  pages = {179--190},
  publisher = {Taylor \& Francis},
  file = {/Users/zenn/Zotero/storage/53XBDCEL/Mallinckrodt et al. - 2003 - Assessing response profiles from incomplete longit.pdf;/Users/zenn/Zotero/storage/76CA2NA2/BIP-120019265.html}
}

@article{mallinckrodtTypeErrorRates2001,
  title = {Type {{I}} Error Rates from Mixed Effects Model Repeated Measures versus Fixed Effects {{ANOVA}} with Missing Values Imputed via Last Observation Carried Forward},
  author = {Mallinckrodt, Craig H. and Clark, W. Scott and David, Stacy R.},
  year = {2001},
  journal = {Drug Information Journal},
  volume = {35},
  number = {4},
  pages = {1215--1225},
  publisher = {SAGE Publications Sage CA: Los Angeles, CA},
  file = {/Users/zenn/Zotero/storage/X2QGYU67/Mallinckrodt et al. - 2001 - Type I error rates from mixed effects model repeat.pdf;/Users/zenn/Zotero/storage/M36VWWS2/009286150103500418.html}
}

@article{manivAlteredUbiquitinSignaling2023,
  title = {Altered Ubiquitin Signaling Induces {{Alzheimer}}'s Disease-like Hallmarks in a Three-Dimensional Human Neural Cell Culture Model},
  author = {Maniv, Inbal and Sarji, Mahasen and Bdarneh, Anwar and Feldman, Alona and Ankawa, Roi and Koren, Elle and {Magid-Gold}, Inbar and Reis, Noa and Soteriou, Despina and {Salomon-Zimri}, Shiran and Lavy, Tali and Kesselman, Ellina and Koifman, Naama and Kurz, Thimo and Kleifeld, Oded and Michaelson, Daniel and Van Leeuwen, Fred W. and Verheijen, Bert M. and Fuchs, Yaron and Glickman, Michael H.},
  year = {2023},
  month = sep,
  journal = {Nature Communications},
  volume = {14},
  number = {1},
  pages = {5922},
  issn = {2041-1723},
  doi = {10.1038/s41467-023-41545-7},
  urldate = {2023-10-12},
  abstract = {Abstract                            Alzheimer's disease (AD) is characterized by toxic protein accumulation in the brain. Ubiquitination is essential for protein clearance in cells, making altered ubiquitin signaling crucial in AD development. A defective variant, ubiquitin B\,+\,1 (UBB               +1               ), created by a non-hereditary RNA frameshift mutation, is found in all AD patient brains post-mortem. We now detect UBB               +1               in human brains during early AD stages. Our study employs a 3D neural culture platform derived from human neural progenitors, demonstrating that UBB               +1               alone induces extracellular amyloid-{$\beta$} (A{$\beta$}) deposits and insoluble hyperphosphorylated tau aggregates. UBB               +1               competes with ubiquitin for binding to the deubiquitinating enzyme UCHL1, leading to elevated levels of amyloid precursor protein (APP), secreted A{$\beta$} peptides, and A{$\beta$} build-up. Crucially, silencing UBB               +1               expression impedes the emergence of AD hallmarks in this model system. Our findings highlight the significance of ubiquitin signalling as a variable contributing to AD pathology and present a nonclinical platform for testing potential therapeutics.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/R27UFBWL/Maniv et al. - 2023 - Altered ubiquitin signaling induces Alzheimer’s di.pdf}
}

@article{mantelStatisticalAspectsAnalysis1959,
  title = {Statistical {{Aspects}} of the {{Analysis}} of {{Data From Retrospective Studies}} of {{Disease}}},
  author = {Mantel, Nathan and Haenszel, William},
  year = {1959},
  month = apr,
  journal = {JNCI: Journal of the National Cancer Institute},
  volume = {22},
  number = {4},
  pages = {719--748},
  issn = {0027-8874},
  doi = {10.1093/jnci/22.4.719},
  urldate = {2023-08-18},
  abstract = {The role and limitations of retrospective investigations of factors possibly associated with the occurrence of a disease are discussed and their relationship to forward-type studies emphasized. Examples of situations in which misleading associations could arise through the use of inappropriate control groups are presented. The possibility of misleading associations may be minimized by controlling or matching on factors which could produce such associations; the statistical analysis will then be modified. Statistical methodology is presented for analyzing retrospective study data, including chi-square measures of statistical significance of the observed association between the disease and the factor under study, and measures for interpreting the association in terms of an increased relative risk of disease. An extension of the chi-square test to the situation where data are subclassified by factors controlled in the analysis is given. A summary relative risk formula, R, is presented and discussed in connection with the problem of weighting the individual subcategory relative risks according to their importance or their precision. Alternative relative-risk formulas, R1, R2, R3, and R4, which require the calculation of subcategory-adjusted proportions of the study factor among diseased persons and controls for the computation of relative risks, are discussed. While these latter formulas may be useful in many instances, they may be biased or inconsistent and are not, in fact, averages of the relative risks observed in the separate subcategories. Only the relative-risk formula, R, of those presented, can be viewed as such an average. The relationship of the matched-sample method to the sub-classification approach is indicated. The statistical methodology presented is illustrated with examples from a study of women with epidermoid and undifferentiated pulmonary carcinoma.},
  file = {/Users/zenn/Zotero/storage/UJDKUTTH/900746.html}
}

@article{mantelStatisticalAspectsAnalysis1959a,
  title = {Statistical {{Aspects}} of the {{Analysis}} of {{Data From Retrospective Studies}} of {{Disease}}},
  author = {Mantel, Nathan and Haenszel, William},
  year = {1959},
  volume = {22},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/SFEIUCAZ/Mantel and Haenszel - 1959 - Statistical Aspects of the Analysis of Data From R.pdf}
}

@article{marchAlgorithm434Exact1972,
  title = {Algorithm 434: Exact Probabilities for {{R}}{\textbackslash}times {{C}} Contingency Tables [{{G2}}]},
  shorttitle = {Algorithm 434},
  author = {March, David L.},
  year = {1972},
  journal = {Communications of the ACM},
  volume = {15},
  number = {11},
  pages = {991--992},
  publisher = {ACM New York, NY, USA}
}

@article{Marder2005,
  title = {Vitamin {{E}} and Donepezil for the Treatment of Mild Cognitive Impairment.},
  author = {Marder, Karen},
  year = {2005},
  journal = {Current neurology and neuroscience reports},
  volume = {5},
  number = {5},
  pages = {337--338},
  issn = {15284042},
  doi = {10.1007/s11910-005-0056-6},
  urldate = {2021-05-18},
  pmid = {16131415},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/marder_2005_vitamin e and donepezil for the treatment of mild cognitive impairment.pdf}
}

@article{marianiArePSPPatients2019,
  title = {Are {{PSP}} Patients Included in Clinical Trials Representative of the General {{PSP}} Population?},
  author = {Mariani, Louise-Laure and {Guimar{\~a}es-Costa}, Raquel and Grabli, David and Le Toullec, Benjamin and {Cormier-Dequaire}, Florence and Degos, Bertrand and Dubois, Bruno and Vidailhet, Marie and Lacomblez, Lucette and Corvol, Jean-Christophe},
  year = {2019},
  month = sep,
  journal = {Parkinsonism \& Related Disorders},
  volume = {66},
  pages = {202--206},
  issn = {1873-5126},
  doi = {10.1016/j.parkreldis.2019.07.012},
  abstract = {BACKGROUND: Progressive supranuclear palsy (PSP) is a rare parkinsonian syndrome with a wide spectrum of clinical presentations. Recently, the MDS published revised diagnosis criteria to provide early and reliable diagnosis of PSP and its variants. Two large randomized clinical trials were initiated in 2017, but the question remains regarding the extrapolation of their results to the general PSP population. OBJECTIVE: To determine if PSP patients included in clinical trials are representative of the general PSP population. METHODS: We conducted a single center retrospective study of PSP patients referred to a tertiary department of Neurology (Piti{\'e}-Salp{\^e}tri{\`e}re Hospital, Paris) for clinical diagnosis and clinical trial inclusion, over a 12-month period. We collected and analyzed gender, age at examination, age at disease onset, disease duration, and core clinical features regarding oculo-motor dysfunction, postural instability, akinesia and cognitive dysfunction, and inclusion/exclusion criteria of clinical trials to assess eligibility for inclusion. We assessed the relative proportions of different PSP subtypes, as defined by the MDS-PSP criteria, in the whole population compared to patients eligible in trials. RESULTS: 206 PSP patients were included, among which 175 (85\%) were diagnosed with probable PSP-Richardson's syndrome (RS) subtype, with a mean age of 73 and mean disease duration of 5 years. Among those patients, 29 (21\%) were eligible (age 71\,{\textpm}\,10.7, disease duration 3.1\,{\textpm}\,1.2 years) and 19 were included in trials, all with a diagnosis of probable PSP-RS. As compared to the whole population, patients included in clinical trials tended to be younger, and showed more PSP-RS subtypes (p\,{$<$}\,0.05). CONCLUSION: The PSP population included in trials is very similar to the general PSP population, but younger, with shorter disease duration. By definition, only probable PSP subtypes are included in clinical trials. The time window for inclusion is short because of diagnosis delay, fast disease progression and old age of the population.},
  langid = {english},
  pmid = {31303434},
  keywords = {Aged,Atypical parkinsonisms,Clinical trials,Clinical Trials as Topic,Female,Humans,Male,Middle Aged,Patient Selection,Progressive supranuclear palsy,Retrospective Studies,Supranuclear Palsy Progressive},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/mariani et al_2019_are psp patients included in clinical trials representative of the general psp.pdf}
}

@incollection{martinandresFisherExactBarnard2004,
  title = {Fisher's {{Exact}} and {{Barnard}}'s {{Tests}}},
  booktitle = {Encyclopedia of {{Statistical Sciences}}},
  author = {Mart{\'i}n Andr{\'e}s, Antonio},
  year = {2004},
  publisher = {John Wiley \& Sons, Ltd},
  doi = {10.1002/0471667196.ess0642},
  urldate = {2023-07-30},
  copyright = {Copyright {\copyright} 2004 by John Wiley \& Sons, Inc. All rights reserved.},
  isbn = {978-0-471-66719-3},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/9I4KD3UN/0471667196.html}
}

@incollection{martinandresFisherExactBarnard2006,
  title = {Fisher's {{Exact}} and {{Barnard}}'s {{Tests}}},
  booktitle = {Encyclopedia of {{Statistical Sciences}}},
  author = {Mart{\i}n Andr{\'e}s, Antonio},
  year = {2006},
  publisher = {John Wiley \& Sons, Ltd},
  doi = {10.1002/0471667196.ess0642.pub2},
  urldate = {2023-07-30},
  copyright = {Copyright {\copyright} 2006 by John Wiley \& Sons, Inc. All rights reserved.},
  isbn = {978-0-471-66719-3},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/RN8BLRVQ/0471667196.ess0642.html}
}

@article{martinEffectMatchingPower1993,
  title = {The Effect of Matching on the Power of Randomized Community Intervention Studies},
  author = {Martin, Donald C. and Diehr, Paula and Perrin, Edward B. and Koepsell, Thomas D.},
  year = {1993},
  journal = {Statistics in Medicine},
  volume = {12},
  number = {3-4},
  pages = {329--338},
  issn = {1097-0258},
  doi = {10.1002/sim.4780120315},
  urldate = {2023-12-15},
  abstract = {Currently, there is considerable interest in studies that use the community as the experimental unit. Health promotion programmes are one example. Because such activities are expensive, the number of experimental units (communities) is usually very small. Investigators often match communities on demographic variables in order to improve the power of their studies. Matching is known to improve power in certain circumstances. However, we show here that if the number of communities is small, the matched design will probably have less power than the unmatched design. This is due primarily to the loss of degrees of freedom in the matched design, which outweighs the benefits of matching on any but the strongest correlates of changes in behaviour. In the community intervention situation, even small differences in sample size between the matched and unmatched analyses can have expensive consequences.},
  copyright = {Copyright {\copyright} 1993 John Wiley \& Sons, Ltd.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/BT5FGVDF/Martin et al. - 1993 - The effect of matching on the power of randomized .pdf;/Users/zenn/Zotero/storage/X2JVZTT8/sim.html}
}

@article{martinMeasuringIndividualDifferences2011,
  title = {Measuring Individual Differences in Reaction Norms in Field and Experimental Studies: A Power Analysis of Random Regression Models},
  shorttitle = {Measuring Individual Differences in Reaction Norms in Field and Experimental Studies},
  author = {Martin, Julien G. A. and Nussey, Daniel H. and Wilson, Alastair J. and R{\'e}ale, Denis},
  year = {2011},
  journal = {Methods in Ecology and Evolution},
  volume = {2},
  number = {4},
  pages = {362--374},
  issn = {2041-210X},
  doi = {10.1111/j.2041-210X.2010.00084.x},
  urldate = {2022-11-16},
  abstract = {1. Interest in measuring individual variation in reaction norms using mixed-effects and, more specifically, random regression models have grown apace in the last few years within evolution and ecology. However, these are data hungry methods, and little effort to date has been put into understanding how much and what kind of data we need to collect in order to apply these models usefully and reliably. 2. We conducted simulations to address three central questions. First, what is the best sampling strategy to collect sufficient data to test for individual variation using random regression models? Second, on occasions when precision is difficult to assess, can we be confident that a failure to detect significant variance in plasticity using random regression represents a biological reality rather than a lack of statistical power? Finally, does the common practice of censoring individuals with one or few repeated measures improve or reduce power to estimate individual variation in random regressions? 3. We have also developed a series of easy-to-use functions in the `pamm' statistical package for R, which is freely available, that will allow researchers to conduct similar power analyses tailored more specifically to their own data. 4. Our results reveal potentially useful rules of thumb: large data sets (N {$>$} 200) are needed to evaluate the variance of individual-specific slopes; a number of individuals/number of observations per individual ratio of approximately 0{$\cdot$}5 consistently yielded the highest power to detect random effects; individuals with one or few observations should not generally be censored as this reduces power to detect variance in plasticity. 5. We discuss the wider implications of these simulations and remaining challenges and suggest a new way to standardize results that would better facilitate the comparison of findings across empirical studies.},
  langid = {english},
  keywords = {individual variation,mixed-effects model,phenotypic plasticity,random regression,reaction norms},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/martin et al_2011_measuring individual differences in reaction norms in field and experimental.pdf;/Users/zenn/Zotero/storage/TCA5GEQ8/j.2041-210X.2010.00084.html}
}

@article{martinMeasuringIndividualDifferences2011a,
  title = {Measuring Individual Differences in Reaction Norms in Field and Experimental Studies: A Power Analysis of Random Regression Models},
  shorttitle = {Measuring Individual Differences in Reaction Norms in Field and Experimental Studies},
  author = {Martin, Julien G. A. and Nussey, Daniel H. and Wilson, Alastair J. and R{\'e}ale, Denis},
  year = {2011},
  month = aug,
  journal = {Methods in Ecology and Evolution},
  volume = {2},
  number = {4},
  pages = {362--374},
  issn = {2041-210X, 2041-210X},
  doi = {10.1111/j.2041-210X.2010.00084.x},
  urldate = {2024-03-11},
  abstract = {Summary                            1.               Interest in measuring individual variation in reaction norms using mixed-effects and, more specifically, random regression models have grown apace in the last few years within evolution and ecology. However, these are data hungry methods, and little effort to date has been put into understanding how much and what kind of data we need to collect in order to apply these models usefully and reliably.                                         2.               We conducted simulations to address three central questions. First, what is the best sampling strategy to collect sufficient data to test for individual variation using random regression models? Second, on occasions when precision is difficult to assess, can we be confident that a failure to detect significant variance in plasticity using random regression represents a biological reality rather than a lack of statistical power? Finally, does the common practice of censoring individuals with one or few repeated measures improve or reduce power to estimate individual variation in random regressions?                                         3.               We have also developed a series of easy-to-use functions in the `pamm' statistical package for R, which is freely available, that will allow researchers to conduct similar power analyses tailored more specifically to their own data.                                         4.               Our results reveal potentially useful rules of thumb: large data sets (               N               {$\quad>\quad$}200) are needed to evaluate the variance of individual-specific slopes; a number of individuals/number of observations per individual ratio of approximately 0{$\cdot$}5 consistently yielded the highest power to detect random effects; individuals with one or few observations should not generally be censored as this reduces power to detect variance in plasticity.                                         5.               We discuss the wider implications of these simulations and remaining challenges and suggest a new way to standardize results that would better facilitate the comparison of findings across empirical studies.},
  langid = {english}
}

@article{martinMeasuringIndividualDifferences2011b,
  title = {Measuring Individual Differences in Reaction Norms in Field and Experimental Studies: A Power Analysis of Random Regression Models},
  shorttitle = {Measuring Individual Differences in Reaction Norms in Field and Experimental Studies},
  author = {Martin, Julien G. A. and Nussey, Daniel H. and Wilson, Alastair J. and R{\'e}ale, Denis},
  year = {2011},
  month = aug,
  journal = {Methods in Ecology and Evolution},
  volume = {2},
  number = {4},
  pages = {362--374},
  issn = {2041-210X, 2041-210X},
  doi = {10.1111/j.2041-210X.2010.00084.x},
  urldate = {2024-03-11},
  abstract = {Summary                            1.               Interest in measuring individual variation in reaction norms using mixed-effects and, more specifically, random regression models have grown apace in the last few years within evolution and ecology. However, these are data hungry methods, and little effort to date has been put into understanding how much and what kind of data we need to collect in order to apply these models usefully and reliably.                                         2.               We conducted simulations to address three central questions. First, what is the best sampling strategy to collect sufficient data to test for individual variation using random regression models? Second, on occasions when precision is difficult to assess, can we be confident that a failure to detect significant variance in plasticity using random regression represents a biological reality rather than a lack of statistical power? Finally, does the common practice of censoring individuals with one or few repeated measures improve or reduce power to estimate individual variation in random regressions?                                         3.               We have also developed a series of easy-to-use functions in the `pamm' statistical package for R, which is freely available, that will allow researchers to conduct similar power analyses tailored more specifically to their own data.                                         4.               Our results reveal potentially useful rules of thumb: large data sets (               N               {$\quad>\quad$}200) are needed to evaluate the variance of individual-specific slopes; a number of individuals/number of observations per individual ratio of approximately 0{$\cdot$}5 consistently yielded the highest power to detect random effects; individuals with one or few observations should not generally be censored as this reduces power to detect variance in plasticity.                                         5.               We discuss the wider implications of these simulations and remaining challenges and suggest a new way to standardize results that would better facilitate the comparison of findings across empirical studies.},
  langid = {english}
}

@article{martinMeasuringIndividualDifferences2011c,
  title = {Measuring Individual Differences in Reaction Norms in Field and Experimental Studies: A Power Analysis of Random Regression Models},
  shorttitle = {Measuring Individual Differences in Reaction Norms in Field and Experimental Studies},
  author = {Martin, Julien G. A. and Nussey, Daniel H. and Wilson, Alastair J. and R{\'e}ale, Denis},
  year = {2011},
  journal = {Methods in Ecology and Evolution},
  volume = {2},
  number = {4},
  pages = {362--374},
  issn = {2041-210X},
  doi = {10.1111/j.2041-210X.2010.00084.x},
  urldate = {2024-03-11},
  abstract = {1. Interest in measuring individual variation in reaction norms using mixed-effects and, more specifically, random regression models have grown apace in the last few years within evolution and ecology. However, these are data hungry methods, and little effort to date has been put into understanding how much and what kind of data we need to collect in order to apply these models usefully and reliably. 2. We conducted simulations to address three central questions. First, what is the best sampling strategy to collect sufficient data to test for individual variation using random regression models? Second, on occasions when precision is difficult to assess, can we be confident that a failure to detect significant variance in plasticity using random regression represents a biological reality rather than a lack of statistical power? Finally, does the common practice of censoring individuals with one or few repeated measures improve or reduce power to estimate individual variation in random regressions? 3. We have also developed a series of easy-to-use functions in the `pamm' statistical package for R, which is freely available, that will allow researchers to conduct similar power analyses tailored more specifically to their own data. 4. Our results reveal potentially useful rules of thumb: large data sets (N {$>$} 200) are needed to evaluate the variance of individual-specific slopes; a number of individuals/number of observations per individual ratio of approximately 0{$\cdot$}5 consistently yielded the highest power to detect random effects; individuals with one or few observations should not generally be censored as this reduces power to detect variance in plasticity. 5. We discuss the wider implications of these simulations and remaining challenges and suggest a new way to standardize results that would better facilitate the comparison of findings across empirical studies.},
  copyright = {{\copyright} 2010 The Authors. Methods in Ecology and Evolution {\copyright} 2010 British Ecological Society},
  langid = {english},
  keywords = {individual variation,mixed-effects model,phenotypic plasticity,random regression,reaction norms},
  file = {/Users/zenn/Zotero/storage/CH9HBVY4/Martin et al. - 2011 - Measuring individual differences in reaction norms.pdf;/Users/zenn/Zotero/storage/NETC2TQ8/j.2041-210X.2010.00084.html}
}

@article{martinMinimisationDesignParallel2023,
  title = {Minimisation for the Design of Parallel Cluster-Randomised Trials: {{An}} Evaluation of Balance in Cluster-Level Covariates and Numbers of Clusters Allocated to Each Arm},
  shorttitle = {Minimisation for the Design of Parallel Cluster-Randomised Trials},
  author = {Martin, James and Middleton, Lee and Hemming, Karla},
  year = {2023},
  month = apr,
  journal = {Clinical Trials},
  volume = {20},
  number = {2},
  pages = {111--120},
  issn = {1740-7745, 1740-7753},
  doi = {10.1177/17407745221149104},
  urldate = {2024-02-02},
  abstract = {Background:               Cluster-randomised trials often use some form of restricted randomisation, such as stratified- or covariate-constrained randomisation. Minimisation has the potential to balance on more covariates than blocked stratification and can be implemented sequentially unlike covariate-constrained randomisation. Yet, unlike stratification, minimisation has no inbuilt guard to maintain close to a 1:1 allocation. A departure from a 1:1 allocation can be unappealing in a setting with a small number of allocation units such as cluster randomisation which typically include about 30 clusters.                                         Methods:               Using simulation (10,000 per scenario), we evaluate the performance of a range of minimisation procedures on the likelihood of a 1:1 allocation of clusters (10--80 clusters) to treatment arms, along with its performance on covariate imbalance. The range of minimisation procedures includes varying: the proportion of clusters allocated to the least imbalanced arm (known as the stochastic element) -- between 0.7 and 1, percentage of first clusters allocated completely at random (known as the bed-in period) -- between 0\% and 20\% and adding `number of clusters allocated to each arm' as a covariate in the minimisation algorithm. We additionally include a comparison of stratifying and then minimising within key strata (such as country within a multi country cluster trial) as a potential aid to increasing balance.                                         Results:               Minimisation is unlikely to result in an exact 1:1 allocation unless the stochastic element is set higher than 0.9. For example, with 20 clusters, 2 binary covariates and setting the stochastic element to 0.7: only 41\% of the possible randomisations over the 10,000 simulations achieved a 1:1 allocation. While typical sizes of imbalance were small (a difference of two clusters per arm), allocations as extreme as of 10:10 were observed. Adding the `number of clusters' into the minimisation algorithm reduces this risk slightly, but covariate imbalance increases slightly. Stratifying and then minimising within key strata improve balance within strata but increase imbalance across all clusters, both on the number of clusters and covariate imbalance.                                         Conclusion:               In cluster trials, where there are typically about 30 allocation units, when using minimisation, unless the stochastic element is set very high, there is a high risk of not achieving a 1:1 allocation, and a small but nonetheless real risk of an extreme departure from a 1:1 allocation. Stratification with minimisation within key strata (such as country) improves the balance within strata although compromises overall balance.},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/martin et al_2023_minimisation for the design of parallel cluster-randomised trials.pdf}
}

@mastersthesis{masters,
  title = {Application of Fourier Density Estimation Methods to the Mixtures of Normals Problem},
  author = {Thomas, Ronald G},
  year = {1982},
  school = {The University of Washington}
}

@article{matthews2020effects,
  title = {The Effects of Rasagiline on Cerebral Glucose Metabolism, Cognition, and Tau in a Double-Blind, Placebo-Controlled {{Phase II}} Clinical Trial in {{Alzheimer}}'s Dementia},
  author = {Matthews, Dawn C and Ritter, Aaron and Thomas, Ronald G and Andrews, Randolph D and Lukic, Ana S and Revta, Carolyn and Kinney, Jefferson and Tousi, Babak and Leverenz, James B and Fillit, Howard and others},
  year = {2020}
}

@article{matthews2020effects,
  title = {The Effects of Rasagiline on Glucose Metabolism and Cognition and Their Relationship to Tau Burden in a Double-Blind, Placebo-Controlled Phase Ii Clinical Trial of Participants with Alzheimer's Dementia},
  author = {Matthews, Dawn and Ritter, Aaron and Thomas, Ronald G and Andrews, Randolph D and Lukic, Ana S and Revta, Carolyn and Tousi, Babak and Leverenz, James B and Fillit, Howard and Zhong, Kate and others},
  year = {2020},
  journal = {Placebo-Controlled Phase Ii Clinical Trial of Participants with Alzheimer's Dementia (2/21/2020)}
}

@article{matthews2021rasagiline,
  title = {Rasagiline Effects on Glucose Metabolism, Cognition, and Tau in {{Alzheimer}}'s Dementia},
  author = {Matthews, Dawn C and Ritter, Aaron and Thomas, Ronald G and Andrews, Randolph D and Lukic, Ana S and Revta, Carolyn and Kinney, Jefferson W and Tousi, Babak and Leverenz, James B and Fillit, Howard and others},
  year = {2021},
  journal = {Alzheimer's \& Dementia: Translational Research \& Clinical Interventions},
  volume = {7},
  number = {1},
  pages = {e12106}
}

@article{mattsson-carlgrenSolublePtau217Reflects2021,
  title = {Soluble {{P-tau217}} Reflects Amyloid and Tau Pathology and Mediates the Association of Amyloid with Tau},
  author = {{Mattsson-Carlgren}, Niklas and Janelidze, Shorena and Bateman, Randall J and Smith, Ruben and Stomrud, Erik and Serrano, Geidy E and Reiman, Eric M and Palmqvist, Sebastian and Dage, Jeffrey L and Beach, Thomas G and Hansson, Oskar},
  year = {2021},
  month = jun,
  journal = {EMBO Molecular Medicine},
  volume = {13},
  number = {6},
  pages = {e14022},
  publisher = {John Wiley \& Sons, Ltd},
  issn = {1757-4676},
  doi = {10.15252/emmm.202114022},
  urldate = {2023-03-22},
  abstract = {Abstract Alzheimer?s disease is characterized by ?-amyloid plaques and tau tangles. Plasma levels of phospho-tau217 (P-tau217) accurately differentiate Alzheimer?s disease dementia from other dementias, but it is unclear to what degree this reflects ?-amyloid plaque accumulation, tau tangle accumulation, or both. In a cohort with post-mortem neuropathological data (N~=~88), both plaque and tangle density contributed independently to higher P-tau217, but P-tau217 was not elevated in patients with non-Alzheimer?s disease tauopathies (N~=~9). Several findings were replicated in a cohort with PET imaging (?BioFINDER-2?, N~=~426), where ?-amyloid and tau PET were independently associated with P-tau217. P-tau217 concentrations correlated with ?-amyloid PET (but not tau PET) in early disease stages and with both ?-amyloid and (more strongly) tau PET in late disease stages. Finally, P-tau217 mediated the association between ?-amyloid and tau in both cohorts, especially for tau outside of the medial temporal lobe. These findings support the hypothesis that plasma P-tau217 concentration is increased by both ?-amyloid plaques and tau tangles and is congruent with the hypothesis that P-tau is involved in ?-amyloid-dependent formation of neocortical tau tangles.},
  keywords = {Alzheimer's disease,amyloid,phosphorylated tau,plasma,tau},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/mattsson-carlgren et al_2021_soluble p-tau217 reflects amyloid and tau pathology and mediates the.pdf}
}

@article{maturoSupervisedClassificationCurves2022,
  title = {Supervised Classification of Curves via a Combined Use of Functional Data Analysis and Tree-Based Methods},
  author = {Maturo, Fabrizio and Verde, Rosanna},
  year = {2022},
  month = may,
  journal = {Computational Statistics},
  issn = {1613-9658},
  doi = {10.1007/s00180-022-01236-1},
  urldate = {2023-01-29},
  abstract = {Technological advancement led to the development of tools to collect vast amounts of data usually recorded at temporal stamps or arriving over time, e.g. data from sensors. Common ways of analysing this kind of data also involve supervised classification techniques; however, despite constant improvements in the literature, learning from high-dimensional data is always a challenging task due to many issues such as, for example, dealing with the curse of dimensionality and looking for a trade-off between complexity and accuracy. Nowadays, research in functional data analysis (FDA) and statistical learning is very lively to address these drawbacks adequately. This study offers a supervised classification strategy that combines FDA and tree-based procedures. Specifically, we introduce functional classification trees, functional bagging, and functional random forest exploiting the functional principal components decomposition as a tool to extract new features and build functional classifiers. In addition, we introduce new tools to support the understanding of the classification rules, such as the functional empirical separation prototype, functional predicted separation prototype, and the leaves' functional deviance. Furthermore, we suggest some possible solutions for choosing the number of functional principal components and functional classification trees to be implemented in the supervised classification procedure. This research aims to provide an approach to improve the accuracy of the functional classifier, serve the interpretation of the functional classification rules, and overcome the classical drawbacks due to the high-dimensionality of the data. An application on a real dataset regarding daily electrical power demand shows the functioning of the supervised classification proposal. A simulation study with nine scenarios highlights the performance of this approach and compares it with other functional classification methods. The results demonstrate that this line of research is exciting and promising; indeed, in addition to the benefits of the suggested interpretative tools, we exceed the previously established accuracy records on a dataset available online.},
  langid = {english},
  keywords = {Functional bagging,Functional classification trees,Functional data analysis,Functional random forest,Supervised classification},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/maturo_verde_2022_supervised classification of curves via a combined use of functional data.pdf}
}

@article{maurerIncompleteEnumerationAlgorithm2007,
  title = {An Incomplete Enumeration Algorithm for an Exact Test of {{Hardy}}--{{Weinberg}} Proportions with Multiple Alleles},
  author = {Maurer, H. P. and Melchinger, A. E. and Frisch, M.},
  year = {2007},
  month = aug,
  journal = {Theoretical and Applied Genetics},
  volume = {115},
  number = {3},
  pages = {393--398},
  issn = {1432-2242},
  doi = {10.1007/s00122-007-0573-6},
  urldate = {2022-11-05},
  abstract = {Testing of Hardy--Weinberg proportions (HWP) with asymptotic goodness-of-fit tests is problematic when the contingency table of observed genotype counts has sparse cells or the sample size is low, and exact procedures are to be preferred. Exact p-values can be (1) calculated via computational demanding enumeration methods or (2) approximated via simulation methods. Our objective was to develop a new algorithm for exact tests of HWP with multiple alleles on the basis of conditional probabilities of genotype arrays, which is faster than existing algorithms. We derived an algorithm for calculating the exact permutation significance value without enumerating all genotype arrays having the same allele counts as the observed one. The algorithm can be used for testing HWP by (1) summation of the conditional probabilities of occurrence of genotype arrays with smaller probability than the observed one, and (2) comparison of the sum with a nominal Type I error rate {$\alpha$}. Application to published experimental data from seven maize populations showed that the exact test is computationally feasible and reduces the number of enumerated genotype count matrices about 30\% compared with previously published algorithms.},
  langid = {english},
  keywords = {Complete Enumeration,Contingency Table,Enumeration Algorithm,Genotype Array,Hybrid Algorithm},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/maurer et al_2007_an incomplete enumeration algorithm for an exact test of hardy–weinberg.pdf}
}

@article{maurerMultipleRepeatedTesting2011,
  title = {Multiple and {{Repeated Testing}} of {{Primary}}, {{Coprimary}}, and {{Secondary Hypotheses}}},
  author = {Maurer, Willi and Glimm, Ekkehard and Bretz, Frank},
  year = {2011},
  month = may,
  journal = {Statistics in Biopharmaceutical Research},
  volume = {3},
  number = {2},
  pages = {336--352},
  issn = {1946-6315},
  doi = {10.1198/sbr.2010.10010},
  urldate = {2018-09-01},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/maurer et al_2011_multiple and repeated testing of primary, coprimary, and secondary hypotheses.pdf}
}

@misc{MaximumProbabilityContingency,
  title = {The {{Maximum Probability}} 2 {\texttimes} c {{Contingency Tables}} and the {{Maximum Probability Points}} of the {{Multivariate Hypergeometric Distribution}}},
  doi = {10.1081/STA-120022706},
  urldate = {2023-07-10},
  howpublished = {https://www.tandfonline.com/doi/epdf/10.1081/STA-120022706?needAccess=true\&role=button},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/TEQUJ93H/STA-120022706.html}
}

@article{may2007potential,
  title = {Potential Outcome Measures and Trial Design Issues for Multiple System Atrophy},
  author = {May, Susanne and Gilman, Sid and Sowell, B Brooke and Thomas, Ronald G and Stern, Matthew B and Colcher, Amy and Tanner, Caroline M and Huang, Neng and Novak, Peter and Reich, Stephen G and others},
  year = {2007},
  journal = {Movement disorders},
  volume = {22},
  number = {16},
  pages = {2371--2377},
  publisher = {Wiley Subscription Services, Inc., A Wiley Company Hoboken}
}

@article{may2007potential,
  title = {Potential Outcome Measures and Trial Design Issues for Multiple System Atrophy {{Members}} of ``{{The North American Multiple System Atrophy Study Group}}'' Are Listed as an {{Appendix}}.},
  author = {May, Susanne and Gilman, Sid and Sowell, B Brooke and Thomas, Ronald G and Stern, Matthew B and Colcher, Amy and Tanner, Caroline M and Huang, Neng and Novak, Peter and Reich, Stephen G and others},
  year = {2007},
  publisher = {Wiley Subscription Services, Inc., A Wiley Company}
}

@article{mayerRandomizedControlledPilot2023,
  title = {Randomized Controlled Pilot Trial of Prazosin for Prophylaxis of Posttraumatic Headaches in Active-duty Service Members and Veterans},
  author = {Mayer, Cindy L. and Savage, Paul J. and Engle, Conner K. and Groh, Soleil S. and Shofer, Jane B. and Hargrove, Ameryth M. and Williams, Tammy J. and Poupore, Eileen L. and Hart, Kimberly L. and Riechers, Ronald G. and Ruff, Robert L. and Peskind, Elaine R. and Raskind, Murray A.},
  year = {2023},
  month = jun,
  journal = {Headache: The Journal of Head and Face Pain},
  volume = {63},
  number = {6},
  pages = {751--762},
  issn = {0017-8748, 1526-4610},
  doi = {10.1111/head.14529},
  urldate = {2023-10-17},
  abstract = {Objective: Evaluate the efficacy and tolerability of prazosin for prophylaxis of headaches following mild traumatic brain injury in active-\-duty service members and military veterans.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/DKA5JRXU/Mayer et al. - 2023 - Randomized controlled pilot trial of prazosin for .pdf}
}

@article{mayerSimulationPracticesAdaptive2019,
  title = {Simulation {{Practices}} for {{Adaptive Trial Designs}} in {{Drug}} and {{Device Development}}},
  author = {Mayer, Cristiana and Perevozskaya, Inna and Leonov, Sergei and Dragalin, Vladimir and Pritchett, Yili and Bedding, Alun and Hartford, Alan and Fardipour, Parvin and Cicconetti, Greg},
  year = {2019},
  month = oct,
  journal = {Statistics in Biopharmaceutical Research},
  volume = {11},
  number = {4},
  pages = {325--335},
  publisher = {Taylor \& Francis},
  issn = {null},
  doi = {10.1080/19466315.2018.1560359},
  urldate = {2023-02-09},
  abstract = {Adaptive clinical trials are the cornerstone of modern drug and device development. The most recent US legislation calls for higher efficiency in designing clinical trials with emphasis on expanding the utilization of complex innovative designs that cannot be developed without simulations. It is well recognized that clinical trial simulation is a fundamental tool to explore, compare, and understand the operating characteristics, statistical properties, and adaptive decisions embedded in different designs to answer the given research questions. This article provides insights from industry on the development of a simulation report from a group of statisticians brought together under the sponsorship of the Drug Information Association Adaptive Design Scientific Working Group. This effort intends to illustrate the key common elements required to ensure higher consistency and clarity in conducting and reporting simulations of adaptive clinical trials, eliminate unnecessary barriers in communicating technical design aspects to different audiences, and facilitate the assessment of pros and cons of candidate designs. The design-dependent elements of a simulation report applicable to specific types of adaptive trials are presented with the examples of dose-escalation designs, dose-ranging studies, trials with sample size re-estimation and early stopping rules, and confirmatory multistage designs.},
  keywords = {Clinical trials,Complex innovative designs,Operating characteristics,Scenarios,Simulation report},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/mayer et al_2019_simulation practices for adaptive trial designs in drug and device development.pdf}
}

@article{mccollumOhBrotherWhere2021,
  title = {Oh Brother, Where Art Tau? {{Amyloid}}, Neurodegeneration, and Cognitive Decline without Elevated Tau},
  author = {Mccollum, Lauren E and Das, Sandhitsu R and Xie, Long and De Flores, Robin and Wang, Jieqiong and Xie, Sharon X and Wisse, Laura E M and Yushkevich, Paul A and Wolk, David A and Mccollum, L E},
  year = {2021},
  doi = {10.1016/j.nicl.2021.102717},
  urldate = {2021-06-10},
  abstract = {Mild cognitive impairment (MCI) can be an early manifestation of Alzheimer's disease (AD) pathology, other pathologic entities [e.g., cerebrovascular disease, Lewy body disease, LATE (limbic-predominant age-related TDP-43 encephalopathy)], or mixed pathologies, with concomitant AD-and non-AD pathology being particularly common, albeit difficult to identify, in living MCI patients. The National Institute on Aging and Alzheimer's Association (NIA-AA) A/T/(N) [{$\beta$}-Amyloid/Tau/(Neurodegeneration)] AD research framework, which classifies research participants according to three binary biomarkers [{$\beta$}-amyloid (A+/A-), tau (T+/T-), and neuro-degeneration (N+/N-)], provides an indirect means of identifying such cases. Individuals with A+T-(N+) MCI are thought to have both AD pathologic change, given the presence of {$\beta$}-amyloid, and non-AD pathophysiology, given neurodegeneration without tau, because in typical AD it is tau accumulation that is most tightly linked to neuronal injury and cognitive decline. Thus, in A+T-(N+) MCI (hereafter referred to as "mismatch MCI" for the tau-neurodegeneration mismatch), non-AD pathology is hypothesized to drive neurodegeneration and symptoms, because {$\beta$}-amyloid, in the absence of tau, likely reflects a preclinical stage of AD. We compared a group of individuals with mismatch MCI to groups with A+T+(N+) MCI (or "prodromal AD") and AT -(N+) MCI (or "neurodegeneration-only MCI") on cross-sectional and longitudinal cognition and neuroimaging characteristics. {$\beta$}-amyloid and tau status were determined by CSF assays, while neurodegeneration status was based on hippo-campal volume on MRI. Overall, mismatch MCI was less "AD-like" than prodromal AD and generally, with some exceptions, more closely resembled the neurodegeneration-only group. At baseline, mismatch MCI had less episodic memory loss compared to prodromal AD. Longitudinally, mismatch MCI declined more slowly than prodromal AD across all included cognitive domains, while mismatch MCI and neurodegeneration-only MCI declined at comparable rates. Prodromal AD had smaller baseline posterior hippocampal volume than mismatch MCI, and whole brain analyses demonstrated cortical thinning that was widespread in prodromal AD but largely restricted to the medial temporal lobes (MTLs) for the mismatch and neurodegeneration-only MCI groups. Longitudinally, mismatch MCI had slower rates of volume loss than prodromal AD throughout the MTLs. Differences in cross-sectional and longitudinal cognitive and neuroimaging measures between mismatch MCI and prodromal AD may reflect disparate underlying pathologic processes, with the mismatch group potentially being driven by non-AD pathologies on a background of largely preclinical AD. These findings suggest that {$\beta$}-amyloid status alone in MCI may not reveal the underlying driver of symptoms with important implications for enrollment in clinical trials and prognosis.},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/mccollum et al_2021_oh brother, where art tau.pdf}
}

@article{mcglynn1987effects,
  title = {Effects of Behavioral Self-Management on Oral Hygiene Adherence among Orthodontic Patients},
  author = {McGlynn, F Dudley and LeCompte, E Joseph and Thomas, Ronald G and Courts, Frank J and Melamed, Barbara G},
  year = {1987},
  journal = {American Journal of Orthodontics and Dentofacial Orthopedics},
  volume = {91},
  number = {1},
  pages = {15--21},
  publisher = {Mosby}
}

@article{mclachlanAnnualReviewStatistics2019,
  title = {Annual {{Review}} of {{Statistics}} and {{Its Application Finite Mixture Models}}},
  author = {Mclachlan, Geoffrey J and Lee, Sharon X and Rathnayake, Suren I},
  year = {2019},
  journal = {Annual Review of Statistics and Its Application},
  doi = {10.1146/annurev-statistics},
  abstract = {The important role of finite mixture models in the statistical analysis of data is underscored by the ever-increasing rate at which articles on mixture applications appear in the statistical and general scientific literature. The aim of this article is to provide an up-to-date account of the theory and methodological developments underlying the applications of finite mixture models. Because of their flexibility, mixture models are being increasingly exploited as a convenient, semiparametric way in which to model unknown distributional shapes. This is in addition to their obvious applications where there is group-structure in the data or where the aim is to explore the data for such structure, as in a cluster analysis. It has now been three decades since the publication of the monograph by McLachlan \& Basford (1988) with an emphasis on the potential usefulness of mixture models for inference and clustering. Since then, mixture models have attracted the interest of many researchers and have found many new and interesting fields of application. Thus, the literature on mixture models has expanded enormously, and as a consequence, the bibliography here can only provide selected coverage. 355},
  keywords = {EM algorithm,mixture proportions,mixtures of factor analyzers,model-based clustering,normal and t-mixture distributions},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/mclachlan et al_2019_annual review of statistics and its application finite mixture models.pdf}
}

@article{medinaOverviewClinicalDevelopment2018,
  title = {An {{Overview}} on the {{Clinical Development}} of {{Tau-Based Therapeutics}}},
  author = {Medina, Miguel},
  year = {2018},
  month = apr,
  journal = {International Journal of Molecular Sciences},
  volume = {19},
  number = {4},
  pages = {1160},
  issn = {1422-0067},
  doi = {10.3390/ijms19041160},
  abstract = {Tauopathies such as Alzheimer's disease (AD), frontotemporal lobar degeneration, or progressive supranuclear palsy constitute a group of brain disorders defined by neurodegeneration and the presence of tau aggregates in the affected brains regions. Tau is a microtubule-associated protein that accumulates in the cytosol under pathological conditions, steering the formation of aggregates or inclusions thought to be involved in the degeneration and neuronal death associated with these diseases. Despite a substantial and unmet medical need for novel, more effective disease-modifying therapies for the treatment of AD and tauopathies, the last couple of decades have seen numerous drug development undertakings primarily focused on {$\beta$}-amyloid, with disappointing results to date. On the other hand, tau-focused approaches have not received much attention until recently, notwithstanding that the presence of extensive tau pathology is fundamental for the disease and tau pathology shows a better correlation with impaired cognitive function than with amyloid pathology in AD patients. The last few years have brought us advances in our comprehension of tau biological functions beyond its well-established role as a microtubule-associated protein, unveiling novel physiological tau functions that may also be involved in pathogenesis and thus provide novel targets for therapeutic intervention. This review describes several emerging, encouraging therapeutic approaches aimed at tackling the underlying causes of tau pathology in AD and other tauopathies that have recently reached the clinical development stage.},
  langid = {english},
  pmcid = {PMC5979300},
  pmid = {29641484},
  keywords = {aggregation,Alzheimer,Animals,Antibodies,Clinical Trials as Topic,dementia,drug development,Humans,immunotherapy,Immunotherapy,neurodegeneration,Neuroprotective Agents,Protein Processing Post-Translational,tau,tau Proteins,tauopathies,Tauopathies,therapy},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/medina_2018_an overview on the clinical development of tau-based therapeutics.pdf}
}

@article{meeterClinicalValueNeurofilament2018,
  title = {Clinical Value of Neurofilament and Phospho-Tau/Tau Ratio in the Frontotemporal Dementia Spectrum},
  author = {Meeter, Lieke H.H. and Vijverberg, Everard G. and Del Campo, Marta and Rozemuller, Annemieke J.M. and Donker Kaat, Laura and {de Jong}, Frank Jan and {van der Flier}, Wiesje M. and Teunissen, Charlotte E. and {van Swieten}, John C. and Pijnenburg, Yolande A.L.},
  year = {2018},
  month = apr,
  journal = {Neurology},
  volume = {90},
  number = {14},
  pages = {e1231-e1239},
  publisher = {NLM (Medline)},
  issn = {1526632X},
  doi = {10.1212/wnl.0000000000005261},
  urldate = {2021-11-08},
  abstract = {OBJECTIVE: To examine the clinical value of neurofilament light chain (NfL) and the phospho-tau/total tau ratio (p/t-tau) across the entire frontotemporal dementia (FTD) spectrum in a large, well-defined cohort. METHODS: CSF NfL and p/t-tau levels were studied in 361 patients with FTD: 179 behavioral variant FTD, 17 FTD with motor neuron disease (FTD-MND), 36 semantic variant primary progressive aphasia (PPA), 19 nonfluent variant PPA, 4 logopenic variant PPA (lvPPA), 42 corticobasal syndrome, and 64 progressive supranuclear palsy. Forty-five cognitively healthy controls were also included. Definite pathology was known in 68 patients (49 frontotemporal lobar degeneration [FTLD]-TDP, 18 FTLD-tau, 1 FTLD-FUS). RESULTS: NfL was higher in all diagnoses, except lvPPA (n = 4), than in controls, equally elevated in behavioral variant FTD, semantic variant PPA, nonfluent variant PPA, and corticobasal syndrome, and highest in FTD-MND. The p/t-tau was lower in all clinical groups, except lvPPA, than in controls and lowest in FTD-MND. NfL did not discriminate between TDP and tau pathology, while the p/t-tau ratio had a good specificity (76\%) and moderate sensitivity (67\%). Both high NfL and low p/t-tau were associated with poor survival (hazard ratio on tertiles 1.7 for NfL, 0.7 for p/t-tau). CONCLUSION: NfL and p/t-tau similarly discriminated FTD from controls, but not between clinical subtypes, apart from FTD-MND. Both markers predicted survival and are promising monitoring biomarkers for clinical trials. Of note, p/t-tau, but not NfL, was specific to discriminate TDP from tau pathology in vivo. CLASSIFICATION OF EVIDENCE: This study provides Class III evidence that for patients with cognitive issues, CSF NfL and p/t-tau levels discriminate between those with and without FTD spectrum disorders.},
  pmid = {29514947},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/meeter et al_2018_clinical value of neurofilament and phospho-tau-tau ratio in the frontotemporal.pdf}
}

@article{mehrotraCautionaryNoteExact2003,
  title = {A {{Cautionary Note}} on {{Exact Unconditional Inference}} for a {{Difference}} between {{Two Independent Binomial Proportions}}},
  author = {Mehrotra, Devan V. and Chan, Ivan S. F. and Berger, Roger L.},
  year = {2003},
  month = jun,
  journal = {Biometrics},
  volume = {59},
  number = {2},
  pages = {441--450},
  issn = {0006-341X, 1541-0420},
  doi = {10.1111/1541-0420.00051},
  urldate = {2023-12-15},
  abstract = {Fisher's exact test for comparing response proportions in a randomized experiment can be overly conservative when the group sizes are small or when the response proportions are close to zero or one. This is primarily because the null distribution of the test statistic becomes too discrete, a partial consequence of the inference being conditional on the total number of responders. Accordingly, exact unconditional procedures have gained in popularity, on the premise that power will increase because the null distribution of the test statistic will presumably be less discrete. However, we caution researchers that a poor choice of test statistic for exact unconditional inference can actually result in a substantially less powerful analysis than Fisher's conditional test. To illustrate, we study a real example and provide exact test size and power results for several competing tests, for both balanced and unbalanced designs. Our results reveal that Fisher's test generally outperforms exact unconditional tests based on using as the test statistic either the observed difference in proportions, or the observed difference divided by its estimated standard error under the alternative hypothesis, the latter for unbalanced designs only. On the other hand, the exact unconditional test based on the observed difference divided by its estimated standard error under the null hypothesis (score statistic) outperforms Fisher's test, and is recommended. Boschloo's test, in which the p-value from Fisher's test is used as the test statistic in an exact unconditional test, is uniformly more powerful than Fisher's test, and is also recommended.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/BSDFBBV8/Mehrotra et al. - 2003 - A Cautionary Note on Exact Unconditional Inference.pdf}
}

@article{mehrotraDraftICHGuidance2018,
  title = {Draft {{ICH Guidance}} on {{Estimands}} and {{Sensitivity Analyses}} : {{Why}} and {{What}} ?},
  author = {Mehrotra, Devan V},
  year = {2018},
  pages = {1--18},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/mehrotra_2018_draft ich guidance on estimands and sensitivity analyses.pdf}
}

@article{mehtaAdaptiveIncreaseSample2011,
  title = {Adaptive Increase in Sample Size When Interim Results Are Promising: {{A}} Practical Guide with Examples},
  shorttitle = {Adaptive Increase in Sample Size When Interim Results Are Promising},
  author = {Mehta, Cyrus R. and Pocock, Stuart J.},
  year = {2011},
  journal = {Statistics in Medicine},
  volume = {30},
  number = {28},
  pages = {3267--3284},
  issn = {1097-0258},
  doi = {10.1002/sim.4102},
  urldate = {2024-04-14},
  abstract = {This paper discusses the benefits and limitations of adaptive sample size re-estimation for phase 3 confirmatory clinical trials. Comparisons are made with more traditional fixed sample and group sequential designs. It is seen that the real benefit of the adaptive approach arises through the ability to invest sample size resources into the trial in stages. The trial starts with a small up-front sample size commitment. Additional sample size resources are committed to the trial only if promising results are obtained at an interim analysis. This strategy is shown through examples of actual trials, one in neurology and one in cardiology, to be more advantageous than the fixed sample or group sequential approaches in certain settings. A major factor that has generated controversy and inhibited more widespread use of these methods has been their reliance on non-standard tests and p-values for preserving the type-1 error. If, however, the sample size is only increased when interim results are promising, one can dispense with these non-standard methods of inference. Therefore, in the spirit of making adaptive increases in trial size more widely appealing and readily implementable we here define those promising circumstances in which a conventional final inference can be performed while preserving the overall type-1 error. Methodological, regulatory and operational issues are examined. Copyright {\copyright} 2010 John Wiley \& Sons, Ltd.},
  copyright = {Copyright {\copyright} 2010 John Wiley \& Sons, Ltd.},
  langid = {english},
  keywords = {adaptive design,conditional power,flexible clinical trials,real examples,sample size re-estimation,two-stage designs},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/mehta_pocock_2011_adaptive increase in sample size when interim results are promising2.pdf;/Users/zenn/Zotero/storage/LFQQHLAP/sim.html}
}

@article{mehtaAdaptiveIncreaseSample2011a,
  title = {Adaptive Increase in Sample Size When Interim Results Are Promising: {{A}} Practical Guide with Examples},
  shorttitle = {Adaptive Increase in Sample Size When Interim Results Are Promising},
  author = {Mehta, Cyrus R. and Pocock, Stuart J.},
  year = {2011},
  month = dec,
  journal = {Statistics in Medicine},
  volume = {30},
  number = {28},
  pages = {3267--3284},
  publisher = {John Wiley \& Sons, Ltd},
  issn = {1097-0258},
  doi = {10.1002/sim.4102},
  urldate = {2024-04-14},
  abstract = {This paper discusses the benefits and limitations of adaptive sample size re-estimation for phase 3 confirmatory clinical trials. Comparisons are made with more traditional fixed sample and group seq...},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/mehta_pocock_2011_adaptive increase in sample size when interim results are promising.pdf}
}

@article{mehtaAdaptiveIncreaseSample2011b,
  title = {Adaptive Increase in Sample Size When Interim Results Are Promising: {{A}} Practical Guide with Examples},
  shorttitle = {Adaptive Increase in Sample Size When Interim Results Are Promising},
  author = {Mehta, Cyrus R. and Pocock, Stuart J.},
  year = {2011},
  journal = {Statistics in Medicine},
  volume = {30},
  number = {28},
  pages = {3267--3284},
  issn = {1097-0258},
  doi = {10.1002/sim.4102},
  urldate = {2024-04-14},
  abstract = {This paper discusses the benefits and limitations of adaptive sample size re-estimation for phase 3 confirmatory clinical trials. Comparisons are made with more traditional fixed sample and group sequential designs. It is seen that the real benefit of the adaptive approach arises through the ability to invest sample size resources into the trial in stages. The trial starts with a small up-front sample size commitment. Additional sample size resources are committed to the trial only if promising results are obtained at an interim analysis. This strategy is shown through examples of actual trials, one in neurology and one in cardiology, to be more advantageous than the fixed sample or group sequential approaches in certain settings. A major factor that has generated controversy and inhibited more widespread use of these methods has been their reliance on non-standard tests and p-values for preserving the type-1 error. If, however, the sample size is only increased when interim results are promising, one can dispense with these non-standard methods of inference. Therefore, in the spirit of making adaptive increases in trial size more widely appealing and readily implementable we here define those promising circumstances in which a conventional final inference can be performed while preserving the overall type-1 error. Methodological, regulatory and operational issues are examined. Copyright {\copyright} 2010 John Wiley \& Sons, Ltd.},
  copyright = {Copyright {\copyright} 2010 John Wiley \& Sons, Ltd.},
  langid = {english},
  keywords = {adaptive design,conditional power,flexible clinical trials,real examples,sample size re-estimation,two-stage designs},
  file = {/Users/zenn/Zotero/storage/6ZQHLSEH/sim.html}
}

@article{mehtaComputingExactConfidence,
  title = {Computing an Exact Confidence Interval for the Common Odds Ratio in Several 2{\texttimes} 2 Contingency Tables},
  author = {Mehta, {\relax CR} and Patel, {\relax NR} and of the American, R Gray - Journal and 1985, undefined},
  journal = {amstat.tandfonline.com},
  urldate = {2018-04-07},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/mehta et al_computing an exact confidence interval for the common odds ratio in several 2×.pdf}
}

@article{mehtaConditionalUnconditionalExact,
  title = {Conditional versus {{Unconditional Exact Tests}} for {{Comparing Two Binomials}}},
  author = {Mehta, Cyrus R and Senchaudhuri, Pralay},
  pages = {5},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/mehta_senchaudhuri_conditional versus unconditional exact tests for comparing two binomials.pdf}
}

@article{mehtaExactPowerConditional,
  title = {Exact Power of Conditional and Unconditional Tests: Going beyond the 2{\texttimes} 2 Contingency Table},
  author = {Mehta, {\relax CR} and Statistician, JF Hilton - The American and 1993, undefined},
  journal = {Taylor \& Francis},
  urldate = {2018-04-07},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/mehta et al_exact power of conditional and unconditional tests.pdf}
}

@article{mehtaExactPowerConditional1993,
  title = {Exact {{Power}} of {{Conditional}} and {{Unconditional Tests}}: {{Going}} beyond the 2 {\texttimes} 2 {{Contingency Table}}},
  shorttitle = {Exact {{Power}} of {{Conditional}} and {{Unconditional Tests}}},
  author = {Mehta, Cyrus R. and Hilton, Joan F.},
  year = {1993},
  month = may,
  journal = {The American Statistician},
  volume = {47},
  number = {2},
  pages = {91--98},
  publisher = {Taylor \& Francis},
  issn = {0003-1305},
  doi = {10.1080/00031305.1993.10475946},
  urldate = {2023-08-12},
  abstract = {The controversial question of whether one should condition on both margins of a contingency table for exact inference is examined from a fresh, computational perspective. The conditional test is believed to be less powerful than the unconditional test. However, in all previous work the actual hard evidence for this alleged power loss has always been provided by the single 2 {\texttimes} 2 table. In this setting the discreteness of the test statistic confounds the issue since the loss in power is offset by a corresponding reduction in Type 1 error. Although one could overcome discreteness through an auxiliary randomization experiment, this would not resolve the controversy, because such post hoc randomization is unacceptable to the practicing statistician. We overcome the discreteness more naturally by extending the power computations to 2 {\texttimes} 3 contingency tables. In doing so we find that the power advantage of the unconditional test rapidly vanishes. The article also discusses computational difficulties we would encounter if we attempted to extend the unconditional test beyond the 2 {\texttimes} 2 table.},
  keywords = {Ancillarity,Barnard's test,Fisher's exact test,p values}
}

@article{mehtaExactPowerConditional1993a,
  title = {Exact {{Power}} of {{Conditional}} and {{Unconditional Tests}}: {{Going}} beyond the 2 {\texttimes} 2 {{Contingency Table}}},
  shorttitle = {Exact {{Power}} of {{Conditional}} and {{Unconditional Tests}}},
  author = {Mehta, Cyrus R. and Hilton, Joan F.},
  year = {1993},
  month = may,
  journal = {The American Statistician},
  volume = {47},
  number = {2},
  pages = {91--98},
  publisher = {Taylor \& Francis},
  issn = {0003-1305},
  doi = {10.1080/00031305.1993.10475946},
  urldate = {2023-08-12},
  abstract = {The controversial question of whether one should condition on both margins of a contingency table for exact inference is examined from a fresh, computational perspective. The conditional test is believed to be less powerful than the unconditional test. However, in all previous work the actual hard evidence for this alleged power loss has always been provided by the single 2 {\texttimes} 2 table. In this setting the discreteness of the test statistic confounds the issue since the loss in power is offset by a corresponding reduction in Type 1 error. Although one could overcome discreteness through an auxiliary randomization experiment, this would not resolve the controversy, because such post hoc randomization is unacceptable to the practicing statistician. We overcome the discreteness more naturally by extending the power computations to 2 {\texttimes} 3 contingency tables. In doing so we find that the power advantage of the unconditional test rapidly vanishes. The article also discusses computational difficulties we would encounter if we attempted to extend the unconditional test beyond the 2 {\texttimes} 2 table.},
  keywords = {Ancillarity,Barnard's test,Fisher's exact test,p values},
  file = {/Users/zenn/Zotero/storage/BZBPCKFA/Mehta and Hilton - 1993 - Exact Power of Conditional and Unconditional Tests.pdf}
}

@article{mehtaNetworkAlgorithmExact1980,
  title = {A Network Algorithm for the Exact Treatment of the 2{\textbackslash}times k Contingency Table: {{A}} Network Algorithm for the Exact Treatment},
  shorttitle = {A Network Algorithm for the Exact Treatment of the 2{\textbackslash}times k Contingency Table},
  author = {Mehta, Cyrus R. and Patel, Nitin R.},
  year = {1980},
  journal = {Communications in Statistics-Simulation and Computation},
  volume = {9},
  number = {6},
  pages = {649--664},
  publisher = {Taylor \& Francis},
  file = {/Users/zenn/Zotero/storage/FB8TY83H/Mehta and Patel - 1980 - A network algorithm for the exact treatment of the.pdf;/Users/zenn/Zotero/storage/GUKKMCNE/03610918008812182.html}
}

@article{mehtaSmarterAdaptivePlatform2022,
  title = {Smarter Adaptive Platform Clinical Trials in Neurology: A Showcase for {{UK}} Innovation},
  shorttitle = {Smarter Adaptive Platform Clinical Trials in Neurology},
  author = {Mehta, Arpan R and Pal, Suvankar and Chataway, Jeremy and Carpenter, James R and Parmar, Mahesh K B and Chandran, Siddharthan},
  year = {2022},
  month = aug,
  journal = {Brain},
  volume = {145},
  number = {8},
  pages = {e64-e65},
  issn = {0006-8950, 1460-2156},
  doi = {10.1093/brain/awac169},
  urldate = {2024-06-26},
  copyright = {https://academic.oup.com/journals/pages/open\_access/funder\_policies/chorus/standard\_publication\_model},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/JT635WQ5/Mehta et al. - 2022 - Smarter adaptive platform clinical trials in neuro.pdf}
}

@article{mehtaTrialsNeurodegenerativeDiseases2021,
  title = {Trials for Neurodegenerative Diseases: Time to Innovate},
  shorttitle = {Trials for Neurodegenerative Diseases},
  author = {Mehta, Arpan R. and Chataway, Jeremy and Pal, Suvankar and Parmar, Mahesh K. B. and Chandran, Siddharthan},
  year = {2021},
  month = dec,
  journal = {The Lancet. Neurology},
  volume = {20},
  number = {12},
  pages = {984},
  issn = {1474-4465},
  doi = {10.1016/S1474-4422(21)00388-4},
  langid = {english},
  pmcid = {PMC7612114},
  pmid = {34800413},
  keywords = {Humans,Neurodegenerative Diseases},
  file = {/Users/zenn/Zotero/storage/NWFN33M5/Mehta et al. - 2021 - Trials for neurodegenerative diseases time to inn.pdf}
}

@inproceedings{mellen1988forms,
  title = {{{FORMS INVENTORY SYSTEM FOR A COMPLEX CLINICAL-TRIAL}}},
  booktitle = {Controlled Clinical Trials},
  author = {Mellen, {\relax BG} and Thomas, {\relax RG} and CASTANO, D},
  year = {1988},
  volume = {9},
  pages = {282--283},
  publisher = {ELSEVIER SCIENCE INC 655 AVENUE OF THE AMERICAS, NEW YORK, NY 10010}
}

@article{messick2011p3,
  title = {P3-406: {{Role}} of Caregiver in Subject's Compliance with Treatment},
  author = {Messick, Viviana and Donohue, Michael and Raman, Rema and Sano, Mary and Quinn, Joseph and Thomas, Ron and Emond, Jennifer and Aisen, Paul},
  year = {2011},
  journal = {Alzheimer's \& Dementia},
  volume = {7},
  pages = {S645--S645},
  publisher = {The Alzheimer's Association}
}

@article{meulepasPValueExactTwoSided1999,
  title = {A {{P-Value}} for an {{Exact Two-Sided Test}} of {{Hardy-Weinberg Equilibrium}}},
  author = {Meulepas, E.},
  year = {1999},
  journal = {Biometrical Journal},
  volume = {41},
  number = {4},
  pages = {499--505},
  issn = {1521-4036},
  doi = {10.1002/(SICI)1521-4036(199907)41:4<499::AID-BIMJ499>3.0.CO;2-B},
  urldate = {2023-02-05},
  abstract = {A two-tailed P-value is proposed for testing two-sided departures from Hardy-Weinberg equilibrium at a diallelic locus. The calculation of P uses the exact conditional distribution of the test statistic P, the observed number of heterozygotes in the sample. The proposed P-value is always two-tailed, unlike other P-values proposed in the literature.},
  langid = {english},
  keywords = {Continuity correction,Hardy-Weinberg equilibrium,P-values},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/meulepas_1999_a p-value for an exact two-sided test of hardy-weinberg equilibrium.pdf;/Users/zenn/Zotero/storage/HJI8FC6V/(SICI)1521-4036(199907)414499AID-BIMJ4993.0.html}
}

@article{meyer2008efficacy,
  title = {Efficacy of Site-Independent Telemedicine in the {{STRokE DOC}} Trial: A Randomised, Blinded, Prospective Study},
  author = {Meyer, Brett C and Raman, Rema and Hemmen, Thomas and Obler, Richard and Zivin, Justin A and Rao, Ramesh and Thomas, Ronald G and Lyden, Patrick D},
  year = {2008},
  journal = {The Lancet Neurology},
  volume = {7},
  number = {9},
  pages = {787--795},
  publisher = {Elsevier}
}

@article{michalowiczTreatmentPeriodontalDisease2006,
  title = {Treatment of {{Periodontal Disease}} and the {{Risk}} of {{Preterm Birth}}},
  author = {Michalowicz, Bryan S. and Hodges, James S. and DiAngelis, Anthony J. and Lupo, Virginia R. and Novak, M. John and Ferguson, James E. and Buchanan, William and Bofill, James and Papapanou, Panos N. and Mitchell, Dennis A. and Matseoane, Stephen and Tschida, Pat A.},
  year = {2006},
  month = nov,
  journal = {New England Journal of Medicine},
  volume = {355},
  number = {18},
  pages = {1885--1894},
  publisher = {Massachusetts Medical Society},
  issn = {0028-4793},
  doi = {10.1056/NEJMoa062249},
  urldate = {2024-02-16},
  abstract = {About 11\% of singleton births in the United States occur before 37 weeks of gestation,1 and the rate of premature delivery has increased during the past 15 years. Preterm and low-birth-weight infants are at elevated risk for death, neurodevelopmental disabilities, cognitive impairment, and behavioral disorders.2--4 About half of mothers delivering preterm infants have no known risk factors.5 Recent studies suggest that periodontitis, an inflammatory disease caused primarily by gram-negative bacteria that destroy tooth-supporting connective tissue and bone, is associated with an increased risk of preterm birth, as well as low birth weight and preeclampsia.6--8 In rodents, subcutaneous inoculations . . .},
  pmid = {17079762},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/michalowicz et al_2006_treatment of periodontal disease and the risk of preterm birth.pdf}
}

@article{Miller2022,
  title = {{{BodyMapR}}: An {{R}} Package and {{Shiny}} Application Designed to Generate Anatomical Visualizations of Cancer Lesions},
  author = {Miller, David M and Shalhout, Sophia Z},
  year = {2022},
  month = jan,
  journal = {JAMIA Open},
  volume = {5},
  number = {1},
  publisher = {Oxford University Press (OUP)},
  doi = {10.1093/jamiaopen/ooac013},
  urldate = {2022-05-29},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/miller_shalhout_2022_bodymapr.pdf}
}

@article{mills2013preclinical,
  title = {Preclinical Trials in Autosomal Dominant {{AD}}: Implementation of the {{DIAN-TU}} Trial},
  author = {Mills, Sarah M and Mallmann, J and Santacruz, Anna M and Fuqua, A and Carril, M and Aisen, Paul S and Althage, {\relax MC} and Belyew, S and Benzinger, Tammie L and Brooks, William S and others},
  year = {2013},
  journal = {Revue neurologique},
  volume = {169},
  number = {10},
  pages = {737--743},
  publisher = {Elsevier Masson}
}

@article{mills2013preclinical,
  title = {Preclinical Trials in Autosomal Dominant {{AD}}: {{Implementation}} of the {{DIAN-TU}} Trial (Vol 169, Pg 737, 2013)},
  author = {Mills, {\relax SM} and Mallmann, J and Santacruz, {\relax AM} and Fuqua, A and Carril, M and Aisen, {\relax PS} and Althage, {\relax MC} and Belyew, S and Benzinger, {\relax TL} and Brooks, {\relax WS} and others},
  year = {2013},
  journal = {REVUE NEUROLOGIQUE},
  volume = {169},
  number = {12},
  pages = {1018--1018},
  publisher = {MASSON EDITEUR 21 STREET CAMILLE DESMOULINS, ISSY, 92789 MOULINEAUX CEDEX 9 {\dots}}
}

@article{MissingDataClinical2012,
  title = {Missing {{Data}} in {{Clinical Trials}}},
  year = {2012},
  month = dec,
  journal = {New England Journal of Medicine},
  volume = {367},
  number = {26},
  pages = {2557--2558},
  publisher = {Massachusetts Medical Society},
  issn = {0028-4793},
  doi = {10.1056/NEJMc1213388},
  urldate = {2023-03-02},
  abstract = {To the Editor: Little et al. (Oct. 4 issue)1 mention limiting ``the burden and inconvenience of data collection on the participants'' as one of several ideas for limiting missing data in the conduct of clinical trials. Actually, this idea should be a design feature, and it is also important in limiting the burden on the investigator (a critical factor in successful data retrieval as well as patient accrual). Prominent trialists have long championed simple randomized trials for these and other reasons.2 Simple, minimal data collection must be one of the most effective strategies for the prevention of missing data. This . . .},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/2012_missing data in clinical trials.pdf}
}

@article{mockus2011dietary,
  title = {Dietary Self-Monitoring and Its Impact on Weight Loss in Overweight Children},
  author = {Mockus, Danyte S and Macera, Caroline A and Wingard, Deborah L and Peddecord, Michael and Thomas, Ronald G and Wilfley, Denise E},
  year = {2011},
  journal = {International journal of pediatric obesity},
  volume = {6},
  number = {3-4},
  pages = {197--205},
  publisher = {Taylor \& Francis}
}

@article{molenberghsAnalyzingIncompleteLongitudinal2004,
  title = {Analyzing Incomplete Longitudinal Clinical Trial Data},
  author = {Molenberghs, Geert and Thijs, Herbert and Jansen, Ivy and Beunckens, Caroline and Kenward, Michael G. and Mallinckrodt, Craig and Carroll, Raymond J.},
  year = {2004},
  journal = {Biostatistics},
  volume = {5},
  number = {3},
  pages = {445--464},
  publisher = {Oxford University Press},
  file = {/Users/zenn/Zotero/storage/TEFDXQW7/Molenberghs et al. - 2004 - Analyzing incomplete longitudinal clinical trial d.pdf;/Users/zenn/Zotero/storage/7G9PAP5B/310196.html}
}

@article{morganMostPathwaysCan2022,
  title = {Most {{Pathways Can Be Related}} to the {{Pathogenesis}} of {{Alzheimer}} ' s {{Disease}}},
  author = {Morgan, Sarah L and Naderi, Pourya and Koler, Katju{\v s}a and {Pita-juarez}, Yered and Prokopenko, Dmitry and Vlachos, Ioannis S and Tanzi, Rudolph E and Bertram, Lars and Hide, Winston A},
  year = {2022},
  volume = {14},
  number = {June},
  pages = {1--13},
  doi = {10.3389/fnagi.2022.846902},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/morgan et al_2022_most pathways can be related to the pathogenesis of alzheimer ’ s disease.pdf}
}

@article{morimotoDavunetideReviewSafety2013,
  title = {Davunetide: A Review of Safety and Efficacy Data with a Focus on Neurodegenerative Diseases},
  shorttitle = {Davunetide},
  author = {Morimoto, Bruce H. and Fox, Anthony W. and Stewart, Alistair J. and Gold, Michael},
  year = {2013},
  month = sep,
  journal = {Expert Review of Clinical Pharmacology},
  volume = {6},
  number = {5},
  pages = {483--502},
  issn = {1751-2441},
  doi = {10.1586/17512433.2013.827403},
  abstract = {Davunetide is the first neuroprotective peptide in its class, and has preclinical evidence for neuroprotective, neurotrophic and cognitive protective properties. Davunetide has also been shown to prevent apoptosis or programmed-cell death in a range of in vitro and in vivo models by promoting microtubule stabilization. Potential clinical uses of davunetide include neurodegenerative disorders such as Alzheimer's disease (AD), progressive supranuclear palsy (PSP), frontotemporal dementia (FTD) or cognitive impairment in other diseases such as schizophrenia where microtubule structure and function is known to be impaired. The nonclinical and clinical safety of davunetide is reviewed here in detail. Pre-clinical toxicology studies in rats and dogs using the maximum feasible dose of davunetide provide strong evidence that davunetide is well-tolerated. Similarly, data from 10 separate clinical trials of davunetide, investigating safety and efficacy provide evidence that davunetide is generally safe and well-tolerated, and has shown some signs of clinical efficacy.},
  langid = {english},
  pmid = {23971871},
  keywords = {Animals,Apoptosis,Clinical Trials as Topic,Dose-Response Relationship Drug,Humans,Microtubules,Neurodegenerative Diseases,Neuroprotective Agents,Oligopeptides,Toxicity Tests,Treatment Outcome}
}

@article{morrisUsingSimulationStudies2019,
  title = {Using Simulation Studies to Evaluate Statistical Methods},
  author = {Morris, Tim P. and White, Ian R. and Crowther, Michael J.},
  year = {2019},
  journal = {Statistics in Medicine},
  volume = {38},
  number = {11},
  pages = {2074--2102},
  issn = {1097-0258},
  doi = {10.1002/sim.8086},
  urldate = {2023-07-21},
  abstract = {Simulation studies are computer experiments that involve creating data by pseudo-random sampling. A key strength of simulation studies is the ability to understand the behavior of statistical methods because some ``truth'' (usually some parameter/s of interest) is known from the process of generating the data. This allows us to consider properties of methods, such as bias. While widely used, simulation studies are often poorly designed, analyzed, and reported. This tutorial outlines the rationale for using simulation studies and offers guidance for design, execution, analysis, reporting, and presentation. In particular, this tutorial provides a structured approach for planning and reporting simulation studies, which involves defining aims, data-generating mechanisms, estimands, methods, and performance measures (``ADEMP''); coherent terminology for simulation studies; guidance on coding simulation studies; a critical discussion of key performance measures and their estimation; guidance on structuring tabular and graphical presentation of results; and new graphical presentations. With a view to describing recent practice, we review 100 articles taken from Volume 34 of Statistics in Medicine, which included at least one simulation study and identify areas for improvement.},
  copyright = {{\copyright} 2019 The Authors. Statistics~in~Medicine Published by John Wiley \& Sons Ltd.},
  langid = {english},
  keywords = {graphics for simulation,Monte Carlo,simulation design,simulation reporting,simulation studies},
  file = {/Users/zenn/Zotero/storage/LKBFLP8J/Morris et al. - 2019 - Using simulation studies to evaluate statistical m.pdf;/Users/zenn/Zotero/storage/H2PJNBBT/sim.html}
}

@article{morrow1993prediction,
  title = {Prediction of Cardiovascular Death in Men Undergoing Noninvasive Evaluation for Coronary Artery Disease},
  author = {Morrow, Kiernan and Morris, Charles K and Froelicher, Victor F and Hideg, Alisa and Hunter, Dodie and Johnson, Eileen and Kawaguchi, Takeo and Lehmann, Kenneth and Ribisl, Paul M and Thomas, Ronald and others},
  year = {1993},
  journal = {Annals of internal medicine},
  volume = {118},
  number = {9},
  pages = {689--695},
  publisher = {American College of Physicians}
}

@article{Morshed2020,
  title = {Quantitative Phosphoproteomics Uncovers Dysregulated Kinase Networks in {{Alzheimer}} ' s Disease},
  author = {Morshed, Nader and Lee, Meelim and Rodriguez, Felicia H and Lauffenburger, Douglas A and White, Forest and Cruces, Las},
  year = {2020},
  journal = {BioArvix},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/morshed et al_2020_quantitative phosphoproteomics uncovers dysregulated kinase networks in.pdf}
}

@misc{moserStatisticalChallengesWhen2023,
  title = {Statistical {{Challenges}} When {{Analyzing SARS-CoV-2 RNA Measurements Below}} the {{Assay Limit}} of {{Quantification}} in {{COVID-19 Clinical Trials}}},
  author = {Moser, Carlee B. and Chew, Kara W. and Giganti, Mark J. and Li, Jonathan Z. and Aga, Evgenia and Ritz, Justin and Greninger, Alexander L. and Javan, Arzhang Cyrus and Ignacio, Rachel Bender and Daar, Eric S. and Wohl, David A. and Currier, Judith S. and Eron, Joseph J. and Smith, Davey M. and Hughes, Michael D. and Team, ACTIV-2/A5401 Study},
  year = {2023},
  month = mar,
  pages = {2023.03.13.23287208},
  publisher = {medRxiv},
  doi = {10.1101/2023.03.13.23287208},
  urldate = {2023-10-17},
  abstract = {Most clinical trials evaluating COVID-19 therapeutics include assessments of antiviral activity. In recently completed outpatient trials, changes in nasal SARS-CoV-2 RNA levels from baseline were commonly assessed using analysis of covariance (ANCOVA) or mixed models for repeated measures (MMRM) with single-imputation for results below assay lower limits of quantification (LLoQ). Analyzing changes in viral RNA levels with singly-imputed values can lead to biased estimates of treatment effects. In this paper, using an illustrative example from the ACTIV-2 trial, we highlight potential pitfalls of imputation when using ANCOVA or MMRM methods, and illustrate how these methods can be used when considering values},
  archiveprefix = {medRxiv},
  copyright = {{\copyright} 2023, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/LYFVSJ4K/Moser et al. - 2023 - Statistical Challenges when Analyzing SARS-CoV-2 R.pdf}
}

@inproceedings{mufson1987comparison,
  title = {A Comparison of Single Lesion Dilatation in Single Vessel and Multivessel Disease},
  booktitle = {Circulation},
  author = {Mufson, {\relax LGAR} and Roubin, {\relax GS} and Black, A and Thomas, {\relax RG}},
  year = {1987},
  volume = {76},
  pages = {464--464},
  publisher = {AMER HEART ASSOC 7272 GREENVILLE AVENUE, DALLAS, TX 75231-4596}
}

@article{muirMinimalClinicallyImportant2024,
  title = {Minimal Clinically Important Difference in {{Alzheimer}}'s Disease: {{Rapid}} Review},
  shorttitle = {Minimal Clinically Important Difference in {{Alzheimer}}'s Disease},
  author = {Muir, Ryan T. and Hill, Michael D. and Black, Sandra E. and Smith, Eric E.},
  year = {2024},
  journal = {Alzheimer's \& Dementia},
  volume = {20},
  number = {5},
  pages = {3352--3363},
  issn = {1552-5279},
  doi = {10.1002/alz.13770},
  urldate = {2024-06-03},
  abstract = {INTRODUCTION We conducted a rapid systematic review of minimal clinically important differences (MCIDs) for Alzheimer's disease (AD) trial endpoints. METHODS Two reviewers searched EMBASE, MEDLINE, and PubMed from inception to June 4, 2023. RESULTS Ten articles were retrieved. For mild cognitive impairment (MCI), a change of +2 to +3 points on the Alzheimer's Disease Assessment Scale--Cognitive Subscale (ADAS-Cog), +1 points on the Clinical Dementia Rating scale sum of boxes (CDR-SB), -5 points on the integrated Alzheimer's Disease Rating Scale (iADRS), or -1 to -2 points on the Mini-Mental State Examination (MMSE) was considered meaningful. For patients with mild AD, a change of +3 on the ADAS-Cog, +2 points on CDR-SB, -9 points on the iADRS, or -2 points on the MMSE was considered meaningful. For patients with moderate to severe AD, a change of +2 points on the CDR-SB or a change of -1.4 to -3 points on the MMSE was considered meaningful. CONCLUSION This review identified previously published MCIDs for AD trial endpoints. Input from patients and caregivers will be needed to derive more meaningful endpoints and thresholds. Highlights This systematic rapid review identified thresholds for minimal clinically important differences (MCIDs) for recently used Alzheimer's disease (AD) trial endpoints: Alzheimer's Disease Assessment Scale--Cognitive Subscale (ADAS-Cog), Clinical Dementia Rating scale sum of boxes (CDR-SB), integrated Alzheimer's Disease Rating Scale (iADRS), Mini-Mental State Examination (MMSE). MCIDs were higher for more severe stages of AD. Average treatment effects in recent trials of anti-amyloid disease modifying monoclonal antibodies are lower than previously published MCIDs. In future trials of disease modifying treatments for AD, the proportion of participants in each treatment group that experienced a clinically meaningful decline could be reported. More work is needed to incorporate the values and preferences of patients and care partners in deriving MCIDs.},
  langid = {english},
  keywords = {Alzheimer's disease,clinical trial,minimal clinically important difference},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/muir et al_2024_minimal clinically important difference in alzheimer's disease.pdf;/Users/zenn/Zotero/storage/U5PQIPGH/alz.html}
}

@article{mulnard2000alzheimer,
  title = {For the {{Alzheimer}}'s {{Disease Cooperative Study}}: {{Estrogen}} Replacement Therapy for Treatment of Mild to Moderate {{Alzheimer}} Disease: A Randomized Controlled Trial},
  author = {Mulnard, {\relax RA} and Cotman, {\relax CW} and Kawas, C and Van Dyck, {\relax CH} and Sano, M and Doody, R and Koss, E and Pfeiffer, E and Jin, S and Gamst, A and others},
  year = {2000},
  journal = {JAMA : the journal of the American Medical Association},
  volume = {283},
  number = {1007},
  pages = {15}
}

@article{mulnard2000estrogen,
  title = {Estrogen Replacement Therapy for Treatment of Mild to Moderate {{Alzheimer}} Disease: A Randomized Controlled Trial},
  author = {Mulnard, Ruth A and Cotman, Carl W and Kawas, Claudia and {van Dyck}, Christopher H and Sano, Mary and Doody, Rachelle and Koss, Elizabeth and Pfeiffer, Eric and Jin, Shelia and Gamst, Anthony and others},
  year = {2000},
  journal = {JAMA : the journal of the American Medical Association},
  volume = {283},
  number = {8},
  pages = {1007--1015},
  publisher = {American Medical Association}
}

@article{MultiscaleClosedloopNeurotoxicity,
  title = {A Multiscale Closed-Loop Neurotoxicity Model of {{Alzheimer}}'s Disease Progression Explains Functional Connectivity Alterations},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/GGYRK3K2/A multiscale closed-loop neurotoxicity model of Al.pdf}
}

@article{Nader2020,
  title = {Simulating the Outcome of Amyloid Treatments in {{Alzheimer}} ' s {{Disease}} from Multi-Modal Imaging and Clinical Data},
  author = {Nader, Cl{\'e}ment Abi and Ayache, Nicholas and Frisoni, Giovanni B and Robert, Philippe},
  year = {2020},
  journal = {BioArvix},
  pages = {1--25},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/nader et al_2020_simulating the outcome of amyloid treatments in alzheimer ’ s disease from.pdf}
}

@misc{nakagawaApproximationProbabilityDensity2021,
  title = {Approximation to Probability Density Functions in Sampling Distributions Based on {{Fourier}} Cosine Series},
  author = {Nakagawa, Shigekazu and Hashiguchi, Hiroki and Ono, Yoko},
  year = {2021},
  month = apr,
  number = {arXiv:2103.11712},
  eprint = {2103.11712},
  primaryclass = {math, stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2103.11712},
  urldate = {2023-03-01},
  abstract = {We derive a simple and precise approximation to probability density functions in sampling distributions based on the Fourier cosine series. After clarifying the required conditions, we illustrate the approximation on two examples: the distribution of the sum of uniformly distributed random variables, and the distribution of sample skewness drawn from a normal population. The probability density function of the first example can be explicitly expressed, but that of the second example has no explicit expression.},
  archiveprefix = {arXiv},
  keywords = {62E15,Mathematics - Statistics Theory,Statistics - Computation},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/nakagawa et al_2021_approximation to probability density functions in sampling distributions based.pdf;/Users/zenn/Zotero/storage/KLTWXQAI/2103.html}
}

@article{nakagawaGeneralSimpleMethod2013,
  title = {A General and Simple Method for Obtaining {{R2}} from Generalized Linear Mixed-Effects Models},
  author = {Nakagawa, Shinichi and Schielzeth, Holger},
  year = {2013},
  journal = {Methods in Ecology and Evolution},
  volume = {4},
  number = {2},
  pages = {133--142},
  issn = {2041-210X},
  doi = {10.1111/j.2041-210x.2012.00261.x},
  urldate = {2022-10-31},
  abstract = {The use of both linear and generalized linear mixed-effects models (LMMs and GLMMs) has become popular not only in social and medical sciences, but also in biological sciences, especially in the field of ecology and evolution. Information criteria, such as Akaike Information Criterion (AIC), are usually presented as model comparison tools for mixed-effects models. The presentation of `variance explained' (R2) as a relevant summarizing statistic of mixed-effects models, however, is rare, even though R2 is routinely reported for linear models (LMs) and also generalized linear models (GLMs). R2 has the extremely useful property of providing an absolute value for the goodness-of-fit of a model, which cannot be given by the information criteria. As a summary statistic that describes the amount of variance explained, R2 can also be a quantity of biological interest. One reason for the under-appreciation of R2 for mixed-effects models lies in the fact that R2 can be defined in a number of ways. Furthermore, most definitions of R2 for mixed-effects have theoretical problems (e.g. decreased or negative R2 values in larger models) and/or their use is hindered by practical difficulties (e.g. implementation). Here, we make a case for the importance of reporting R2 for mixed-effects models. We first provide the common definitions of R2 for LMs and GLMs and discuss the key problems associated with calculating R2 for mixed-effects models. We then recommend a general and simple method for calculating two types of R2 (marginal and conditional R2) for both LMMs and GLMMs, which are less susceptible to common problems. This method is illustrated by examples and can be widely employed by researchers in any fields of research, regardless of software packages used for fitting mixed-effects models. The proposed method has the potential to facilitate the presentation of R2 for a wide range of circumstances.},
  langid = {english},
  keywords = {coefficient of determination,goodness-of-fit,heritability,information criteria,intra-class correlation,linear models,model fit,repeatability,variance explained},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/nakagawa_schielzeth_2013_a general and simple method for obtaining r2 from generalized linear.pdf;/Users/zenn/Zotero/storage/LRJ866TY/j.2041-210x.2012.00261.html}
}

@article{nashPowerSamplesizeCalculations2021,
  title = {Power and Sample-Size Calculations for Trials That Compare Slopes over Time: {{Introducing}} the Slopepower Command},
  shorttitle = {Power and Sample-Size Calculations for Trials That Compare Slopes over Time},
  author = {Nash, Stephen and Morgan, Katy E. and Frost, Chris and Mulick, Amy},
  year = {2021},
  month = sep,
  journal = {The Stata Journal},
  volume = {21},
  number = {3},
  pages = {575--601},
  publisher = {SAGE Publications},
  issn = {1536-867X},
  doi = {10.1177/1536867X211045512},
  urldate = {2022-10-20},
  abstract = {Trials of interventions that aim to slow disease progression may analyze a continuous outcome by comparing its change over time?its slope?between the treated and the untreated group using a linear mixed model. To perform a sample-size calculation for such a trial, one must have estimates of the parameters that govern the between- and within-subject variability in the outcome, which are often unknown. The algebra needed for the sample-size calculation can also be complex for such trial designs. We have written a new user-friendly command, slopepower, that performs sample-size or power calculations for trials that compare slope outcomes. The package is based on linear mixed-model methodology, described for this setting by Frost, Kenward, and Fox (2008, Statistics in Medicine 27: 3717?3731). In the first stage of this approach, slopepower obtains estimates of mean slopes together with variances and covariances from a linear mixed model fit to previously collected user-supplied data. In the second stage, these estimates are combined with user input about the target effectiveness of the treatment and design of the future trial to give an estimate of either a sample size or a statistical power. In this article, we present the slopepower command, briefly explain the methodology behind it, and demonstrate how it can be used to help plan a trial and compare the sample sizes needed for different trial designs.},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/nash et al_2021_power and sample-size calculations for trials that compare slopes over time.pdf}
}

@misc{nativioChromatinConformationLandscape2024,
  title = {The Chromatin Conformation Landscape of {{Alzheimer}}'s Disease},
  author = {Nativio, Raffaella and Lan, Yemin and Donahue, Greg and Shcherbakova, Oksana and Barnett, Noah and Titus, Katelyn R. and Chandrashekar, Harshini and {Phillips-Cremins}, Jennifer E. and Bonini, Nancy M. and Berger, Shelley L.},
  year = {2024},
  month = apr,
  primaryclass = {New Results},
  pages = {2024.04.09.588722},
  publisher = {bioRxiv},
  doi = {10.1101/2024.04.09.588722},
  urldate = {2024-04-14},
  abstract = {We have been investigating epigenetic alterations in the brain during human aging and Alzheimer's disease (AD), and have evidence for histone acetylation both protecting the aging epigenome and driving AD. Here we extend our studies to chromatin architecture via looping studies, and with binding studies of key proteins required for looping: CTCF and RAD21. We detected changes in CTCF and RAD21 levels and localization, finding major changes in CTCF in AD compared to fewer changes in healthy aging. In our study of 3D genome conformation changes, we identified stable topological associating domains (TADs) in Old and AD; in contrast, in AD, there is loss of interaction at genomic sites/loops within TADs, likely reflecting the loss of CTCF. We identified genes and potential transcription factor binding at the loops that are lost in AD. in addition, we found enrichment of CTCF peak losses for AD eQTLs, suggesting that architectural dysfunction has a role in Alzheimer's. Functional experiments lowering the homologues of several key genes in a Drosophila model of A{$\beta$}42 toxicity exacerbate neurodegeneration. Taken together, these data indicate both functional protections and losses occur in the Alzheimer's brain genome compared to normal aging.},
  archiveprefix = {bioRxiv},
  chapter = {New Results},
  copyright = {{\copyright} 2024, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/nativio et al_2024_the chromatin conformation landscape of alzheimer's disease.pdf}
}

@article{neilPracticalVimEdit2015,
  title = {Practical {{Vim}} : {{Edit Text}} at the {{Speed}} of {{Thought}}},
  shorttitle = {Practical {{Vim}}},
  author = {Neil, Drew},
  year = {2015},
  pages = {1--356},
  publisher = {The Pragmatic Bookshelf},
  urldate = {2023-09-05},
  abstract = {Purchase online the PDF of Practical Vim, Neil, Drew - The Pragmatic Bookshelf - E-book},
  langid = {english}
}

@article{newmanTreatmentProgressiveSupranuclear1985,
  title = {Treatment of Progressive Supranuclear Palsy with Tricyclic Antidepressants},
  author = {Newman, G. C.},
  year = {1985},
  month = aug,
  journal = {Neurology},
  volume = {35},
  number = {8},
  pages = {1189--1193},
  issn = {0028-3878},
  doi = {10.1212/wnl.35.8.1189},
  abstract = {After a single patient with progressive supranuclear palsy (PSP) improved when given amitriptyline, we compared the effects of amitriptyline, desipramine, and placebo on the symptoms and signs of four patients with PSP in a double-blind, double-crossover manner. There was good correlation between the use of tricyclic agents and symptomatic improvement, although all patients remained disabled. Amitriptyline produced better overall improvement, whereas desipramine preferentially improved apraxia of eyelid opening.},
  langid = {english},
  pmid = {3895032},
  keywords = {Aged,Amitriptyline,Antidepressive Agents Tricyclic,Bulbar Palsy Progressive,Clinical Trials as Topic,Desipramine,Disability Evaluation,Eye Movements,Female,Humans,Male,Middle Aged}
}

@article{newsPersonalizedMedicineTime,
  title = {Personalized Medicine: Time for One-Person Trials},
  author = {News, NJ Schork - Nature and 2015, undefined},
  journal = {nature.com},
  urldate = {2021-11-06},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/news_2015_personalized medicine.pdf}
}

@article{nguy2021,
  title = {A {{Probabilistic Approach}} to {{The Moments}} of {{Binomial Random Variables}} and {{Application}}},
  author = {Nguyen, Duy},
  year = {2021},
  journal = {American Statistician},
  volume = {75},
  number = {1},
  pages = {101--103},
  publisher = {Teacher's Corner},
  issn = {15372731},
  doi = {10.1080/00031305.2019.1679257},
  abstract = {In this paper, we provide a closed form formula for the moments of binomial random variables using a probabilistic approach. As an interesting application, we give a closed form formula for the sum (Formula presented.).},
  keywords = {Binomial distribution,marginal density function,moment},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/nguyen_2021_a probabilistic approach to the moments of binomial random variables and.pdf}
}

@article{Nguyen2019,
  title = {Predicting {{Alzheimer}} ' s Disease Progression Using Deep Recurrent Neural Networks},
  author = {Nguyen, Minh and He, Tong and An, Lijun and Alexander, Daniel C and Feng, Jiashi and Thomas, B T},
  year = {2019},
  journal = {bioRxiv},
  pages = {1--35},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/nguyen et al_2019_predicting alzheimer ’ s disease progression using deep recurrent neural.pdf}
}

@article{nicollPersistentNeuropathologicalEffects2019,
  title = {Persistent Neuropathological Effects 14 Years Following Amyloid-{$\beta$} Immunization in {{Alzheimer}}'s Disease},
  author = {Nicoll, James A. R. and Buckland, George R. and Harrison, Charlotte H. and Page, Anton and Harris, Scott and Love, Seth and Neal, James W. and Holmes, Clive and Boche, Delphine},
  year = {2019},
  month = jul,
  journal = {Brain: A Journal of Neurology},
  volume = {142},
  number = {7},
  pages = {2113--2126},
  issn = {1460-2156},
  doi = {10.1093/brain/awz142},
  abstract = {We performed a 15-year post-mortem neuropathological follow-up of patients in the first trial of amyloid-{$\beta$} immunotherapy for Alzheimer's disease. Twenty-two participants of a clinical trial of active amyloid-{$\beta$}42 immunization (AN1792, Elan Pharmaceuticals) or placebo were studied. Comprehensive post-mortem neuropathological assessments were performed from 4 months to 15 years after the trial. We analysed the relationships between the topographical distribution of amyloid-{$\beta$} removal from the cerebral cortex and tau pathology, cerebrovascular territories, plasma anti-AN1792 antibody titres and late cognitive status. Seventeen of 22 (77\%) participants had Alzheimer's neuropathological change, whereas 5 of 22 (23\%) had alternative causes for dementia (progressive supranuclear palsy = 1, Lewy body disease = 1, vascular brain injury = 1, and frontotemporal lobar degeneration = 2). Nineteen of the 22 participants had received the active agent, three the placebo. Fourteen of 16 (88\%) patients with Alzheimer's disease receiving the active agent had evidence of plaque removal (very extensive removal = 5, intermediate = 4, very limited = 5, no removal = 2). Of particular note, two Alzheimer's patients who died 14 years after immunization had only very sparse or no detectable plaques in all regions examined. There was a significant inverse correlation between post-vaccination peripheral blood anti-AN1792 antibody titres and post-mortem plaque scores ({$\rho$} = - 0.664, P = 0.005). Cortical foci cleared of plaques contained less tau than did cortex with remaining plaques, but the overall distribution of tangles was extensive (Braak V/VI). In conclusion, patients with Alzheimer's disease actively immunized against amyloid-{$\beta$} can remain virtually plaque-free for 14 years. The extent of plaque removal is related to the immune response. This long duration of efficacy is important in support of active immunization protocols as therapy for, or potentially prevention of, neurodegeneration-associated protein accumulations. Inclusion of patients without Alzheimer's disease in Alzheimer's therapy trials is a problem for assessing the efficacy of treatment. Despite modification of Alzheimer's pathology, most patients had progressed to severe dementia, notably including the five with very extensive plaque removal, possibly due to continued tau propagation. Neuropathology follow-up of patients in therapeutic trials provides valuable information on the causes of dementia and effects of treatment.},
  langid = {english},
  pmcid = {PMC6598630},
  pmid = {31157360},
  keywords = {Aged,Aged 80 and over,Alzheimer Disease,Alzheimer's disease,Amyloid beta-Peptides,amyloid-,Antibodies,Cerebral Cortex,Clinical Trials as Topic,dementia,Dementia,Follow-Up Studies,Humans,Immunization,immunotherapy,Middle Aged,Neurodegenerative Diseases,neuropathology,Peptide Fragments,Plaque Amyloid,tau Proteins,Time Factors},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/nicoll et al_2019_persistent neuropathological effects 14 years following amyloid-β immunization.pdf}
}

@article{niewczasInterimAnalysisIncorporating2019,
  title = {Interim Analysis Incorporating Short-and Long-Term Binary Endpoints},
  author = {Niewczas, Julia and Kunz, Cornelia U. and K{\"o}nig, Franz},
  year = {2019},
  journal = {Biometrical Journal},
  volume = {61},
  number = {3},
  pages = {665--687},
  publisher = {Wiley Online Library},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/niewczas et al_2019_interim analysis incorporating short-and long-term binary endpoints.pdf;/Users/zenn/Zotero/storage/J3YHTIMN/bimj.html}
}

@article{nobleQuickGuideOrganizing2009,
  title = {A Quick Guide to Organizing Computational Biology Projects},
  author = {Noble, William Stafford},
  year = {2009},
  month = jul,
  journal = {PLoS Computational Biology},
  volume = {5},
  number = {7},
  issn = {1553734X},
  doi = {10.1371/JOURNAL.PCBI.1000424},
  urldate = {2022-06-09},
  pmid = {19649301},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/noble_2009_a quick guide to organizing computational biology projects.pdf}
}

@article{NoTitle2019,
  title = {({{No Title}})},
  year = {2019},
  doi = {10.1111/eci.13145},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/2019_(no title).pdf}
}

@article{nustRockerversePackagesApplications2020,
  title = {The {{Rockerverse}}: {{Packages}} and {{Applications}} for {{Containerization}} with {{R}}},
  shorttitle = {The {{Rockerverse}}},
  author = {N{\"u}st, Daniel and Eddelbuettel, Dirk and Bennett, Dom and Cannoodt, Robrecht and Clark, Dav and Daroczi, Gergely and Edmondson, Mark and Fay, Colin and Hughes, Ellis and Kjeldgaard, Lars and Lopp, Sean and Marwick, Ben and Nolis, Heather and Nolis, Jacqueline and Ooi, Hong and Ram, Karthik and Ross, Noam and Shepherd, Lori and S{\'o}lymos, P{\'e}ter and Swetnam, Tyson Lee and Turaga, Nitesh and Van Petegem, Charlotte and Williams, Jason and Willis, Craig and Xiao, Nan},
  year = {2020},
  journal = {The R Journal},
  volume = {12},
  number = {1},
  eprint = {2001.10641},
  primaryclass = {cs},
  pages = {437},
  issn = {2073-4859},
  doi = {10.32614/RJ-2020-007},
  urldate = {2023-06-22},
  abstract = {The Rocker Project provides widely used Docker images for R across different application scenarios. This article surveys downstream projects that build upon the Rocker Project images and presents the current state of R packages for managing Docker images and controlling containers. These use cases cover diverse topics such as package development, reproducible research, collaborative work, cloud-based data processing, and production deployment of services. The variety of applications demonstrates the power of the Rocker Project specifically and containerisation in general. Across the diverse ways to use containers, we identified common themes: reproducible environments, scalability and efficiency, and portability across clouds. We conclude that the current growth and diversification of use cases is likely to continue its positive impact, but see the need for consolidating the Rockerverse ecosystem of packages, developing common practices for applications, and exploring alternative containerisation software.},
  archiveprefix = {arXiv},
  keywords = {68N01,Computer Science - Distributed Parallel and Cluster Computing,Computer Science - Software Engineering,D.2.6,D.2.7,K.6.3},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/nüst et al_2020_the rockerverse.pdf;/Users/zenn/Zotero/storage/ZNUWEFFZ/2001.html}
}

@article{nustRockerversePackagesApplications2020a,
  title = {The {{Rockerverse}}: {{Packages}} and {{Applications}} for {{Containerization}} with {{R}}},
  shorttitle = {The {{Rockerverse}}},
  author = {N{\"u}st, Daniel and Eddelbuettel, Dirk and Bennett, Dom and Cannoodt, Robrecht and Clark, Dav and Daroczi, Gergely and Edmondson, Mark and Fay, Colin and Hughes, Ellis and Kjeldgaard, Lars and Lopp, Sean and Marwick, Ben and Nolis, Heather and Nolis, Jacqueline and Ooi, Hong and Ram, Karthik and Ross, Noam and Shepherd, Lori and S{\'o}lymos, P{\'e}ter and Swetnam, Tyson Lee and Turaga, Nitesh and Van Petegem, Charlotte and Williams, Jason and Willis, Craig and Xiao, Nan},
  year = {2020},
  journal = {The R Journal},
  volume = {12},
  number = {1},
  eprint = {2001.10641},
  primaryclass = {cs},
  pages = {437},
  issn = {2073-4859},
  doi = {10.32614/RJ-2020-007},
  urldate = {2023-07-10},
  abstract = {The Rocker Project provides widely used Docker images for R across different application scenarios. This article surveys downstream projects that build upon the Rocker Project images and presents the current state of R packages for managing Docker images and controlling containers. These use cases cover diverse topics such as package development, reproducible research, collaborative work, cloud-based data processing, and production deployment of services. The variety of applications demonstrates the power of the Rocker Project specifically and containerisation in general. Across the diverse ways to use containers, we identified common themes: reproducible environments, scalability and efficiency, and portability across clouds. We conclude that the current growth and diversification of use cases is likely to continue its positive impact, but see the need for consolidating the Rockerverse ecosystem of packages, developing common practices for applications, and exploring alternative containerisation software.},
  archiveprefix = {arXiv},
  keywords = {68N01,Computer Science - Distributed Parallel and Cluster Computing,Computer Science - Software Engineering,D.2.6,D.2.7,K.6.3},
  file = {/Users/zenn/Zotero/storage/PQ8U3RL4/Nüst et al. - 2020 - The Rockerverse Packages and Applications for Con.pdf;/Users/zenn/Zotero/storage/NGW9P77A/2001.html}
}

@article{objectIndependentIncrementsGroup,
  title = {Independent Increments in Group Sequential Tests : A Review},
  shorttitle = {Independent Increments in Group Sequential Tests},
  author = {Object, object},
  urldate = {2024-03-20},
  abstract = {In order to apply group sequential methods for interim analysis for early stopping in clinical trials, the joint distribution of test statistics over time has to be known. Often the distribution is multivariate normal or asymptotically so, and an application of group sequential methods requires multivariate integration to determine the group sequential boundaries. However, if the increments between successive test statistics are independent, the multivariate integration reduces to a univariate integration involving simple recursion based on convolution. This allows application of standard group sequential methods. In this paper we review group sequential methods and the development that established independent increments in test statistics for the primary outcomes of longitudinal or failure time data},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/object_independent increments in group sequential tests.pdf}
}

@article{offenbacherProgressivePeriodontalDisease2006,
  title = {Progressive {{Periodontal Disease}} and {{Risk}} of {{Very Preterm Delivery}}},
  author = {Offenbacher, Steven and Boggess, Kim A and Murtha, Amy P and Jared, Heather L and Lieff, Susan and McKaig, Rosemary G and Mauriello, Sally M and Moss, Kevin L and Beck, James D},
  year = {2006},
  volume = {107},
  number = {1},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/6JU86GQI/Offenbacher et al. - 2006 - Progressive Periodontal Disease and Risk of Very P.pdf}
}

@article{offenbacherProgressivePeriodontalDisease2006a,
  title = {Progressive {{Periodontal Disease}} and {{Risk}} of {{Very Preterm Delivery}}},
  author = {Offenbacher, Steven and Boggess, Kim A. and Murtha, Amy P. and Jared, Heather L. and Lieff, Susan and McKaig, Rosemary G. and Mauriello, Sally M. and Moss, Kevin L. and Beck, James D.},
  year = {2006},
  month = jan,
  journal = {Obstetrics \& Gynecology},
  volume = {107},
  number = {1},
  pages = {29},
  issn = {0029-7844},
  doi = {10.1097/01.AOG.0000190212.87012.96},
  urldate = {2024-02-27},
  abstract = {OBJECTIVE:~           The goal was to estimate whether maternal periodontal disease was predictive of preterm (less than 37 weeks) or very preterm (less than 32 weeks) births.           METHODS:~           A prospective study of obstetric outcomes, entitled Oral Conditions and Pregnancy (OCAP), was conducted with 1,020 pregnant women who received both an antepartum and postpartum periodontal examination. Predictive models were developed to estimate whether maternal exposure to either periodontal disease at enrollment (less than 26 weeks) and/or periodontal disease progression during pregnancy, as determined by comparing postpartum with antepartum status, were predictive of preterm or very preterm births, adjusting for risk factors including previous preterm delivery, race, smoking, social domain variables, and other infections.           RESULTS:~           Incidence of preterm birth was 11.2\% among periodontally healthy women, compared with 28.6\% in women with moderate-severe periodontal disease (adjusted risk ratio [RR] 1.6, 95\% confidence interval [CI] 1.1--2.3). Antepartum moderate-severe periodontal disease was associated with an increased incidence of spontaneous preterm births (15.2\% versus 24.9\%, adjusted RR 2.0, 95\% CI 1.2--3.2). Similarly, the unadjusted rate of very preterm delivery was 6.4\% among women with periodontal disease progression, significantly higher than the 1.8\% rate among women without disease progression (adjusted RR 2.4, 95\% CI 1.1--5.2).           CONCLUSION:~           The OCAP study demonstrates that maternal periodontal disease increases relative risk for preterm or spontaneous preterm births. Furthermore, periodontal disease progression during pregnancy was a predictor of the more severe adverse pregnancy outcome of very preterm birth, independently of traditional obstetric, periodontal, and social domain risk factors.           LEVEL OF EVIDENCE:~           II-2},
  langid = {american},
  file = {/Users/zenn/Zotero/storage/H2N2HFDN/Periodontal_Disease_and_Upper_Genital_Tract.7.html}
}

@article{offenbacherProgressivePeriodontalDisease2006b,
  title = {Progressive Periodontal Disease and Risk of Very Preterm Delivery},
  author = {Offenbacher, Steven and Boggess, Kim A. and Murtha, Amy P. and Jared, Heather L. and Lieff, Susan and McKaig, Rosemary G. and Mauriello, Sally M. and Moss, Kevin L. and Beck, James D.},
  year = {2006},
  journal = {Obstetrics \& Gynecology},
  volume = {107},
  number = {1},
  pages = {29--36},
  publisher = {LWW},
  urldate = {2024-02-27},
  file = {/Users/zenn/Zotero/storage/ZPDWUA6B/Periodontal_Disease_and_Upper_Genital_Tract.7.html}
}

@article{ofMatchingSequencesDeletion,
  title = {Matching Sequences under Deletion/Insertion Constraints},
  author = {{of}, D Sankoff - Proceedings of the National Academy and 1972, undefined},
  journal = {National Acad Sciences},
  urldate = {2018-09-01},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/of_1972_matching sequences under deletion-insertion constraints.pdf}
}

@misc{olaimatPPADDeepLearning2023,
  title = {{{PPAD}}: {{A}} Deep Learning Architecture to Predict Progression of {{Alzheimer}}'s Disease},
  shorttitle = {{{PPAD}}},
  author = {Olaimat, Mohammad Al and Martinez, Jared and Saeed, Fahad and Bozdag, Serdar and Initiative, Alzheimer's Disease Neuroimaging},
  year = {2023},
  month = jan,
  primaryclass = {New Results},
  pages = {2023.01.28.526045},
  publisher = {bioRxiv},
  doi = {10.1101/2023.01.28.526045},
  urldate = {2023-02-02},
  abstract = {Alzheimer's disease (AD) is a neurodegenerative disease that affects millions of people worldwide. Mild cognitive impairment (MCI) is an intermediary stage between cognitively normal (CN) state and AD. Not all people who have MCI convert to AD. The diagnosis of AD is made after significant symptoms of dementia such as short-term memory loss are already present. Since AD is currently an irreversible disease, diagnosis at the onset of disease brings a huge burden on patients, their caregivers, and the healthcare sector. Thus, there is a crucial need to develop methods for the early prediction AD for patients who have MCI. Recurrent Neural Networks (RNN) have been successfully used to handle Electronic Health Records (EHR) for predicting conversion from MCI to AD. However, RNN ignores irregular time intervals between successive events which occurs common in EHR data. In this study, we propose two deep learning architectures based on RNN, namely Predicting Progression of Alzheimer's Disease (PPAD) and PPAD-Autoencoder (PPAD-AE). PPAD and PPAD-AE are designed for early predicting conversion from MCI to AD at the next visit and multiple visits ahead for patients, respectively. To minimize the effect of the irregular time intervals between visits, we propose using age in each visit as an indicator of time change between successive visits. Our experimental results conducted on Alzheimer's Disease Neuroimaging Initiative (ADNI) and National Alzheimer's Coordinating Center (NACC) datasets showed that our proposed models outperformed all baseline models for most prediction scenarios in terms of F2 and sensitivity. We also observed that the age feature was one of top features and was able to address irregular time interval problem.},
  archiveprefix = {bioRxiv},
  chapter = {New Results},
  copyright = {{\copyright} 2023, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/olaimat et al_2023_ppad.pdf}
}

@article{olin1999clinical,
  title = {Clinical Symptoms of Dementia with {{Lewy}} Bodies: {{Secondary}} Analyses of the {{Alzheimer}}'s Disease Cooperative Study Selegiline and Vitamin {{E}} Clinical Trial},
  author = {Olin, {\relax JT} and Papka, M and Jin, S and Sano, M and Grundman, M and Thomas, R},
  year = {1999},
  journal = {European Neuropsychopharmacology},
  number = {9},
  pages = {323}
}

@article{oliveiraDiscussionSignificanceIndices2018,
  title = {A Discussion on Significance Indices for Contingency Tables under Small Sample Sizes},
  author = {Oliveira, Natalia L. and Pereira, Carlos A. de B. and Diniz, Marcio A. and Polpo, Adriano},
  year = {2018},
  month = aug,
  journal = {PLOS ONE},
  volume = {13},
  number = {8},
  pages = {e0199102},
  publisher = {Public Library of Science},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0199102},
  urldate = {2023-08-12},
  abstract = {Hypothesis testing in contingency tables is usually based on asymptotic results, thereby restricting its proper use to large samples. To study these tests in small samples, we consider the likelihood ratio test (LRT) and define an accurate index for the celebrated hypotheses of homogeneity, independence, and Hardy-Weinberg equilibrium. The aim is to understand the use of the asymptotic results of the frequentist Likelihood Ratio Test and the Bayesian FBST (Full Bayesian Significance Test) under small-sample scenarios. The proposed exact LRT p-value is used as a benchmark to understand the other indices. We perform analysis in different scenarios, considering different sample sizes and different table dimensions. The conditional Fisher's exact test for 2 {\texttimes} 2 tables and the Barnard's exact test are also discussed. The main message of this paper is that all indices have very similar behavior, except for Fisher and Barnard tests that has a discrete behavior. The most powerful test was the asymptotic p-value from the likelihood ratio test, suggesting that is a good alternative for small sample sizes.},
  langid = {english},
  keywords = {Animal behavior,Chi square tests,Contingency tables,Power grids,Random variables,Statistical distributions,Test statistics,Variant genotypes},
  file = {/Users/zenn/Zotero/storage/TLR8K98H/Oliveira et al. - 2018 - A discussion on significance indices for contingen.pdf}
}

@misc{onisiforouViralInfectionsAlzheimer2023,
  title = {From {{Viral Infections}} to {{Alzheimer}}'s {{Disease}}: {{Unveiling}} the {{Mechanistic Links Through Systems Bioinformatics}}},
  shorttitle = {From {{Viral Infections}} to {{Alzheimer}}'s {{Disease}}},
  author = {Onisiforou, Anna and Zanos, Panos},
  year = {2023},
  month = dec,
  primaryclass = {New Results},
  pages = {2023.12.05.570187},
  publisher = {bioRxiv},
  doi = {10.1101/2023.12.05.570187},
  urldate = {2024-01-19},
  abstract = {Background Emerging evidence suggests that certain microorganisms, including viral infections, may contribute to the onset and/or progression of Alzheimer's Disease (AD), a neurodegenerative condition characterized by memory impairment and cognitive decline. However, the precise extent of their involvement and the underlying mechanisms through which specific viruses increase AD susceptibility risk remain elusive. Methods We used an integrative systems bioinformatics approach to identity viral-mediated pathogenic mechanisms by which specific viral species, namely Herpes Simplex Virus 1 (HSV-1), Human Cytomegalovirus (HCMV), Epstein-Barr Virus (EBV), Kaposi Sarcoma-associated Herpesvirus (KSHV), Hepatitis B Virus (HBV), Hepatitis C Virus (HCV), Influenza A virus (IAV) and Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2), could facilitate the pathogenesis of AD via virus-host protein-protein interactions (PPIs). We also sought to uncover potential synergistic pathogenic effects resulting from the reactivation of specific herpesviruses (HSV-1, HCMV and EBV) during acute SARS-CoV-2 infection, potentially increasing AD susceptibility. Results Our findings show that Herpesviridae Family members (HSV-1, EBV, KSHV, HCMV) impact AD-related processes like amyloid-beta formation, neuronal death, and autophagy. Hepatitis viruses (HBV, HCV) influence processes crucial for cellular homeostasis and dysfunction. Importantly, hepatitis viruses affect microglia activation via virus-host PPIs. Reactivation of HCMV during SARS-CoV-2 infection could potentially foster a lethal interplay of neurodegeneration, via synergistic pathogenic effects on AD-related processes like response to unfolded protein, regulation of autophagy, response to oxidative stress and amyloid-beta formation. Conclusions Collectively, these findings underscore the complex link between viral infections and AD development. Perturbations in AD-related processes by viruses can arise from both shared and distinct mechanisms among viral species in different categories, potentially influencing variations in AD susceptibility.},
  archiveprefix = {bioRxiv},
  chapter = {New Results},
  copyright = {{\copyright} 2023, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/GY5K5RX8/Onisiforou and Zanos - 2023 - From Viral Infections to Alzheimer’s Disease Unve.pdf}
}

@article{oosthoekUtilizationFluidbasedBiomarkers2024,
  title = {Utilization of Fluid-Based Biomarkers as Endpoints in Disease-Modifying Clinical Trials for {{Alzheimer}}'s Disease: A Systematic Review},
  shorttitle = {Utilization of Fluid-Based Biomarkers as Endpoints in Disease-Modifying Clinical Trials for {{Alzheimer}}'s Disease},
  author = {Oosthoek, Marlies and Vermunt, Lisa and {de Wilde}, Arno and Bongers, Bram and {Antwi-Berko}, Daniel and Scheltens, Philip and {van Bokhoven}, Pieter and Vijverberg, Everard G. B. and Teunissen, Charlotte E.},
  year = {2024},
  month = apr,
  journal = {Alzheimer's Research \& Therapy},
  volume = {16},
  number = {1},
  pages = {93},
  issn = {1758-9193},
  doi = {10.1186/s13195-024-01456-1},
  urldate = {2024-04-29},
  abstract = {Clinical trials in Alzheimer's disease (AD) had high failure rates for several reasons, including the lack of biological endpoints. Fluid-based biomarkers may present a solution to measure biologically relevant endpoints. It is currently unclear to what extent fluid-based biomarkers are applied to support drug development.},
  keywords = {Alzheimer,Clinical trial,Fluid-based biomarker},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/oosthoek et al_2024_utilization of fluid-based biomarkers as endpoints in disease-modifying.pdf;/Users/zenn/Zotero/storage/ARN6LMRE/s13195-024-01456-1.html}
}

@article{opelEffectsTraumaticBrain2019,
  title = {Effects of Traumatic Brain Injury on Sleep and Enlarged Perivascular Spaces},
  author = {Opel, Ryan A and Christy, Alison and Boespflug, Erin L and Weymann, Kristianna B and Case, Brendan and Pollock, Jeffery M and Silbert, Lisa C and Lim, Miranda M},
  year = {2019},
  month = nov,
  journal = {Journal of Cerebral Blood Flow \& Metabolism},
  volume = {39},
  number = {11},
  pages = {2258--2267},
  issn = {0271-678X},
  doi = {10.1177/0271678X18791632},
  urldate = {2023-11-13},
  abstract = {Clearance of perivascular wastes in the brain may be critical to the pathogenesis of amyloidopathies. Enlarged perivascular spaces (ePVS) on MRI have also been associated with amyloidopathies, suggesting that there may be a mechanistic link between ePVS and impaired clearance. Sleep and traumatic brain injury (TBI) both modulate clearance of amyloid-beta through glymphatic function. Therefore, we sought to evaluate the relationship between sleep, TBI, and ePVS on brain MRI. A retrospective study was performed in individuals with overnight polysomnography and 3T brain MRI consented from a single site (n\,=\,38). Thirteen of these individuals had a medically confirmed history of TBI. ePVS were visually assessed by blinded experimenters and analyzed in conjunction with sleep metrics and TBI status. Overall, individuals with shorter total sleep time had significantly higher ePVS burden. Furthermore, individuals with TBI showed a stronger relationship between sleep and ePVS compared to the non-TBI group. These results support the hypothesis that ePVS may be modulated by sleep and TBI, and may have implications for the role of the glymphatic system in ePVS.},
  pmcid = {PMC6827121},
  pmid = {30092696},
  file = {/Users/zenn/Zotero/storage/VRGYJFAE/Opel et al. - 2019 - Effects of traumatic brain injury on sleep and enl.pdf}
}

@article{oquigleyContinualReassessmentMethod1996,
  title = {Continual {{Reassessment Method}}: {{A Likelihood Approach}}},
  shorttitle = {Continual {{Reassessment Method}}},
  author = {O'Quigley, John and Shen, Larry Z.},
  year = {1996},
  journal = {Biometrics},
  volume = {52},
  number = {2},
  eprint = {2532905},
  eprinttype = {jstor},
  pages = {673--684},
  publisher = {[Wiley, International Biometric Society]},
  issn = {0006-341X},
  doi = {10.2307/2532905},
  urldate = {2024-03-19},
  abstract = {The continual reassessment method as described by O'Quigley, Pepe, and Fisher (1990, Biometrics 46, 33-48) leans to a large extent upon a Bayesian methodology. Initial experimentation and sequential updating are carried out in a natural way within the context of a Bayesian framework. In this paper we argue that such a framework is easily changed to a more classic one leaning upon likelihood theory. The essential features of the continual reassessment method remain unchanged. In particular, large sample properties are the same unless the prior is degenerate. For small samples, and as far as the final recommended dose level is concerned, simulations indicate that there is not much to choose between a likelihood approach and a Bayesian one. However, for in-trial allocation of dose levels to patients, there are some differences and these are discussed. In contrast to the Bayesian approach, a likelihood one requires some extra effort to get off the ground. This is because the likelihood equation has no solution until we observe a toxicity. Initially then we suggest working with either a standard Up-and-Down scheme or standard continual reassessment method until toxicity is observed and then switching to the new scheme.},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/o'quigley_shen_1996_continual reassessment method.pdf}
}

@article{oquigleyExperimentalDesignsPhase2006,
  title = {Experimental Designs for Phase {{I}} and Phase {{I}}/{{II}} Dose-Finding Studies},
  author = {O'Quigley, J. and Zohar, S.},
  year = {2006},
  month = mar,
  journal = {British Journal of Cancer},
  volume = {94},
  number = {5},
  pages = {609--613},
  publisher = {Nature Publishing Group},
  issn = {1532-1827},
  doi = {10.1038/sj.bjc.6602969},
  urldate = {2024-03-19},
  abstract = {We review the rationale behind the statistical design of dose-finding studies as used in phase I and phase I/II clinical trials. We underline what the objectives of such dose-finding studies should be and why the widely used standard design fails to meet any of these objectives. The standard design is a `memoryless' design and we discuss how this impacts on practical behaviour. Designs introduced over the last two decades can be viewed as designs with memory and we discuss how these designs are superior to memoryless designs. By superior we mean that they require less patients overall, less patients to attain the maximum tolerated dose (MTD), and concentrate a higher percentage of patients at and near to the MTD. We reanalyse some recently published studies in order to provide support to our contention that markedly better results could have been achieved had a design with memory been used instead of a memoryless design.},
  copyright = {2006 The Author(s)},
  langid = {english},
  keywords = {Biomedicine,Cancer Research,Drug Resistance,Epidemiology,general,Molecular Medicine,Oncology},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/o'quigley_zohar_2006_experimental designs for phase i and phase i-ii dose-finding studies.pdf}
}

@article{oquigleyMethodsDoseFinding1991,
  title = {Methods for Dose Finding Studies in Cancer Clinical Trials: {{A}} Review and Results of a Monte Carlo Study},
  shorttitle = {Methods for Dose Finding Studies in Cancer Clinical Trials},
  author = {O'Quigley, John and Chevret, Sylvie},
  year = {1991},
  journal = {Statistics in Medicine},
  volume = {10},
  number = {11},
  pages = {1647--1664},
  issn = {1097-0258},
  doi = {10.1002/sim.4780101104},
  urldate = {2024-03-19},
  abstract = {We discuss some of the statistical approaches to the design and analysis of phase I clinical trials in cancer. An attempt is made to identify the issues, particular to this type of trial, that should be addressed by an appropriate methodology. A brief review of schemes currently in use is provided together with our views of the extent to which any particular scheme addresses the main issues. Some simulations are provided together with graphical illustration of the operating characteristics of the particular methods. It appears that the continual reassessment method is preferable to other contending schemes.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/8W552JNC/sim.html}
}

@article{oquigleyMethodsDoseFinding1991a,
  title = {Methods for Dose Finding Studies in Cancer Clinical Trials: {{A}} Review and Results of a Monte Carlo Study},
  shorttitle = {Methods for Dose Finding Studies in Cancer Clinical Trials},
  author = {O'Quigley, John and Chevret, Sylvie},
  year = {1991},
  journal = {Statistics in Medicine},
  volume = {10},
  number = {11},
  pages = {1647--1664},
  issn = {1097-0258},
  doi = {10.1002/sim.4780101104},
  urldate = {2024-03-19},
  abstract = {We discuss some of the statistical approaches to the design and analysis of phase I clinical trials in cancer. An attempt is made to identify the issues, particular to this type of trial, that should be addressed by an appropriate methodology. A brief review of schemes currently in use is provided together with our views of the extent to which any particular scheme addresses the main issues. Some simulations are provided together with graphical illustration of the operating characteristics of the particular methods. It appears that the continual reassessment method is preferable to other contending schemes.},
  copyright = {Copyright {\copyright} 1991 John Wiley \& Sons, Ltd.},
  langid = {english}
}

@misc{ortmannIntegralPointsPezzo2023,
  title = {Integral {{Points}} on a Del {{Pezzo Surface}} over {{Imaginary Quadratic Fields}}},
  author = {Ortmann, Judith},
  year = {2023},
  month = jul,
  number = {arXiv:2307.12877},
  eprint = {2307.12877},
  primaryclass = {math},
  publisher = {arXiv},
  urldate = {2023-07-25},
  abstract = {We characterise integral points of bounded log-anticanonical height on a quartic del Pezzo surface of singularity type A3 over imaginary quadratic fields with respect to its singularity and its lines. Furthermore, we count these integral points of bounded height by using universal torsors and interpret the count geometrically to prove an analogue of Manin's conjecture for the set of integral points with respect to the singularity and to a line.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {11D45 (Primary) 11G35 11R11 14G05 14J26 (Secondary),Mathematics - Algebraic Geometry,Mathematics - Number Theory},
  file = {/Users/zenn/Zotero/storage/PTZGVMD7/Ortmann - 2023 - Integral Points on a del Pezzo Surface over Imagin.pdf}
}

@article{overallRuleofthumbAdjustmentSample2006,
  title = {Rule-of-Thumb Adjustment of Sample Sizes to Accommodate Dropouts in a Two-Stage Analysis of Repeated Measurements},
  author = {Overall, John E. and Tonidandel, Scott and Starbuck, Robert R.},
  year = {2006},
  journal = {International Journal of Methods in Psychiatric Research},
  volume = {15},
  number = {1},
  pages = {1--11},
  issn = {1557-0657},
  doi = {10.1002/mpr.23},
  urldate = {2024-05-08},
  abstract = {Recent contributions to the statistical literature have provided elegant model-based solutions to the problem of estimating sample sizes for testing the significance of differences in mean rates of change across repeated measures in controlled longitudinal studies with differentially correlated error and missing data due to dropouts. However, the mathematical complexity and model specificity of these solutions make them generally inaccessible to most applied researchers who actually design and undertake treatment evaluation research in psychiatry. In contrast, this article relies on a simple two-stage analysis in which dropout-weighted slope coefficients fitted to the available repeated measurements for each subject separately serve as the dependent variable for a familiar ANCOVA test of significance for differences in mean rates of change. This article is about how a sample of size that is estimated or calculated to provide desired power for testing that hypothesis without considering dropouts can be adjusted appropriately to take dropouts into account. Empirical results support the conclusion that, whatever reasonable level of power would be provided by a given sample size in the absence of dropouts, essentially the same power can be realized in the presence of dropouts simply by adding to the original dropout-free sample size the number of subjects who would be expected to drop from a sample of that original size under conditions of the proposed study. Copyright {\copyright} 2006 John Wiley \& Sons, Ltd.},
  copyright = {Copyright {\copyright} 2006 John Wiley \& Sons, Ltd.},
  langid = {english},
  keywords = {constant power,dropouts,mixed models,repeated measures,sample size,two-stage analysis},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/overall et al_2006_rule-of-thumb adjustment of sample sizes to accommodate dropouts in a two-stage.pdf;/Users/zenn/Zotero/storage/75T6KSQ9/mpr.html}
}

@misc{OverviewModernApproaches,
  title = {Overview of Modern Approaches for Identifying and Evaluating Heterogeneous Treatment Effects from Clinical Data},
  doi = {10.1177/17407745231174544},
  urldate = {2023-08-19},
  howpublished = {https://journals.sagepub.com/doi/epub/10.1177/17407745231174544},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/HN2HUR5E/17407745231174544.html}
}

@misc{OverviewModernApproachesa,
  title = {Overview of Modern Approaches for Identifying and Evaluating Heterogeneous Treatment Effects from Clinical Data - {{Ilya Lipkovich}}, {{David Svensson}}, {{Bohdana Ratitch}}, {{Alex Dmitrienko}}, 2023},
  urldate = {2023-08-19},
  howpublished = {https://journals.sagepub.com/doi/full/10.1177/17407745231174544?casa\_token=him2dZ1uwnQAAAAA\%3AX-laZt1YJN5QeipxT5gmlSO\_w2bFI5ZPz-gvS9kiE9HDCqPiurF\_HTqmem74VUW8WgJuOrzMoqC3},
  file = {/Users/zenn/Zotero/storage/ZRLYLC8K/17407745231174544.html}
}

@article{owenMetaInsightInteractiveWebbased2019,
  title = {{{MetaInsight}}: {{An}} Interactive Web-Based Tool for Analyzing, Interrogating, and Visualizing Network Meta-Analyses Using {{R-shiny}} and Netmeta},
  shorttitle = {{{MetaInsight}}},
  author = {Owen, Rhiannon K. and Bradbury, Naomi and Xin, Yiqiao and Cooper, Nicola and Sutton, Alex},
  year = {2019},
  journal = {Research Synthesis Methods},
  volume = {10},
  number = {4},
  pages = {569--581},
  issn = {1759-2887},
  doi = {10.1002/jrsm.1373},
  urldate = {2023-12-15},
  abstract = {Background Network meta-analysis (NMA) is a powerful analysis method used to identify the best treatments for a condition and is used extensively by health care decision makers. Although software routines exist for conducting NMA, they require considerable statistical programming expertise to use, which limits the number of researchers able to conduct such analyses. Objectives To develop a web-based tool allowing users with only standard internet browser software to be able to conduct NMAs using an intuitive ``point and click'' interface and present the results using visual plots. Methods Using the existing netmeta and Shiny packages for R to conduct the analyses, and to develop the user interface, we created the MetaInsight tool which is freely available to use via the web. Results A package was created for conducting NMA which satisfied our objectives, and this is described, and its application demonstrated, using an illustrative example. Conclusions We believe that many researchers will find our package helpful for facilitating NMA as well as allowing decision makers to scrutinize presented results visually and in real time. This will impact on the relevance of statistical analyses for health care decision making and sustainably increase capacity by empowering informed nonspecialists to be able to conduct more clinically relevant reviews. It is also hoped that others will be inspired to create similar tools for other advanced specialist analyses methods using the freely available technologies we have adopted.},
  copyright = {{\copyright} 2019 The Authors. Research Synthesis Methods published by John Wiley \& Sons Ltd.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/EEZ29K8E/Owen et al. - 2019 - MetaInsight An interactive web-based tool for ana.pdf;/Users/zenn/Zotero/storage/XH2H7E9Z/jrsm.html}
}

@article{Oxtoby2016,
  title = {{{TADPOLE Challenge}} : {{Prediction}} of {{Longitudinal Evolution}} in {{Alzheimer}} ' s {{Disease}}},
  author = {Oxtoby, Neil P and Young, Alexandra L and Bron, Esther E and Toga, Arthur W and Weiner, Michael W and Fox, Nick C and Klein, Stefan and Alexander, Daniel C and Initiative, Neuroimaging},
  year = {2016},
  eprint = {1805.03909v2},
  archiveprefix = {arXiv},
  keywords = {alzheimer,biomarkers,community challenge,disease prediction,s disease},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/oxtoby et al_2016_tadpole challenge.pdf}
}

@article{Ozan2010,
  title = {Assessing the Impact of Carryover Effects on the Variances of Estimators of Treatment Differences in Crossover Designs},
  author = {Ozan, M. Ozgu and Stufken, John},
  year = {2010},
  month = oct,
  journal = {Statistics in Medicine},
  volume = {29},
  number = {24},
  pages = {2480--2485},
  issn = {02776715},
  doi = {10.1002/sim.4009},
  urldate = {2021-11-06},
  abstract = {Different models that include carryover effects have been studied in the optimal design literature. It has been suggested that the use of these models results in increased variances of estimated contrasts of the direct treatment effects, leading to inferior estimators in terms of precision. Under a number of models and selected designs, we present variance expressions for the pairwise differences of direct treatment effects and observe that adjusting for carryover effects need not affect the precision of estimators negatively. We investigate the existence of designs that produce estimators with relatively small variances under all models considered. We conclude that even if a model is not correct, it can still be useful in increasing the precision of estimators for treatment contrasts. Copyright {\copyright} 2010 John Wiley \& Sons, Ltd.},
  pmid = {20683837},
  keywords = {Balanced crossover designs,Proportional carryover effects,Self and mixed carryover effects},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/ozan_stufken_2010_assessing the impact of carryover effects on the variances of estimators of.pdf}
}

@article{packerWhyHasRunIn2017,
  title = {Why {{Has}} a {{Run-In Period Been}} a {{Design Element}} in {{Most Landmark Clinical Trials}}? {{Analysis}} of the {{Critical Role}} of {{Run-In Periods}} in {{Drug Development}}},
  shorttitle = {Why {{Has}} a {{Run-In Period Been}} a {{Design Element}} in {{Most Landmark Clinical Trials}}?},
  author = {Packer, Milton},
  year = {2017},
  month = sep,
  journal = {Journal of Cardiac Failure},
  volume = {23},
  number = {9},
  pages = {697--699},
  issn = {1071-9164},
  doi = {10.1016/j.cardfail.2017.07.401},
  urldate = {2022-10-20},
  abstract = {Prior exposure to one of the randomized treatments has been a routine design element of large-scale trials in patients at high cardiovascular risk. A run-in feature has allowed our trials to be more realistic; it has strengthened their ability to estimate the true treatment effect; and it has never undermined the validity of a trial's findings. Those who suggest that run-in periods distort the results of large-scale trials should become more familiar with our history of drug development and our standards of clinical practice. Physicians use run-in periods every day in real life, and trialists have used run-in periods for decades to reliably establish the role of new cardiovascular drugs. Those who reflexively criticize the trials because of their inclusion of a run-in period need to carefully reexamine how medicine is practiced and how it advances.},
  langid = {english},
  keywords = {Clinical trial design,drug efficacy studies,heart failure trials,run-in periods},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/packer_2017_why has a run-in period been a design element in most landmark clinical trials.pdf;/Users/zenn/Zotero/storage/BMBK8JYV/S1071916417306206.html}
}

@article{paganoAlgorithmFindingExact1981,
  title = {An Algorithm for Finding the Exact Significance Levels of R{\textbackslash}times c Contingency Tables},
  author = {Pagano, Marcello and Halvorsen, Katherine Taylor},
  year = {1981},
  journal = {Journal of the American statistical Association},
  volume = {76},
  number = {376},
  pages = {931--934},
  publisher = {Taylor \& Francis}
}

@article{pagePRISMA2020Explanation2021,
  title = {{{PRISMA}} 2020 Explanation and Elaboration: Updated Guidance and Exemplars for Reporting Systematic Reviews},
  shorttitle = {{{PRISMA}} 2020 Explanation and Elaboration},
  author = {Page, Matthew J. and Moher, David and Bossuyt, Patrick M. and Boutron, Isabelle and Hoffmann, Tammy C. and Mulrow, Cynthia D. and Shamseer, Larissa and Tetzlaff, Jennifer M. and Akl, Elie A. and Brennan, Sue E. and Chou, Roger and Glanville, Julie and Grimshaw, Jeremy M. and Hr{\'o}bjartsson, Asbj{\o}rn and Lalu, Manoj M. and Li, Tianjing and Loder, Elizabeth W. and {Mayo-Wilson}, Evan and McDonald, Steve and McGuinness, Luke A. and Stewart, Lesley A. and Thomas, James and Tricco, Andrea C. and Welch, Vivian A. and Whiting, Penny and McKenzie, Joanne E.},
  year = {2021},
  month = mar,
  journal = {BMJ},
  volume = {372},
  pages = {n160},
  publisher = {British Medical Journal Publishing Group},
  issn = {1756-1833},
  doi = {10.1136/bmj.n160},
  urldate = {2023-12-22},
  abstract = {{$<$}p{$>$}The methods and results of systematic reviews should be reported in sufficient detail to allow users to assess the trustworthiness and applicability of the review findings. The Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) statement was developed to facilitate transparent and complete reporting of systematic reviews and has been updated (to PRISMA 2020) to reflect recent advances in systematic review methodology and terminology. Here, we present the explanation and elaboration paper for PRISMA 2020, where we explain why reporting of each item is recommended, present bullet points that detail the reporting recommendations, and present examples from published reviews. We hope that changes to the content and structure of PRISMA 2020 will facilitate uptake of the guideline and lead to more transparent, complete, and accurate reporting of systematic reviews.{$<$}/p{$>$}},
  chapter = {Research Methods \&amp; Reporting},
  copyright = {{\copyright} Author(s) (or their employer(s)) 2019. Re-use permitted under CC                 BY. No commercial re-use. See rights and permissions. Published by                 BMJ.. http://creativecommons.org/licenses/by/4.0/This is an Open Access article distributed in accordance with the terms of the Creative Commons Attribution (CC BY 4.0) license, which permits others to distribute, remix, adapt and build upon this work, for commercial use, provided the original work is properly cited. See: http://creativecommons.org/licenses/by/4.0/.},
  langid = {english},
  pmid = {33781993},
  file = {/Users/zenn/Zotero/storage/DQ5RCMM3/Page et al. - 2021 - PRISMA 2020 explanation and elaboration updated g.pdf}
}

@article{palmerSomaticLossChromosome2022,
  title = {Somatic {{Loss}} of the {{Y Chromosome}} and {{Alzheimer}}'s {{Disease Risk}}},
  author = {Palmer, Ellen L. and Benchek, Penelope and Wheeler, Nicholas R. and Smeiszek, Sandra and Naj, Adam C. and Haines, Jonathan L. and {Pericak-Vance}, Margaret A. and Forsberg, Lars A. and Cukier, Holly N. and Song, Yeunjoo},
  year = {2022},
  journal = {bioRxiv},
  publisher = {Cold Spring Harbor Laboratory},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/palmer et al_2022_somatic loss of the y chromosome and alzheimer's disease risk.pdf;/Users/zenn/Zotero/storage/UWNCC3L9/2022.11.14.516433v1.html}
}

@article{palmqvistPredictionFutureAlzheimer2021,
  title = {Prediction of Future {{Alzheimer}}'s Disease Dementia Using Plasma Phospho-Tau Combined with Other Accessible Measures},
  author = {Palmqvist, Sebastian and Tideman, Pontus and Cullen, Nicholas and Zetterberg, Henrik and Blennow, Kaj and Dage, Jeffery L. and Stomrud, Erik and Janelidze, Shorena and {Mattsson-Carlgren}, Niklas and Hansson, Oskar},
  year = {2021},
  journal = {Nature Medicine},
  volume = {27},
  number = {June},
  publisher = {Springer US},
  issn = {1546170X},
  doi = {10.1038/s41591-021-01348-z},
  abstract = {A combination of plasma phospho-tau (P-tau) and other accessible biomarkers might provide accurate prediction about the risk of developing Alzheimer's disease (AD) dementia. We examined this in participants with subjective cognitive decline and mild cognitive impairment from the BioFINDER (n = 340) and Alzheimer's Disease Neuroimaging Initiative (ADNI) (n = 543) studies. Plasma P-tau, plasma A{$\beta$}42/A{$\beta$}40, plasma neurofilament light, APOE genotype, brief cognitive tests and an AD-specific magnetic resonance imaging measure were examined using progression to AD as outcome. Within 4 years, plasma P-tau217 predicted AD accurately (area under the curve (AUC) = 0.83) in BioFINDER. Combining plasma P-tau217, memory, executive function and APOE produced higher accuracy (AUC = 0.91, P {$<$} 0.001). In ADNI, this model had similar AUC (0.90) using plasma P-tau181 instead of P-tau217. The model was implemented online for prediction of the individual probability of progressing to AD. Within 2 and 6 years, similar models had AUCs of 0.90--0.91 in both cohorts. Using cerebrospinal fluid P-tau, A{$\beta$}42/A{$\beta$}40 and neurofilament light instead of plasma biomarkers did not improve the accuracy significantly. The clinical predictions by memory clinic physicians had significantly lower accuracy (4-year AUC = 0.71). In summary, plasma P-tau, in combination with brief cognitive tests and APOE genotyping, might greatly improve the diagnostic prediction of AD and facilitate recruitment for AD trials.},
  pmid = {34031605},
  keywords = {Alzheimer's disease,Prognostic markers},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/palmqvist et al_2021_prediction of future alzheimer’s disease dementia using plasma phospho-tau.pdf}
}

@article{panzaTaubasedTherapeuticsAlzheimer2016,
  title = {Tau-Based Therapeutics for {{Alzheimer}}'s Disease: Active and Passive Immunotherapy},
  shorttitle = {Tau-Based Therapeutics for {{Alzheimer}}'s Disease},
  author = {Panza, Francesco and Solfrizzi, Vincenzo and Seripa, Davide and Imbimbo, Bruno P. and Lozupone, Madia and Santamato, Andrea and Tortelli, Rosanna and Galizia, Ilaria and Prete, Camilla and Daniele, Antonio and Pilotto, Alberto and Greco, Antonio and Logroscino, Giancarlo},
  year = {2016},
  month = sep,
  journal = {Immunotherapy},
  volume = {8},
  number = {9},
  pages = {1119--1134},
  issn = {1750-7448},
  doi = {10.2217/imt-2016-0019},
  abstract = {Pharmacological manipulation of tau protein in Alzheimer's disease included microtubule-stabilizing agents, tau protein kinase inhibitors, tau aggregation inhibitors, active and passive immunotherapies and, more recently, inhibitors of tau acetylation. Animal studies have shown that both active and passive approaches can remove tau pathology and, in some cases, improve cognitive function. Two active vaccines targeting either nonphosphorylated (AAD-vac1) and phosphorylated tau (ACI-35) have entered Phase I testing. Notwithstanding, the recent discontinuation of the monoclonal antibody RG7345 for Alzheimer's disease, two other antitau antibodies, BMS-986168 and C2N-8E12, are also currently in Phase I testing for progressive supranuclear palsy. After the recent impressive results in animal studies obtained by salsalate, the dimer of salicylic acid, inhibitors of tau acetylation are being actively pursued.},
  langid = {english},
  pmid = {27485083},
  keywords = {Acetylation,active immunotherapy,Alzheimer Disease,Alzheimer's disease,Animals,Anti-Inflammatory Agents Non-Steroidal,Antibodies Monoclonal,Clinical Trials as Topic,Cognition,Disease Models Animal,Humans,Immunization Passive,Immunotherapy Active,Microtubules,passive immunotherapy,Salicylates,tau Proteins,Vaccines}
}

@article{papiniIsradipineEnhancementVirtual2020,
  title = {Isradipine Enhancement of Virtual Reality Cue Exposure for Smoking Cessation: {{Rationale}} and Study Protocol for a Double-Blind Randomized Controlled Trial},
  shorttitle = {Isradipine Enhancement of Virtual Reality Cue Exposure for Smoking Cessation},
  author = {Papini, Santiago and Young, Cara C. and Gebhardt, Catherine S. and Perrone, Alex and Morikawa, Hitoshi and Otto, Michael W. and Roache, John D. and Smits, Jasper A.J.},
  year = {2020},
  month = jul,
  journal = {Contemporary Clinical Trials},
  volume = {94},
  pages = {106013},
  issn = {15517144},
  doi = {10.1016/j.cct.2020.106013},
  urldate = {2023-08-01},
  abstract = {Cigarette smoking remains a leading cause of preventable death in the United States, contributing to over 480,000 deaths each year. Although significant strides have been made in the development of effective smoking cessation treatments, most established interventions are associated with high relapse rates. One avenue for increasing the effectiveness of smoking cessation interventions is to design focused, efficient, and rigorous experiments testing engagement of well-defined mechanistic targets. Toward this aim, the current protocol will apply a pharmacologic augmentation strategy informed by basic research in animal models of addiction. Our goal is to evaluate the enhancing effect of isradipine, an FDA-approved calcium channel blocker, on the extinction of craving---a key mechanism of drug relapse after periods of abstinence. To activate craving robustly in human participants, we will use multimodal smoking cues including novel 360{$^\circ$} video environments developed for this project and delivered through consumer virtual reality headsets. Adult smokers will take either isradipine or placebo and complete the cue exposure protocol in a double-blind randomized control trial. In order to test the hypothesis that isradipine will enhance retention of craving extinction, participants will repeat cue exposure 24 h later without the administration of isradipine or placebo. The study will be implemented in a primary care setting where adult smokers receive healthcare, and smoking behavior will be tracked throughout the trial with ecological momentary assessment.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/R85AEIFP/Papini et al. - 2020 - Isradipine enhancement of virtual reality cue expo.pdf}
}

@misc{ParameterefficientDeepLearning,
  title = {A Parameter-Efficient Deep Learning Approach to Predict Conversion from Mild Cognitive Impairment to {{Alzheimer}}'s Disease {\textbar} {{Elsevier Enhanced Reader}}},
  doi = {10.1016/j.neuroimage.2019.01.031},
  urldate = {2023-04-06},
  howpublished = {https://reader.elsevier.com/reader/sd/pii/S105381191930031X?token=BF497869EE3D3625BA894A90BF56986BD97C94E567FAD695A267FC4ABE4E9175DC234F6EDE8D538A9D9BFBA3CA2C8996\&originRegion=us-east-1\&originCreation=20230406001231},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/a parameter-efficient deep learning approach to predict conversion from mild.pdf}
}

@article{parkRandomInterceptHierarchical2024,
  title = {Random Intercept Hierarchical Linear Model for Multi-Regional Clinical Trials},
  author = {Park, Chunkyun and Kang, Seung-Ho},
  year = {2024},
  month = jan,
  journal = {Journal of Biopharmaceutical Statistics},
  volume = {34},
  number = {1},
  pages = {16--36},
  publisher = {Taylor \& Francis},
  issn = {1054-3406},
  doi = {10.1080/10543406.2023.2170395},
  urldate = {2024-04-19},
  abstract = {In multi-regional clinical trials, hierarchical linear models have been actively studied because they can reflect that patients in the same region share common intrinsic and extrinsic factors. In this paper, we investigate the statistical properties of the hierarchical linear model including a random effect in the intercept. The big advantage of the random intercept hierarchical linear model is that it can control the type I error rates of testing the overall treatment effect when there are no or clinically negligible regional differences in the treatment effect. Moreover, we compare the pros and cons with the hierarchical linear model in which the random effect is included in the slope. For the two hierarchical linear models, the model selection criteria are determined according to the magnitude of the difference in treatment effect across the regions, and we provide the criteria through simulation studies.},
  pmid = {36710387},
  keywords = {between-cluster variability,extrinsic factor,intrinsic factor,multi-level model,random coefficient model}
}

@article{parmarTestingManyTreatments2017,
  title = {Testing Many Treatments within a Single Protocol over 10\,Years at {{MRC Clinical Trials Unit}} at {{UCL}}: {{Multi-arm}}, Multi-Stage Platform, Umbrella and Basket Protocols},
  shorttitle = {Testing Many Treatments within a Single Protocol over 10\,Years at {{MRC Clinical Trials Unit}} at {{UCL}}},
  author = {Parmar, Mahesh Kb and Sydes, Matthew R. and Cafferty, Fay H. and {Choodari-Oskooei}, Babak and Langley, Ruth E. and Brown, Louise and Phillips, Patrick Pj and Spears, Melissa R. and Rowley, Sam and Kaplan, Richard and James, Nicholas D. and Maughan, Timothy and Paton, Nicholas and Royston, Patrick J.},
  year = {2017},
  month = oct,
  journal = {Clinical Trials (London, England)},
  volume = {14},
  number = {5},
  pages = {451--461},
  issn = {1740-7753},
  doi = {10.1177/1740774517725697},
  abstract = {There is real need to change how we do some of our clinical trials, as currently the testing and development process is too slow, too costly and too failure-prone often we find that a new treatment is no better than the current standard. Much of the focus on the development and testing pathway has been in improving the design of phase I and II trials. In this article, we present examples of new methods for improving the design of phase III trials (and the necessary lead up to them) as they are the most time-consuming and expensive part of the pathway. Key to all these methods is the aim to test many treatments and/or pose many therapeutic questions within one protocol.},
  langid = {english},
  pmcid = {PMC5700799},
  pmid = {28830236},
  keywords = {basket,Clinical Protocols,Clinical Trials Phase III as Topic,Humans,London,Male,Multi-arm,multi-stage,Outcome Assessment Health Care,Patient Selection,platform,randomised trials,Randomized Controlled Trials as Topic,Research Design,Treatment Outcome,umbrella},
  file = {/Users/zenn/Zotero/storage/PE4YZ4T3/Parmar et al. - 2017 - Testing many treatments within a single protocol o.pdf}
}

@inproceedings{pasner2009adas,
  title = {The {{ADAS-cog}}'s Performance as a Measure Lessons from the {{ADNI}} Study: {{Part}} 1-{{Evaluation}} Using Traditional Psychometric Methods},
  booktitle = {Neurology},
  author = {Pasner, Holly and Cano, Stefan J and Aisen, Paul and Selnes, Ola and Stern, Yaakov and Thomas, Ronald and Weiner, Michael and Zajicek, John and Zeger, Scott and Hobart, Jeremy},
  year = {2009},
  volume = {72},
  pages = {A271--A272},
  publisher = {LIPPINCOTT WILLIAMS \& WILKINS 530 WALNUT ST, PHILADELPHIA, PA 19106-3621 USA}
}

@article{patersonSILKStudiesCapturing2019,
  title = {{{SILK}} Studies --- Capturing the Turnover of Proteins Linked to Neurodegenerative Diseases},
  author = {Paterson, Ross W and Gabelle, Audrey and Lucey, Brendan P and Barth{\'e}lemy, Nicolas R and Leckey, Claire A and Hirtz, Christophe and Lehmann, Sylvain and Sato, Chihiro and Patterson, Bruce W and West, Tim and Yarasheski, Kevin and Rohrer, Jonathan D and Wildburger, Norelle C and Schott, Jonathan M and Karch, Celeste M and Wray, Selina and Miller, Timothy M and Elbert, Donald L and Zetterberg, Henrik and Fox, Nick C and Bateman, Randall J},
  year = {2019},
  journal = {Nature Reviews Neurology},
  volume = {15},
  number = {7},
  pages = {419--427},
  issn = {17594766},
  doi = {10.1038/s41582-019-0222-0},
  urldate = {2022-01-16},
  abstract = {Alzheimer disease (AD) is one of several neurodegenerative diseases characterized by dysregulation, misfolding and accumulation of specific proteins in the CNS. The stable isotope labelling kinetics (SILK) technique is based on generating amino acids labelled with naturally occurring stable (that is, nonradioactive) isotopes of carbon and/or nitrogen. These labelled amino acids can then be incorporated into proteins, enabling rates of protein production and clearance to be determined in vivo and in vitro without the use of radioactive or chemical labels. Over the past decade, SILK studies have been used to determine the turnover of key pathogenic proteins amyloid-{$\beta$} (A{$\beta$}), tau and superoxide dismutase 1 (SOD1) in the cerebrospinal fluid of healthy individuals, patients with AD and those with other neurodegenerative diseases. These studies led to the identification of several factors that alter the production and/or clearance of these proteins, including age, sleep and disease-causing genetic mutations. SILK studies have also been used to measure A{$\beta$} turnover in blood and within brain tissue. SILK studies offer the potential to elucidate the mechanisms underlying various neurodegenerative disease mechanisms, including neuroinflammation and synaptic dysfunction, and to demonstrate target engagement of novel disease-modifying therapies.},
  pmid = {31222062},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/paterson et al_2019_silk studies — capturing the turnover of proteins linked to neurodegenerative.pdf}
}

@article{patterson1997longitudinal,
  title = {A Longitudinal Study of Behavioral Pathology across Five Levels of Dementia Severity in {{Alzheimer}}'s Disease: {{The CERAD Behavior Rating Scale}} for {{Dementia}}.},
  author = {Patterson, Marian B and Mack, James L and Mackell, Joan A and Thomas, Ronald and Tariot, Pierre and Weiner, Myron and Whitehouse, Peter J},
  year = {1997},
  journal = {Alzheimer disease and associated disorders},
  publisher = {Lippincott Williams \& Wilkins}
}

@article{paulsen2000incidence,
  title = {Incidence of and Risk Factors for Hallucinations and Delusions in Patients with Probable {{AD}}},
  author = {Paulsen, Jane S and Salmon, {\relax DP} and Thal, {\relax LJ} and Romero, R and {Weisstein--Jenkins}, C and Galasko, D and Hofstetter, {\relax CR} and Thomas, R and Grant, I and Jeste, {\relax DV}},
  year = {2000},
  journal = {Neurology},
  volume = {54},
  number = {10},
  pages = {1965--1971},
  publisher = {Wolters Kluwer Health, Inc. on behalf of the American Academy of Neurology}
}

@article{payanDiseaseSeverityProgression2011,
  title = {Disease Severity and Progression in Progressive Supranuclear Palsy and Multiple System Atrophy: Validation of the {{NNIPPS--Parkinson Plus Scale}}},
  shorttitle = {Disease Severity and Progression in Progressive Supranuclear Palsy and Multiple System Atrophy},
  author = {Payan, Christine A. M. and Viallet, Fran{\c c}ois and Landwehrmeyer, Bernhard G. and Bonnet, Anne-Marie and Borg, Michel and Durif, Franck and Lacomblez, Lucette and Bloch, Fr{\'e}d{\'e}ric and Verny, Marc and Fermanian, Jacques and Agid, Yves and Ludolph, Albert C. and Leigh, Peter N. and Bensimon, Gilbert and {NNIPPS Study Group}},
  year = {2011},
  journal = {PloS One},
  volume = {6},
  number = {8},
  pages = {e22293},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0022293},
  abstract = {BACKGROUND: The Natural History and Neuroprotection in Parkinson Plus Syndromes (NNIPPS) study was a large phase III randomized placebo-controlled trial of riluzole in Progressive Supranuclear Palsy (PSP, n = 362) and Multiple System Atrophy (MSA, n = 398). To assess disease severity and progression, we constructed and validated a new clinical rating scale as an ancillary study. METHODS AND FINDINGS: Patients were assessed at entry and 6-montly for up to 3 years. Evaluation of the scale's psychometric properties included reliability (n = 116), validity (n = 760), and responsiveness (n = 642). Among the 85 items of the initial scale, factor analysis revealed 83 items contributing to 15 clinically relevant dimensions, including Activity of daily Living/Mobility, Axial bradykinesia, Limb bradykinesia, Rigidity, Oculomotor, Cerebellar, Bulbar/Pseudo-bulbar, Mental, Orthostatic, Urinary, Limb dystonia, Axial dystonia, Pyramidal, Myoclonus and Tremor. All but the Pyramidal dimension demonstrated good internal consistency (Cronbach {$\alpha$} {$\geq$} 0.70). Inter-rater reliability was high for the total score (Intra-class coefficient = 0.94) and 9 dimensions (Intra-class coefficient = 0.80-0.93), and moderate (Intra-class coefficient = 0.54-0.77) for 6. Correlations of the total score with other clinical measures of severity were good (rho {$\geq$} 0.70). The total score was significantly and linearly related to survival (p{$<$}0.0001). Responsiveness expressed as the Standardized Response Mean was high for the total score slope of change (SRM = 1.10), though higher in PSP (SRM = 1.25) than in MSA (SRM = 1.0), indicating a more rapid progression of PSP. The slope of change was constant with increasing disease severity demonstrating good linearity of the scale throughout disease stages. Although MSA and PSP differed quantitatively on the total score at entry and on rate of progression, the relative contribution of clinical dimensions to overall severity and progression was similar. CONCLUSIONS: The NNIPPS-PPS has suitable validity, is reliable and sensitive, and therefore is appropriate for use in clinical studies with PSP or MSA. TRIAL REGISTRATION: ClinicalTrials.gov NCT00211224.},
  langid = {english},
  pmcid = {PMC3150329},
  pmid = {21829612},
  keywords = {Disease Progression,Humans,Multiple System Atrophy,Observer Variation,Randomized Controlled Trials as Topic,Severity of Illness Index,Supranuclear Palsy Progressive},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/payan et al_2011_disease severity and progression in progressive supranuclear palsy and multiple.pdf}
}

@article{pearlChallengingHegemonyRandomized2018,
  title = {Challenging the Hegemony of Randomized Controlled Trials: {{A}} Commentary on {{Deaton}} and {{Cartwright}}},
  shorttitle = {Challenging the Hegemony of Randomized Controlled Trials},
  author = {Pearl, Judea},
  year = {2018},
  journal = {Social Science \& Medicine},
  file = {/Users/zenn/Zotero/storage/35UHRM5X/Pearl - 2018 - Challenging the hegemony of randomized controlled .pdf}
}

@inproceedings{peavy1998cognitive,
  title = {Cognitive and Functional Abilities in Severely Demented {{Alzheimer}}'s Patients},
  booktitle = {Clinical Neuropsychologist},
  author = {Peavy, {\relax GM} and Salmon, {\relax DP} and Thomas, {\relax RG}},
  year = {1998},
  volume = {12},
  pages = {281--281},
  publisher = {TAYLOR \& FRANCIS INC 530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA}
}

@article{peikertReproducibleDataAnalysis2021,
  title = {A {{Reproducible Data Analysis Workflow}}},
  author = {Peikert, Aaron and Brandmaier, Andreas M},
  year = {2021},
  journal = {Quantitative and Computational Methods in Behavioral Sciences},
  volume = {1},
  doi = {10.5964/qcmb.3763},
  urldate = {2021-12-09},
  abstract = {In this tutorial, we describe a workflow to ensure long-term reproducibility of R-based data analyses. The workflow leverages established tools and practices from software engineering. It combines the benefits of various open-source software tools including R Markdown, Git, Make, and Docker, whose interplay ensures seamless integration of version management, dynamic report generation conforming to various journal styles, and full cross-platform and long-term computational reproducibility. The workflow ensures meeting the primary goals that 1) the reporting of statistical results is consistent with the actual statistical results (dynamic report generation), 2) the analysis exactly reproduces at a later point in time even if the computing platform or software is changed (computational reproducibility), and 3) changes at any time (during development and post-publication) are tracked, tagged, and documented while earlier versions of both data and code remain accessible. While the research community increasingly recognizes dynamic document generation and version management as tools to ensure reproducibility, we demonstrate with practical examples that these alone are not sufficient to ensure long-term computational reproducibility. Combining containerization, dependence management, version management, and dynamic document generation, the proposed workflow increases scientific productivity by facilitating later reproducibility and reuse of code and data.},
  keywords = {containerization,dependency management,dynamic document generation,open science,R,reproducibility,version management},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/peikert_brandmaier_2021_a reproducible data analysis workflow.pdf}
}

@article{peikertReproducibleDataAnalysis2021a,
  title = {A {{Reproducible Data Analysis Workflow With R Markdown}}, {{Git}}, {{Make}}, and {{Docker}}},
  author = {Peikert, Aaron and Brandmaier, Andreas M.},
  year = {2021},
  month = may,
  journal = {Quantitative and Computational Methods in Behavioral Sciences},
  pages = {1--27},
  issn = {2699-8432},
  doi = {10.5964/qcmb.3763},
  urldate = {2023-07-10},
  abstract = {In this tutorial, we describe a workflow to ensure long-term reproducibility of R-based data analyses. The workflow leverages established tools and practices from software engineering. It combines the benefits of various open-source software tools including R Markdown, Git, Make, and Docker, whose interplay ensures seamless integration of version management, dynamic report generation conforming to various journal styles, and full cross-platform and long-term computational reproducibility. The workflow ensures meeting the primary goals that 1) the reporting of statistical results is consistent with the actual statistical results (dynamic report generation), 2) the analysis exactly reproduces at a later point in time even if the computing platform or software is changed (computational reproducibility), and 3) changes at any time (during development and post-publication) are tracked, tagged, and documented while earlier versions of both data and code remain accessible. While the research community increasingly recognizes dynamic document generation and version management as tools to ensure reproducibility, we demonstrate with practical examples that these alone are not sufficient to ensure long-term computational reproducibility. Combining containerization, dependence management, version management, and dynamic document generation, the proposed workflow increases scientific productivity by facilitating later reproducibility and reuse of code and data.},
  copyright = {Copyright (c) 2021 Aaron Peikert, Andreas M. Brandmaier},
  langid = {english},
  keywords = {containerization,dependency management,dynamic document generation,open science,R,reproducibility,version management},
  file = {/Users/zenn/Zotero/storage/Q3Q5SX2Q/Peikert and Brandmaier - 2021 - A Reproducible Data Analysis Workflow With R Markd.pdf}
}

@article{peikertReproducibleDataAnalysis2021b,
  title = {A {{Reproducible Data Analysis Workflow With R Markdown}}, {{Git}}, {{Make}}, and {{Docker}}},
  author = {Peikert, Aaron and Brandmaier, Andreas M.},
  year = {2021},
  month = may,
  journal = {Quantitative and Computational Methods in Behavioral Sciences},
  pages = {1--27},
  issn = {2699-8432},
  doi = {10.5964/qcmb.3763},
  urldate = {2023-08-13},
  abstract = {In this tutorial, we describe a workflow to ensure long-term reproducibility of R-based data analyses. The workflow leverages established tools and practices from software engineering. It combines the benefits of various open-source software tools including R Markdown, Git, Make, and Docker, whose interplay ensures seamless integration of version management, dynamic report generation conforming to various journal styles, and full cross-platform and long-term computational reproducibility. The workflow ensures meeting the primary goals that 1) the reporting of statistical results is consistent with the actual statistical results (dynamic report generation), 2) the analysis exactly reproduces at a later point in time even if the computing platform or software is changed (computational reproducibility), and 3) changes at any time (during development and post-publication) are tracked, tagged, and documented while earlier versions of both data and code remain accessible. While the research community increasingly recognizes dynamic document generation and version management as tools to ensure reproducibility, we demonstrate with practical examples that these alone are not sufficient to ensure long-term computational reproducibility. Combining containerization, dependence management, version management, and dynamic document generation, the proposed workflow increases scientific productivity by facilitating later reproducibility and reuse of code and data.},
  copyright = {Copyright (c) 2021 Aaron Peikert, Andreas M. Brandmaier},
  langid = {english},
  keywords = {containerization,dependency management,dynamic document generation,open science,R,reproducibility,version management},
  file = {/Users/zenn/Zotero/storage/ZWEECNZK/Peikert and Brandmaier - 2021 - A Reproducible Data Analysis Workflow With R Markd.pdf}
}

@article{peikertReproducibleResearchTutorial2021,
  title = {Reproducible {{Research}} in {{R}}: {{A Tutorial}} on {{How}} to {{Do}} the {{Same Thing More Than Once}}},
  shorttitle = {Reproducible {{Research}} in {{R}}},
  author = {Peikert, Aaron and Van Lissa, Caspar J. and Brandmaier, Andreas M.},
  year = {2021},
  month = dec,
  journal = {Psych},
  volume = {3},
  number = {4},
  pages = {836--867},
  issn = {2624-8611},
  doi = {10.3390/psych3040053},
  urldate = {2024-02-08},
  abstract = {Computational reproducibility is the ability to obtain identical results from the same data with the same computer code. It is a building block for transparent and cumulative science because it enables the originator and other researchers, on other computers and later in time, to reproduce and thus understand how results came about, while avoiding a variety of errors that may lead to erroneous reporting of statistical and computational results. In this tutorial, we demonstrate how the R package repro supports researchers in creating fully computationally reproducible research projects with tools from the software engineering community. Building upon this notion of fully automated reproducibility, we present several applications including the preregistration of research plans with code (Preregistration as Code, PAC). PAC eschews all ambiguity of traditional preregistration and offers several more advantages. Making technical advancements that serve reproducibility more widely accessible for researchers holds the potential to innovate the research process and to help it become more productive, credible, and reliable.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/INASGJ6L/Peikert et al. - 2021 - Reproducible Research in R A Tutorial on How to D.pdf}
}

@article{peikertReproducibleResearchTutorial2021a,
  title = {Reproducible {{Research}} in {{R}}: {{A Tutorial}} on {{How}} to {{Do}} the {{Same Thing More Than Once}}},
  shorttitle = {Reproducible {{Research}} in {{R}}},
  author = {Peikert, Aaron and {van Lissa}, Caspar J. and Brandmaier, Andreas M.},
  year = {2021},
  month = dec,
  journal = {Psych},
  volume = {3},
  number = {4},
  pages = {836--867},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2624-8611},
  doi = {10.3390/psych3040053},
  urldate = {2024-02-08},
  abstract = {Computational reproducibility is the ability to obtain identical results from the same data with the same computer code. It is a building block for transparent and cumulative science because it enables the originator and other researchers, on other computers and later in time, to reproduce and thus understand how results came about, while avoiding a variety of errors that may lead to erroneous reporting of statistical and computational results. In this tutorial, we demonstrate how the R package repro supports researchers in creating fully computationally reproducible research projects with tools from the software engineering community. Building upon this notion of fully automated reproducibility, we present several applications including the preregistration of research plans with code (Preregistration as Code, PAC). PAC eschews all ambiguity of traditional preregistration and offers several more advantages. Making technical advancements that serve reproducibility more widely accessible for researchers holds the potential to innovate the research process and to help it become more productive, credible, and reliable.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {computational reproducibility,Docker,GitHub,Make,open science,preregistration,R,R Markdown},
  file = {/Users/zenn/Zotero/storage/RFHKLLZ9/Peikert et al. - 2021 - Reproducible Research in R A Tutorial on How to D.pdf}
}

@misc{PenguinsGoParallel,
  title = {Penguins {{Go Parallel}}: {{A Grammar}} of {{Graphics Framework}} for {{Generalized Parallel Coordinate Plots}}},
  shorttitle = {Penguins {{Go Parallel}}},
  issn = {1061-8600},
  urldate = {2023-12-29},
  howpublished = {https://www.tandfonline.com/doi/epdf/10.1080/10618600.2023.2195462?needAccess=true},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/SWT39IKX/10618600.2023.html}
}

@article{pepe1983early,
  title = {Early Prediction of the Adult Respiratory Distress Syndrome by a Simple Scoring Method},
  author = {Pepe, Paul E and Thomas, Ronald G and Stager, Marie Anne and Hudson, Leonard D and Carrico, C James},
  year = {1983},
  journal = {Annals of emergency medicine},
  volume = {12},
  number = {12},
  pages = {749--755},
  publisher = {Mosby}
}

@article{perez-riverolTenSimpleRules2016,
  title = {Ten {{Simple Rules}} for {{Taking Advantage}} of {{Git}} and {{GitHub}}},
  author = {{Perez-Riverol}, Yasset and Gatto, Laurent and Wang, Rui and Sachsenberg, Timo and Uszkoreit, Julian and Leprevost, Felipe da Veiga and Fufezan, Christian and Ternent, Tobias and Eglen, Stephen J. and Katz, Daniel S. and Pollard, Tom J. and Konovalov, Alexander and Flight, Robert M. and Blin, Kai and Vizca{\'i}no, Juan Antonio},
  year = {2016},
  month = jul,
  journal = {PLoS Computational Biology},
  volume = {12},
  number = {7},
  publisher = {Public Library of Science},
  issn = {15537358},
  doi = {10.1371/JOURNAL.PCBI.1004947},
  urldate = {2022-06-09},
  pmid = {27415786},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/perez-riverol et al_2016_ten simple rules for taking advantage of git and github.pdf}
}

@article{peskind2005propranolol,
  title = {Propranolol for Disruptive Behaviors in Nursing Home Residents with Probable or Possible {{Alzheimer}} Disease: A Placebo-Controlled Study},
  author = {Peskind, Elaine R and Tsuang, Debby W and Bonner, Lauren T and Pascualy, Marcella and Riekse, Robert G and Snowden, Mark B and Thomas, Ronald and Raskind, Murray A},
  year = {2005},
  journal = {Alzheimer Disease \& Associated Disorders},
  volume = {19},
  number = {1},
  pages = {23--28},
  publisher = {LWW}
}

@article{peterlinCorrectSpecificationDesign2023,
  title = {Correct Specification of Design Matrices in Linear Mixed Effects Models: Tests with Graphical Representation},
  shorttitle = {Correct Specification of Design Matrices in Linear Mixed Effects Models},
  author = {Peterlin, Jakob and Kej{\v z}ar, Nata{\v s}a and Blagus, Rok},
  year = {2023},
  month = mar,
  journal = {TEST},
  volume = {32},
  number = {1},
  pages = {184--210},
  issn = {1863-8260},
  doi = {10.1007/s11749-022-00830-1},
  urldate = {2024-02-14},
  abstract = {Linear mixed effects models (LMMs) are a popular and powerful tool for analysing grouped or repeated observations for numeric outcomes. LMMs consist of a fixed and a random component, which are specified in the model through their respective design matrices. Verifying the correct specification of the two design matrices is important since mis-specifying them can affect the validity and efficiency of the analysis. We show how to use empirical stochastic processes constructed from appropriately ordered and standardized residuals from the model to test whether the design matrices of the fitted LMM are correctly specified. We define two different processes: one can be used to test whether both design matrices are correctly specified, and the other can be used only to test whether the fixed effects design matrix is correctly specified. The proposed empirical stochastic processes are smoothed versions of cumulative sum processes, which have a nice graphical representation in which model mis-specification can easily be observed. The amount of smoothing can be adjusted, which facilitates visual inspection and can potentially increase the power of the tests. We propose a computationally efficient procedure for estimating p-values in which refitting of the LMM is not necessary. Its validity is shown by using theoretical results and a large Monte Carlo simulation study. The proposed methodology could be used with LMMs with multilevel or crossed random effects.},
  langid = {english},
  keywords = {62G09,62J05,Asymptotic convergence,Correlated data,Empirical stochastic processes,Monte Carlo simulations,Sign-flipping,Wild bootstrap},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/peterlin et al_2023_correct specification of design matrices in linear mixed effects models.pdf}
}

@inproceedings{petersen2004donepezil,
  title = {Donepezil and Vitamin {{E}} for Mild Cognitive Impairment},
  booktitle = {9th International Congress on Alzheimer's Disease. {{Philadelphia}}},
  author = {Petersen, {\relax RGM} and Thomas, R and Thal, L},
  year = {2004}
}

@inproceedings{petersen2004donepezil,
  title = {Donepezil and Vitamin {{E}} as Treatments for Mild Cognitive Impairment},
  booktitle = {Neurobiology of Aging},
  author = {Petersen, R and Grundman, M and Thomas, R and Thal, L},
  year = {2004},
  volume = {25},
  pages = {S20--S20},
  publisher = {ELSEVIER SCIENCE INC 360 PARK AVE SOUTH, NEW YORK, NY 10010-1710 USA}
}

@article{petersen2005o1,
  title = {[{{O1-04-04}}]: {{Operational}} Criteria for Patient Recruitment in Trials of Mild Cognitive Impairment},
  author = {Petersen, Ronald C and Thomas, Ronald G and Grundman, Michael and Bennett, David A and Kaye, Jeffrey and Levey, Allan I and Pfeiffer, Eric and Sano, Mary and {van Dyck}, Christopher H and Thal, Leon J},
  year = {2005},
  journal = {Alzheimer's \& Dementia},
  volume = {1},
  pages = {S87--S87}
}

@inproceedings{petersen2005treatment,
  title = {Treatment of {{MCI}} with Cholinesterase Inhibitors: Current Data},
  booktitle = {International Psychogeriatrics},
  author = {Petersen, {\relax RC} and Thomas, R and Grundman, M and Thal, L},
  year = {2005},
  volume = {17},
  pages = {34--34},
  publisher = {CAMBRIDGE UNIV PRESS 40 WEST 20TH ST, NEW YORK, NY 10011-4211 USA}
}

@article{petersen2005vitamin,
  title = {Vitamin {{E}} and Donepezil for the Treatment of Mild Cognitive Impairment},
  author = {Petersen, Ronald C and Thomas, Ronald G and Grundman, Michael and Bennett, David and Doody, Rachelle and Ferris, Steven and Galasko, Douglas and Jin, Shelia and Kaye, Jeffrey and Levey, Allan and others},
  year = {2005},
  journal = {New England Journal of Medicine},
  volume = {352},
  number = {23},
  pages = {2379--2388},
  publisher = {Massachusetts Medical Society}
}

@inproceedings{petersen2006cognitive,
  title = {Cognitive Changes in the Treatment of Mild Cognitive Impairment with Donepazil and Vitamin {{E}}},
  booktitle = {{{NEUROLOGY}}},
  author = {Petersen, {\relax ER} and Thomas, R and Grundman, M and Thal, L},
  year = {2006},
  volume = {66},
  pages = {A118--A119},
  publisher = {LIPPINCOTT WILLIAMS \& WILKINS 530 WALNUT ST, PHILADELPHIA, PA 19106-3621 USA}
}

@article{petersen2017randomized,
  title = {Randomized Controlled Trials in Mild Cognitive Impairment: Sources of Variability},
  author = {Petersen, Ronald C and Thomas, Ronald G and Aisen, Paul S and Mohs, Richard C and Carrillo, Maria C and Albert, Marilyn S and (ADNI, Alzheimer's Disease Neuroimaging Initiative and others},
  year = {2017},
  journal = {Neurology},
  volume = {88},
  number = {18},
  pages = {1751--1758},
  publisher = {Wolters Kluwer Health, Inc. on behalf of the American Academy of Neurology}
}

@article{petersenRandomizedControlledTrials2017,
  title = {Randomized Controlled Trials in Mild Cognitive Impairment: {{Sources}} of Variability},
  author = {Petersen, R.C. and Thomas, R.G. and Aisen, P.S. and Mohs, R.C. and Carrillo, M.C. and Albert, M.S.},
  year = {2017},
  journal = {Neurology},
  volume = {88},
  number = {18},
  issn = {1526632X},
  doi = {10.1212/WNL.0000000000003907},
  abstract = {{\copyright} 2017 American Academy of Neurology. Objective: To examine the variability in performance among placebo groups in randomized controlled trials for mild cognitive impairment (MCI). Methods: Placebo group data were obtained from 2 National Institute on Aging (NIA) MCI randomized controlled trials, the Alzheimer's Disease Cooperative Study (ADCS) MCI trial and the Alzheimer's Disease Neuroimaging Initiative (ADNI), which is a simulated clinical trial, in addition to industry-sponsored clinical trials involving rivastigmine, galantamine, rofecoxib, and donepezil. The data were collated for common measurement instruments. The performance of the placebo participants from these studies was tracked on the Alzheimer's Disease Assessment Scale-cognitive subscale, Mini-Mental State Examination, and Clinical Dementia Rating-sum of boxes, and for progression on these measures to prespecified clinical study endpoints. APOE status, where available, was also analyzed for its effects. Results: The progression to clinical endpoints varied a great deal among the trials. The expected performances were seen for the participants in the 2 NIA trials, ADCS and ADNI, with generally worsening of performance over time; however, the industry-sponsored trials largely showed stable or improved performance in their placebo participants. APOE4 carrier status influenced results in an expected fashion on the study outcomes, including rates of progression and cognitive subscales. Conclusions: In spite of apparently similar criteria for MCI being adopted by the 7 studies, the implementation of the criteria varied a great deal. Several explanations including instruments used to characterize participants and variability among study populations contributed to the findings.},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/petersen et al_2017_randomized controlled trials in mild cognitive impairment.pdf;/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/petersen et al_2017_randomized controlled trials in mild cognitive impairment2.pdf}
}

@article{petersenVitaminDonepezilTreatment2005,
  title = {Vitamin {{E}} and Donepezil for the Treatment of Mild Cognitive Impairment},
  author = {Petersen, Ronald C. and Thomas, Ronald G. and Grundman, Michael and Bennett, David and Doody, Rachelle and Ferris, Steven and Galasko, Douglas and Jin, Shelia and Kaye, Jeffrey and Levey, Allan},
  year = {2005},
  journal = {New England Journal of Medicine},
  volume = {352},
  number = {23},
  pages = {2379--2388},
  publisher = {Mass Medical Soc},
  file = {/Users/zenn/Zotero/storage/HSV78PEQ/NEJMoa050151.html}
}

@article{petersenVitaminDonepezilTreatment2005a,
  title = {Vitamin {{E}} and {{Donepezil}} for the {{Treatment}} of {{Mild Cognitive Impairment}}},
  author = {Petersen, Ronald C and Bennett, David and Jin, Shelia and {van Dyck}, Christopher H},
  year = {2005},
  journal = {The New England Journal of Medicine},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/CL4WR7KT/Petersen et al. - 2005 - Vitamin E and Donepezil for the Treatment of Mild .pdf}
}

@article{petersenVitaminDonepezilTreatment2005b,
  title = {Vitamin {{E}} and {{Donepezil}} for the {{Treatment}} of {{Mild Cognitive Impairment}}},
  author = {Petersen, Ronald C. and Thomas, Ronald G. and Grundman, Michael and Bennett, David and Doody, Rachelle and Ferris, Steven and Galasko, Douglas and Jin, Shelia and Kaye, Jeffrey and Levey, Allan and Pfeiffer, Eric and Sano, Mary and {van Dyck}, Christopher H. and Thal, Leon J.},
  year = {2005},
  month = jun,
  journal = {New England Journal of Medicine},
  volume = {352},
  number = {23},
  pages = {2379--2388},
  publisher = {Massachusetts Medical Society},
  issn = {0028-4793},
  doi = {10.1056/NEJMoa050151},
  urldate = {2023-08-10},
  abstract = {Mild cognitive impairment represents a transitional state between the cognitive changes of normal aging and the earliest clinical features of Alzheimer's disease.1 Amnestic mild cognitive impairment refers to the subtype that has a primary memory component, either alone (single domain) or in conjunction with other cognitive-domain impairments (multiple domain), but of insufficient severity to constitute dementia.2--6 Previous research has shown that the rate of progression to clinically diagnosable Alzheimer's disease is 10 to 15 percent per year among persons who meet the criteria for the amnestic form of mild cognitive impairment, in contrast to a rate of 1 to . . .},
  pmid = {15829527},
  file = {/Users/zenn/Zotero/storage/BCCCDX3S/Petersen et al. - 2005 - Vitamin E and Donepezil for the Treatment of Mild .pdf}
}

@article{peterUsingEndtoEndSolution,
  title = {Using {{R}} as an {{End-to-End Solution}} to {{Capture}} and {{Analyze Data}} for a {{Local Outdoors Company Through}} the {{Usage}} of {{Shiny}} for {{R}} and Other {{Packages}}},
  author = {Peter, Edwin},
  abstract = {As the technological age takes over, the usage of data is particularly important across all industries. In this project, we have partnered with a local outdoors company that organizes outdoor learning events for children. The company is growing and has data from past programs that are archived and unused. They wish to keep track of the client database as well as the programs with different clients to identify useful insights. Hence, this project seeks to help ease the management of data and information for the company through the R and Shiny packages. Traditionally, developers turn to programming languages such as Java, JavaScript or even using PHP to create a web application that serves this need. This requires heavy computational work and maintenance, usually requiring the use of an online web server and database. However, not all companies require such complexity to manage their databases or draw analytical insights. The Shiny package in R is helpful in that it can be used to create interactive web apps while having the statistical analysis frameworks that R is able to provide. With this in mind, we have decided to use Shiny as a front-end tool to help ease the seamless transition from the capturing of new data up to the analysis and higher-level view of the data. The R framework is used to tie all the information together by cleaning the captured data which will then be displayed back onto Shiny for the user to look at their data. The data will then be analyzed using a market basket analysis as it can show a shift in customer preferences and profiles resulting in an actionable recommendation after understanding these insights. Data visualization is an important final step because it enables the business user to understand changes in customer behavior and helps the user to discover insights across their different customer profiles as the business continues to add and capture new data. The end goal is to create an analytics dashboard which will provide a forecasting tool that stores and process information for the user to better manage the operations and planning for the company.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/V8CQBSS7/Peter - Using R as an End-to-End Solution to Capture and A.pdf}
}

@article{peterUsingEndtoEndSolutiona,
  title = {Using {{R}} as an {{End-to-End Solution}} to {{Capture}} and {{Analyze Data}} for a {{Local Outdoors Company Through}} the {{Usage}} of {{Shiny}} for {{R}} and Other {{Packages}}},
  author = {Peter, Edwin and Yussaini, Abdul Shafiq Bin Mohd},
  urldate = {2023-12-15},
  file = {/Users/zenn/Zotero/storage/PR4DD34V/Peter and Yussaini - Using R as an End-to-End Solution to Capture and A.pdf}
}

@article{petrellaPersonalizedComputationalCausal2024,
  title = {Personalized {{Computational Causal Modeling}} of the {{Alzheimer Disease Biomarker Cascade}}},
  author = {Petrella, Jeffrey R. and Jiang, J. and Sreeram, K. and Dalziel, S. and Doraiswamy, P. M. and Hao, W. and {Alzheimer's Disease Neuroimaging Initiative}},
  year = {2024},
  month = mar,
  journal = {The Journal of Prevention of Alzheimer's Disease},
  volume = {11},
  number = {2},
  pages = {435--444},
  issn = {2426-0266},
  doi = {10.14283/jpad.2023.134},
  urldate = {2024-04-03},
  abstract = {Mathematical models of complex diseases, such as Alzheimer's disease, have the potential to play a significant role in personalized medicine. Specifically, models can be personalized by fitting parameters with individual data for the purpose of discovering primary underlying disease drivers, predicting natural history, and assessing the effects of theoretical interventions. Previous work in causal/mechanistic modeling of Alzheimer's Disease progression has modeled the disease at the cellular level and on a short time scale, such as minutes to hours. No previous studies have addressed mechanistic modeling on a personalized level using clinically validated biomarkers in individual subjects.},
  langid = {english},
  keywords = {Alzheimer's disease,dementia,disease,Mathematical modeling},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/petrella et al_2024_personalized computational causal modeling of the alzheimer disease biomarker.pdf}
}

@article{petrellaPersonalizedComputationalCausal2024a,
  title = {Personalized {{Computational Causal Modeling}} of the {{Alzheimer Disease Biomarker Cascade}}},
  author = {Petrella, Jeffrey R. and Jiang, J. and Sreeram, K. and Dalziel, S. and Doraiswamy, P. M. and Hao, W. and {Alzheimer's Disease Neuroimaging Initiative}},
  year = {2024},
  month = mar,
  journal = {The Journal of Prevention of Alzheimer's Disease},
  volume = {11},
  number = {2},
  pages = {435--444},
  issn = {2426-0266},
  doi = {10.14283/jpad.2023.134},
  urldate = {2024-04-03},
  abstract = {Mathematical models of complex diseases, such as Alzheimer's disease, have the potential to play a significant role in personalized medicine. Specifically, models can be personalized by fitting parameters with individual data for the purpose of discovering primary underlying disease drivers, predicting natural history, and assessing the effects of theoretical interventions. Previous work in causal/mechanistic modeling of Alzheimer's Disease progression has modeled the disease at the cellular level and on a short time scale, such as minutes to hours. No previous studies have addressed mechanistic modeling on a personalized level using clinically validated biomarkers in individual subjects.},
  langid = {english},
  keywords = {Alzheimer's disease,dementia,disease,Mathematical modeling}
}

@article{petsaniTherapeuticApplicationRTMS2021,
  title = {Therapeutic {{Application}} of {{rTMS}} in {{Atypical Parkinsonian Disorders}}},
  author = {Petsani, Chrysi and Aloizou, Athina-Maria and Siokas, Vasileios and Messinis, Lambros and Peristeri, Eleni and Bakirtzis, Christos and Nasios, Grigorios and Dardiotis, Efthimios},
  year = {2021},
  journal = {Behavioural Neurology},
  volume = {2021},
  pages = {3419907},
  issn = {1875-8584},
  doi = {10.1155/2021/3419907},
  abstract = {The terms atypical parkinsonian disorders (APDs) and Parkinson plus syndromes are mainly used to describe the four major entities of sporadic neuronal multisystem degeneration: progressive supranuclear palsy (PSP), corticobasal degeneration (CBD), multiple system atrophy (MSA), and dementia with Lewy bodies (LBD). APDs are characterized by a variety of symptoms and a lack of disease modifying therapies; their treatment thus remains mainly symptomatic. Brain stimulation via repetitive transcranial magnetic stimulation (rTMS) is a safe and noninvasive intervention using a magnetic coil, and it is considered an alternative therapy in various neuropsychiatric pathologies. In this paper, we review the available studies that investigate the efficacy of rTMS in the treatment of these APDs and Parkinson plus syndromes. {$T$}he majority of the studies have shown beneficial effects on motor and nonmotor symptoms, but research is still at a preliminary phase, with large, double-blind studies lacking in the literature.},
  langid = {english},
  pmcid = {PMC8718319},
  pmid = {34976231},
  keywords = {Corticobasal Degeneration,Humans,Multiple System Atrophy,Parkinsonian Disorders,Randomized Controlled Trials as Topic,Supranuclear Palsy Progressive,Transcranial Magnetic Stimulation},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/petsani et al_2021_therapeutic application of rtms in atypical parkinsonian disorders.pdf}
}

@inproceedings{pfeiffer2005cognition,
  title = {Cognition in the Treatment of Mild Cognitive Impairment with Donepezil and Vitamin {{E}}},
  booktitle = {International Psychogeriatrics},
  author = {Pfeiffer, E and Petersen, {\relax RC} and Thomas, {\relax RG} and Thal, {\relax LJ}},
  year = {2005},
  volume = {17},
  pages = {169--170},
  publisher = {CAMBRIDGE UNIV PRESS 32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA}
}

@phdthesis{phd,
  title = {Parametric Extimation through the Use of the Empirical Characteristic Function},
  author = {Thomas, Ronald G},
  year = {1983},
  school = {The University of Washington}
}

@article{piantinoLinkMildTraumatic2021,
  title = {Link between {{Mild Traumatic Brain Injury}}, {{Poor Sleep}}, and {{Magnetic Resonance Imaging}}: {{Visible Perivascular Spaces}} in {{Veterans}}},
  shorttitle = {Link between {{Mild Traumatic Brain Injury}}, {{Poor Sleep}}, and {{Magnetic Resonance Imaging}}},
  author = {Piantino, Juan and Schwartz, Daniel L. and Luther, Madison and Newgard, Craig and Silbert, Lisa and Raskind, Murray and Pagulayan, Kathleen and Kleinhans, Natalia and Iliff, Jeffrey and Peskind, Elaine},
  year = {2021},
  month = sep,
  journal = {Journal of Neurotrauma},
  volume = {38},
  number = {17},
  pages = {2391--2399},
  issn = {0897-7151, 1557-9042},
  doi = {10.1089/neu.2020.7447},
  urldate = {2023-11-13},
  abstract = {Impaired clearance of perivascular waste in the brain may play a critical role in morbidity after mild traumatic brain injury (mTBI). We aimed to determine the effect of mTBI on the burden of magnetic resonance imaging (MRI)-visible perivascular spaces (PVSs) in a cohort of U.S. military veterans and whether sleep modulates this effect. We also investigated the correlation between PVS burden and severity of persistent post-concussive symptoms. Fifty-six Iraq/Afghanistan veterans received 3 Tesla MRI as part of a prospective cohort study on military blast mTBI. White matter PVS burden (i.e., number and volume) was calculated using an established automated segmentation algorithm. Multi-variate regression was used to establish the association between mTBIs sustained in the military and PVS burden. Covariates included age, blood pressure, number of impact mTBIs outside the military, and blast exposures. Correlation coefficients were calculated between PVS burden and severity of persistent post-concussive symptoms. There was a significant positive relationship between the number of mTBIs sustained in the military and both PVS number and volume ( p = 0.04). A significant interaction was found between mTBI and poor sleep on PVS volume ( p = 0.04). A correlation was found between PVS number and volume, as well as severity of postconcussive symptoms ( p = 0.03). Further analysis revealed a moderate correlation between PVS number and volume, as well as balance problems ( p {$<$} 0.001). In Iraq/Afghanistan veterans, mTBI is associated with an increase in PVS burden. Further, an interaction exists between mTBI and poor sleep on PVS burden. Increased PVS burden, which may indicate waste clearance dysfunction, is associated with persistent post-concussive symptom severity.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/2CL87T27/Piantino et al. - 2021 - Link between Mild Traumatic Brain Injury, Poor Sle.pdf}
}

@article{piephoCoefficientDeterminationR22019,
  title = {A Coefficient of Determination ({{R2}}) for Generalized Linear Mixed Models},
  author = {Piepho, Hans-Peter},
  year = {2019},
  journal = {Biometrical Journal},
  volume = {61},
  number = {4},
  pages = {860--872},
  issn = {1521-4036},
  doi = {10.1002/bimj.201800270},
  urldate = {2023-12-15},
  abstract = {Extensions of linear models are very commonly used in the analysis of biological data. Whereas goodness of fit measures such as the coefficient of determination (R2) or the adjusted R2 are well established for linear models, it is not obvious how such measures should be defined for generalized linear and mixed models. There are by now several proposals but no consensus has yet emerged as to the best unified approach in these settings. In particular, it is an open question how to best account for heteroscedasticity and for covariance among observations present in residual error or induced by random effects. This paper proposes a new approach that addresses this issue and is universally applicable for arbitrary variance-covariance structures including spatial models and repeated measures. It is exemplified using three biological examples.},
  copyright = {{\copyright} 2019 WILEY-VCH Verlag GmbH \& Co. KGaA, Weinheim},
  langid = {english},
  keywords = {generalized linear mixed models,generalized linear models,goodness-of-fit,linear mixed models,semivariogram,total variance},
  file = {/Users/zenn/Zotero/storage/2H7GW2SL/bimj.html}
}

@article{piephoCoefficientDeterminationR22019a,
  title = {A Coefficient of Determination ({{R2}}) for Generalized Linear Mixed Models},
  author = {Piepho, Hans-Peter},
  year = {2019},
  journal = {Biometrical Journal},
  volume = {61},
  number = {4},
  pages = {860--872},
  issn = {1521-4036},
  doi = {10.1002/bimj.201800270},
  urldate = {2023-12-15},
  abstract = {Extensions of linear models are very commonly used in the analysis of biological data. Whereas goodness of fit measures such as the coefficient of determination (R2) or the adjusted R2 are well established for linear models, it is not obvious how such measures should be defined for generalized linear and mixed models. There are by now several proposals but no consensus has yet emerged as to the best unified approach in these settings. In particular, it is an open question how to best account for heteroscedasticity and for covariance among observations present in residual error or induced by random effects. This paper proposes a new approach that addresses this issue and is universally applicable for arbitrary variance-covariance structures including spatial models and repeated measures. It is exemplified using three biological examples.},
  copyright = {{\copyright} 2019 WILEY-VCH Verlag GmbH \& Co. KGaA, Weinheim},
  langid = {english},
  keywords = {generalized linear mixed models,generalized linear models,goodness-of-fit,linear mixed models,semivariogram,total variance},
  file = {/Users/zenn/Zotero/storage/ADP6WVLG/bimj.html}
}

@article{piephoCoefficientDeterminationR22019b,
  title = {A Coefficient of Determination ({{R2}}) for Generalized Linear Mixed Models},
  author = {Piepho, Hans-Peter},
  year = {2019},
  journal = {Biometrical Journal},
  volume = {61},
  number = {4},
  pages = {860--872},
  issn = {1521-4036},
  doi = {10.1002/bimj.201800270},
  urldate = {2023-12-15},
  abstract = {Extensions of linear models are very commonly used in the analysis of biological data. Whereas goodness of fit measures such as the coefficient of determination (R2) or the adjusted R2 are well established for linear models, it is not obvious how such measures should be defined for generalized linear and mixed models. There are by now several proposals but no consensus has yet emerged as to the best unified approach in these settings. In particular, it is an open question how to best account for heteroscedasticity and for covariance among observations present in residual error or induced by random effects. This paper proposes a new approach that addresses this issue and is universally applicable for arbitrary variance-covariance structures including spatial models and repeated measures. It is exemplified using three biological examples.},
  langid = {english},
  keywords = {generalized linear mixed models,generalized linear models,goodness-of-fit,linear mixed models,semivariogram,total variance},
  file = {/Users/zenn/Zotero/storage/R5GSD76T/Piepho - 2019 - A coefficient of determination (R2) for generalize.pdf;/Users/zenn/Zotero/storage/Q4HXUD47/bimj.html}
}

@article{piephoHitchhikerGuideMixed2003,
  title = {A {{Hitchhiker}}'s {{Guide}} to {{Mixed Models}} for {{Randomized Experiments}}},
  author = {Piepho, H. P. and B{\"u}chse, A. and Emrich, K.},
  year = {2003},
  month = oct,
  journal = {Journal of Agronomy and Crop Science},
  volume = {189},
  number = {5},
  pages = {310--322},
  issn = {0931-2250, 1439-037X},
  doi = {10.1046/j.1439-037X.2003.00049.x},
  urldate = {2023-12-15},
  abstract = {Abstract             Designed experiments conducted by crop scientists often give rise to several random sources of variation. Pertinent examples are split-plot designs, series of experiments and repeated measurements taken on the same field plot. Data arising from such experiments may be conveniently analysed by mixed models. While the mixed model framework is by now very well developed theoretically, and good software is readily available, the technology is still under-utilized. The purpose of the present paper is, therefore, to encourage more widespread use of mixed models. We outline basic principles, which help in setting up mixed models appropriate in a given situation, the main task required from users of mixed model software. Several examples are considered to demonstrate key issues. The theoretical underpinnings are briefly sketched in so far as they are practically relevant for making informed use of mixed-model computer packages. Finally, a brief review is given of some recent methodological developments, which are of interest to the plant sciences. A German version of this paper is available from the corresponding author upon request.},
  langid = {english}
}

@article{piephoHitchhikerGuideMixed2003a,
  title = {A {{Hitchhiker}}'s {{Guide}} to {{Mixed Models}} for {{Randomized Experiments}}},
  author = {Piepho, H. P. and B{\"u}chse, A. and Emrich, K.},
  year = {2003},
  journal = {Journal of Agronomy and Crop Science},
  volume = {189},
  number = {5},
  pages = {310--322},
  issn = {1439-037X},
  doi = {10.1046/j.1439-037X.2003.00049.x},
  urldate = {2023-12-15},
  abstract = {Designed experiments conducted by crop scientists often give rise to several random sources of variation. Pertinent examples are split-plot designs, series of experiments and repeated measurements taken on the same field plot. Data arising from such experiments may be conveniently analysed by mixed models. While the mixed model framework is by now very well developed theoretically, and good software is readily available, the technology is still under-utilized. The purpose of the present paper is, therefore, to encourage more widespread use of mixed models. We outline basic principles, which help in setting up mixed models appropriate in a given situation, the main task required from users of mixed model software. Several examples are considered to demonstrate key issues. The theoretical underpinnings are briefly sketched in so far as they are practically relevant for making informed use of mixed-model computer packages. Finally, a brief review is given of some recent methodological developments, which are of interest to the plant sciences. A German version of this paper is available from the corresponding author upon request.},
  langid = {english},
  keywords = {analysis of variance,blocking,error strata,geostatistics,longitudinal data,mixed model,random effect,randomization,repeated measurements,series of experiments},
  file = {/Users/zenn/Zotero/storage/IIIL6Z5L/Piepho et al. - 2003 - A Hitchhiker's Guide to Mixed Models for Randomize.pdf;/Users/zenn/Zotero/storage/E5IL63MC/j.1439-037X.2003.00049.html}
}

@article{pierce2002randomized,
  title = {A Randomized Trial of the Effect of a Plant-Based Dietary Pattern on Additional Breast Cancer Events and Survival:: The {{Women}}'s {{Healthy Eating}} and {{Living}} ({{WHEL}}) {{Study}}},
  author = {Pierce, John P and Faerber, Susan and Wright, Fred A and Rock, Cheryl L and Newman, Vicky and Flatt, Shirley W and Kealey, Sheila and Jones, Vicky E and Caan, Bette J and Gold, Ellen B and others},
  year = {2002},
  journal = {Controlled clinical trials},
  volume = {23},
  number = {6},
  pages = {728--756},
  publisher = {Elsevier}
}

@article{pirondiniCovariateAdjustmentCardiovascular2022,
  title = {Covariate {{Adjustment}} in {{Cardiovascular Randomized Controlled Trials}}},
  author = {Pirondini, Leah and Gregson, John and Owen, Ruth and Collier, Tim and Pocock, Stuart},
  year = {2022},
  month = may,
  journal = {JACC: Heart Failure},
  volume = {10},
  number = {5},
  pages = {297--305},
  publisher = {American College of Cardiology Foundation},
  doi = {10.1016/j.jchf.2022.02.007},
  urldate = {2023-05-06},
  keywords = {covariate adjustment,randomized controlled trials,statistics},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/pirondini et al_2022_covariate adjustment in cardiovascular randomized controlled trials.pdf}
}

@article{pisaniMetaAnalysisRandomised2021,
  title = {A Meta-analysis of Randomised Controlled Trials of Physical Activity in People with {{Alzheimer}}'s Disease and Mild Cognitive Impairment with a Comparison to Donepezil},
  author = {Pisani, Sara and Mueller, Christoph and Huntley, Jonathan and Aarsland, Dag and Kempton, Matthew J.},
  year = {2021},
  month = may,
  journal = {International Journal of Geriatric Psychiatry},
  pages = {gps.5581},
  issn = {0885-6230},
  doi = {10.1002/gps.5581},
  urldate = {2021-06-05},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/pisani et al_2021_a meta‐analysis of randomised controlled trials of physical activity in people.pdf}
}

@article{pocockSubgroupAnalysisCovariate2002,
  title = {Subgroup Analysis, Covariate Adjustment and Baseline Comparisons in Clinical Trial Reporting: Current Practiceand Problems},
  shorttitle = {Subgroup Analysis, Covariate Adjustment and Baseline Comparisons in Clinical Trial Reporting},
  author = {Pocock, Stuart J. and Assmann, Susan E. and Enos, Laura E. and Kasten, Linda E.},
  year = {2002},
  journal = {Statistics in Medicine},
  volume = {21},
  number = {19},
  pages = {2917--2930},
  issn = {1097-0258},
  doi = {10.1002/sim.1296},
  urldate = {2024-06-27},
  abstract = {Clinical trial investigators often record a great deal of baseline data on each patient at randomization. When reporting the trial's findings such baseline data can be used for (i) subgroup analyses which explore whether there is evidence that the treatment difference depends on certain patient characteristics, (ii) covariate-adjusted analyses which aim to refine the analysis of the overall treatment difference by taking account of the fact that some baseline characteristics are related to outcome and may be unbalanced between treatment groups, and (iii) baseline comparisons which compare the baseline characteristics of patients in each treatment group for any possible (unlucky) differences. This paper examines how these issues are currently tackled in the medical journals, based on a recent survey of 50 trial reports in four major journals. The statistical ramifications are explored, major problems are highlighted and recommendations for future practice are proposed. Key issues include: the overuse and overinterpretation of subgroup analyses; the underuse of appropriate statistical tests for interaction; inconsistencies in the use of covariate-adjustment; the lack of clear guidelines on covariate selection; the overuse of baseline comparisons in some studies; the misuses of significance tests for baseline comparability, and the need for trials to have a predefined statistical analysis plan for all these uses of baseline data. Copyright {\copyright} 2002 John Wiley \& Sons, Ltd.},
  copyright = {Copyright {\copyright} 2002 John Wiley \& Sons, Ltd.},
  langid = {english},
  keywords = {baseline comparisons,clinical trials,covariate adjustment,medical journals,subgroup analysis},
  file = {/Users/zenn/Zotero/storage/WP7K8EK4/Pocock et al. - 2002 - Subgroup analysis, covariate adjustment and baseli.pdf;/Users/zenn/Zotero/storage/ITTDG2ZV/sim.html}
}

@article{poeweTherapeuticAdvancesMultiple2015,
  title = {Therapeutic Advances in Multiple System Atrophy and Progressive Supranuclear Palsy},
  author = {Poewe, Werner and Mahlknecht, Philipp and Krismer, Florian},
  year = {2015},
  month = sep,
  journal = {Movement Disorders: Official Journal of the Movement Disorder Society},
  volume = {30},
  number = {11},
  pages = {1528--1538},
  issn = {1531-8257},
  doi = {10.1002/mds.26334},
  abstract = {Multiple system atrophy (MSA) and progressive supranuclear palsy (PSP) are relentlessly progressive neurodegenerative diseases leading to severe disability and ultimately death within less than 10 y. Despite increasing efforts in basic and clinical research, effective therapies for these atypical parkinsonian disorders are lacking. Although earlier small clinical studies in MSA and PSP mainly focused on symptomatic treatment, advances in the understanding of the molecular underpinnings of these diseases and in the search for biomarkers have paved the way for the first large and well-designed clinical trials aiming at disease modification. Targets of intervention in these trials have included {$\alpha$}-synuclein inclusion pathology in the case of MSA and tau-related mechanisms in PSP. Since 2013, four large randomized, placebo-controlled, double-blind disease-modification trials have been completed and published, using rasagiline (MSA), rifampicin (MSA), tideglusib (PSP), or davunetide (PSP). All of these failed to demonstrate signal efficacy with regard to the primary outcome measures. In addition, two randomized, placebo-controlled, double-blind trials have studied the efficacy of droxidopa in the symptomatic treatment of neurogenic orthostatic hypotension, including patients with MSA, with positive results in one trial. This review summarizes the design and the outcomes of these and other smaller trials published since 2013 and attempts to highlight priority areas of future therapeutic research in MSA and PSP. {\copyright} 2015 International Parkinson and Movement Disorder Society.},
  langid = {english},
  pmid = {26227071},
  keywords = {clinical trials,Clinical Trials as Topic,Humans,multiple system atrophy,Multiple System Atrophy,progressive supranuclear palsy,Supranuclear Palsy Progressive,therapies}
}

@article{poeweTherapeuticAdvancesMultiple2015a,
  title = {Therapeutic Advances in Multiple System Atrophy and Progressive Supranuclear Palsy},
  author = {Poewe, Werner and Mahlknecht, Philipp and Krismer, Florian},
  year = {2015},
  month = sep,
  journal = {Movement Disorders: Official Journal of the Movement Disorder Society},
  volume = {30},
  number = {11},
  pages = {1528--1538},
  issn = {1531-8257},
  doi = {10.1002/mds.26334},
  abstract = {Multiple system atrophy (MSA) and progressive supranuclear palsy (PSP) are relentlessly progressive neurodegenerative diseases leading to severe disability and ultimately death within less than 10 y. Despite increasing efforts in basic and clinical research, effective therapies for these atypical parkinsonian disorders are lacking. Although earlier small clinical studies in MSA and PSP mainly focused on symptomatic treatment, advances in the understanding of the molecular underpinnings of these diseases and in the search for biomarkers have paved the way for the first large and well-designed clinical trials aiming at disease modification. Targets of intervention in these trials have included {$\alpha$}-synuclein inclusion pathology in the case of MSA and tau-related mechanisms in PSP. Since 2013, four large randomized, placebo-controlled, double-blind disease-modification trials have been completed and published, using rasagiline (MSA), rifampicin (MSA), tideglusib (PSP), or davunetide (PSP). All of these failed to demonstrate signal efficacy with regard to the primary outcome measures. In addition, two randomized, placebo-controlled, double-blind trials have studied the efficacy of droxidopa in the symptomatic treatment of neurogenic orthostatic hypotension, including patients with MSA, with positive results in one trial. This review summarizes the design and the outcomes of these and other smaller trials published since 2013 and attempts to highlight priority areas of future therapeutic research in MSA and PSP. {\copyright} 2015 International Parkinson and Movement Disorder Society.},
  langid = {english},
  pmid = {26227071},
  keywords = {clinical trials,Clinical Trials as Topic,Humans,multiple system atrophy,Multiple System Atrophy,progressive supranuclear palsy,Supranuclear Palsy Progressive,therapies}
}

@article{poeweTherapeuticAdvancesMultiple2015b,
  title = {Therapeutic Advances in Multiple System Atrophy and Progressive Supranuclear Palsy},
  author = {Poewe, Werner and Mahlknecht, Philipp and Krismer, Florian},
  year = {2015},
  month = sep,
  journal = {Movement Disorders: Official Journal of the Movement Disorder Society},
  volume = {30},
  number = {11},
  pages = {1528--1538},
  issn = {1531-8257},
  doi = {10.1002/mds.26334},
  abstract = {Multiple system atrophy (MSA) and progressive supranuclear palsy (PSP) are relentlessly progressive neurodegenerative diseases leading to severe disability and ultimately death within less than 10 y. Despite increasing efforts in basic and clinical research, effective therapies for these atypical parkinsonian disorders are lacking. Although earlier small clinical studies in MSA and PSP mainly focused on symptomatic treatment, advances in the understanding of the molecular underpinnings of these diseases and in the search for biomarkers have paved the way for the first large and well-designed clinical trials aiming at disease modification. Targets of intervention in these trials have included {$\alpha$}-synuclein inclusion pathology in the case of MSA and tau-related mechanisms in PSP. Since 2013, four large randomized, placebo-controlled, double-blind disease-modification trials have been completed and published, using rasagiline (MSA), rifampicin (MSA), tideglusib (PSP), or davunetide (PSP). All of these failed to demonstrate signal efficacy with regard to the primary outcome measures. In addition, two randomized, placebo-controlled, double-blind trials have studied the efficacy of droxidopa in the symptomatic treatment of neurogenic orthostatic hypotension, including patients with MSA, with positive results in one trial. This review summarizes the design and the outcomes of these and other smaller trials published since 2013 and attempts to highlight priority areas of future therapeutic research in MSA and PSP. {\copyright} 2015 International Parkinson and Movement Disorder Society.},
  langid = {english},
  pmid = {26227071},
  keywords = {clinical trials,Clinical Trials as Topic,Humans,multiple system atrophy,Multiple System Atrophy,progressive supranuclear palsy,Supranuclear Palsy Progressive,therapies}
}

@article{ponjoanSexMattersAssociation2024,
  title = {Sex Matters in the Association between Cardiovascular Health and Incident Dementia: Evidence from Real World Data},
  shorttitle = {Sex Matters in the Association between Cardiovascular Health and Incident Dementia},
  author = {Ponjoan, Anna and Blanch, Jordi and {Fages-Masmiquel}, Ester and {Mart{\'i}-Lluch}, Ruth and {Alves-Cabratosa}, Lia and {Garcia-Gil}, Mar{\'i}a Del Mar and {Dom{\'i}nguez-Armengol}, Gina and {Ribas-Aulinas}, Francesc and {Zacar{\'i}as-Pons}, Llu{\'i}s and Ramos, Rafel},
  year = {2024},
  month = mar,
  journal = {Alzheimer's Research \& Therapy},
  volume = {16},
  number = {1},
  pages = {58},
  issn = {1758-9193},
  doi = {10.1186/s13195-024-01406-x},
  urldate = {2024-03-18},
  abstract = {Background{\enspace} Cardiovascular health has been associated with dementia onset, but little is known about the variation of such association by sex and age considering dementia subtypes. We assessed the role of sex and age in the asso-ciation between cardiovascular risk and the onset of all-cause dementia, Alzheimer's disease, and vascular dementia in people aged 50--74 years. Methods{\enspace} This is a retrospective cohort study covering 922.973 Catalans who attended the primary care services of the Catalan Health Institute (Spain). Data were obtained from the System for the Development of Research in Primary Care (SIDIAP database). Exposure was the cardiovascular risk (CVR) at baseline categorized into four levels of Framingham-REGICOR score (FRS): low (FRS\,{$<$}\,5\%), low-intermediate (5\%\,{$\leq$}\,FRS\,{$<$}\,7.5\%), high-intermediate (7.5\%\,{$\leq$}\,FRS\,{$<$}\,10\%), high (FRS\,{$\geq$}\,10\%), and one group with previous vascular disease. Cases of all-cause dementia and Alzheimer's disease were identified using validated algorithms, and cases of vascular dementia were identified by diagnostic codes. We fitted stratified Cox models using age parametrized as b-Spline. Results{\enspace} A total of 51,454 incident cases of all-cause dementia were recorded over a mean follow-up of 12.7 years. The hazard ratios in the low-intermediate and high FRS groups were 1.12 (95\% confidence interval: 1.08--1.15) and 1.55 (1.50--1.60) for all-cause dementia; 1.07 (1.03--1.11) and 1.17 (1.11--1.24) for Alzheimer's disease; and 1.34 (1.21--1.50) and 1.90 (1.67--2.16) for vascular dementia. These associations were stronger in women and in midlife compared to later life in all dementia types. Women with a high Framingham-REGICOR score presented a similar risk of develop-ing dementia --- of any type --- to women who had previous vascular disease, and at age 50--55, they showed three times higher risk of developing dementia risk compared to the lowest Framingham-REGICOR group. Conclusions{\enspace} We found a dose-response association between the Framingham-REGICOR score and the onset of all dementia types. Poor cardiovascular health in midlife increased the onset of all dementia types later in life, especially in women.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/ZVUPRT52/s13195-024-01406-x.pdf}
}

@article{posner2009p1,
  title = {P1-269: {{The ADAS-cog}}'s Performance as a Measure-Lessons from the {{ADNI}} Study: {{Part}} 1-Evaluation Using Traditional Psychometric Methods},
  author = {Posner, Holly and Cano, Stefan and Aisen, Paul and Selnes, Ola and Stern, Yaakov and Thomas, Ronald and Weiner, Michael and Zajicek, John and Zeger, Scott and Hobart, Jeremy},
  year = {2009},
  journal = {Alzheimer's \& Dementia},
  volume = {5},
  number = {4S\_Part\_9},
  pages = {P256--P256}
}

@article{posner2013establishing,
  title = {Establishing the Psychometric Underpinning of Cognition Measures for Clinical Trials of {{Alzheimer}}'s Disease and Its Precursors: A New Approach},
  author = {Posner, Holly B and Cano, Stefan and Carrillo, Maria C and Selnes, Ola and Stern, Yaakov and Thomas, Ronald G and Zajicek, John and Hobart, Jeremy and Initiative, Alzheimer's Disease Neuroimaging and others},
  year = {2013},
  journal = {Alzheimer's \& Dementia},
  volume = {9},
  number = {1},
  pages = {S56--S60},
  publisher = {No longer published by Elsevier}
}

@article{predescuTimesSquareSampling2023,
  title = {Times {{Square}} Sampling: An Adaptive Algorithm for Free Energy Estimation},
  shorttitle = {Times {{Square}} Sampling},
  author = {Predescu, Cristian and Snarski, Michael and {Robinson-Mosher}, Avi and Sritharan, Duluxan and Szalay, Tamas and Shaw, David E.},
  year = {2023},
  journal = {Journal of Computational and Graphical Statistics},
  volume = {0},
  number = {ja},
  pages = {1--29},
  publisher = {Taylor \& Francis},
  issn = {1061-8600},
  doi = {10.1080/10618600.2023.2291108},
  urldate = {2023-12-15},
  abstract = {Estimating free energy differences, an important problem in computational drug discovery and in a wide range of other application areas, commonly involves a computationally intensive process of sampling a family of high-dimensional probability distributions and a procedure for computing estimates based on those samples. The variance of the free energy estimate of interest typically depends strongly on how the total computational resources available for sampling are divided among the distributions, but determining an efficient allocation is difficult without sampling the distributions. Here we introduce the Times Square sampling algorithm, a novel on-the-fly estimation method that dynamically allocates resources in such a way as to significantly accelerate the estimation of free energies and other observables, while providing rigorous convergence guarantees for the estimators. We also show that it is possible, surprisingly, for on-the-fly free energy estimation to achieve lower asymptotic variance than the maximum-likelihood estimator MBAR, raising the prospect that on-the-fly estimation could reduce variance in a variety of other statistical applications. Supplementary materials for this article are available online.},
  file = {/Users/zenn/Zotero/storage/3TM3BHA9/Predescu et al. - 2023 - Times Square sampling an adaptive algorithm for f.pdf}
}

@article{preudhommeHeadtoheadComparisonClustering2021,
  title = {Head-to-Head Comparison of Clustering Methods for Heterogeneous Data: A Simulation-Driven Benchmark},
  shorttitle = {Head-to-Head Comparison of Clustering Methods for Heterogeneous Data},
  author = {Preud'homme, Gregoire and Duarte, Kevin and Dalleau, Kevin and Lacomblez, Claire and Bresso, Emmanuel and {Sma{\"i}l-Tabbone}, Malika and Couceiro, Miguel and Devignes, Marie-Dominique and Kobayashi, Masatake and Huttin, Olivier and Ferreira, Jo{\~a}o Pedro and Zannad, Faiez and Rossignol, Patrick and Girerd, Nicolas},
  year = {2021},
  month = feb,
  journal = {Scientific Reports},
  volume = {11},
  number = {1},
  pages = {4202},
  publisher = {Nature Publishing Group},
  issn = {2045-2322},
  doi = {10.1038/s41598-021-83340-8},
  urldate = {2024-03-30},
  abstract = {The choice of the most appropriate unsupervised machine-learning method for ``heterogeneous'' or ``mixed'' data, i.e. with both continuous and categorical variables, can be challenging. Our aim was to examine the performance of various clustering strategies for mixed data using both simulated and real-life data. We conducted a benchmark analysis of ``ready-to-use'' tools in R comparing 4 model-based (Kamila algorithm, Latent Class Analysis, Latent Class Model [LCM] and Clustering by Mixture Modeling) and 5 distance/dissimilarity-based (Gower distance or Unsupervised Extra Trees dissimilarity followed by hierarchical clustering or Partitioning Around Medoids, K-prototypes) clustering methods. Clustering performances were assessed by Adjusted Rand Index (ARI) on 1000 generated virtual populations consisting of mixed variables using 7 scenarios with varying population sizes, number of clusters, number of continuous and categorical variables, proportions of relevant (non-noisy) variables and degree of variable relevance (low, mild, high). Clustering methods were then applied on the EPHESUS randomized clinical trial data (a heart failure trial evaluating the effect of eplerenone) allowing to illustrate the differences between different clustering techniques. The simulations revealed the dominance of K-prototypes, Kamila and LCM models over all other methods. Overall, methods using dissimilarity matrices in classical algorithms such as Partitioning Around Medoids and Hierarchical Clustering had a lower ARI compared to model-based methods in all scenarios. When applying clustering methods to a real-life clinical dataset, LCM showed promising results with regard to differences in (1) clinical profiles across clusters, (2) prognostic performance (highest C-index) and (3) identification of patient subgroups with substantial treatment benefit. The present findings suggest key differences in clustering performance between the tested algorithms (limited to tools readily available in R). In most of the tested scenarios, model-based methods (in particular the Kamila and LCM packages) and K-prototypes typically performed best in the setting of heterogeneous data.},
  copyright = {2021 The Author(s)},
  langid = {english},
  keywords = {Computational biology and bioinformatics,Functional clustering,Machine learning},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/preud’homme et al_2021_head-to-head comparison of clustering methods for heterogeneous data.pdf}
}

@article{proudfootJointMarginalconditionalModel2017,
  title = {A Joint Marginal-Conditional Model for Multivariate Longitudinal Data},
  author = {Proudfoot, James and Faig, Walter and Natarajan, Loki and Xu, Ronghui and Ronghui Xu, Correspondence},
  year = {2017},
  doi = {10.1002/sim.7552},
  urldate = {2021-11-27},
  abstract = {Multivariate longitudinal data frequently arise in biomedical applications; however , their analyses are often performed one outcome at a time, or jointly using existing software in an ad hoc fashion. A main challenge in the proper analysis of such data is the fact that the different outcomes are measured on different unknown scales. Methodology for handling the scale problem has been previously proposed for cross-sectional data, and here we extend it to the longitudinal setting. We consider modeling the longitudinal data using random effects, while leaving the joint distribution of the multiple outcomes unspecified. We propose an estimating equation together with an expectation-maximization-type (expectation-substitution) algorithm. The consistency and the asymptotic distribution of the parameter estimates are established. The method is evaluated using extensive simulations and applied to a longitudinal nutrition data set from a large dietary intervention trial on breast cancer survivors, the Women's Healthy Eating and Living Study.},
  keywords = {common effect,ES algorithm,generalized estimating equations,random effects,scaling},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/proudfoot et al_2017_a joint marginal-conditional model for multivariate longitudinal data.pdf}
}

@article{puigBayesianModelSelection2019,
  title = {Bayesian Model Selection for the Study of {{Hardy}}--{{Weinberg}} Proportions and Homogeneity of Gender Allele Frequencies},
  author = {Puig, Xavier and Ginebra, Josep and Graffelman, Jan},
  year = {2019},
  journal = {Heredity},
  volume = {123},
  number = {5},
  pages = {549--564},
  publisher = {Springer Nature B.V},
  address = {England},
  issn = {0018-067X},
  doi = {10.1038/s41437-019-0232-0},
  abstract = {Standard statistical tests for Hardy-Weinberg equilibrium assume the equality of allele frequencies in the sexes, whereas tests for the equality of allele frequencies in the sexes assume Hardy-Weinberg equilibrium. This produces a circularity in the testing of genetic variants, which has recently been resolved with new frequentist likelihood and exact procedures. In this paper, we tackle the same problem by posing it as a Bayesian model comparison problem. We formulate an exhaustive set of ten alternative scenarios for biallelic genetic variants. Using Dirichlet and Beta priors for genotype and allele frequencies, we derive marginal likelihoods for all scenarios, and select the most likely scenario using the posterior probabilities that each of these scenarios is the one in place. Different from the usual frequentist testing approach, the Bayesian approach allows one to compare any number of models, and not just two at a time, and the models compared do not have to be nested. We illustrate our Bayesian approach with genetic data from the 1,000 genomes project and through a simulation study.},
  langid = {english},
  keywords = {Akaike's information criterion,Alleles,Animals,Arees tematiques de la UPC,Bayesian analysis,Bioinformatics,Computer simulation,Dirichlet prior,Dirichlet problem,Equilibrium,Estadistica matematica,Evolution,Female,Gene Frequency,Genetic variance,Genetic variation,Genomes,Genomics,Genotype,Genotypes,Hardy,Hardy-Weinberg equilibrium,Homogeneity,Humans,Inbreeding coefficient,Male,Marginal likelihood,Matematiques i estadistica,Mathematical models,Mathematical statistics,Models Genetic,Multinomial model,Population genetics,Populations,Quantitative Biology,Statistical analysis,Statistical tests,Weinberg equilibrium},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/puig et al_2019_bayesian model selection for the study of hardy–weinberg proportions and.pdf}
}

@article{puigBayesianTestHardy2017,
  title = {A {{Bayesian}} Test for {{Hardy}}--{{Weinberg}} Equilibrium of Biallelic {{X-chromosomal}} Markers},
  author = {Puig, X. and Ginebra, J. and Graffelman, J.},
  year = {2017},
  journal = {Heredity},
  volume = {119},
  number = {4},
  pages = {226--236},
  publisher = {Springer Nature B.V},
  address = {England},
  issn = {0018-067X},
  doi = {10.1038/hdy.2017.30},
  abstract = {The X chromosome is a relatively large chromosome, harboring a lot of genetic information. Much of the statistical analysis of X-chromosomal information is complicated by the fact that males only have one copy. Recently, frequentist statistical tests for Hardy-Weinberg equilibrium have been proposed specifically for dealing with markers on the X chromosome. Bayesian test procedures for Hardy-Weinberg equilibrium for the autosomes have been described, but Bayesian work on the X chromosome in this context is lacking. This paper gives the first Bayesian approach for testing Hardy-Weinberg equilibrium with biallelic markers at the X chromosome. Marginal and joint posterior distributions for the inbreeding coefficient in females and the male to female allele frequency ratio are computed, and used for statistical inference. The paper gives a detailed account of the proposed Bayesian test, and illustrates it with data from the 1000 Genomes project. In that implementation, a novel approach to tackle multiple testing from a Bayesian perspective through posterior predictive checks is used.},
  langid = {english},
  keywords = {Animals,Bayes Theorem,Bayesian analysis,Chromosomes,Deoxyribonucleic acid,DNA,Equilibrium,Female,Females,Gene Frequency,Genetic Markers - genetics,Genomes,Inbreeding,Male,Males,Markers,Models Genetic,Original,Original Article,Statistical analysis,Statistical inference,Statistical tests,X Chromosome - genetics,X Chromosomes},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/puig et al_2017_a bayesian test for hardy–weinberg equilibrium of biallelic x-chromosomal.pdf}
}

@article{pusponegoroLinearMixedModel2017,
  title = {Linear {{Mixed Model}} for {{Analyzing Longitudinal Data}}: {{A Simulation Study}} of {{Children Growth Differences}}},
  shorttitle = {Linear {{Mixed Model}} for {{Analyzing Longitudinal Data}}},
  author = {Pusponegoro, Novi Hidayat and Rachmawati, Ro'fah Nur and Notodiputro, Khairil Anwar and Sartono, Bagus},
  year = {2017},
  journal = {Procedia Computer Science},
  volume = {116},
  pages = {284--291},
  issn = {18770509},
  doi = {10.1016/j.procs.2017.10.071},
  urldate = {2023-02-12},
  abstract = {Abstract Growth developmental research is one example of the application of longitudinal data that have correlated value over time. LGirnoewatrhMdiexveedloMpmoednetlal(LreMseMar)chis iasnoneextenxsaimonpleofocflathsesicapsptalitcisattiicoanl opfrolcoendguirtuesdinthaaltdpartoavtihdaets hfalevxeibciolirtryelatneadlyvsiasluien ocvoerretliamteed. lLoingeiatrudMiniaxledaMta oadnedl a(lLloMwMs )reisseaarncheexrtetonsmioondeolfthcelascsoivcarsitanticseticsatrlupcrtuorceesduthreast rtehpartespernotvidtsesrafnldexoimbileiftyfecatnsa. lTyshiiss ipnapceorrrberliaetfeldy dloensgcritiubdesinaglrodwatah acnudrvaelslowmsodresleasrchaesrintoglme oLdMelMthethcaotvraerpiarnecsensttrtuwcoturlesvetlhsatofreporbesseernvtatiitosnr,anwdhoimchefofeccutsse.dThoins pmaopdeerlibnrgiefiltys cdoevscarriibaenscegsrtorwucthturceutrovecsapmtuordeecl oarsrelaatseidnginlefoLrmMaMtionthoavt erretpirmeeseonft itnwdoivildeuvaelspeorffoorbmsaenrvcaet.ioWne, awphpilcyhLfMocMuseadndomn omdeolddeliifnfegreintst tcyopveasriaonfcietsstcrouvcaturiraentcoecsatprutucrteurceorirneltahtedsimnfuolramtiaotniosntuodvyerotfimcheioldfriennd'isvigdruoawltpherdfiofrfemraence.s Wbaeseadppolyn LthMe Mfeeadnidngmmodeetlhoddifsf.erWenet ptyeprefosrmof siitms ucloavtiaornianscensatrriuocutusrienginMtIhXeEsDimpurloactieodnursetuidnySoAfSchsyilsdtreemn,'sbagsreodwothn dthifrfeeerefnitceinsdbicaessed(-2oRn LthLe, AfeIeCdianngdmSeBthCo)dasn. dWpevpaelrufoersmigsniimfiucalantcioenlesvceeln, awrieooubstianign MUnIXstrEuDctuprreodce(dUuNre) cinovSaAriSanscyestiesmal,wbaayssedbeonthtehrbeeestfiftitinindipcreesse(n-2tiRnLgLth, eAcIhCaraancdteSriBstCic) oafndaptabvaultuneostigthneifbiceasnt cceholeicvelc, ownesiodbetraining Uinnesftfriucicetnutrendu(mUbNer)scofvaprairaanmceetiesrsalwwhaiylse bHeetehreobgesntefoiut sinFpirrsets-eonrdtienrgAthuetocrhegaraecssteivriest(iAc RofHd(a1t)a) ibsuat nporotpthere abletesrtncahtioviececocovnarsiiadnecreinsgtriuncetfufriceiwenithnueamsebeorfsdoaftapainratemrpetrertastwiohnilferoHmetfeerwogereneuomubseFrsirostf-oesrdtiemraAteudtopraergarmesestievres.(ARH(1)) is a proper alternative covariance structure with ease of data interpretation from fewer numbers of estimated parameters.},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/pusponegoro et al_2017_linear mixed model for analyzing longitudinal data.pdf}
}

@article{pyaShapeConstrainedAdditive2015,
  title = {Shape Constrained Additive Models},
  author = {Pya, Natalya and Wood, Simon N.},
  year = {2015},
  month = may,
  journal = {Statistics and Computing},
  volume = {25},
  number = {3},
  pages = {543--559},
  issn = {1573-1375},
  doi = {10.1007/s11222-013-9448-7},
  urldate = {2024-04-03},
  abstract = {A framework is presented for generalized additive modelling under shape constraints on the component functions of the linear predictor of the GAM. We represent shape constrained model components by mildly non-linear extensions of P-splines. Models can contain multiple shape constrained and unconstrained terms as well as shape constrained multi-dimensional smooths. The constraints considered are on the sign of the first or/and the second derivatives of the smooth terms. A key advantage of the approach is that it facilitates efficient estimation of smoothing parameters as an integral part of model estimation, via GCV or AIC, and numerically robust algorithms for this are presented. We also derive simulation free approximate Bayesian confidence intervals for the smooth components, which are shown to achieve close to nominal coverage probabilities. Applications are presented using real data examples including the risk of disease in relation to proximity to municipal incinerators and the association between air pollution and health.},
  langid = {english},
  keywords = {Convex smoothing,Generalized additive model,Monotonic smoothing,P-splines},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/pya_wood_2015_shape constrained additive models.pdf}
}

@inproceedings{quanDoublesaddlepointApproximationEnumeration2016,
  title = {Double-Saddlepoint Approximation for Enumeration of Tables for Exact Tests of {{Hardy-Weinberg}} Proportions},
  booktitle = {31st {{International Workshop}} on {{Statistical Modelling}}},
  author = {Quan, Xiaoyun and Booth, James G.},
  year = {2016},
  pages = {125},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/quan_booth_2016_double-saddlepoint approximation for enumeration of tables for exact tests of.pdf}
}

@article{quinn2008p4,
  title = {P4-343: {{Omega}} 3 Fatty Acids and {{Alzheimer}}'s Disease: {{Trial}} Design and Baseline Study Population Characteristics in a Clinical Trial of Docosahexanoic Acid for {{Alzheimer}}'s Disease},
  author = {Quinn, Joseph F and Raman, Rema and Thomas, Ronald and Ernstrom, Karin and {Yurko-Mauro}, Karin and Nelson, Edward and Aisen, Paul S},
  year = {2008},
  journal = {Alzheimer's \& Dementia},
  volume = {4},
  pages = {T773--T773}
}

@article{quinn2009o1,
  title = {O1-04-02: {{A}} Clinical Trial of Docosahexanoic Acid ({{DHA}}) for the Treatment of {{Alzheimer}}'s Disease},
  author = {Quinn, Joseph F and Raman, Rema and Thomas, Ronald G and Ernstrom, Karin and {Yurko-Mauro}, Karin and Nelson, Edward B and Shinto, Lynne and Nair, Anil K and Aisen, Paul},
  year = {2009},
  journal = {Alzheimer's \& Dementia},
  volume = {5},
  number = {4S\_Part\_3},
  pages = {P84--P84}
}

@article{quinn2010docosahexaenoic,
  title = {Docosahexaenoic Acid Supplementation and Cognitive Decline in {{Alzheimer}} Disease: A Randomized Trial},
  author = {Quinn, Joseph F and Raman, Rema and Thomas, Ronald G and {Yurko-Mauro}, Karin and Nelson, Edward B and Van Dyck, Christopher and Galvin, James E and Emond, Jennifer and Jack, Clifford R and Weiner, Michael and others},
  year = {2010},
  journal = {JAMA : the journal of the American Medical Association},
  volume = {304},
  number = {17},
  pages = {1903--1911},
  publisher = {American Medical Association}
}

@article{quinn2010p1,
  title = {P1-447: {{Cerebrospinal}} Fluid Biomarker Outcomes in a Trial of Docosahexaenoic Acid ({{DHA}}) for {{Alzheimer}}'s Disease},
  author = {Quinn, Joseph F and Thomas, Ronald and Raman, Rema and {Yurko-Mauro}, Karin and {Bailey-Hall}, Eileen and Nelson, Edward and Shaw, Les and Aisen, Paul},
  year = {2010},
  journal = {Alzheimer's \& Dementia},
  volume = {6},
  pages = {S307--S307},
  publisher = {The Alzheimer's Association}
}

@misc{quinn2011omega,
  title = {Omega-3 Fatty Acids for Alzheimer's Disease. {{What}} a Pill Can Tell Us about Eating Fish},
  author = {Quinn, {\relax JF} and Raman, R and Thomas, {\relax RG} and {Yurko-Mauro}, K and Nelson, {\relax EB} and Van Dyck, C and Galvin, {\relax JE} and Emond, J and Jack Jr, {\relax CR} and Weiner, M and others},
  year = {2011},
  volume = {18},
  number = {1},
  pages = {43--44},
  publisher = {KARGER ALLSCHWILERSTRASSE 10, CH-4009 BASEL, SWITZERLAND}
}

@article{quinnDocosahexaenoicAcidSupplementation2010,
  title = {Docosahexaenoic {{Acid Supplementation}} and {{Cognitive Decline}} in {{Alzheimer Disease}}},
  author = {Quinn, Joseph F. and Raman, Rema and Thomas, Ronald G. and {Yurko-Mauro}, Karin and Nelson, Edward B. and Van Dyck, Christopher and Galvin, James E. and Emond, Jennifer and Jack, Clifford R. and Weiner, Michael and Shinto, Lynne and Aisen, Paul S.},
  year = {2010},
  month = nov,
  journal = {JAMA},
  volume = {304},
  number = {17},
  pages = {1903},
  issn = {0098-7484},
  doi = {10.1001/jama.2010.1510},
  abstract = {Context: Docosahexaenoic acid (DHA) is the most abundant long-chain polyunsaturated fatty acid in the brain. Epidemiological studies suggest that consumption of DHA is associated with a reduced incidence of Alzheimer disease. Animal studies demonstrate that oral intake of DHA reduces Alzheimer-like brain pathology. Objective: To determine if supplementation with DHA slows cognitive and functional decline in individuals with Alzheimer disease. Design, Setting, and Patients: A randomized, double-blind, placebo-controlled trial of DHA supplementation in individuals with mild to moderate Alzheimer disease (Mini-Mental State Examination scores, 14-26) was conducted between November 2007 and May 2009 at 51 US clinical research sites of the Alzheimer's Disease Cooperative Study. Intervention: Participants were randomly assigned to algal DHA at a dose of 2 g/d or to identical placebo (60\% were assigned to DHA and 40\% were assigned to placebo). Duration of treatment was 18 months. Main Outcome Measures: Change in the cognitive subscale of the Alzheimer's Disease Assessment Scale (ADAS-cog) and change in the Clinical Dementia Rating (CDR) sum of boxes. Rate of brain atrophy was also determined by volumetric magnetic resonance imaging in a subsample of participants (n=102). Results: A total of 402 individuals were randomized and a total of 295 participants completed the trial while taking study medication (DHA: 171; placebo: 124). Supplementation with DHA had no beneficial effect on rate of change on ADAS-cog score, which increased by a mean of 7.98 points (95\% confidence interval [CI], 6.51-9.45 points) for the DHA group during 18 months vs 8.27 points (95\% CI, 6.72-9.82 points) for the placebo group (linear mixed-effects model: P=.41). The CDR sum of boxes score increased by 2.87 points (95\% CI, 2.44-3.30 points) for the DHA group during 18 months compared with 2.93 points (95\% CI, 2.44-3.42 points) for the placebo group (linear mixed-effects model: P=.68). In the subpopulation of participants (DHA: 53; placebo: 49), the rate of brain atrophy was not affected by treatment with DHA. Individuals in the DHA group had a mean decline in total brain volume of 24.7 cm3 (95\% CI, 21.4-28.0 cm3) during 18 months and a 1.32\% (95\% CI, 1.14\%-1.50\%) volume decline per year compared with 24.0 cm 3 (95\% CI, 20-28 cm3) for the placebo group during 18 months and a 1.29\% (95\% CI, 1.07\%-1.51\%) volume decline per year (P=.79). Conclusion: Supplementation with DHA compared with placebo did not slow the rate of cognitive and functional decline in patients with mild to moderate Alzheimer disease. Trial Registration: clinicaltrials.gov Identifier: NCT00440050. {\copyright}2010 American Medical Association. All rights reserved.},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/quinn et al_2010_docosahexaenoic acid supplementation and cognitive decline in alzheimer disease.pdf}
}

@article{quiroz2019f4,
  title = {F4-04-04: {{ASSOCIATION BETWEEN CEREBRAL AMYLOIDOSIS AND WORSE COGNITIVE PERFORMANCE IN PRECLINICAL AUTOSOMAL DOMINANT ALZHEIMER}}'{{S DISEASE}}: {{BASELINE FINDINGS FROM THE API COLOMBIA AUTOSOMAL DOMINANT AD TRIAL}}},
  author = {Quiroz, Yakeel T and Tariot, Pierre N and Sink, Kaycee and Clayton, David and Langbaum, Jessica B and Thomas, Ronald G and Giraldo, Margarita and Tobon, Carlos and {Acosta-Baena}, Natalia and Luna, Ernesto and others},
  year = {2019},
  journal = {Alzheimer's \& Dementia},
  volume = {15},
  pages = {P1224--P1224}
}

@article{raabHowSelectCovariates2000,
  title = {How to {{Select Covariates}} to {{Include}} in the {{Analysis}} of a {{Clinical Trial}}},
  author = {Raab, Gillian M and Day, Simon and Sales, Jill},
  year = {2000},
  month = aug,
  journal = {Controlled Clinical Trials},
  volume = {21},
  number = {4},
  pages = {330--342},
  issn = {0197-2456},
  doi = {10.1016/S0197-2456(00)00061-1},
  urldate = {2023-04-14},
  abstract = {The comparisons of treatments in randomized clinical trials may use the analysis of covariance to adjust for patient characteristics. We present theoretical results that describe when such an adjustment would be expected to be beneficial. A distinction is made between covariates that are balanced in the design and those that are assigned by the randomization process. The results support the commonly held view that features balanced in the design of the trial (e.g., by stratification) and those that are strongly predictive of the outcome, and thus considered clinically prognostic, should normally be included in the analysis. For other covariates that are not balanced in the design, the potential benefits of including them in the analysis will depend on the number of patients in the trial. However, there is frequently a set of variables whose relevance is unknown and for which data-dependent methods of selection, based on the data for the current trial, have been proposed. A review of the literature has shown that these methods can produce misleading inferences. The decision as to which covariates to include in the analysis should be specified in the protocol on the basis of data from previous trials on similar patient populations. The methods are illustrated with data from a trial comparing two therapies for treating scalp psoriasis where the clinical importance of patients' age and sex as prognostic factors for efficacy is unknown. We show for what size of future trials it would be beneficial to adjust for these covariates and for what size trials it would not. In all cases, prespecification of variables to be included in the analysis is essential in order to avoid bias. Control Clin Trials 2000;21:330--342},
  langid = {english},
  keywords = {adjustment,covariates,design,planning,stratification,Variable selection},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/raab et al_2000_how to select covariates to include in the analysis of a clinical trial.pdf;/Users/zenn/Zotero/storage/S8CN4A3A/S0197245600000611.html}
}

@article{rabinoviciFrontotemporalLobarDegeneration2010,
  title = {Frontotemporal Lobar Degeneration: {{Epidemiology}}, Pathophysiology, Diagnosis and Management},
  author = {Rabinovici, Gil D. and Miller, Bruce L.},
  year = {2010},
  journal = {CNS Drugs},
  volume = {24},
  number = {5},
  pages = {375--398},
  issn = {11727047},
  doi = {10.2165/11533100-000000000-00000},
  urldate = {2021-11-08},
  abstract = {Frontotemporal lobar degeneration (FTLD) is a clinically and pathologically heterogeneous syndrome, characterized by progressive decline in behaviour or language associated with degeneration of the frontal and anterior temporal lobes. While the seminal cases were described at the turn of the 20th century, FTLD has only recently been appreciated as a leading cause of dementia, particularly in patients presenting before the age of 65 years. Three distinct clinical variants of FTLD have been described: (i) behavioural-variant frontotemporal dementia, characterized by changes in behaviour and personality in association with frontal-predominant cortical degeneration; (ii) semantic dementia, a syndrome of progressive loss of knowledge about words and objects associated with anterior temporal neuronal loss; and (iii) progressive nonfluent aphasia, characterized by effortful language output, loss of grammar and motor speech deficits in the setting of left perisylvian cortical atrophy.The majority of pathologies associated with FTLD clinical syndromes include either tau-positive (FTLD-TAU) or TAR DNA-binding protein 43 (TDP-43)-positive (FTLD-TDP) inclusion bodies. FTLD overlaps clinically and pathologically with the atypical parkinsonian disorders corticobasal degeneration and progressive supranuclear palsy, and with amyotrophic lateral sclerosis. The majority of familial FTLD cases are caused by mutations in the genes encoding microtubule-associated protein tau (leading to FTLD-TAU) or progranulin (leading to FTLD-TDP).The clinical and pathological heterogeneity of FTLD poses a significant diagnostic challenge, and in vivo prediction of underlying histopathology can be significantly improved by supplementing the clinical evaluation with genetic tests and emerging biological markers.Current pharmacotherapy for FTLD focuses on manipulating serotonergic or dopaminergic neurotransmitter systems to ameliorate behavioural or motor symptoms. However, recent advances in FTLD genetics and molecular pathology make the prospect of biologically driven, disease-specific therapies for FTLD seem closer than ever. {\copyright} 2010 Adis Data Information BV. All rights reserved.},
  pmid = {20369906},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/rabinovici_miller_2010_frontotemporal lobar degeneration.pdf}
}

@article{rafii2011phase,
  title = {A Phase {{II}} Trial of Huperzine {{A}} in Mild to Moderate {{Alzheimer}} Disease},
  author = {Rafii, {\relax MS} and Walsh, S and Little, {\relax JT} and Behan, K and Reynolds, B and Ward, C and Jin, S and Thomas, R and Aisen, {\relax PS} and others},
  year = {2011},
  journal = {Neurology},
  volume = {76},
  number = {16},
  pages = {1389--1394},
  publisher = {Wolters Kluwer Health, Inc. on behalf of the American Academy of Neurology}
}

@article{rafii2018adeno,
  title = {Adeno-Associated Viral Vector (Serotype 2)--Nerve Growth Factor for Patients with Alzheimer Disease: A Randomized Clinical Trial},
  author = {Rafii, Michael S and Tuszynski, Mark H and Thomas, Ronald G and Barba, David and Brewer, James B and Rissman, Robert A and Siffert, Joao and Aisen, Paul S and Team, AAV2-NGF Study and others},
  year = {2018},
  journal = {JAMA neurology},
  volume = {75},
  number = {7},
  pages = {834--841},
  publisher = {American Medical Association}
}

@misc{raghuramanLateralEntorhinalCortex2024,
  title = {Lateral {{Entorhinal Cortex Dysfunction}} in {{Alzheimer}}'s {{Disease Mice}}},
  author = {Raghuraman, Radha and Aoun, Andrew and Herman, Mathieu and Shetler, Charles Oliver and Nahmani, Eden and Hussaini, Syed Abid},
  year = {2024},
  month = apr,
  primaryclass = {New Results},
  pages = {2024.04.15.589589},
  publisher = {bioRxiv},
  doi = {10.1101/2024.04.15.589589},
  urldate = {2024-04-18},
  abstract = {In Alzheimer's disease (AD), the formation of amyloid beta and neurofibrillary tangles (NFTs) leads to neuronal loss in entorhinal cortex (EC), a crucial brain region involved in memory and navigation. These pathological changes are concurrent with the onset of memory-related issues in AD patients with symptoms of forgetfulness such as misplacing items, disorientation in familiar environments etc. The lateral EC (LEC) is associated with non-spatial memory processing including object recognition. Since in LEC, neurons fire in response to objects (object cells) and at locations previously occupied by objects (trace cells), pathology in this region could lead to dysfunction in object location coding. In this paper we show that a transgenic mouse model, EC-App/Tau, which expresses both APP and tau primarily in the EC region, have deficits in LEC-specific memory tasks. Using in vivo single-unit electrophysiology recordings we show that the LEC neurons are hyperactive with low information content and high sparsity compared to the controls indicating poor firing fidelity. We finally show that object cells and trace cells fire less precisely in the EC-App/Tau mice compared to controls indicating poor encoding of objects. Overall, we show that AD pathology causes erratic firing of LEC neurons and object coding defects leading to LEC-specific memory impairment.},
  archiveprefix = {bioRxiv},
  chapter = {New Results},
  copyright = {{\copyright} 2024, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/raghuraman et al_2024_lateral entorhinal cortex dysfunction in alzheimer's disease mice.pdf}
}

@article{raketNonlinearMixedeffectsModel2014,
  title = {A Nonlinear Mixed-Effects Model for Simultaneous Smoothing and Registration of Functional Data},
  author = {Rak{\^e}t, Lars Lau and Sommer, Stefan and Markussen, Bo},
  year = {2014},
  month = mar,
  journal = {Pattern Recognition Letters},
  volume = {38},
  pages = {1--7},
  issn = {0167-8655},
  doi = {10.1016/j.patrec.2013.10.018},
  urldate = {2024-01-18},
  abstract = {We consider misaligned functional data, where data registration is necessary for proper statistical analysis. This paper proposes to treat misalignment as a nonlinear random effect, which makes simultaneous likelihood inference for horizontal and vertical effects possible. By simultaneously fitting the model and registering data, the proposed method estimates parameters and predicts random effects more precisely than conventional methods that register data in preprocessing. The ability of the model to estimate both hyperparameters and predict horizontal and vertical effects are illustrated on both simulated and real data.},
  keywords = {Amplitude variation,Data alignment,Functional mixed-effects model,Nonlinear mixed-effects model,Phase variation,Smoothing},
  file = {/Users/zenn/Zotero/storage/LP6VWQVC/S0167865513004108.html}
}

@article{raketProgressionModelsRepeated2022,
  title = {Progression Models for Repeated Measures: {{Estimating}} Novel Treatment Effects in Progressive Diseases},
  shorttitle = {Progression Models for Repeated Measures},
  author = {Raket, Lars Lau},
  year = {2022},
  month = dec,
  journal = {Statistics in Medicine},
  volume = {41},
  number = {28},
  pages = {5537--5557},
  issn = {0277-6715, 1097-0258},
  doi = {10.1002/sim.9581},
  urldate = {2023-08-07},
  abstract = {Mixed Models for Repeated Measures (MMRMs) are ubiquitous when analyzing outcomes of clinical trials. However, the linearity of the fixed-effect structure in these models largely restrict their use to estimating treatment effects that are defined as linear combinations of effects on the outcome scale. In some situations, alternative quantifications of treatment effects may be more appropriate. In progressive diseases, for example, one may want to estimate if a drug has cumulative effects resulting in increasing efficacy over time or whether it slows the time progression of disease. is paper introduces a class of nonlinear mixed-effects models called Progression Models for Repeated Measures (PMRMs) that, based on a continuous-time extension of the categorical-time parametrization of MMRMs, enables estimation of novel types of treatment effects, including measures of slowing or delay of the time progression of disease. Compared to conventional estimates of treatment effects where the unit matches that of the outcome scale (e.g. points benefit on a cognitive scale), the time-based treatment effects can offer better interpretability and clinical meaningfulness (e.g. months delay in progression of cognitive decline). e PMRM class includes conventionally used MMRMs and related models for longitudinal data analysis, as well as variants of previously proposed disease progression models as special cases. e potential of the PMRM framework is illustrated using both simulated and historical data from clinical trials in Alzheimer's disease with different types of artificially simulated treatment effects. Compared to conventional models it is shown that PMRMs can offer substantially increased power to detect disease-modifying treatment effects where the benefit is increasing with treatment duration.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/SESJMIJV/Raket - 2022 - Progression models for repeated measures Estimati.pdf}
}

@article{ramamoorthyIdentifyingPatternsAmyotrophic2022,
  title = {Identifying Patterns in Amyotrophic Lateral Sclerosis Progression from Sparse Longitudinal Data},
  author = {Ramamoorthy, Divya and Severson, Kristen and Ghosh, Soumya and Sachs, Karen and {Answer ALS} and Baxi, Emily G. and Coyne, Alyssa N. and Mosmiller, Elizabeth and Hayes, Lindsey and Cerezo, Aianna and Ahmad, Omar and Roy, Promit and Zeiler, Steven and Krakauer, John W. and Li, Jonathan and Donde, Aneesh and Huynh, Nhan and Adam, Miriam and Wassie, Brook T. and Lenail, Alex and {Patel-Murray}, Natasha Leanna and Raghav, Yogindra and Sachs, Karen and Kozareva, Velina and Tsitkov, Stanislav and Ehrenberger, Tobias and Kaye, Julia A. and Lima, Leandro and Wyman, Stacia and Vertudes, Edward and Amirani, Naufa and Raja, Krishna and Thomas, Reuben and Lim, Ryan G. and Miramontes, Ricardo and Wu, Jie and Vaibhav, Vineet and Matlock, Andrea and Venkatraman, Vidya and Holewenski, Ronald and Sundararaman, Niveda and Pandey, Rakhi and Manalo, Danica-Mae and Frank, Aaron and Ornelas, Loren and Panther, Lindsey and Gomez, Emilda and Galvez, Erick and Perez, Daniel and Meepe, Imara and Lei, Susan and Pinedo, Louis and Liu, Chunyan and Moran, Ruby and Sareen, Dhruv and Landin, Barry and Agurto, Carla and Cecchi, Guillermo and Norel, Raquel and Thrower, Sara and Luppino, Sarah and Farrar, Alanna and Pothier, Lindsay and Yu, Hong and Sinani, Ervin and Vigneswaran, Prasha and Sherman, Alexander V. and Farr, S. Michelle and Mandefro, Berhan and Trost, Hannah and Banuelos, Maria G. and Garcia, Veronica and Workman, Michael and Ho, Richie and Baloh, Robert and Roggenbuck, Jennifer and Harms, Matthew B. and Prina, Carolyn and Heintzman, Sarah and Kolb, Stephen and Stocksdale, Jennifer and Wang, Keona and Morgan, Todd and Heitzman, Daragh and Jamil, Arish and {Jockel-Balsarotti}, Jennifer and Karanja, Elizabeth and Markway, Jesse and McCallum, Molly and Miller, Tim and Joslin, Ben and Alibazoglu, Deniz and {Ajroud-Driss}, Senda and Beavers, Jay C. and Bellard, Mary and Bruce, Elizabeth and Maragakis, Nicholas and Cudkowicz, Merit E. and Berry, James and Thompson, Terri and Finkbeiner, Steven and Thompson, Leslie M. and Van Eyk, Jennifer E. and Svendsen, Clive N. and Rothstein, Jeffrey D. and Glass, Jonathan D. and Fournier, Christina N. and {Pooled Resource Open-Access ALS Clinical Trials Consortium} and Sherman, Alexander and {ALS/MND Natural History Consortium} and Lunetta, Christian and Walk, David and Hayat, Ghazala and Wymer, James and Gwathmey, Kelly and Olney, Nicholas and {Ajroud-Driss}, Senda and {Heiman-Patterson}, Terry and {Arcila-Londono}, Ximena and Faulconer, Kenneth and Sanani, Ervin and Berger, Alex and Mirochnick, Julia and Herrington, Todd M. and Berry, James D. and Ng, Kenney and Fraenkel, Ernest},
  year = {2022},
  month = sep,
  journal = {Nature Computational Science},
  volume = {2},
  number = {9},
  pages = {605--616},
  issn = {2662-8457},
  doi = {10.1038/s43588-022-00299-w},
  urldate = {2024-03-19},
  abstract = {Abstract             The clinical presentation of amyotrophic lateral sclerosis (ALS), a fatal neurodegenerative disease, varies widely across patients, making it challenging to determine if potential therapeutics slow progression. We sought to determine whether there were common patterns of disease progression that could aid in the design and analysis of clinical trials. We developed an approach based on a mixture of Gaussian processes to identify clusters of patients sharing similar disease progression patterns, modeling their average trajectories and the variability in each cluster. We show that ALS progression is frequently nonlinear, with periods of stable disease preceded or followed by rapid decline. We also show that our approach can be extended to Alzheimer's and Parkinson's diseases. Our results advance the characterization of disease progression of ALS and provide a flexible modeling approach that can be applied to other progressive diseases.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/GARGR3XE/s43588-022-00299-w.pdf}
}

@article{raman2008p4,
  title = {P4-387: {{Adding}} Delayed Recall to the {{Alzheimer}}'s Disease Assessment Scale-Cognitive Subscale ({{ADAS-cog}}): {{Sensitivity}} in a Clinical Trial for {{Alzheimer}}'s Disease and Mild Cognitive Impairment},
  author = {Raman, Rema and Emond, Jennifer and Thomas, Ronald G and Petersen, Ronald C and Schneider, Lon S and Aisen, Paul S and Sano, Mary},
  year = {2008},
  journal = {Alzheimer's \& Dementia},
  volume = {4},
  pages = {T787--T788}
}

@article{raman2009mri,
  title = {{{MRI}} Substudy Participation in {{Alzheimer}} Disease ({{AD}}) Clinical Trials: Baseline Comparability of a Substudy Sample to Entire Study Population},
  author = {Raman, Rema and Thomas, Ronald G and Weiner, Michael W and Jack, Clifford R and Ernstrom, Karin and Aisen, Paul S and Tariot, Pierre N and Quinn, Joseph F},
  year = {2009},
  journal = {Alzheimer disease and associated disorders},
  volume = {23},
  number = {4},
  pages = {333},
  publisher = {NIH Public Access}
}

@article{raskind2003reduction,
  title = {Reduction of Nightmares and Other {{PTSD}} Symptoms in Combat Veterans by Prazosin: A Placebo-Controlled Study},
  author = {Raskind, Murray A and Peskind, Elaine R and Kanter, Evan D and Petrie, Eric C and Radant, Allen and Thompson, Charles E and Dobie, Dorcas J and Hoff, David and Rein, Rebekah J and {Straits-Tr{\"o}ster}, Kristy and others},
  year = {2003},
  journal = {American Journal of Psychiatry},
  volume = {160},
  number = {2},
  pages = {371--373},
  publisher = {American Psychiatric Publishing}
}

@inproceedings{raskind2021randomized,
  title = {Randomized Controlled Trial of Prazosin for Alcohol Use Disorder in Active Duty Service Members},
  booktitle = {{{NEUROPSYCHOPHARMACOLOGY}}},
  author = {Raskind, Murray and Holmes, Hollie and Williams, Tammy and Thomas, Ronald G and Hart, Kim and Hendrickson, Rebecca and Terry, Garth and Mayer, Cynthia and Saxon, Andrew and Simpson, Tracy and others},
  year = {2021},
  volume = {46},
  pages = {489--489},
  publisher = {SPRINGERNATURE CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND}
}

@article{raskindmurraya.TrialPrazosinPostTraumatic2018,
  title = {Trial of {{Prazosin}} for {{Post-Traumatic Stress Disorder}} in {{Military Veterans}}},
  author = {{Raskind Murray A.} and {Peskind Elaine R.} and {Chow Bruce} and {Harris Crystal} and {Davis-Karim Anne} and {Holmes Hollie A.} and {Hart Kimberly L.} and {McFall Miles} and {Mellman Thomas A.} and {Reist Christopher} and {Romesser Jennifer} and {Rosenheck Robert} and {Shih Mei-Chiung} and {Stein Murray B.} and {Swift Robert} and {Gleason Theresa} and {Lu Ying} and {Huang Grant D.}},
  year = {2018},
  month = feb,
  journal = {New England Journal of Medicine},
  volume = {378},
  number = {6},
  pages = {507--517},
  publisher = {Massachusetts Medical Society},
  doi = {10.1056/NEJMoa1507598},
  urldate = {2024-06-11},
  abstract = {In a trial involving 304 veterans with stable PTSD, prazosin did not alleviate distressing dreams and did not improve sleep quality or overall clinical symptoms over 10 or 26 weeks. This result is in contrast to findings in several previous smaller or briefer trials.},
  file = {/Users/zenn/Zotero/storage/TJGAXGRD/Raskind Murray A. et al. - 2018 - Trial of Prazosin for Post-Traumatic Stress Disord.pdf}
}

@article{raskindRandomizedControlledClinical2023,
  title = {A Randomized Controlled Clinical Trial of Prazosin for Alcohol Use Disorder in Active Duty Soldiers: {{Predictive}} Effects of Elevated Cardiovascular Parameters},
  shorttitle = {A Randomized Controlled Clinical Trial of Prazosin for Alcohol Use Disorder in Active Duty Soldiers},
  author = {Raskind, Murray A. and Williams, Tammy and Holmes, Hollie and Hart, Kim and Crews, Laura and Poupore, Eileen L. and Thomas, Ronald G. and Darnell, Jolee and Daniels, Colin and Goke, Kevin and Hendrickson, Rebecca and Terry, Garth and Mayer, Cynthia and Simpson, Tracy and Saxon, Andrew and Rasmussen, Dennis and Peskind, Elaine R.},
  year = {2023},
  journal = {Alcohol: Clinical and Experimental Research},
  volume = {47},
  number = {2},
  pages = {348--360},
  issn = {1530-0277},
  doi = {10.1111/acer.14989},
  urldate = {2023-05-19},
  abstract = {Background Excessive noradrenergic signaling contributes to aversive symptoms of alcohol withdrawal that interfere with abstinence or reductions in harmful use. Methods To address this aspect of alcohol use disorder, 102 active-duty soldiers participating in command-mandated Army outpatient alcohol treatment were randomized to also receive the brain-penetrant alpha-1 adrenergic receptor antagonist prazosin or placebo for 13 weeks. Primary outcomes were scores on the Penn Alcohol Craving Scale (PACS), standard drink units (SDUs) per day averaged over each week, \% days of any drinking per week, and \% days of heavy drinking per week. Results PACS declines did not differ significantly between the prazosin and placebo groups in the overall sample. In the subgroup with comorbid PTSD (n = 48), PACS declines were significantly greater in the prazosin than in the placebo condition (p {$<$} 0.05). Baseline alcohol consumption was markedly reduced by the pre-randomization outpatient alcohol treatment program, but the addition of prazosin treatment produced a greater slope of decline in SDUs per day compared to placebo (p = 0.01). Preplanned subgroup analyses were performed in soldiers with elevated baseline cardiovascular measures consistent with increased noradrenergic signaling. In soldiers with elevated standing heart rate (n = 15), prazosin reduced SDUs per day (p = 0.01), \% days drinking (p = 0.03), and \% days heavy drinking (p = 0.001) relative to placebo. In soldiers with elevated standing systolic blood pressure (n = 27), prazosin reduced SDUs per day (p = 0.04) and tended to reduce \% days drinking (p = 0.056). Prazosin also reduced depressive symptoms and the incidence of emergent depressed mood more than placebo (p = 0.05 and p = 0.01, respectively). During the final 4 weeks of prazosin vs. placebo treatment that followed completion of Army outpatient AUD treatment, alcohol consumption in soldiers with elevated baseline cardiovascular measures increased in those receiving placebo but remained suppressed in those receiving prazosin. Conclusions These results extend reports that higher pretreatment cardiovascular measures predict beneficial effects of prazosin, which may be useful for relapse prevention in patients with AUD.},
  langid = {english},
  keywords = {active duty military,alcohol use disorder,antiadrenergic,prazosin,randomized controlled trial,relapse prevention},
  file = {/Users/zenn/Zotero/storage/PS2TK4VX/acer.html}
}

@article{raskindRandomizedControlledClinical2023a,
  title = {A Randomized Controlled Clinical Trial of Prazosin for Alcohol Use Disorder in Active Duty Soldiers: {{Predictive}} Effects of Elevated Cardiovascular Parameters},
  shorttitle = {A Randomized Controlled Clinical Trial of Prazosin for Alcohol Use Disorder in Active Duty Soldiers},
  author = {Raskind, Murray A. and Williams, Tammy and Holmes, Hollie and Hart, Kim and Crews, Laura and Poupore, Eileen L. and Thomas, Ronald G. and Darnell, Jolee and Daniels, Colin and Goke, Kevin and Hendrickson, Rebecca and Terry, Garth and Mayer, Cynthia and Simpson, Tracy and Saxon, Andrew and Rasmussen, Dennis and Peskind, Elaine R.},
  year = {2023},
  journal = {Alcohol, Clinical and Experimental Research},
  volume = {47},
  number = {2},
  pages = {348--360},
  issn = {2993-7175},
  doi = {10.1111/acer.14989},
  urldate = {2024-06-11},
  abstract = {Background Excessive noradrenergic signaling contributes to aversive symptoms of alcohol withdrawal that interfere with abstinence or reductions in harmful use. Methods To address this aspect of alcohol use disorder, 102 active-duty soldiers participating in command-mandated Army outpatient alcohol treatment were randomized to also receive the brain-penetrant alpha-1 adrenergic receptor antagonist prazosin or placebo for 13 weeks. Primary outcomes were scores on the Penn Alcohol Craving Scale (PACS), standard drink units (SDUs) per day averaged over each week, \% days of any drinking per week, and \% days of heavy drinking per week. Results PACS declines did not differ significantly between the prazosin and placebo groups in the overall sample. In the subgroup with comorbid PTSD (n = 48), PACS declines were significantly greater in the prazosin than in the placebo condition (p {$<$} 0.05). Baseline alcohol consumption was markedly reduced by the pre-randomization outpatient alcohol treatment program, but the addition of prazosin treatment produced a greater slope of decline in SDUs per day compared to placebo (p = 0.01). Preplanned subgroup analyses were performed in soldiers with elevated baseline cardiovascular measures consistent with increased noradrenergic signaling. In soldiers with elevated standing heart rate (n = 15), prazosin reduced SDUs per day (p = 0.01), \% days drinking (p = 0.03), and \% days heavy drinking (p = 0.001) relative to placebo. In soldiers with elevated standing systolic blood pressure (n = 27), prazosin reduced SDUs per day (p = 0.04) and tended to reduce \% days drinking (p = 0.056). Prazosin also reduced depressive symptoms and the incidence of emergent depressed mood more than placebo (p = 0.05 and p = 0.01, respectively). During the final 4 weeks of prazosin vs. placebo treatment that followed completion of Army outpatient AUD treatment, alcohol consumption in soldiers with elevated baseline cardiovascular measures increased in those receiving placebo but remained suppressed in those receiving prazosin. Conclusions These results extend reports that higher pretreatment cardiovascular measures predict beneficial effects of prazosin, which may be useful for relapse prevention in patients with AUD.},
  langid = {english},
  keywords = {active duty military,alcohol use disorder,antiadrenergic,prazosin,randomized controlled trial,relapse prevention},
  file = {/Users/zenn/Zotero/storage/HHMFGXPK/acer.html}
}

@inproceedings{raynauld1992progression,
  title = {Progression of Functional Disability in Rheumatoid-Arthritis},
  booktitle = {Arthritis and Rheumatism},
  author = {RAYNAULD, {\relax JP} and THOMAS, {\relax RG} and BLOCH, {\relax DA}},
  year = {1992},
  volume = {35},
  pages = {S180--S180},
  publisher = {LIPPINCOTT-RAVEN PUBL 227 EAST WASHINGTON SQ, PHILADELPHIA, PA 19106}
}

@article{Reddy2017,
  title = {Using {{Gaussian}} Mixture Models to Detect Outliers in Seasonal Univariate Network Traffic},
  author = {Reddy, Aarthi and {Ordway-West}, Meredith and Lee, Melissa and Dugan, Matt and Whitney, Joshua and Kahana, Ronen and Ford, Brad and Muedsam, Johan and Henslee, Austin and Rao, Max},
  year = {2017},
  journal = {Proceedings - 2017 IEEE Symposium on Security and Privacy Workshops, SPW 2017},
  volume = {2017-Decem},
  pages = {229--234},
  publisher = {IEEE},
  doi = {10.1109/SPW.2017.9},
  abstract = {This article presents an algorithm to detect outliers in seasonal, univariate network traffic data using Gaussian Mixture Models (GMMs). Additionally we show that this methodology can easily be implemented in a big data scenario and delivers the required information to a security analyst in an efficient manner. The unsupervised clustering algorithm GMM, is modified such that all data points in a set are labelled as either outliers or normal data points. In this article, the algorithm is only evaluated on time series data obtained from network traffic, however it can easily be modified to be used for other types of seasonal univariate big data sets. Detecting outliers in network traffic data occurs in two stages. First, GMMs are built for training data in each time bin of seasonal time series data. Outliers or anomalies are detected and removed in this training data set by examining the probability associated with each data point. Second, GMMs are rebuilt after outliers are removed in historical or training data and the re-computed GMMs are used to detect outliers in test data. Results are compared to traditional methods of outlier detection which usually treat all data from a set as coming from a single probability density function.},
  isbn = {9781538619674},
  keywords = {Gaussian Mixtures,network traffic,outlier detection},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/reddy et al_2017_using gaussian mixture models to detect outliers in seasonal univariate network.pdf}
}

@misc{RegressionTreeApproach,
  title = {A Regression Tree Approach to Identifying Subgroups with Differential Treatment\,Effects - {{Loh}} - 2015 - {{Statistics}} in {{Medicine}} - {{Wiley Online Library}}},
  urldate = {2023-08-15},
  howpublished = {https://onlinelibrary.wiley.com/doi/full/10.1002/sim.6454?casa\_token=0N7EblWbDxQAAAAA\%3APXwaoqi2Z-k01bhVaSOJZB8b1e-3iMGqRbkI5CnGXDWwxPH6irv99l5ih2AfEBKjiiGzgtJUT0xSdx8},
  file = {/Users/zenn/Zotero/storage/NXRV3YIZ/sim.html}
}

@article{reiman2018p4,
  title = {P4-209: {{A PUBLIC RESOURCE OF BASELINE DATA FROM THE API AUTOSOMAL DOMINANT ALZHEIMER}}'{{S DISEASE COLOMBIA TRIAL}}},
  author = {Reiman, Eric M and Sink, Kaycee M and Hu, Nan and Guthrie, Heather and Smith, Jillian and Cho, William and Knoll, Katie L and Langbaum, Jessica B and Thomas, Ronald G and Toga, Arthur W and others},
  year = {2018},
  journal = {Alzheimer's \& Dementia},
  volume = {14},
  number = {7S\_Part\_29},
  pages = {P1521--P1521}
}

@article{reimanCAPadvancingEvaluationPreclinical2016,
  title = {{{CAP-advancing}} the Evaluation of Preclinical {{Alzheimer}} Disease Treatments},
  author = {Reiman, Eric M and Langbaum, Jessica B and Tariot, Pierre N and Lopera, Francisco and Bateman, Randall J and Morris, John C and Sperling, Reisa A and Aisen, Paul S and Roses, Allen D and {Welsh-Bohmer}, Kathleen A. and Carrillo, Maria C and Weninger, Stacie},
  year = {2016},
  journal = {Nature Reviews Neurology},
  volume = {12},
  number = {1},
  pages = {56--61},
  publisher = {Nature Publishing Group},
  issn = {17594766},
  doi = {10.1038/nrneurol.2015.177},
  abstract = {If we are to find treatments to postpone, reduce the risk of, or completely prevent the clinical onset of Alzheimer disease (AD), we need faster methods to evaluate promising preclinical AD treatments, new ways to work together in support of common goals, and a determination to expedite the initiation and performance of preclinical AD trials. In this article, we note some of the current challenges, opportunities and emerging strategies in preclinical AD treatment. We describe the Collaboration for Alzheimer's Prevention (CAP)-a convening, harmonizing and consensus-building initiative to help stakeholders advance AD prevention research with rigour, care and maximal impact-and we demonstrate the impact of CAP on the goals and design of new preclinical AD trials.},
  isbn = {1759-4758},
  pmid = {26416539},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/reiman et al_2016_cap-advancing the evaluation of preclinical alzheimer disease treatments.pdf}
}

@article{reimanHHSPublicAccess2015,
  title = {{{HHS Public Access}}},
  author = {Reiman, Eric M and Langbaum, Jessica and Tariot, Pierre N},
  year = {2015},
  volume = {75},
  number = {6},
  pages = {661--662},
  doi = {10.4088/JCP.14com09235.Endpoints},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/reiman et al_2015_hhs public access.pdf}
}

@article{reimanPublicResourceBaseline2022a,
  title = {A Public Resource of Baseline Data from the {{Alzheimer}}'s {{Prevention Initiative Autosomal-Dominant Alzheimer}}'s {{Disease Trial}}},
  author = {Reiman, Eric M. and Pruzin, Jeremy J. and {Rios-Romenets}, Silvia and Brown, Chris and Giraldo, Margarita and {Acosta-Baena}, Natalia and Tobon, Carlos and Hu, Nan and Chen, Yinghua and Ghisays, Valentina and Enos, Jessica and Goradia, Dhruman D. and Lee, Wendy and Luo, Ji and {Malek-Ahmadi}, Michael and Protas, Hillary and Thomas, Ronald G. and Chen, Kewei and Su, Yi and Boker, Connie and Mastroeni, Diego and Alvarez, Sergio and Quiroz, Yakeel T. and Langbaum, Jessica B. and Sink, Kaycee M. and Lopera, Francisco and Tariot, Pierre N. and {and the API ADAD Colombia Trial Group}},
  year = {2022},
  month = nov,
  journal = {Alzheimer's \& Dementia},
  pages = {alz.12843},
  issn = {1552-5260, 1552-5279},
  doi = {10.1002/alz.12843},
  abstract = {Introduction: The Alzheimer's Prevention Initiative Autosomal-Dominant Alzheimer's Disease (API ADAD) Trial evaluated the anti-oligomeric amyloid beta (A{$\beta$}) antibody therapy crenezumab in cognitively unimpaired members of the Colombian presenilin 1 (PSEN1) E280A kindred. We report availability, methods employed to protect confidentiality and anonymity of participants, and process for requesting and accessing baseline data.},
  langid = {english}
}

@misc{RelativeEfficiencyTimetothreshold,
  title = {The Relative Efficiency of Time-to-Threshold and Rate of Change in Longitudinal Data {\textbar} {{Elsevier Enhanced Reader}}},
  doi = {10.1016/j.cct.2011.04.007},
  urldate = {2023-04-14},
  howpublished = {https://reader.elsevier.com/reader/sd/pii/S1551714411000978?token=7064830857E3D827277CBE3117D78B9567B3F25989D6956CE8336500513034EA0A358F360D58D1D1CEB8E197846C7717\&originRegion=us-east-1\&originCreation=20230414173725},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/the relative efficiency of time-to-threshold and rate of change in longitudinal.pdf}
}

@article{relkin2012o3,
  title = {O3-13-05: {{The}} Gammaglobulin Alzheimer Partnership Study ({{GAP}}): {{Design}}, Screening, Enrollment and Futility Analysis Results},
  author = {Relkin, Norman and Gessert, Devon and Stokes, Karen and Adamiak, Basia and Ngo, Leock Y and Thomas, Ronald and Gelmont, David and Aisen, Paul},
  year = {2012},
  journal = {Alzheimer's \& Dementia},
  volume = {8},
  number = {4S\_Part\_12},
  pages = {P456--P456}
}

@article{relkin2017phase,
  title = {A Phase 3 Trial of {{IV}} Immunoglobulin for {{Alzheimer}} Disease},
  author = {Relkin, Norman R and Thomas, Ronald G and Rissman, Robert A and Brewer, James B and Rafii, Michael S and Van Dyck, Christopher H and Jack, Clifford R and Sano, Mary and Knopman, David S and Raman, Rema and others},
  year = {2017},
  journal = {Neurology},
  volume = {88},
  number = {18},
  pages = {1768--1775},
  publisher = {Wolters Kluwer Health, Inc. on behalf of the American Academy of Neurology}
}

@misc{RepeatedSignificanceTests,
  title = {Repeated {{Significance Tests}} for {{Clinical Trials}} with a {{Fixed Number}} of {{Patients}} and {{Variable Follow-Up}} on {{JSTOR}}},
  eprint = {2530861},
  eprinttype = {jstor},
  urldate = {2024-03-30},
  howpublished = {https://www.jstor.org/stable/2530861},
  file = {/Users/zenn/Zotero/storage/N9B4SRXS/2530861.html}
}

@article{requenaCharacterizationMaximumProbability2000,
  title = {Characterization of Maximum Probability Points in the {{Multivariate Hypergeometric}} Distribution},
  author = {Requena, F. and Ciudad, N. Martin},
  year = {2000},
  month = oct,
  journal = {Statistics \& Probability Letters},
  volume = {50},
  number = {1},
  pages = {39--47},
  issn = {0167-7152},
  doi = {10.1016/S0167-7152(00)00079-1},
  urldate = {2023-07-30},
  abstract = {This paper presents the characterization of the mode of the Multivariate Hypergeometric distribution MH(R1;C1,{\dots},Cc) or, equivalently, of the maximum probability 2{\texttimes}c contingency table with fixed marginal sums and row and column independence. Some results concerning the uniqueness of this mode are given. In addition, a relation between the maximum probability points, for different fixed values of one of the variables, is studied, enabling us to obtain a recurrence relation between its maximum probabilities.},
  langid = {english},
  keywords = {2 contingency table,Mode,Multivariate Hypergeometric distribution},
  file = {/Users/zenn/Zotero/storage/MZE4DF8U/Requena and Ciudad - 2000 - Characterization of maximum probability points in .pdf;/Users/zenn/Zotero/storage/X38PTULE/S0167715200000791.html}
}

@article{requenaCharacterizationMaximumProbability2020,
  title = {Characterization of the {{Maximum Probability Fixed Marginals R}}{\texttimes}{{C Contingency Tables}}},
  author = {Requena, Francisco},
  year = {2020},
  month = feb,
  journal = {REVSTAT-Statistical Journal},
  volume = {18},
  number = {1},
  pages = {71--88},
  issn = {2183-0371},
  doi = {10.57805/revstat.v18i1.286},
  urldate = {2024-05-01},
  abstract = {In this paper operators i[j] and [j]k are defined, whose effects on an r{\texttimes}c contingency table X are to subtract 1 from xij and to add 1 to xkj , respectively, so that the composition i[j]k of the two operators changes the j-th column of the contingency table without altering its total. Also a loop is defined as a composition of such operators that leaves unchanged both row and column totals. This is used to characterize the r{\texttimes}c contingency tables of maximum probability over the fixed marginals reference set (under the hypothesis of row and column independence). Another characterization of such maximum probability tables is given using the concept of associated U tables, a U = \{uij\} table being defined as a table such that uij \&gt; 0, 1 {$\leq$} i {$\leq$} r and 1 {$\leq$} j {$\leq$} c, and for a given set of values rh, 1 {$\leq$} h \&lt; r, uh+1,j = rhuhj for all j. Finally, a necessary and sufficient condition for the uniqueness of a maximum probability table in the fixed marginals reference set is provided.},
  copyright = {Copyright (c) 2020 REVSTAT-Statistical Journal},
  langid = {english},
  keywords = {Fisher's exact test},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/requena_2020_characterization of the maximum probability fixed marginals r×c contingency.pdf}
}

@article{requenaMajorImprovementNetwork2006,
  title = {A Major Improvement to the {{Network Algorithm}} for {{Fisher}}'s {{Exact Test}} in Contingency Tables},
  author = {Requena, F. and Ciudad, N. Mart{\'i}n},
  year = {2006},
  month = nov,
  journal = {Computational Statistics \& Data Analysis},
  volume = {51},
  number = {2},
  pages = {490--498},
  issn = {01679473},
  doi = {10.1016/j.csda.2005.09.004},
  urldate = {2023-07-10},
  abstract = {Based on the Network Algorithm proposed by Mehta and Patel for Fisher's Exact Test on 2 {\texttimes} c contingency tables, the relations between maximum subpath lengths are studied. A recurrence relation between maximum subpath lengths is obtained and an ordering of the maximum path lengths is established. Based on these results, some modifications in the Network Algorithm for 2 {\texttimes} c tables are proposed. These modifications produce a drastic reduction in computation time which in some cases is higher than 99.5\% compared to StatXact-5. Moreover, and with purely practical objectives, a grouping in intervals of subpath lengths of the Network Algorithm is proposed which enable us to obtain the p-value with a limited number of exact figures which is more than sufficient in practice, while with a drastic reduction in the amount of memory required and additional reductions in computational time. The proposed modifications are valid for any 2 {\texttimes} c contingency table, and are compatible with other improvements already proposed for the Network Algorithm, and especially with the Hybrid Algorithm of Mehta and Patel.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/L8DXYZHC/Requena and Ciudad - 2006 - A major improvement to the Network Algorithm for F.pdf}
}

@article{requenaMaximumProbabilityContingency2003,
  title = {The {{Maximum Probability}} 2 {\texttimes} c {{Contingency Tables}} and the {{Maximum Probability Points}} of the {{Multivariate Hypergeometric Distribution}}},
  author = {Requena, F. and Mart{\'i}n Ciudad, N.},
  year = {2003},
  month = jan,
  journal = {Communications in Statistics - Theory and Methods},
  volume = {32},
  number = {9},
  pages = {1737--1752},
  publisher = {Taylor \& Francis},
  issn = {0361-0926},
  doi = {10.1081/STA-120022706},
  urldate = {2023-07-30},
  abstract = {The problem of obtaining the maximum probability 2 {\texttimes} c contingency table with fixed marginal sums, R = (R 1, R 2) and C = (C 1, {\dots} , C c ), and row and column independence is equivalent to the problem of obtaining the maximum probability points (mode) of the multivariate hypergeometric distribution MH(R 1; C 1, {\dots} , C c ). The most simple and general method for these problems is Joe's (Joe, H. (1988). Extreme probabilities for contingency tables under row and column independence with application to Fisher's exact test. Commun. Statist. Theory Meth. 17(11):3677--3685.) In this article we study a family of MH's in which a connection relationship is defined between its elements. Based on this family and on a characterization of the mode described in Requena and Mart{\'i}n (Requena, F., Mart{\'i}n, N. (2000). Characterization of maximum probability points in the multivariate hypergeometric distribution. Statist. Probab. Lett. 50:39--47.), we develop a new method for the above problems, which is completely general, non recursive, very simple in practice and more efficient than the Joe's method. Also, under weak conditions (which almost always hold), the proposed method provides a simple explicit solution to these problems. In addition, the well-known expression for the mode of a hypergeometric distribution is just a particular case of the method in this article.},
  keywords = {2c contingency tables,Mode,Multivariate hypergeometric distribution},
  file = {/Users/zenn/Zotero/storage/SPCC9QL8/Requena and Martín Ciudad - 2003 - The Maximum Probability 2 × c Contingency Tables a.pdf}
}

@article{resesarchTrajectoryMAPTPACCPreclinicalAlzheimer2017,
  title = {Trajectory of the {{MAPT-PACC-Preclinical Alzheimer Cognitive Composite}} in the {{Placebo Group}} of a {{Randomized Control Trial}}: {{Results}} from the {{MAPT Study}}: {{Lessons}} for {{Further Trials}}},
  author = {Resesarch, Original},
  year = {2017},
  pages = {3--7},
  keywords = {cognitive disorder,dementia,mapt,pacc,preclinical alzheimer cognitive composite},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/resesarch_2017_trajectory of the mapt-pacc-preclinical alzheimer cognitive composite in the.pdf}
}

@article{reyesUtilityAcuteSubacute2023,
  title = {Utility of {{Acute}} and {{Subacute Blood Biomarkers}} to {{Assist Diagnosis}} in {{CT-Negative Isolated Mild Traumatic Brain Injury}}},
  author = {Reyes, Jonathan and Spitz, Gershon and Major, Brendan P. and O'Brien, William T. and Giesler, Lauren P. and Bain, Jesse W.P. and Xie, Becca and Rosenfeld, Jeffrey V. and Law, Meng and Ponsford, Jennie L. and O'Brien, Terence J. and Shultz, Sandy R. and Willmott, Catherine and Mitra, Biswadev and McDonald, Stuart J.},
  year = {2023},
  month = nov,
  journal = {Neurology},
  volume = {101},
  number = {20},
  pages = {e1992-e2004},
  publisher = {Wolters Kluwer},
  doi = {10.1212/WNL.0000000000207881},
  urldate = {2024-07-11},
  abstract = {Background and Objectives Blood biomarkers glial fibrillary acidic protein (GFAP) and ubiquitin carboxy-terminal hydrolase L1 (UCH-L1) have recently been Food and Drug Administration approved as predictors of intracranial lesions on CT after mild traumatic brain injury (mTBI). However, most cases with mTBI are CT negative, and no biomarkers are approved to assist diagnosis in these individuals. In this study, we aimed to determine the optimal combination of blood biomarkers to assist mTBI diagnosis in otherwise healthy adults younger than 50 years presenting to an emergency department within 6 hours of injury. To further understand the utility of biomarkers, we assessed how biological sex, presence or absence of loss of consciousness and/or post-traumatic amnesia (LOC/PTA), and delayed presentation affected classification performance. Methods Blood samples, symptom questionnaires, and cognitive tests were prospectively conducted for participants with mTBI recruited from The Alfred Hospital Level 1 Emergency \& Trauma Center and uninjured controls. Follow-up testing was conducted at 7 days. Simoa quantified plasma GFAP, UCH-L1, tau, neurofilament light chain (NfL), interleukin (IL)--6, and IL-1{$\beta$}. Area under the receiver operating characteristic (AUC) analysis assessed classification accuracy for diagnosed mTBI, and logistic regression models identified optimal biomarker combinations. Results Plasma IL-6 (AUC 0.91, 95\% CI 0.86--0.96), GFAP (AUC 0.85, 95\% CI 0.78--0.93), and UCH-L1 (AUC 0.79, 95\% CI 0.70--0.88) best differentiated mTBI (n = 74) from controls (n = 44) acutely ({$<$}6 hours), with NfL (AUC 0.81, 95\% CI 0.72--0.90) the only marker to have such utility subacutely (7 days). Biomarker performance was similar between sexes and for participants with and without LOC/PTA, with the exception at 7 days, where GFAP and IL-6 retained some utility in female participants (GFAP: AUC 0.71, 95\% CI 0.55--0.88; IL-6: AUC 0.71, 95\% CI 0.55--0.87) and in those with LOC/PTA (GFAP: AUC 0.73, 95\% CI 0.59--0.86; IL-6: AUC 0.71, 95\% CI 0.57--0.84). Acute IL-6 (R2 = 0.50, 95\% CI 0.34--0.64) outperformed GFAP and UCH-L1 combined (R2 = 0.35, 95\% CI 0.17--0.50), with the best acute model featuring GFAP and IL-6 (R2 = 0.54, 95\% CI 0.34--0.68). Discussion These findings indicate that adding IL-6 to a panel of brain-specific proteins such as GFAP and UCH-L1 might assist in the acute diagnosis of mTBI in adults younger than 50 years. Multiple markers had high classification accuracy in participants without LOC/PTA. When compared with the best-performing acute markers, subacute measures of plasma NfL resulted in minimal reduction in classification accuracy. Future studies will investigate the optimal time frame over which plasma IL-6 might assist diagnostic decisions and how extracranial trauma affects utility.},
  file = {/Users/zenn/Zotero/storage/IHD28NRS/Reyes et al. - 2023 - Utility of Acute and Subacute Blood Biomarkers to .pdf}
}

@article{riceNewProbabilityModel1988,
  title = {A {{New Probability Model}} for {{Determining Exact P-Values}} for 2 x 2 {{Contingency Tables When Comparing Binomial Proportions}}},
  author = {Rice, William R.},
  year = {1988},
  journal = {Biometrics},
  volume = {44},
  number = {1},
  eprint = {2531892},
  eprinttype = {jstor},
  pages = {1--22},
  publisher = {[Wiley, International Biometric Society]},
  issn = {0006-341X},
  doi = {10.2307/2531892},
  urldate = {2024-07-06},
  abstract = {A new probability model to determine exact P-values for 2 x 2 contingency tables and its computerized solution are described. This model can be used in place of Fisher's "exact test" when analyzing contingency tables that compare binomial proportions estimated from samples of larger populations. The model accommodates different levels of a priori information about the underlying probability of success. The computerized solution is interactive, written in Pascal, and specifically designed to run on small desktop microcomputers. Applications of the probability model to behavioral and evolutionary data are described.},
  file = {/Users/zenn/Zotero/storage/WE96BTWQ/Rice - 1988 - A New Probability Model for Determining Exact P-Va.pdf}
}

@article{riesMitochondrialDysfunctionTherapeutic2011,
  title = {Mitochondrial Dysfunction as a Therapeutic Target in Progressive Supranuclear Palsy},
  author = {Ries, Vincent and Oertel, Wolfgang H. and H{\"o}glinger, G{\"u}nter U.},
  year = {2011},
  month = nov,
  journal = {Journal of molecular neuroscience: MN},
  volume = {45},
  number = {3},
  pages = {684--689},
  issn = {1559-1166},
  doi = {10.1007/s12031-011-9606-3},
  abstract = {Progressive supranuclear palsy (PSP) is a sporadic and progressive neurodegenerative disease, most often leading to a symmetric, akinetic-rigid syndrome with prominent postural instability, vertical supranuclear gaze palsy, and cognitive decline. It belongs to the family of tauopathies and involves both cortical and subcortical structures. There is evidence from laboratory as well as in vivo studies suggesting that mitochondrial energy metabolism is impaired in PSP. Furthermore, several findings suggest that a failure in mitochondrial energy production might act as an upstream event in the chain of pathological events leading to the aggregation of tau and neuronal cell death. Agents targeting mitochondrial dysfunction have already shown a positive effect in a phase II study; however, further studies to verify these results need to be conducted. This review will focus on the pathophysiological concept of mitochondrial dysfunction in PSP and its possible role as a therapeutic target.},
  langid = {english},
  pmid = {21792607},
  keywords = {Cell Respiration,Clinical Trials as Topic,Humans,Mitochondria,Oligopeptides,Supranuclear Palsy Progressive,Ubiquinone,Vitamins}
}

@article{rios2020baseline,
  title = {Baseline Demographic, Clinical, and Cognitive Characteristics of the Alzheimer's Prevention Initiative ({{API}}) Autosomal-Dominant Alzheimer's Disease Colombia Trial},
  author = {{Rios-Romenets}, Silvia and Lopera, Francisco and Sink, Kaycee M and Hu, Nan and Lian, Qinshu and Guthrie, Heather and Smith, Jillian and Cho, William and Mackey, Howard and Langbaum, Jessica B and others},
  year = {2020},
  journal = {Alzheimer's \& Dementia},
  volume = {16},
  number = {7},
  pages = {1023--1030}
}

@article{ritchieEuropeanPreventionAlzheimer2020,
  title = {The {{European Prevention}} of {{Alzheimer}}'s {{Dementia}} ({{EPAD}}) {{Longitudinal Cohort Study}}: {{Baseline Data Release V500}}.0},
  author = {Ritchie, Craig William and {Muniz-Terrera}, G. and Kivipelto, M. and Solomon, A. and Tom, B. and Molinuevo, J. L.},
  year = {2020},
  month = jan,
  journal = {Journal of Prevention of Alzheimer's Disease},
  volume = {7},
  number = {1},
  pages = {8--13},
  publisher = {Serdi-Editions},
  doi = {10.14283/JPAD.2019.46},
  urldate = {2021-10-02},
  abstract = {Background: The European Prevention of Alzheimer's Dementia (EPAD) Programme is a pan-European project whose objective is to deliver a platform, adaptive, Phase 2 proof of concept (PoC) trial for the secondary prevention of Alzheimer's dementia. A component of this platform is the Longitudinal Cohort Study (LCS) which acts as a readiness cohort for the PoC Trial as well as generating data for disease modelling work in the preclinical and prodromal phases of Alzheimer's dementia. Objectives: The first data wave has been collected, quality checked, released and now available for analysis to answer numerous research questions. Here we describe the results from key variables in the EPAD LCS with the objective of using these results to compliment analyses of these data in the future. Design: EPAD LCS is a cohort study whose primary objective is as a readiness cohort for the EPAD PoC Trial. As such recruitment is not capped at any particular number but will continue to facilitate delivery of the EPAD PoC Trial. Research Participants are seen annually (with an additional 6 month visit in the first year). Setting: The EPAD Trial Delivery Network comprises currently 21 centres across Europe. Participants: Research participants are included if they are over 50 years old and do not have a diagnosis of dementia. Measurements: All research participants undergo multiple assessments to fully characterise the biology of Alzheimer's disease and relate this to risk factors (both fixed and modifiable) and biomarker expression of disease through brain imaging, fluid samples (CSF, blood, urine and saliva), cognitive performance, functional abilities and neuropsychiatric symptomatology. Results: V500.0 represents the first 500 research participants baselined into EPAD LCS. The mean age was 66.4 (SD=6.7) and 47.8\% were male. The data was split for presentation into 4 groups: [1] CDR=0 and Amyloid + (preclinical AD), [2] CDR=0 and Amyloid -, [3] CDR=0.5 and Amyloid + (prodromal AD) and [4] CDR=0.5 and Amyloid -. Conclusions: The EPAD LCS is achieving its primary objective of trial readiness and the structured approach to data release as manifest by this first data release of V500.0 will assist researchers to describe and compare their findings as well as in systematic reviews and meta-analyses. It is anticipated given current recruitment rates that V1500.0 data release will take place in Autumn 2019. V500.1 (when the 1 year follow up is completed on the V500.0 (sub)cohort will be in Autumn 2019 also.},
  keywords = {Alzheimer's disease,cohort,disease modelling,EPAD,prevention},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/ritchie et al_2020_the european prevention of alzheimer’s dementia (epad) longitudinal cohort study.pdf}
}

@book{rizzoStatisticalComputing2019,
  title = {Statistical Computing with {{R}}},
  author = {Rizzo, Maria L.},
  year = {2019},
  publisher = {{Chapman and Hall/CRC}},
  urldate = {2024-05-20}
}

@article{roch1997defective,
  title = {Defective Neurite Extension Is Caused by a Mutation in Amyloid Beta-{{A4}} (Abeta ) Protein Precursor Found in Familial Alzheimers Disease},
  author = {Roch, J-M and Sundsmo, M and Otero, D and Sisodia, S and Thomas, R and Saitoh, T},
  year = {1997},
  journal = {JOURNAL OF NEUROBIOLOGY},
  volume = {32},
  pages = {469--480},
  publisher = {JOHN WILEY \& SONS LTD}
}

@article{roch2005cognitive,
  title = {Cognitive Outcomes of Corrective Lenses on Low Income Preschoolers with {{Hyperopia}}/{{Astimgatism}}: {{A}} Longitudinal Pilot Study},
  author = {{Roch--Levecq}, A--C and Brody, B and Thomas, {\relax RG} and Brown, {\relax SI}},
  year = {2005},
  journal = {Investigative Ophthalmology \& Visual Science},
  volume = {46},
  number = {13},
  pages = {4592--4592},
  publisher = {{The Association for Research in Vision and Ophthalmology}}
}

@article{roch2008ametropia,
  title = {Ametropia, Preschoolers' Cognitive Abilities, and Effects of Spectacle Correction},
  author = {{Roch-Levecq}, Anne-Catherine and Brody, Barbara L and Thomas, Ronald G and Brown, Stuart I},
  year = {2008},
  journal = {Archives of Ophthalmology},
  volume = {126},
  number = {2},
  pages = {252--258},
  publisher = {American Medical Association}
}

@article{roch2008ametropia,
  title = {Ametropia, Preschoolers' Cognitive Abilities and Effects of Spectacle Correction at 6-Month Follow-Up},
  author = {{Roch-Levecq}, A-C and Brody, {\relax BL} and Thomas, {\relax RG} and Brown, {\relax SI}},
  year = {2008},
  journal = {Investigative Ophthalmology \& Visual Science},
  volume = {49},
  number = {13},
  pages = {1427--1427},
  publisher = {{The Association for Research in Vision and Ophthalmology}}
}

@techreport{roeschJuliaBiologists2021,
  title = {Julia for {{Biologists}}},
  author = {Roesch, Elisabeth and Greener, Joe G and Maclean, Adam L and Nassar, Huda and Rackauckas, Christopher and Holy, Timothy E and Stumpf, Michael P H},
  year = {2021},
  eprint = {2109.09973v1},
  abstract = {Increasing emphasis on data and quantitative methods in the biomedical sciences is making biological research more computational. Collecting, curating, processing, and analysing large genomic and imaging data sets poses major computational challenges, as does simulating larger and more realistic models in systems biology. Here we discuss how a relative newcomer among computer programming languages-Julia-is poised to meet the current and emerging demands in the computational biosciences, and beyond. Speed, flexibility, a thriving package ecosystem, and readability are major factors that make high-performance computing and data analysis available to an unprecedented degree to "gifted amateurs". We highlight how Julia's design is already enabling new ways of analysing biological data and systems, and we provide a, necessarily incomplete, list of resources that can facilitate the transition into the Julian way of computing. C omputers are tools. Like pipettes or centrifuges, they allow us to perform tasks more quickly or efficiently; and like microscopes, NMR or mass-spectrometers, they allow us to gain new, more detailed insights into biological systems and data. Computers also allow us to define, simulate and test mathematical models of biology. As computational power evolved, solving biological problems computationally became possible , then popular, and eventually, necessary [1]. Entire fields such as computational biology and bioinfor-matics emerged. Without computers, the reconstruction of structures from X-ray crystallography, NMR, or cryo-EM methods would be impossible. The same goes for the genome project [2], which used computer programs to assemble and analyze the DNA sequences generated; and, to this day, computer programs continue to enable new science by analyzing data from the genome project. More recently, vaccine development has benefited immensely from recent advances in algorithms, software, and computer hardware [3]. Programming languages are also tools. They provide the bridge between hypothesis or model formulation and computational power. Programming languages make it possible to instruct computers to run algorithms, for example for the analysis of biological data. Some languages are very good at specific tasks-think Perl for string processing tasks; or R for statistics and data analysis-whereas others-including C, C++, and Python-have been used with success across many different domains. In biomedical research the prevailing languages have arguably been R [4] and Python [5]. Much of the high-performance backbone supporting computationally intensive research, hidden from most users, however, continues to rely on C/C++ or Fortran. Many computa-tionally intensive studies are designed in a way where an initial first draft is coded in R, Python or Matlab (first language), and subsequently translated into C/C++ or Fortran (second language) for performance reasons. This is known as the two-language problem. While this two-language approach has effectively facilitated and sped up scientific discovery in many instances, one can imagine instances where this model has been limiting. When moving a certain implementation from one programming language to a second, faster, programming language, straightforward "verbatim" translation may not be the optimal route: the faster language (such as C/C++ or Fortran) often provides the programmer with a much higher margin of autonomy, such as the ability to choose how memory is accessed or allocated or to employ slightly more sophisticated data structures [6]. Exploiting these gains may require a complete rewrite of the algorithm [7, 8] to ensure faster implementations, faster scaling, or potentially better packaged code. This requires expertise across both languages, but also rigorous testing of the code in both languages. As the field of computational biology evolves, the two-language approach is still surprisingly persistent: higher-level languages (R, Python) are used for algorithm devel-1},
  archiveprefix = {arXiv},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/roesch et al_2021_julia for biologists.pdf}
}

@article{roigAdaptiveClinicalTrial2023,
  title = {Adaptive Clinical Trial Designs with Blinded Selection of Binary Composite Endpoints and Sample Size Reassessment},
  author = {Roig, Marta Bofill and Melis, Guadalupe G{\'o}mez and Posch, Martin and Koenig, Franz},
  year = {2023},
  month = dec,
  journal = {Biostatistics},
  volume = {25},
  number = {1},
  pages = {237--252},
  issn = {1465-4644, 1468-4357},
  doi = {10.1093/biostatistics/kxac040},
  urldate = {2024-03-10},
  abstract = {For randomized clinical trials where a single, primary, binary endpoint would require unfeasibly large sample sizes, composite endpoints (CEs) are widely chosen as the primary endpoint. Despite being commonly used, CEs entail challenges in designing and interpreting results. Given that the components may be of different relevance and have different effect sizes, the choice of components must be made carefully. Especially, sample size calculations for composite binary endpoints depend not only on the anticipated effect sizes and event probabilities of the composite components but also on the correlation between them. However, information on the correlation between endpoints is usually not reported in the literature which can be an obstacle for designing future sound trials. We consider two-arm randomized controlled trials with a primary composite binary endpoint and an endpoint that consists only of the clinically more important component of the CE. We propose a trial design that allows an adaptive modification of the primary endpoint based on blinded information obtained at an interim analysis. Especially, we consider a decision rule to select between a CE and its most relevant component as primary endpoint. The decision rule chooses the endpoint with the lower estimated required sample size. Additionally, the sample size is reassessed using the estimated event probabilities and correlation, and the expected effect sizes of the composite components. We investigate the statistical power and significance level under the proposed design through simulations. We show that the adaptive design is equally or more powerful than designs without adaptive modification on the primary endpoint. Besides, the targeted power is achieved even if the correlation is misspecified at the planning stage while maintaining the type 1 error. All the computations are implemented in R and illustrated by means of a peritoneal dialysis trial.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/JNLTRXMX/kxac040.pdf}
}

@article{Rojas2021,
  title = {Plasma {{Neurofilament Light}} for {{Prediction}} of {{Disease Progression}} in {{Familial Frontotemporal Lobar Degeneration}}},
  author = {Rojas, Julio C. and Wang, Ping and Staffaroni, Adam M. and Heller, Carolin and Cobigo, Yann and Wolf, Amy and Goh, Sheng Yang M. and Ljubenkov, Peter A. and Heuer, Hilary W. and Fong, Jamie C. and Taylor, Joanne B. and Veras, Eliseo and Song, Linan and Jeromin, Andreas and Hanlon, David and Yu, Lili and Khinikar, Arvind and Sivasankaran, Rajeev and Kieloch, Agnieszka and Valentin, Marie Anne and Karydas, Anna M. and Mitic, Laura L. and Pearlman, Rodney and Kornak, John and Kramer, Joel H. and Miller, Bruce L. and Kantarci, Kejal and Knopman, David S. and {Graff-Radford}, Neill and Petrucelli, Leonard and Rademakers, Rosa and Irwin, David J. and Grossman, Murray and Ramos, Eliana Marisa and Coppola, Giovanni and Mendez, Mario F. and Bordelon, Yvette and Dickerson, Bradford C. and Ghoshal, Nupur and Huey, Edward D. and Mackenzie, Ian R. and Appleby, Brian S. and {Domoto-Reilly}, Kimiko and Hsiung, Ging Yuek R. and Toga, Arthur W. and Weintraub, Sandra and Kaufer, Daniel I. and Kerwin, Diana and Litvan, Irene and Onyike, Chiadikaobi U. and Pantelyat, Alexander and Roberson, Erik D. and Tartaglia, Maria C. and Foroud, Tatiana and Chen, Weiping and Czerkowicz, Julie and Graham, Danielle L. and {van Swieten}, John C. and Borroni, Barbara and {Sanchez-Valle}, Raquel and Moreno, Fermin and Laforce, Robert and Graff, Caroline and Synofzik, Matthis and Galimberti, Daniela and Rowe, James B. and Masellis, Mario and Finger, Elizabeth and Vandenberghe, Rik and {de Mendon{\c c}a}, Alexandre and Tagliavini, Fabrizio and Santana, Isabel and Ducharme, Simon and Butler, Chris R. and Gerhard, Alexander and Levin, Johannes and Danek, Adrian and Otto, Markus and Sorbi, Sandro and Cash, David M. and Convery, Rhian S. and Bocchetta, Martina and Foiani, Martha and Greaves, Caroline V. and Peakman, Georgia and Russell, Lucy and Swift, Imogen and Todd, Emily and Rohrer, Jonathan D. and Boeve, Bradley F. and Rosen, Howard J. and Boxer, Adam L.},
  year = {2021},
  month = may,
  journal = {Neurology},
  volume = {96},
  number = {18},
  pages = {e2296-e2312},
  publisher = {Wolters Kluwer Health, Inc. on behalf of the American Academy of Neurology},
  issn = {1526632X},
  doi = {10.1212/WNL.0000000000011848},
  urldate = {2021-11-11},
  abstract = {OBJECTIVE: We tested the hypothesis that plasma neurofilament light chain (NfL) identifies asymptomatic carriers of familial frontotemporal lobar degeneration (FTLD)-causing mutations at risk of disease progression. METHODS: Baseline plasma NfL concentrations were measured with single-molecule array in original (n = 277) and validation (n = 297) cohorts. C9orf72, GRN, and MAPT mutation carriers and noncarriers from the same families were classified by disease severity (asymptomatic, prodromal, and full phenotype) using the CDR Dementia Staging Instrument plus behavior and language domains from the National Alzheimer's Disease Coordinating Center FTLD module (CDR+NACC-FTLD). Linear mixed-effect models related NfL to clinical variables. RESULTS: In both cohorts, baseline NfL was higher in asymptomatic mutation carriers who showed phenoconversion or disease progression compared to nonprogressors (original: 11.4 {\textpm} 7 pg/mL vs 6.7 {\textpm} 5 pg/mL, p = 0.002; validation: 14.1 {\textpm} 12 pg/mL vs 8.7 {\textpm} 6 pg/mL, p = 0.035). Plasma NfL discriminated symptomatic from asymptomatic mutation carriers or those with prodromal disease (original cutoff: 13.6 pg/mL, 87.5\% sensitivity, 82.7\% specificity; validation cutoff: 19.8 pg/mL, 87.4\% sensitivity, 84.3\% specificity). Higher baseline NfL correlated with worse longitudinal CDR+NACC-FTLD sum of boxes scores, neuropsychological function, and atrophy, regardless of genotype or disease severity, including asymptomatic mutation carriers. CONCLUSIONS: Plasma NfL identifies asymptomatic carriers of FTLD-causing mutations at short-term risk of disease progression and is a potential tool to select participants for prevention clinical trials. TRIAL REGISTRATION INFORMATION: ClinicalTrials.gov Identifier: NCT02372773 and NCT02365922. CLASSIFICATION OF EVIDENCE: This study provides Class I evidence that in carriers of FTLD-causing mutations, elevation of plasma NfL predicts short-term risk of clinical progression.},
  pmid = {33827960},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/rojas et al_2021_plasma neurofilament light for prediction of disease progression in familial.pdf}
}

@article{rojasCSFNeurofilamentLight2018,
  title = {{{CSF}} Neurofilament Light Chain and Phosphorylated Tau 181 Predict Disease Progression in {{PSP}}},
  author = {Rojas, Julio C. and Bang, Jee and Lobach, Iryna V. and Tsai, Richard M. and Rabinovici, Gil D. and Miller, Bruce L. and Boxer, Adam L. and {AL-108-231 Investigators} and Williams, David and Lafontaine, Anne Louise and Marras, Connie and Jog, Mandar and Panisset, Michael and Lang, Anthony and Parker, Lesley and Stewart, Alistair J. and Corvol, Jean-Christophe and Azulay, Jean-Philippe and Couratier, Philippe and Mollenhauer, Brit and Lorenzl, Stefan and Ludolph, Albert and Benecke, Reiner and Hoglinger, Gunter and Lipp, Axel and Reichmann, Heinz and Woitalla, Dirk and Chan, Dennis and Zermansky, Adam and Burn, David and Lees, Andrew and Gozes, Illana and Boxer, Adam and Miller, Bruce L. and Lobach, Iryna V. and Roberson, Erik and Honig, Lawrence and Zamrini, Edward and Pahwa, Rajesh and Bordelon, Yvette and {Driver-Dunkley}, Erika and Lessig, Stephanie and Lew, Mark and Womack, Kyle and Boeve, Brad and Ferrara, Joseph and Hillis, Argyle and Kaufer, Daniel and Kumar, Rajeev and Xie, Tao and Gunzler, Steven and Zesiewicz, Theresa and Dayalu, Praveen and Golbe, Lawrence and Grossman, Murray and Jankovic, Joseph and McGinnis, Scott and Santiago, Anthony and Tuite, Paul and Isaacson, Stuart and {Leegwater-Kim}, Julie and Litvan, Irene and Knopman, David S. and Schneider, Lon S. and Doody, Rachelle S. and Koestler, Mary and Jack, Clifford R. and Van Deerlin, Viviana and Randolph, Christopher and Whitaker, Steve and Hirman, Joe and Gold, Michael and Morimoto, Bruce H.},
  year = {2018},
  month = jan,
  journal = {Neurology},
  volume = {90},
  number = {4},
  issn = {0028-3878, 1526-632X},
  doi = {10.1212/WNL.0000000000004859},
  urldate = {2024-06-05},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/8PVF32PX/Rojas et al. - 2018 - CSF neurofilament light chain and phosphorylated t.pdf}
}

@article{romeroFutureNowModelbased2015,
  title = {The Future Is Now: {{Model-based}} Clinical Trial Design for {{Alzheimer}}'s Disease},
  author = {Romero, K and Ito, K and Rogers, {\relax JA} and Polhamus, D and Qiu, R and Stephenson, D and Mohs, R and Lalonde, R and Sinha, V and Wang, Y and Brown, D and Isaac, M and Vamvakas, S and Hemmings, R and Pani, L and Bain, {\relax LJ} and Corrigan, B},
  year = {2015},
  month = mar,
  journal = {Clinical Pharmacology \& Therapeutics},
  volume = {97},
  number = {3},
  pages = {210--214},
  issn = {00099236},
  doi = {10.1002/cpt.16},
  urldate = {2016-10-22},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/romero et al_2015_the future is now.pdf}
}

@article{Rosen1984,
  title = {A {{New Rating Scale}} for {{Alzheimer}}'s {{Disease}}},
  author = {Rosen, {\relax WG} and Mohs, {\relax RC} and Davis, {\relax KL}},
  year = {1984},
  journal = {The American journal of {\dots}},
  pages = {1356--1364},
  urldate = {2014-01-16},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/rosen et al_1984_a new rating scale for alzheimer’s disease.pdf}
}

@article{rosenbergerRandomizationForgottenComponent2019,
  title = {Randomization: {{The}} Forgotten Component of the Randomized Clinical Trial},
  shorttitle = {Randomization},
  author = {Rosenberger, William F. and Uschner, Diane and Wang, Yanying},
  year = {2019},
  month = jan,
  journal = {Statistics in Medicine},
  volume = {38},
  number = {1},
  pages = {1--12},
  issn = {0277-6715, 1097-0258},
  doi = {10.1002/sim.7901},
  urldate = {2023-12-15},
  abstract = {``{\dots}The customary test for an observed difference{\dots}is based on an enumeration of the probabilities, on the initial hypothesis that two treatments do not differ in their effects,{\dots}of all the various results which would occur if the trial were repeated indefinitely with different random samples of the same size as those actually used.'' --Peter Armitage (``Sequential tests in prophylactic and therapeutic trials'' in               Quarterly Journal of Medicine               , 1954;23(91):255-274). Randomization has been the hallmark of the clinical trial since Sir Bradford Hill adopted it in the 1946 streptomycin trial. An exploration of the early literature yields three rationales, ie, (i) the incorporation of randomization provides unpredictability in treatment assignments, thereby mitigating selection bias; (ii) randomization tends to ensure similarity in the treatment groups on known and unknown confounders (at least asymptotically); and (iii) the act of randomization itself provides a basis for inference when random sampling is not conducted from a population model. Of these three, rationale (iii) is often forgotten, ignored, or left untaught. Today, randomization is a rote exercise, scarcely considered in protocols or medical journal articles. Yet, the literature of the last century is rich with statistical articles on randomization methods and their consequences, authored by some of the pioneers of the biostatistics and statistics world. In this paper, we review some of this literature and describe very simple methods to rectify some of the oversight. We describe how randomization-based inference can be used for virtually any outcome of interest in a clinical trial. Special mention is made of nonstandard clinical trials situations.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/9BAWNL5M/Rosenberger et al. - 2019 - Randomization The forgotten component of the rand.pdf}
}

@article{rosenbergerUseSpendingFunctions1993,
  title = {Use o f Spending Functions for Occasional o r Continuous Monitoring o f Data in Clinical Trials},
  author = {Rosenberger, William F and Lachin, J O H N M},
  year = {1993},
  volume = {12},
  number = {October 1992},
  pages = {2219--2231},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/rosenberger_lachin_1993_use o f spending functions for occasional o r continuous monitoring o f data in.pdf}
}

@article{rossNonparametricMixtureGaussian,
  title = {Nonparametric {{Mixture}} of {{Gaussian Processes}} with {{Constraints}}},
  author = {Ross, James C and Dy, Jennifer G},
  abstract = {Motivated by the need to identify new and clinically relevant categories of lung disease, we propose a novel clustering with constraints method using a Dirichlet process mixture of Gaussian processes in a variational Bayesian nonparametric framework. We claim that individuals should be grouped according to biological and/or genetic similarity regardless of their level of disease severity; therefore, we introduce a new way of looking at subtyping/clustering by recasting it in terms of discovering associations of individuals to disease trajectories (i.e., grouping individuals based on their similarity in response to environmental and/or disease causing variables). The nonparametric nature of our algorithm allows for learning the unknown number of meaningful trajectories. Additionally, we acknowledge the usefulness of expert guidance by providing for their input using must-link and cannot-link constraints. These constraints are encoded with Markov random fields. We also provide an efficient variational approach for performing inference on our model.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/5YH823QY/ross13a.pdf}
}

@inproceedings{roubin1987prognosis,
  title = {Prognosis after Multiple Vessel Angioplasty (Ptca) in Patients with Coronary-Artery Disease},
  booktitle = {Circulation},
  author = {Roubin, {\relax GS} and Sutor, C and Lembo, {\relax NJ} and Hoffmeister, J and Thomas, {\relax RG} and Douglas, {\relax JS} and King, {\relax SB}},
  year = {1987},
  volume = {76},
  pages = {465--465},
  publisher = {AMER HEART ASSOC 7272 GREENVILLE AVENUE, DALLAS, TX 75231-4596}
}

@article{roubin1988influence,
  title = {Influence of Balloon Size on Initial Success, Acute Complications, and Restenosis after Percutaneous Transluminal Coronary Angioplasty. {{A}} Prospective Randomized Study.},
  author = {Roubin, Gary S and Douglas Jr, John S and King 3rd, {\relax SB} and Lin, {\relax SF} and Hutchison, N and Thomas, {\relax RG} and Gruentzig, {\relax AR}},
  year = {1988},
  journal = {Circulation},
  volume = {78},
  number = {3},
  pages = {557--565}
}

@article{rouseNetworkMetaanalysisIntroduction2017,
  title = {Network Meta-Analysis: An Introduction for Clinicians},
  shorttitle = {Network Meta-Analysis},
  author = {Rouse, Benjamin and Chaimani, Anna and Li, Tianjing},
  year = {2017},
  journal = {Internal and emergency medicine},
  volume = {12},
  pages = {103--111},
  publisher = {Springer},
  urldate = {2023-12-21},
  file = {/Users/zenn/Zotero/storage/SCUCNGM3/s11739-016-1583-7.html}
}

@article{rouseNetworkMetaanalysisIntroduction2017a,
  title = {Network Meta-Analysis: An Introduction for Clinicians},
  shorttitle = {Network Meta-Analysis},
  author = {Rouse, Benjamin and Chaimani, Anna and Li, Tianjing},
  year = {2017},
  month = feb,
  journal = {Internal and Emergency Medicine},
  volume = {12},
  number = {1},
  pages = {103--111},
  issn = {1970-9366},
  doi = {10.1007/s11739-016-1583-7},
  urldate = {2023-12-21},
  abstract = {Network meta-analysis is a technique for comparing multiple treatments simultaneously in a single analysis by combining direct and indirect evidence within a network of randomized controlled trials. Network meta-analysis may assist assessing the comparative effectiveness of different treatments regularly used in clinical practice and, therefore, has become attractive among clinicians. However, if proper caution is not taken in conducting and interpreting network meta-analysis, inferences might be biased. The aim of this paper is to illustrate the process of network meta-analysis with the aid of a working example on first-line medical treatment for primary open-angle glaucoma. We discuss the key assumption of network meta-analysis, as well as the unique considerations for developing appropriate research questions, conducting the literature search, abstracting data, performing qualitative and quantitative synthesis, presenting results, drawing conclusions, and reporting the findings in a network meta-analysis.},
  langid = {english},
  keywords = {Comparative effectiveness,Multiple treatment meta-analysis,Network meta-analysis,Transitivity},
  file = {/Users/zenn/Zotero/storage/3FM8NRZ6/Rouse et al. - 2017 - Network meta-analysis an introduction for clinici.pdf}
}

@article{royallEffectSampleSize2012,
  title = {The {{Effect}} of {{Sample Size}} on the {{Meaning}} of {{Significance Tests The Effect}} of {{Sample Size}} on the {{Meaning}} of {{Significance Tests}}},
  author = {Royall, Richard M and Royall, Richard M},
  year = {2012},
  volume = {1305},
  keywords = {1,choosing between two statistical,dresses the problem of,evidence,hypothesis testing ad-,p value,statistical significance,testing statistical hypotheses,the neyman-pearson theory of},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/royall_royall_2012_the effect of sample size on the meaning of significance tests the effect of.pdf}
}

@article{rymanSymptomOnsetAutosomal2014,
  title = {Symptom Onset in Autosomal Dominant {{Alzheimer}} Disease: {{A}} Systematic Review and Meta-Analysis},
  shorttitle = {Symptom Onset in Autosomal Dominant {{Alzheimer}} Disease},
  author = {Ryman, Davis C. and {Acosta-Baena}, Natalia and Aisen, Paul S. and Bird, Thomas and Danek, Adrian and Fox, Nick C. and Goate, Alison and Frommelt, Peter and Ghetti, Bernardino and Langbaum, Jessica B. S. and Lopera, Francisco and Martins, Ralph and Masters, Colin L. and Mayeux, Richard P. and McDade, Eric and Moreno, Sonia and Reiman, Eric M. and Ringman, John M. and Salloway, Steve and Schofield, Peter R. and Sperling, Reisa and Tariot, Pierre N. and Xiong, Chengjie and Morris, John C. and Bateman, Randall J. and Network, And the Dominantly Inherited Alzheimer},
  year = {2014},
  month = jul,
  journal = {Neurology},
  volume = {83},
  number = {3},
  pages = {253--260},
  publisher = {Wolters Kluwer Health, Inc. on behalf of the American Academy of Neurology},
  issn = {0028-3878, 1526-632X},
  doi = {10.1212/WNL.0000000000000596},
  urldate = {2023-05-15},
  abstract = {Objective: To identify factors influencing age at symptom onset and disease course in autosomal dominant Alzheimer disease (ADAD), and develop evidence-based criteria for predicting symptom onset in ADAD. Methods: We have collected individual-level data on ages at symptom onset and death from 387 ADAD pedigrees, compiled from 137 peer-reviewed publications, the Dominantly Inherited Alzheimer Network (DIAN) database, and 2 large kindreds of Colombian (PSEN1 E280A) and Volga German (PSEN2 N141I) ancestry. Our combined dataset includes 3,275 individuals, of whom 1,307 were affected by ADAD with known age at symptom onset. We assessed the relative contributions of several factors in influencing age at onset, including parental age at onset, age at onset by mutation type and family, and APOE genotype and sex. We additionally performed survival analysis using data on symptom onset collected from 183 ADAD mutation carriers followed longitudinally in the DIAN Study. Results: We report summary statistics on age at onset and disease course for 174 ADAD mutations, and discover strong and highly significant (p {$<$} 10-16, r2 {$>$} 0.38) correlations between individual age at symptom onset and predicted values based on parental age at onset and mean ages at onset by mutation type and family, which persist after controlling for APOE genotype and sex. Conclusions: Significant proportions of the observed variance in age at symptom onset in ADAD can be explained by family history and mutation type, providing empirical support for use of these data to estimate onset in clinical research.},
  chapter = {Article},
  copyright = {{\copyright} 2014 American Academy of Neurology},
  langid = {english},
  pmid = {24928124},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/ryman et al_2014_symptom onset in autosomal dominant alzheimer disease.pdf}
}

@article{rymanSymptomOnsetAutosomal2014a,
  title = {Symptom Onset in Autosomal Dominant {{Alzheimer}} Disease: A Systematic Review and Meta-Analysis},
  shorttitle = {Symptom Onset in Autosomal Dominant {{Alzheimer}} Disease},
  author = {Ryman, Davis C. and {Acosta-Baena}, Natalia and Aisen, Paul S. and Bird, Thomas and Danek, Adrian and Fox, Nick C. and Goate, Alison and Frommelt, Peter and Ghetti, Bernardino and Langbaum, Jessica BS},
  year = {2014},
  journal = {Neurology},
  volume = {83},
  number = {3},
  pages = {253--260},
  publisher = {AAN Enterprises},
  file = {/Users/zenn/Zotero/storage/5L8YP83R/PMC4117367.html;/Users/zenn/Zotero/storage/TRHQ8C8R/253.html}
}

@article{sabbagh1999neurochemical,
  title = {Neurochemical Markers Do Not Correlate with Cognitive Decline in the {{Lewy}} Body Variant of {{Alzheimer}} Disease},
  author = {Sabbagh, Marwan N and {Corey-Bloom}, Jody and Tiraboschi, Pietro and Thomas, Ronald and Masliah, Eliezer and Thal, Leon J},
  year = {1999},
  journal = {Archives of neurology},
  volume = {56},
  number = {12},
  pages = {1458--1461},
  publisher = {American Medical Association}
}

@article{sainaniMakingSenseIntention2010,
  title = {Making {{Sense}} of {{Intention}}-to-{{Treat}}},
  author = {Sainani, Kristin L.},
  year = {2010},
  month = mar,
  journal = {PM\&R},
  volume = {2},
  number = {3},
  pages = {209--213},
  issn = {1934-1482, 1934-1563},
  doi = {10.1016/j.pmrj.2010.01.004},
  urldate = {2024-03-06},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/HW9F2FF7/PM R - 2010 - Sainani - Making Sense of Intention‐to‐Treat.pdf}
}

@article{salloway2021trial,
  title = {A Trial of Gantenerumab or Solanezumab in Dominantly Inherited {{Alzheimer}}'s Disease},
  author = {Salloway, Stephen and Farlow, Martin and McDade, Eric and Clifford, David B and Wang, Guoqiao and {Llibre-Guerra}, Jorge J and Hitchcock, Janice M and Mills, Susan L and Santacruz, Anna M and Aschenbrenner, Andrew J and others},
  year = {2021},
  journal = {Nature medicine},
  volume = {27},
  number = {7},
  pages = {1187--1196},
  publisher = {Nature Publishing Group}
}

@article{salmon2002alzheimer,
  title = {Alzheimer's Disease Can Be Accurately Diagnosed in Very Mildly Impaired Individuals},
  author = {Salmon, David P and Thomas, {\relax RG} and Pay, {\relax MM} and Booth, A and Hofstetter, {\relax CR} and Thal, {\relax LJ} and Katzman, R},
  year = {2002},
  journal = {Neurology},
  volume = {59},
  number = {7},
  pages = {1022--1028},
  publisher = {Wolters Kluwer Health, Inc. on behalf of the American Academy of Neurology}
}

@article{salmon2013age,
  title = {Age and Apolipoprotein {{E}} Genotype Influence Rate of Cognitive Decline in Nondemented Elderly.},
  author = {Salmon, David P and Ferris, Steven H and Thomas, Ronald G and Sano, Mary and Cummings, Jeffery L and Sperling, Reisa A and Petersen, Ronald C and Aisen, Paul S},
  year = {2013},
  journal = {Neuropsychology},
  volume = {27},
  number = {4},
  pages = {391},
  publisher = {American Psychological Association}
}

@inproceedings{sano1996evaluation,
  title = {Evaluation of Efficacy Measures in Clinical Trials for {{Alzheimer}}'s Disease: {{Does}} Psychometric Test Performance Predict Clinically Relevant Outcomes?},
  booktitle = {Neurology},
  author = {Sano, M and Growdon, J and Thomas, R and Ernesto, C and Schafer, K and Woodbury, P and Grundman, M and Thal, L},
  year = {1996},
  volume = {46},
  pages = {14004--14004},
  publisher = {LITTLE BROWN CO 34 BEACON STREET, BOSTON, MA 02108-1493}
}

@article{sano1996rationale,
  title = {Rationale and Design of a Multicenter Study of Selegiline and Alpha-Tocopherol in the Treatment of {{Alzheimer}} Disease Using Novel Clinical Outcomes. {{Alzheimer}}'s {{Disease Cooperative Study}}.},
  author = {Sano, Mary and Ernesto, Christopher and Klauber, Melville R and Schafer, Kimberly and Woodbury, Peter and Thomas, Ronald and Grundman, Michael and Growdon, John and Thal, Leon J},
  year = {1996},
  journal = {Alzheimer disease and associated disorders},
  volume = {10},
  number = {3},
  pages = {132--140}
}

@article{sano1997alpha,
  title = {Alpha-Tocopherol and {{Alzheimer}}'s Disease-Reply},
  author = {Sano, M and Thomas, {\relax RG} and Thal, {\relax LJ}},
  year = {1997},
  journal = {New England Journal of Medicine},
  volume = {337},
  number = {8},
  pages = {573--573},
  publisher = {MASS MEDICAL SOC 10 SHATTUCK, BOSTON, MA 02115}
}

@article{sano1997controlled,
  title = {A Controlled Trial of Selegiline, Alpha-Tocopherol, or Both as Treatment for {{Alzheimer}}'s Disease},
  author = {Sano, Mary and Ernesto, Christopher and Thomas, Ronald G and Klauber, Melville R and Schafer, Kimberly and Grundman, Michael and Woodbury, Peter and Growdon, John and Cotman, Carl W and Pfeiffer, Eric and others},
  year = {1997},
  journal = {New England Journal of Medicine},
  volume = {336},
  number = {17},
  pages = {1216--1222},
  publisher = {Mass Medical Soc}
}

@inproceedings{sano1997effects,
  title = {Effects of {{Selegiline}} and Alpha-{{Tocopherol}} on Cognitive and Functional Outcome Measures in Moderately Impaired Patients with {{Alzheimer}}'s Disease},
  booktitle = {Neurology},
  author = {Sano, M and Ernesto, C and Thomas, {\relax RG} and Klauber, {\relax MR} and Schafer, K and Grundman, M and Woodbury, P and Growdon, J and Cotman, {\relax CW} and Pfeiffer, E and others},
  year = {1997},
  volume = {48},
  pages = {63002--63002},
  publisher = {LIPPINCOTT-RAVEN PUBL 227 EAST WASHINGTON SQ, PHILADELPHIA, PA 19106}
}

@article{sano1997pfeiffer,
  title = {Pfeiffer {{E Schneider LS}}, {{Thal LJ}}. {{A}} Controlled Trial of Selegiline, Alpha-Tocopherol or Both as Treatment for {{Alzheimer}}'s Disease},
  author = {Sano, M and Ernesto, C and Thomas, {\relax RG} and Klauber, {\relax MR} and Schafer, K and Grundman, M and Woodbury, P and Growdon, J and Cotman, {\relax CW}},
  year = {1997},
  journal = {The New England journal of medicine},
  volume = {336},
  pages = {1216--22}
}

@article{sano1997spanish,
  title = {The {{Spanish Instrument Protocol}}: {{Design}} and Implementation of a Study to Evaluate Treatment Efficacy Instruments for {{Spanish-speaking}} Patients with {{Alzheimer}}'s Disease.},
  author = {Sano, M and Mackell, {\relax JA} and Ponton, M and Ferreira, P and Wilson, J and Pawluczyk, S and Pfeiffer, E and Thomas, {\relax RG} and Jin, S and Schafer, K and others},
  year = {1997},
  journal = {Alzheimer disease and associated disorders},
  publisher = {Lippincott Williams \& Wilkins}
}

@article{sano2000multiple,
  title = {Multiple Sclerosis: {{Current}} Treatment},
  author = {Sano, M and Ernesto, C and Thomas, {\relax RG} and others},
  year = {2000},
  journal = {Melmon and Morrelli's Clinical Pharmacology: Basic Principles in Therapeutics},
  pages = {453},
  publisher = {McGraw-Hill/Appleton \& Lange}
}

@inproceedings{sano2000predicting,
  title = {Predicting Nursing Home Placement with Change on Cognitive Measures in {{Alzheimer}}'s Disease},
  booktitle = {Neurology},
  author = {Sano, {\relax MC} and Berg, {\relax JD} and Knopman, D and Farlow, {\relax MR} and Thomas, {\relax RG}},
  year = {2000},
  volume = {54},
  pages = {A208--A208},
  publisher = {LIPPINCOTT WILLIAMS \& WILKINS 530 WALNUT ST, PHILADELPHIA, PA 19106-3621 USA}
}

@inproceedings{sano2001incidence,
  title = {Incidence and Persistence of Psychosis in {{Alzheimer}}'s Disease},
  booktitle = {Neurology},
  author = {Sano, {\relax MC} and Berg, {\relax JD} and Thomas, {\relax RG} and Schneider, {\relax LS} and Aisen, {\relax PS} and Mulnard, R and Thal, {\relax LJ}},
  year = {2001},
  volume = {56},
  pages = {A179--A179},
  publisher = {LIPPINCOTT WILLIAMS \& WILKINS 530 WALNUT ST, PHILADELPHIA, PA 19106-3621 USA}
}

@article{sano2006adcs,
  title = {{{ADCS Prevention Instrument Project}}: Pharmacoeconomics: Assessing Health-Related Resource Use among Healthy Elderly},
  author = {Sano, Mary and Zhu, Carolyn W and Whitehouse, Peter J and Edland, Steven and Jin, Shelia and Ernstrom, Karin and Thomas, Ronald G and Thal, Leon J and Ferris, Steven H},
  year = {2006},
  journal = {Alzheimer disease and associated disorders},
  volume = {20},
  number = {4 Suppl 3},
  pages = {S191},
  publisher = {NIH Public Access}
}

@article{sano2007p,
  title = {P-081: {{The ACDS}} Home Assessment Instrument: {{A}} Pilot Study},
  author = {Sano, Mary and Kaye, Jeffrey and Ferris, Steven and Hayes, Tamara and Egelko, Susan and Mundt, James and Li, Yan and Walter, Sarah and Thomas, Ronald and Edland, Steven and others},
  year = {2007},
  journal = {Alzheimer's \& Dementia},
  volume = {3},
  number = {3S\_Part\_1},
  pages = {S124--S125}
}

@article{sano2011adding,
  title = {Adding Delayed Recall to the {{Alzheimer Disease Assessment Scale}} Is Useful in Studies of Mild Cognitive Impairment but Not {{Alzheimer}} Disease},
  author = {Sano, Mary and Raman, Rema and Emond, Jennifer and Thomas, Ronald G and Petersen, Ronald and Schneider, Lon S and Aisen, Paul S},
  year = {2011},
  journal = {Alzheimer disease and associated disorders},
  volume = {25},
  number = {2},
  pages = {122},
  publisher = {NIH Public Access}
}

@article{sano2011randomized,
  title = {A Randomized, Double-Blind, Placebo-Controlled Trial of Simvastatin to Treat {{Alzheimer}} Disease},
  author = {Sano, M and Bell, {\relax KL} and Galasko, D and Galvin, {\relax JE} and Thomas, {\relax RG} and Van Dyck, {\relax CH} and Aisen, {\relax PS}},
  year = {2011},
  journal = {Neurology},
  volume = {77},
  number = {6},
  pages = {556--563},
  publisher = {Wolters Kluwer Health, Inc. on behalf of the American Academy of Neurology}
}

@article{sano2019randomized,
  title = {A Randomized Clinical Trial to Evaluate Home-Based Assessment of People over 75 Years Old},
  author = {Sano, Mary and Zhu, Carolyn W and Kaye, Jeffrey and Mundt, James C and Hayes, Tamara L and Ferris, Steven and Thomas, Ronald G and Sun, Chung-Kai and Jiang, Yanxin and Donohue, Michael C and others},
  year = {2019},
  journal = {Alzheimer's \& Dementia},
  volume = {15},
  number = {5},
  pages = {615--624}
}

@article{santoroMinimizationCaseStudy2019,
  title = {Minimization: {{A Case Study}} of {{Covariate-Adaptive Randomization}}},
  author = {Santoro, Debora and Statistician, Project and A, Chiesi Farmaceutici S},
  year = {2019},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/santoro et al_2019_minimization.pdf}
}

@article{Sarkar2015,
  title = {Editorial},
  author = {Sarkar, Deepayan and Lawrence, Michael and Bivand, Roger and Gr{\"u}n, Bettina},
  year = {2015},
  journal = {The R Journal},
  volume = {7},
  number = {1},
  issn = {2073-4859},
  abstract = {On behalf of the editorial board, I am pleased to publish Volume 7, Issue 1 of the R Journal. This issue contains 16 contributed research articles. Each of them either presents an R package, a specific extension of an R package or applications using R packages available from the Comprehensive R Archive Network (CRAN, http:://CRAN.R-project.org). It thus provides a small insight into the wide variety of functionality covered currently by the more than 6800 packages available from CRAN. The presented packages include packages for enhancing the graphics functionality of R such as package gridGraphics for converting graphics drawn with the graphics package to grid graphics and showtext for using system fonts in R graphics. Additional graphical tools are provided by package sparkTable, which allows to enhance tables, and by package fanplot, which allows to visualize the uncertainty connected with forecasts using fan charts. Further infrastructure is implemented in package rstackdeque which provides efficient data structures for stacks and queues.},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/sarkar et al_2015_editorial.pdf}
}

@article{schafer1996a34,
  title = {A34 {{Clinical}} Monitoring of Rating Scales in Multicenter Clinical Trials},
  author = {Schafer, Kimberly and Ernesto, Christopher and Sano, Mary and Mackell, Joan and Thomas, Ronald and Morris, John C},
  year = {1996},
  journal = {Controlled Clinical Trials},
  volume = {17},
  number = {2},
  pages = {S57--S58},
  publisher = {Elsevier}
}

@article{schafer1996p63,
  title = {P63 {{Informed}} Consent Issues When Including Genetic Testing in Clinical Trials},
  author = {Schafer, Kimberly and Thomas, Ronald and Galasko, Douglas and Morris, John C and Whitehouse, Peter and Bochenek, Jacqueline and Thal, Leon},
  year = {1996},
  journal = {Controlled Clinical Trials},
  volume = {2},
  number = {17},
  pages = {S130--S131}
}

@article{schafer1997p23,
  title = {P23 Use of the World Wide Web for Clinical Monitoring in Multicenter Clinical Trials},
  author = {Schafer, Kimberly and Thomas, Ronald G and Welty, Greg and Berry, Angela Lambert and Schittini, Mario},
  year = {1997},
  journal = {Controlled Clinical Trials},
  volume = {3},
  number = {18},
  pages = {S124}
}

@article{schafer1998use,
  title = {Use of the World Wide Web in Data Dissemination to Central Review Committees},
  author = {Schafer, Kimberly A and Welty, Greg and Thomas, Ronald G},
  year = {1998},
  journal = {Controlled Clinical Trials},
  volume = {19},
  number = {3},
  pages = {S81},
  publisher = {Elsevier}
}

@article{schafer2004reliability,
  title = {Reliability of Monitoring the Clinical Dementia Rating in Multicenter Clinical Trials},
  author = {Schafer, Kimberly A and Tractenberg, Rochelle E and Sano, Mary and Mackell, Joan A and Thomas, Ronald G and Gamst, Anthony and Thal, Leon J and Morris, John C and others},
  year = {2004},
  journal = {Alzheimer disease and associated disorders},
  volume = {18},
  number = {4},
  pages = {219},
  publisher = {NIH Public Access}
}

@article{schneider1997alzheimer,
  title = {The {{Alzheimer}}'s {{Disease Cooperative Study}}. {{Validity}} and Reliability of the {{Alzheimer}}'s Disease Cooperative Study-Clinical Global Impression of Change},
  author = {Schneider, {\relax LS} and Olin, {\relax JT} and Doody, {\relax RS} and Clark, {\relax CM} and Morris, {\relax JC} and Reisberg, B and Schmitt, {\relax FA} and Grundman, M and Thomas, {\relax RG} and Ferris, {\relax SH}},
  year = {1997},
  journal = {Alzheimer disease and associated disorders},
  volume = {11},
  number = {suppl 2},
  pages = {S22--S32}
}

@incollection{schneider1997validity,
  title = {Validity and Reliability of the Alzheimer's Disease Cooperative Study-Clinical Global Impression of Change ({{ADCS-CGIC}})},
  booktitle = {Alzheimer Disease},
  author = {Schneider, Lon S and Olin, Jason T and Doody, Rachelle S and Clark, Christopher M and Morris, John C and Reisberg, Barry and Ferris, Steven H and Schmitt, Frederick A and Grundman, Michael and Thomas, Ronald G},
  year = {1997},
  pages = {425--429},
  publisher = {Birkh{\"a}user Boston}
}

@article{schneider2017p4,
  title = {[{{P4}}--573]: {{A PHASE}} 2 {{MULTICENTER}}, {{RANDOMIZED}}, {{PLACEBO-CONTROLLED TRIAL TO EVALUATE THE EFFICACY AND SAFETY OF EDONERPIC}} ({{T-817}}) {{IN PATIENTS WITH MILD TO MODERATE ALZHEIMER}}'s {{DISEASE}}},
  author = {Schneider, Lon S and Thomas, Ronald G and Hendrix, Suzanne and Brewer, James B and Rissman, Robert A and Salmon, David P and Kobayashi, Hiroshi and Feldman, Howard H},
  year = {2017},
  journal = {Alzheimer's \& Dementia},
  volume = {13},
  number = {7S\_Part\_32},
  pages = {P1572--P1572},
  publisher = {The Alzheimer's Association, Inc.}
}

@article{schneider2019low,
  title = {Low-Dose Ladostigil for Mild Cognitive Impairment: {{A}} Phase 2 Placebo-Controlled Clinical Trial},
  author = {Schneider, Lon S and Geffen, Yona and Rabinowitz, Jonathan and Thomas, Ronald G and Schmidt, Reinhold and Ropele, Stefan and Weinstock, Marta and Group, Ladostigil Study and others},
  year = {2019},
  journal = {Neurology},
  volume = {93},
  number = {15},
  pages = {e1474--e1484},
  publisher = {Wolters Kluwer Health, Inc. on behalf of the American Academy of Neurology}
}

@article{schneider2019safety,
  title = {Safety and Efficacy of Edonerpic Maleate for Patients with Mild to Moderate {{Alzheimer}} Disease: A Phase 2 Randomized Clinical Trial},
  author = {Schneider, Lon S and Thomas, Ronald G and Hendrix, Suzanne and Rissman, Robert A and Brewer, James B and Salmon, David P and Oltersdorf, Tilman and Okuda, Tomohiro and Feldman, Howard H and others},
  year = {2019},
  journal = {JAMA neurology},
  volume = {76},
  number = {11},
  pages = {1330--1339},
  publisher = {American Medical Association}
}

@article{schneider2021impact,
  title = {Impact of Potential Modifications to {{Alzheimer}}'s Disease Clinical Trials in Response to Disruption by {{COVID-19}}: A Simulation Study},
  author = {Schneider, Lon S and Qiu, Yuqi and Thomas, Ronald G and Evans, Carol and Jacobs, Diane M and Jin, Shelia and Kaye, Jeffrey A and LaCroix, Andrea Z and Messer, Karen and Salmon, David P and others},
  year = {2021},
  journal = {Alzheimer's research \& therapy},
  volume = {13},
  number = {1},
  pages = {1--13},
  publisher = {BioMed Central}
}

@article{schneiderCompositeCognitiveFunctional2020,
  title = {Composite Cognitive and Functional Measures for Early Stage {{Alzheimer}}'s Disease Trials},
  author = {Schneider, Lon S. and Goldberg, Terry E.},
  year = {2020},
  journal = {Alzheimer's and Dementia: Diagnosis, Assessment and Disease Monitoring},
  volume = {12},
  number = {1},
  issn = {23528729},
  doi = {10.1002/dad2.12017},
  abstract = {Introduction: Composite scales have been advanced as primary outcomes in early stage Alzheimer's disease trials, and endorsed by the U.S. Food and Drug Administration (FDA) for pivotal trials. They are generally composed of several neurocognitive subscales and may include clinical and functional activity scales. Methods: We summarized the development of 12 composite scales intended as outcomes for clinical trials and assessed their characteristics. Results: Composite scales have been constructed from past observational and clinical trial databases by selecting components of individual neuropsychological tests previously used in clinical trials. The atheoretical approaches to combining scales into a composite scale that have often been used risk omitting clinically important measures and so may include redundant, irrelevant, or noncontributory tests.~The deliberate combining of neurocognitive scales with functional activity scales provides arbitrary weightings that also may be clinically irrelevant or obscure change in a particular domain. Basic psychometric information is lacking for most of the composites. Discussion: Although composite scales are desirable for pivotal clinical trials because they, in principle, provide for a single, primary outcome combining neurocognitive and/or functional domains, they have substantial limitations, including their common derivations, inattention to basic psychometric principles, redundancy, absence of alternate forms, and, arguably, the inclusion of functional measures in some. In effect, any currently used composite is undergoing validation through its use in a trial. The assumption that a composite, by its construction alone, is more likely than an individual measure to detect an effect from any particular drug and that the effect is more clinically relevant or valid has not been demonstrated.},
  keywords = {activities of daily living,Alzheimer's disease,clinical outcomes,clinical trials,cognition,composite outcomes,MCI,mild cognitive impairment,neuropsychological tests,preclinical,prodromal,psychometrics},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/schneider_goldberg_2020_composite cognitive and functional measures for early stage alzheimer's disease.pdf}
}

@incollection{Schork2019,
  title = {Artificial {{Intelligence}} and {{Personalized Medicine}}},
  booktitle = {Cancer {{Treatment}} and {{Research}}},
  author = {Schork, Nicholas J.},
  year = {2019},
  volume = {178},
  pages = {265--283},
  publisher = {Springer International Publishing},
  issn = {09273042},
  doi = {10.1007/978-3-030-16391-4_11},
  urldate = {2021-11-06},
  abstract = {The development of high-throughput, data-intensive biomedical research assays and technologies has created a need for researchers to develop strategies for analyzing, integrating, and interpreting the massive amounts of data they generate. Although a wide variety of statistical methods have been designed to accommodate `big data,' experiences with the use of artificial intelligence (AI) techniques suggest that they might be particularly appropriate. In addition, the{\^A} results of the application of{\^A} these assays{\^A} reveal a great{\^A} heterogeneity in the pathophysiologic{\^A} factors and processes that contribute to disease,{\^A} suggesting that there is a need to tailor, or `personalize,' medicines to the nuanced and often unique features possessed by individual patients. Given how important data-intensive assays are to revealing appropriate intervention targets and strategies for treating an individual with a disease, AI can play an important role in the development of personalized medicines. We describe many areas where AI can play such{\^A} a role and argue that AI's ability to advance personalized medicine will depend critically on not{\^A} only{\^A} the refinement of relevant assays, but also on{\^A} ways of storing, aggregating, accessing, and ultimately integrating, the data they produce. We also point out the limitations of many AI techniques in developing personalized medicines{\^A} as well as consider areas for further research.},
  pmid = {31209850},
  keywords = {Artificial intelligence,Big data,Clinical trials,Personalized medicine},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/schork_2019_artificial intelligence and personalized medicine.pdf}
}

@article{schorkAccommodatingSerialCorrelation2022,
  title = {Accommodating {{Serial Correlation}} and {{Sequential Design Elements}} in {{Personalized Studies}} and {{Aggregated Personalized Studies}}},
  author = {Schork, Nicholas},
  year = {2022},
  month = sep,
  journal = {Harvard Data Science Review},
  number = {Special Issue 3},
  issn = {2644-2353, 2688-8513},
  doi = {10.1162/99608f92.f1eef6f4},
  urldate = {2024-02-14},
  abstract = {Single subject, or `N-of-1,' studies are receiving a great deal of attention from both theoretical and applied researchers. This is consistent with the growing acceptance of `personalized' approaches to health care and the need to prove that personalized interventions tailored to an individual's likely unique physiological profile and other characteristics work as they should. In fact, the preferred way of referring to N-of-1 studies in contemporary settings is as `personalized studies.' Designing efficient personalized studies and analyzing data from them in ways that ensure statistically valid inferences are not trivial, however. I briefly discuss some of the more complex issues surrounding the design and analysis of personalized studies, such as the use of washout periods, the frequency with which measures associated with the efficacy of an intervention are collected during a study, and the serious effect that serial correlation can have on the analysis and interpretation of personalized study data and results if not accounted for explicitly. I point out that more efficient sequential designs for personalized and aggregated personalized studies can be developed, and I explore the properties of sequential personalized studies in a few settings via simulation studies. Finally, I comment on contexts within which personalized studies will likely be pursued in the future.Keywords: precision medicine, serial correlation, sequential analysis, drug development},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/schork_2022_accommodating serial correlation and sequential design elements in personalized2.pdf}
}

@article{schorkAccommodatingSerialCorrelation2022a,
  title = {Accommodating {{Serial Correlation}} and {{Sequential Design Elements}} in {{Personalized Studies}} and {{Aggregated Personalized Studies}}},
  author = {Schork, Nicholas J.},
  year = {2022},
  journal = {Harvard data science review},
  volume = {2022},
  number = {SI3},
  pages = {10.1162/99608f92.f1eef6f4},
  issn = {2688-8513},
  doi = {10.1162/99608f92.f1eef6f4},
  urldate = {2024-02-14},
  abstract = {Single subject, or `N-of-1,' studies are receiving a great deal of attention from both theoretical and applied researchers. This is consistent with the growing acceptance of `personalized' approaches to health care and the need to prove that personalized interventions tailored to an individual's likely unique physiological profile and other characteristics work as they should. In fact, the preferred way of referring to N-of-1 studies in contemporary settings is as `personalized studies.' Designing efficient personalized studies and analyzing data from them in ways that ensure statistically valid inferences are not trivial, however. I briefly discuss some of the more complex issues surrounding the design and analysis of personalized studies, such as the use of washout periods, the frequency with which measures associated with the efficacy of an intervention are collected during a study, and the serious effect that serial correlation can have on the analysis and interpretation of personalized study data and results if not accounted for explicitly. I point out that more efficient sequential designs for personalized and aggregated personalized studies can be developed, and I explore the properties of sequential personalized studies in a few settings via simulation studies. Finally, I comment on contexts within which personalized studies will likely be pursued in the future., The introduction of new therapies or disease prevention interventions must come with a commitment to determine if they actually provide benefit. To achieve this, relevant studies typically focus on the effects that a therapy or intervention might have on a randomly chosen individual with certain characteristics (like a disease or frequently observed disease-risk profile). As a result, such studies often provide insight into the average or population-level effects that the therapy or intervention has, addressing questions such as: `Do many people benefit based on some predefined criteria of benefit?' `How many people exhibit side effects?' and `Does the new therapy or intervention benefit more people than another therapy or intervention?' Such studies rarely collect enough information on any one individual to unequivocally characterize the nature of that individual's response and therefore do not address questions such as: `Does the therapy affect that individual to a quantifiably greater or lesser degree than other individuals?' `Are there factors unique to that individual, for example, aspects of their diet or other medications they are on, that affect their response at any given time?' and `Does the therapy affect other aspects of the health of that individual, for example, their sleep, in deterministic ways?' Studies designed to explore individual responses to a therapy or intervention are referred to, unsurprisingly, as single subject, `N-of-1' or, preferentially, as `personalized' studies. Personalized studies can be complicated and expensive to pursue, especially if a goal is to aggregate the results of many personalized studies to, for example, determine how many people exhibit similar overall responses. In addition, personalized studies must be designed and analyzed in ways that are sensitive to the use of washout periods, serial correlation among the measurements made during the study, and other phenomena. I describe some of the challenges in the design and conduct of personalized studies and propose making them more efficient in certain contexts by analyzing the data collected during their execution sequentially; that is, making decisions about the effects of an intervention on an individual in real time, stopping the study at any point in which sufficient data have been collected to make compelling claims about the efficacy (or lack thereof) of the intervention. I use simulation studies to explore the properties of personalized studies, including sequential personalized studies. I also briefly mention a few future directions for N-of-1 studies that build off the proposed study designs and issues discussed.},
  pmcid = {PMC10081537},
  pmid = {37032736},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/schork_2022_accommodating serial correlation and sequential design elements in personalized.pdf}
}

@article{schorkRandomizedClinicalTrials2018,
  title = {Randomized Clinical Trials and Personalized Medicine: {{A}} Commentary on Deaton and Cartwright},
  shorttitle = {Randomized Clinical Trials and Personalized Medicine},
  author = {Schork, Nicholas J.},
  year = {2018},
  month = aug,
  journal = {Social Science \& Medicine},
  volume = {210},
  pages = {71--73},
  issn = {02779536},
  doi = {10.1016/j.socscimed.2018.04.033},
  urldate = {2023-08-11},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/HSQFRJ5R/Schork - 2018 - Randomized clinical trials and personalized medici.pdf}
}

@article{schorkRandomizedClinicalTrials2018a,
  title = {Randomized Clinical Trials and Personalized Medicine: {{A}} Commentary on Deaton and Cartwright},
  shorttitle = {Randomized Clinical Trials and Personalized Medicine},
  author = {Schork, Nicholas J.},
  year = {2018},
  journal = {Social science \& medicine},
  volume = {210},
  pages = {71--73},
  publisher = {Elsevier},
  file = {/Users/zenn/Zotero/storage/2MV6J8PX/S0277953618302004.html}
}

@article{schottReducedSampleSizes2010,
  title = {Reduced Sample Sizes for Atrophy Outcomes in {{Alzheimer}}'s Disease Trials: Baseline Adjustment},
  shorttitle = {Reduced Sample Sizes for Atrophy Outcomes in {{Alzheimer}}'s Disease Trials},
  author = {Schott, J. M. and Bartlett, J. W. and Barnes, J. and Leung, K. K. and Ourselin, S. and Fox, N. C.},
  year = {2010},
  month = aug,
  journal = {Neurobiology of Aging},
  series = {Alzheimer's {{Disease Neuroimaging Initiative}} ({{ADNI}}) {{Studies}}},
  volume = {31},
  number = {8},
  pages = {1452-1462.e2},
  issn = {0197-4580},
  doi = {10.1016/j.neurobiolaging.2010.04.011},
  urldate = {2022-10-20},
  abstract = {Cerebral atrophy rate is increasingly used as an outcome measure for Alzheimer's disease (AD) trials. We used the Alzheimer's disease Neuroimaging initiative (ADNI) dataset to assess if adjusting for baseline characteristics can reduce sample sizes. Controls (n = 199), patients with mild cognitive impairment (MCI) (n = 334) and AD (n = 144) had two MRI scans, 1-year apart; {$\sim$} 55\% had baseline CSF tau, p-tau, and A{$\beta$}1-42. Whole brain (KN--BSI) and hippocampal (HMAPS-HBSI) atrophy rate, and ventricular expansion (VBSI) were calculated for each group; numbers required to power a placebo-controlled trial were estimated. Sample sizes per arm (80\% power, 25\% absolute rate reduction) for AD were (95\% CI): brain atrophy = 81 (64,109), hippocampal atrophy = 88 (68,119), ventricular expansion = 118 (92,157); and for MCI: brain atrophy = 149 (122,188), hippocampal atrophy = 201 (160,262), ventricular expansion = 234 (191,295). To detect a 25\% reduction relative to normal aging required increased sample sizes {$\sim$} 3-fold (AD), and {$\sim$} 5-fold (MCI). Disease severity and A{$\beta$}1-42 contributed significantly to atrophy rate variability. Adjusting for 11 predefined covariates reduced sample sizes by up to 30\%. Treatment trials in AD should consider the effects of normal aging; adjusting for baseline characteristics can significantly reduce required sample sizes.},
  langid = {english},
  keywords = {Alzheimer's disease,Biomarker,Clinical Trials,CSF,MRI},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/schott et al_2010_reduced sample sizes for atrophy outcomes in alzheimer's disease trials.pdf;/Users/zenn/Zotero/storage/QAY7RCBM/S0197458010001764.html}
}

@inproceedings{schubert1983effect,
  title = {The Effect of Mandibular Orthopedic Repositioning Appliances on Body Strength},
  booktitle = {Journal of Dental Research},
  author = {Schubert, M and Guttu, R and Hunter, L and Hall, R and Thomas, R},
  year = {1983},
  volume = {62},
  pages = {259--259},
  publisher = {AMER ASSOC DENTAL RESEARCH 1619 DUKE ST, ALEXANDRIA, VA 22314}
}

@article{schubert1984changes,
  title = {Changes in Shoulder and Leg Strength in Athletes Wearing Mandibular Orthopedic Repositioning Appliances},
  author = {Schubert, Mark M and Guttu, Ronald L and Hunter, Letha H and Hall, Richard and Thomas, Ronald},
  year = {1984},
  journal = {The Journal of the American Dental Association},
  volume = {108},
  number = {3},
  pages = {334--337},
  publisher = {Elsevier}
}

@article{schulerChoiceFutilityBoundaries2017,
  title = {Choice of Futility Boundaries for Group Sequential Designs with Two Endpoints},
  author = {Sch{\"u}ler, Svenja and Kieser, Meinhard and Rauch, Geraldine},
  year = {2017},
  month = aug,
  journal = {BMC Medical Research Methodology},
  volume = {17},
  number = {1},
  publisher = {BioMed Central Ltd.},
  issn = {14712288},
  doi = {10.1186/S12874-017-0387-4},
  urldate = {2022-01-30},
  abstract = {Background: In clinical trials, the opportunity for an early stop during an interim analysis (either for efficacy or for futility) may relevantly save time and financial resources. This is especially important, if the planning assumptions required for power calculation are based on a low level of evidence. For example, when including two primary endpoints in the confirmatory analysis, the power of the trial depends on the effects of both endpoints and on their correlation. Assessing the feasibility of such a trial is therefore difficult, as the number of parameter assumptions to be correctly specified is large. For this reason, so-called 'group sequential designs' are of particular importance in this setting. Whereas the choice of adequate boundaries to stop a trial early for efficacy has been broadly discussed in the literature, the choice of optimal futility boundaries has not been investigated so far, although this may have serious consequences with respect to performance characteristics. Methods: In this work, we propose a general method to construct 'optimal' futility boundaries according to predefined criteria. Further, we present three different group sequential designs for two endpoints applying these futility boundaries. Our methods are illustrated by a real clinical trial example and by Monte-Carlo simulations. Results: By construction, the provided method of choosing futility boundaries maximizes the probability to correctly stop in case of small or opposite effects while limiting the power loss and the probability of stopping the study 'wrongly'. Our results clearly demonstrate the benefit of using such 'optimal' futility boundaries, especially compared to futility boundaries commonly applied in practice. Conclusions: As the properties of futility boundaries are often not considered in practice and unfavorably chosen futility boundaries may imply bad properties of the study design, we recommend assessing the performance of these boundaries according to the criteria proposed in here.},
  pmid = {28789615},
  keywords = {Group sequential design,Intersection-union test,Stopping for futility,Two endpoints},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/schüler et al_2017_choice of futility boundaries for group sequential designs with two endpoints.pdf}
}

@article{schulerIncreasingEfficiencyRandomized2022,
  title = {Increasing the Efficiency of Randomized Trial Estimates via Linear Adjustment for a Prognostic Score},
  author = {Schuler, Alejandro and Walsh, David and Hall, Diana and Walsh, Jon and Fisher, Charles},
  year = {2022},
  journal = {The international journal of biostatistics},
  volume = {18},
  number = {2},
  pages = {329--356},
  publisher = {De Gruyter},
  address = {Germany},
  issn = {1557-4679},
  doi = {10.1515/ijb-2021-0072},
  abstract = {Estimating causal effects from randomized experiments is central to clinical research. Reducing the statistical uncertainty in these analyses is an important objective for statisticians. Registries, prior trials, and health records constitute a growing compendium of historical data on patients under standard-of-care that may be exploitable to this end. However, most methods for historical borrowing achieve reductions in variance by sacrificing strict type-I error rate control. Here, we propose a use of historical data that exploits linear covariate adjustment to improve the efficiency of trial analyses without incurring bias. Specifically, we train a prognostic model on the historical data, then estimate the treatment effect using a linear regression while adjusting for the trial subjects' predicted outcomes (their ). We prove that, under certain conditions, this prognostic covariate adjustment procedure attains the minimum variance possible among a large class of estimators. When those conditions are not met, prognostic covariate adjustment is still more efficient than raw covariate adjustment and the gain in efficiency is proportional to a measure of the predictive accuracy of the prognostic model above and beyond the linear relationship with the raw covariates. We demonstrate the approach using simulations and a reanalysis of an Alzheimer's disease clinical trial and observe meaningful reductions in mean-squared error and the estimated variance. Lastly, we provide a simplified formula for asymptotic variance that enables power calculations that account for these gains. Sample size reductions between 10\% and 30\% are attainable when using prognostic models that explain a clinically realistic percentage of the outcome variance.},
  langid = {english},
  keywords = {Alzheimers disease,Bias,Clinical trials,Computer Simulation,Critical path,Efficiency,historical controls,Humans,Linear Models,Machine learning,Medical imaging,Neuroimaging,Patients,Prognosis,prognostic score,randomized trial,Sample Size,sample size estimation},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/schuler et al_2022_increasing the efficiency of randomized trial estimates via linear adjustment.pdf}
}

@article{schulerIncreasingEfficiencyRandomized2022a,
  title = {Increasing the Efficiency of Randomized Trial Estimates via Linear Adjustment for a Prognostic Score},
  author = {Schuler, Alejandro and Walsh, David and Hall, Diana and Walsh, Jon and Fisher, Charles},
  year = {2022},
  month = dec,
  journal = {The International Journal of Biostatistics},
  volume = {18},
  number = {2},
  pages = {329--356},
  issn = {1557-4679},
  doi = {10.1515/ijb-2021-0072},
  urldate = {2023-12-19},
  abstract = {Estimating causal effects from randomized experiments is central to clinical research. Reducing the statistical uncertainty in these analyses is an important objective for statisticians. Registries, prior trials, and health records constitute a growing compendium of historical data on patients under standard-of-care that may be exploitable to this end. However, most methods for historical borrowing achieve reductions in variance by sacrificing strict type-I error rate control. Here, we propose a use of historical data that exploits linear covariate adjustment to improve the efficiency of trial analyses without incurring bias. Specifically, we train a prognostic model on the historical data, then estimate the treatment effect using a linear regression while adjusting for the trial subjects' predicted outcomes (their prognostic scores). We prove that, under certain conditions, this prognostic covariate adjustment procedure attains the minimum variance possible among a large class of estimators. When those conditions are not met, prognostic covariate adjustment is still more efficient than raw covariate adjustment and the gain in efficiency is proportional to a measure of the predictive accuracy of the prognostic model above and beyond the linear relationship with the raw covariates. We demonstrate the approach using simulations and a reanalysis of an Alzheimer's disease clinical trial and observe meaningful reductions in mean-squared error and the estimated variance. Lastly, we provide a simplified formula for asymptotic variance that enables power calculations that account for these gains. Sample size reductions between 10\% and 30\% are attainable when using prognostic models that explain a clinically realistic percentage of the outcome variance.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/J6GYQ5TQ/Schuler et al. - 2022 - Increasing the efficiency of randomized trial esti.pdf}
}

@misc{schulerMixedModelsRepeated2021,
  title = {Mixed Models for Repeated Measures Should Include Time-by-Covariate Interactions to Assure Power Gains and Robustness against Dropout Bias Relative to Complete-Case {{ANCOVA}}},
  author = {Schuler, Alejandro},
  year = {2021},
  month = sep,
  number = {arXiv:2108.06621},
  eprint = {2108.06621},
  primaryclass = {stat},
  publisher = {arXiv},
  urldate = {2023-08-03},
  abstract = {In randomized trials with continuous-valued outcomes the goal is often to estimate the difference in average outcomes between two treatment groups. However, the outcome in some trials is longitudinal, meaning that multiple measurements of the same outcome are taken over time for each subject. The target of inference in this case is often still the difference in averages at a given timepoint. One way to analyze these data is to ignore the measurements at intermediate timepoints and proceed with a standard covariate-adjusted analysis (e.g. ANCOVA) with the complete cases. However, it is generally thought that exploiting information from intermediate timepoints using mixed models for repeated measures (MMRM) a) increases power and b) more naturally ``handles'' missing data. Here we prove that neither of these conclusions is entirely correct when baseline covariates are adjusted for without including timeby-covariate interactions. We back these claims up with simulations. MMRM provides benefits over complete-cases ANCOVA in many cases, but covariate-time interaction terms should always be included to guarantee the best results.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Statistics - Methodology},
  file = {/Users/zenn/Zotero/storage/I7ISJU93/Schuler - 2021 - Mixed models for repeated measures should include .pdf}
}

@misc{schulerMixedModelsRepeated2021a,
  title = {Mixed Models for Repeated Measures Should Include Time-by-Covariate Interactions to Assure Power Gains and Robustness against Dropout Bias Relative to Complete-Case {{ANCOVA}}},
  author = {Schuler, Alejandro},
  year = {2021},
  month = sep,
  number = {arXiv:2108.06621},
  eprint = {2108.06621},
  primaryclass = {stat},
  publisher = {arXiv},
  urldate = {2023-08-04},
  abstract = {In randomized trials with continuous-valued outcomes the goal is often to estimate the difference in average outcomes between two treatment groups. However, the outcome in some trials is longitudinal, meaning that multiple measurements of the same outcome are taken over time for each subject. The target of inference in this case is often still the difference in averages at a given timepoint. One way to analyze these data is to ignore the measurements at intermediate timepoints and proceed with a standard covariate-adjusted analysis (e.g. ANCOVA) with the complete cases. However, it is generally thought that exploiting information from intermediate timepoints using mixed models for repeated measures (MMRM) a) increases power and b) more naturally ``handles'' missing data. Here we prove that neither of these conclusions is entirely correct when baseline covariates are adjusted for without including timeby-covariate interactions. We back these claims up with simulations. MMRM provides benefits over complete-cases ANCOVA in many cases, but covariate-time interaction terms should always be included to guarantee the best results.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Statistics - Methodology},
  file = {/Users/zenn/Zotero/storage/82DBSVFW/Schuler - 2021 - Mixed models for repeated measures should include .pdf}
}

@article{schwartzEstimationProbabilityDensity1967,
  title = {Estimation of {{Probability Density}} by an {{Orthogonal Series}}},
  author = {Schwartz, Stuart C.},
  year = {1967},
  journal = {The Annals of Mathematical Statistics},
  volume = {38},
  number = {4},
  eprint = {2238845},
  eprinttype = {jstor},
  pages = {1261--1265},
  publisher = {Institute of Mathematical Statistics},
  issn = {0003-4851},
  urldate = {2023-03-01},
  abstract = {Let X1 {$\cdots$} Xn represent a sequence of independent random variables with a common (unknown) density function f(x). In this paper, an estimate of f(x) of the form {\^f}n(x) = {$\sum$}q(n) j = 0 {\^a}jn{$\varphi$}j (x) is considered, where \${\textbackslash}hat\{a\}\_\{jn\} = (1/n) {\textbackslash}sum{\textasciicircum}n\_\{i = 1{\textbackslash}varphi\_j\}(X\_i), {\textbackslash}varphi\_j()\$ is the jth Hermite function and q(n) is an integer dependent on n. Assuming f(x) is L2, it is shown that the sequence of estimates is consistent in the sense of mean integrated square error, \${\textbackslash}lim\_\{n {\textbackslash}rightarrow {\textbackslash}infty\} E {\textbackslash}cdot {\textbackslash}int (f(x) - {\textbackslash}hat f\_n(x)){\textasciicircum}2 dx = 0\$ and, under additional conditions on f(x), the sequence of estimates is also consistent in mean square error, \${\textbackslash}lim\_\{n {\textbackslash}rightarrow {\textbackslash}infty\} E(f(x) - {\textbackslash}hat\{f\}\_n(x)){\textasciicircum}2 = 0\$, uniformly in x. For both error criteria, bounds on the rate of convergence of the estimate are obtained. The rate of convergence is seen to depend on the smoothness and integrability properties of f(x)--the maximum rate being bounded by 1/n. In order for the series method to achieve the same rate of convergence as an estimate which uses the "kernel" technique [4], [6], more assumptions on f(x) are required. However, in estimating a multivariate density, with the same type of conditions as in the univariate case, the rate of convergence remains the same for the multivariate series estimate. With the "kernel" method, the rate depends on the dimension of the density being estimated; the rate of convergence of the estimate decreases as the dimension increases. In the next section, we introduce notation and give some preliminary results. Conditions for consistency and rates of convergence are established in Section 3. These results are then compared in Section 4 to previous work in the area.},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/schwartz_1967_estimation of probability density by an orthogonal series.pdf}
}

@article{schweyerCurrentTherapyStudies2018,
  title = {{[Current therapy studies in atypical Parkinson syndromes]}},
  author = {Schweyer, Kerstin and Levin, Johannes and H{\"o}glinger, G{\"u}nter U.},
  year = {2018},
  month = sep,
  journal = {Fortschritte Der Neurologie-Psychiatrie},
  volume = {86},
  number = {S 01},
  pages = {S21-S29},
  issn = {1439-3522},
  doi = {10.1055/a-0586-3440},
  abstract = {Atypical Parkinson syndromes are a heterogeneous group of neurodegenerative diseases which present with parkinsonism and other non-motor symptoms. On the basis of the underlying pathology, namely the abnormal aggregation of the proteins alpha-synuclein or tau, atypical Parkinson syndromes can be divided into synucleinopathies (multiple system atrophy, Lewy body dementia) and tauopathies (progressive supranuclear palsy, corticobasal degeneration). Currently there are no effective treatments to slow down disease progression available. Medications which help to manage the symptoms show only temporary and insufficient efficacy. In recent years, preclinical research identified essential steps in the pathogenesis of the diseases. Treatments which inhibit pathological protein aggregation and its spreading were developed and showed promising results in animal models. First clinical trials of causal treatments targeting the underlying pathomechanism have been finished; several trials are recruiting patients or being planned at the moment. In the following article we present the latest developments regarding the causal therapy of atypical Parkinson syndromes and the current clinical trials.},
  langid = {german},
  pmid = {29996158},
  keywords = {Animals,Antiparkinson Agents,Clinical Trials as Topic,Disease Progression,Humans,Parkinsonian Disorders}
}

@misc{ScienceDirectComScience,
  title = {{{ScienceDirect}}.Com {\textbar} {{Science}}, Health and Medical Journals, Full Text Articles and Books.},
  urldate = {2023-12-23},
  howpublished = {https://www.sciencedirect.com/science/article/pii/S0895435607000613/pdf?crasolve=1\&r=83a3428e890952d1\&ts=1703362352422\&rtype=https\&vrr=UKN\&redir=UKN\&redir\_fr=UKN\&redir\_arc=UKN\&vhash=UKN\&host=d3d3LnNjaWVuY2VkaXJlY3QuY29t\&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t\&rh=d3d3LnNjaWVuY2VkaXJlY3QuY29t\&re=X2JsYW5rXw\%3D\%3D\&ns\_h=d3d3LnNjaWVuY2VkaXJlY3QuY29t\&ns\_e=X2JsYW5rXw\%3D\%3D\&rh\_fd=rrr)n\%5Ed\%60i\%5E\%60\_dm\%60\%5Eo)\%5Ejh\&tsoh\_fd=rrr)n\%5Ed\%60i\%5E\%60\_dm\%60\%5Eo)\%5Ejh\&iv=7c144a8986237e5ba489173be264c110\&token=62626262343835313436653061616362353833366561636536383264343862663338386432623034363035383537613264613735323863306437653964653535396665343331303162383436616461643538663463373532633135353a636535616337316137366262633433343838363834373865\&text=bfcba7b38b4ca2e5429e03e156687b745c22b3f9f126a45939e3022c8e85855a599007b67b59ae1a4dbf18cbc700adf649b54f3d1c36a8498886fcacb671ae89c729a19279386c938089e1f276e3ba2b17454341dbceba31d836e56690045a84ec240086ab824d9f00cda18ddf251b64d9b674cd6947f35691d5b6f177f786d141dd9f8edbe79a703cce97b6ae05746cfd57f12d4a80530aaee9e934ee84401a74416ccad6f3b9e871255c031ad17c7fc779fb9a2d77df50e9de667623da53eccb48c4b0b8dc6ed71d691eb8c10f198ba6d7dbae8f740c7bf166f66ba5b55c44ba7a58e8bd25545a51276e61dfdfb48303e73dfc5b263aa11281887a5dd181b3faa532e174b4e0e44cf2055175608aa3b52210e61c8cbfd31007559d19a73803f4151647703b7dd6dad2f63c6f104730\&original=3f},
  file = {/Users/zenn/Zotero/storage/IHN8Z3X4/pdf.html}
}

@article{seidenfeldAncillarityContraRandomization2019,
  title = {Ancillarity Contra {{Randomization}} as a Basis for Inference},
  author = {Seidenfeld, Teddy},
  year = {2019},
  journal = {Statistics in Medicine},
  volume = {38},
  number = {1},
  pages = {23--26},
  issn = {1097-0258},
  doi = {10.1002/sim.7965},
  urldate = {2022-10-20},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/seidenfeld_2019_ancillarity contra randomization as a basis for inference.pdf;/Users/zenn/Zotero/storage/A4IJ4KPP/sim.html}
}

@article{seidner1996substance,
  title = {Substance-Dependent Inpatients Who Accept Smoking Treatment},
  author = {Seidner, Andrea L and Burling, Thomas A and Gaither, David E and Thomas, Ronald G},
  year = {1996},
  journal = {Journal of Substance Abuse},
  volume = {8},
  number = {1},
  pages = {33--44},
  publisher = {JAI}
}

@misc{SelectionNumberParticipants,
  title = {Selection of the {{Number}} of {{Participants}} in {{Intensive Longitudinal Studies}}: {{A User-Friendly Shiny App}} and {{Tutorial}} for {{Performing Power Analysis}} in {{Multilevel Regression Models That Account}} for {{Temporal Dependencies}}},
  shorttitle = {Selection of the {{Number}} of {{Participants}} in {{Intensive Longitudinal Studies}}},
  doi = {10.1177/2515245920978738},
  urldate = {2023-08-02},
  howpublished = {https://journals.sagepub.com/doi/epub/10.1177/2515245920978738},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/FD89AVUW/Selection of the Number of Participants in Intensi.pdf;/Users/zenn/Zotero/storage/8NYF2N8Y/2515245920978738.html}
}

@article{sellersTheoryComputationEvolutionary1974,
  title = {On the {{Theory}} and {{Computation}} of {{Evolutionary Distances}}},
  author = {Sellers, Peter H.},
  year = {1974},
  month = jun,
  journal = {SIAM Journal on Applied Mathematics},
  volume = {26},
  number = {4},
  pages = {787--793},
  issn = {0036-1399},
  doi = {10.1137/0126070},
  urldate = {2018-09-01},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/sellers_1974_on the theory and computation of evolutionary distances.pdf}
}

@article{sennMasteringVariationVariance2016,
  title = {Mastering Variation: Variance Components and Personalised Medicine},
  shorttitle = {Mastering Variation},
  author = {Senn, Stephen},
  year = {2016},
  month = mar,
  journal = {Statistics in Medicine},
  volume = {35},
  number = {7},
  pages = {966--977},
  issn = {0277-6715, 1097-0258},
  doi = {10.1002/sim.6739},
  urldate = {2024-02-14},
  abstract = {Abstract                            Various sources of variation in observed response in clinical trials and clinical practice are considered, and ways in which the corresponding components of variation might be estimated are discussed. Although the issues have been generally well-covered in the statistical literature, they seem to be poorly understood in the medical literature and even the statistical literature occasionally shows some confusion. To increase understanding and communication, some simple graphical approaches to illustrating issues are proposed. It is also suggested that reducing variation in medical practice might make as big a contribution to improving health outcome as personalising its delivery according to the patient. It is concluded that the common belief that there is a strong personal element in response to treatment is not based on sound statistical evidence. {\copyright} 2015 The Authors.               Statistics in Medicine               published by John Wiley \& Sons Ltd.},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/senn_2016_mastering variation.pdf}
}

@article{sennTestingBaselineBalance1994,
  title = {Testing for Baseline Balance in Clinical Trials},
  author = {Senn, Stephen},
  year = {1994},
  month = sep,
  journal = {Statistics in Medicine},
  volume = {13},
  number = {17},
  pages = {1715--1726},
  issn = {0277-6715, 1097-0258},
  doi = {10.1002/sim.4780131703},
  urldate = {2024-06-27},
  abstract = {Abstract             Once the data from a clinical trial are available for analysis it is common practice to carry out `tests of baseline homogeneity' on prognostic covariates before proceeding to analyse the effects of treatment on outcome variables. It is argued that this practice is philosophically unsound, of no practical value and potentially misleading. Instead it is recommended that prognostic variables be identified in the trial-plan and fitted in an analysis of covariance regardless of their baseline distribution (statistical significance).},
  copyright = {http://onlinelibrary.wiley.com/termsAndConditions\#vor},
  langid = {english}
}

@article{sennTestingBaselineBalance1994a,
  title = {Testing for Baseline Balance in Clinical Trials},
  author = {Senn, Stephen},
  year = {1994},
  journal = {Statistics in Medicine},
  volume = {13},
  number = {17},
  pages = {1715--1726},
  issn = {1097-0258},
  doi = {10.1002/sim.4780131703},
  urldate = {2024-06-27},
  abstract = {Once the data from a clinical trial are available for analysis it is common practice to carry out `tests of baseline homogeneity' on prognostic covariates before proceeding to analyse the effects of treatment on outcome variables. It is argued that this practice is philosophically unsound, of no practical value and potentially misleading. Instead it is recommended that prognostic variables be identified in the trial-plan and fitted in an analysis of covariance regardless of their baseline distribution (statistical significance).},
  copyright = {Copyright {\copyright} 1994 John Wiley \& Sons, Ltd.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/REJNUDMT/Senn - 1994 - Testing for baseline balance in clinical trials.pdf;/Users/zenn/Zotero/storage/CNAEVFB2/sim.html}
}

@article{senOPTIMRE1987,
  title = {{{OPT IM A L RE P E A T E D M E A S U R E M E N T S DESIGNS U N D E R INTERACTION Mausumi SEN}} and {{Rahul MUKERJEE}}},
  author = {Sen, M.},
  year = {1987},
  volume = {17},
  pages = {81--91},
  keywords = {1,and phrases,circular model,each experimental unit is,exposed to,in repeated measurements designs,interaction,introduction and preliminaries,non-circular model,rmd,s,strongly balanced,uniform design,universal optimality},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/sen_1987_opt im a l re p e a t e d m e a s u r e m e n t s designs u n d e r interaction.pdf}
}

@inproceedings{seubert1997apoe,
  title = {{{ApoE}} Genotype Influences the {{CSF}} Level of {{A}} {{ beta}} 42 in {{Alzheimer}}'s Disease},
  booktitle = {Neurology},
  author = {Seubert, {\relax PA} and Motter, {\relax RN} and Schenk, {\relax DB} and Lieberburg, {\relax IM} and Kholodenko, D and Galasko, D and Thomas, R and Chang, L and Miller, B and Clark, C and others},
  year = {1997},
  volume = {48},
  pages = {63006--63006},
  publisher = {LIPPINCOTT-RAVEN PUBL 227 EAST WASHINGTON SQ, PHILADELPHIA, PA 19106}
}

@article{shadyab2021recruitment,
  title = {Recruitment of a Multi-Site Randomized Controlled Trial of Aerobic Exercise for Older Adults with Amnestic Mild Cognitive Impairment: {{The EXERT}} Trial},
  author = {Shadyab, Aladdin H and LaCroix, Andrea Z and Feldman, Howard H and {van Dyck}, Christopher H and Okonkwo, Ozioma C and Tam, Steven P and Fairchild, J Kaci and {Welsh-Bohmer}, Kathleen A and Matthews, Genevieve and Bennett, Daniel and others},
  year = {2021},
  journal = {Alzheimer's \& Dementia},
  volume = {17},
  number = {11},
  pages = {1808--1817}
}

@article{Shadyab2022a,
  title = {T2 {{Protect AD}}: {{Achieving}} a Rapid Recruitment Timeline in a Multisite Clinical Trial for Individuals with Mild to Moderate {{Alzheimer}}'s Disease},
  author = {Shadyab, Aladdin H. and LaCroix, Andrea Z. and Matthews, Genevieve and Bennett, Daniel and Shadyab, Alexandre A. and Tan, Donna and Thomas, Ronald G. and Mason, Jennifer and Lopez, Alex and Askew, Brianna and Donahue, Lia and Kaplita, Stephen and Qureshi, Irfan A. and Huisa, Branko and Feldman, Howard H.},
  year = {2022},
  month = jan,
  journal = {Alzheimer's \& Dementia: Translational Research \& Clinical Interventions},
  volume = {8},
  number = {1},
  issn = {2352-8737},
  doi = {10.1002/trc2.12265}
}

@article{shadyabRecruitmentMultisiteRandomized2021,
  title = {Recruitment of a Multi-Site Randomized Controlled Trial of Aerobic Exercise for Older Adults with Amnestic Mild Cognitive Impairment: {{The EXERT}} Trial},
  author = {Shadyab, Aladdin H. and LaCroix, Andrea Z. and Feldman, Howard H. and {van Dyck}, Christopher H. and Okonkwo, Ozioma C. and Tam, Steven P. and Fairchild, J. Kaci and {Welsh-Bohmer}, Kathleen A. and Matthews, Genevieve and Bennett, Daniel and Shadyab, Alexandre A. and Schafer, Kimberly A. and Morrison, Rosemary H. and Kipperman, Sean A. and Mason, Jennifer and Tan, Donna and Thomas, Ronald G. and Cotman, Carl W. and Baker, Laura D.},
  year = {2021},
  month = nov,
  journal = {Alzheimer's \& Dementia},
  volume = {17},
  number = {11},
  pages = {1808--1817},
  publisher = {John Wiley \& Sons, Ltd},
  issn = {1552-5279},
  doi = {10.1002/ALZ.12401},
  urldate = {2021-12-06},
  abstract = {Introduction: Effective strategies to recruit older adults with mild cognitive impairment (MCI) into nonpharmacological intervention trials are lacking. Methods: Recruitment for EXERT, a multisite randomized controlled 18-month trial examining the effects of aerobic exercise on cognitive trajectory in adults with amnestic MCI, involved a diverse portfolio of strategies to enroll 296 participants. Results: Recruitment occurred September 2016 through March 2020 and was initially slow. After mass mailings of 490,323 age- and geo-targeted infographic postcards and brochures, recruitment rates increased substantially, peaking at 16 randomizations/month in early 2020. Mass mailings accounted for 52\% of randomized participants, whereas 25\% were recruited from memory clinic rosters, electronic health records, and national and local registries. Other sources included news broadcasts, public service announcements (PSA), local advertising, and community presentations. Discussion: Age- and geo-targeted mass mailing of infographic materials was the most effective approach in recruiting older adults with amnestic MCI into an 18-month exercise trial.},
  keywords = {Alzheimer's disease,clinical trial,exercise,lifestyle intervention,mild cognitive impairment,nonpharmacological,recruitment},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/shadyab et al_2021_recruitment of a multi-site randomized controlled trial of aerobic exercise for.pdf}
}

@article{shahCreationAdoptionLarge2023,
  title = {Creation and {{Adoption}} of {{Large Language Models}} in {{Medicine}}},
  author = {Shah, Nigam H. and Entwistle, David and Pfeffer, Michael A.},
  year = {2023},
  month = sep,
  journal = {JAMA},
  volume = {330},
  number = {9},
  pages = {866},
  issn = {0098-7484},
  doi = {10.1001/jama.2023.14217},
  urldate = {2023-12-07},
  abstract = {Importance               There is increased interest in and potential benefits from using large language models (LLMs) in medicine. However, by simply wondering how the LLMs and the applications powered by them will reshape medicine instead of getting actively involved, the agency in shaping how these tools can be used in medicine is lost.                                         Observations               Applications powered by LLMs are increasingly used to perform medical tasks without the underlying language model being trained on medical records and without verifying their purported benefit in performing those tasks.                                         Conclusions and Relevance               The creation and use of LLMs in medicine need to be actively shaped by provisioning relevant training data, specifying the desired benefits, and evaluating the benefits via testing in real-world deployments.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/4J2PGJAB/Shah et al. - 2023 - Creation and Adoption of Large Language Models in .pdf}
}

@article{shanComparisonPocockSimon2024,
  title = {Comparison of {{Pocock}} and {{Simon}}'s Covariate-Adaptive Randomization Procedures in Clinical Trials},
  author = {Shan, Guogen and Li, Yulin and Lu, Xinlin and Zhang, Yahui and Wu, Samuel~S.},
  year = {2024},
  month = jan,
  journal = {BMC Medical Research Methodology},
  volume = {24},
  number = {1},
  pages = {22},
  issn = {1471-2288},
  doi = {10.1186/s12874-024-02151-3},
  urldate = {2024-02-02},
  abstract = {Abstract             When multiple influential covariates need to be balanced during a clinical trial, stratified blocked randomization and covariate-adaptive randomization procedures are frequently used in trials to prevent bias and enhance the validity of data analysis results. The latter approach is increasingly used in practice for a study with multiple covariates and limited sample sizes. Among a group of these approaches, the covariate-adaptive procedures proposed by Pocock and Simon are straightforward to be utilized in practice. We aim to investigate the optimal design parameters for the patient treatment assignment probability of their developed three methods. In addition, we seek to answer the question related to the randomization performance when additional covariates are added to the existing randomization procedure. We conducted extensive simulation studies to address these practically important questions.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/6MQNKS3L/s12874-024-02151-3.html}
}

@article{shanNoteExactConditional2013,
  title = {A Note on Exact Conditional and Unconditional Tests for {{Hardy-Weinberg}} Equilibrium},
  author = {Shan, Guogen},
  year = {2013},
  journal = {Human Heredity},
  volume = {76},
  number = {1},
  pages = {10--17},
  publisher = {Karger Publishers},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/shan_2013_a note on exact conditional and unconditional tests for hardy-weinberg.pdf;/Users/zenn/Zotero/storage/85WBSJ3H/353205.html}
}

@article{shanSampleSizeCalculation2018,
  title = {Sample Size Calculation for Agreement between Two Raters with Binary Endpoints Using Exact Tests},
  author = {Shan, Guogen},
  year = {2018},
  journal = {Statistical methods in medical research},
  volume = {27},
  number = {7},
  pages = {2132--2141},
  publisher = {SAGE Publications Sage UK: London, England},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/shan_2018_sample size calculation for agreement between two raters with binary endpoints.pdf}
}

@article{shaoEfficientAlgorithmExact1997,
  title = {An Efficient Algorithm for the Exact Test on Unordered 2 x {{J}} Contingency Tables with Equal Column Sums},
  author = {Shao, Xuesi M},
  year = {1997},
  journal = {Computational Statistics},
  abstract = {An efficient algorithm for Fisher's exact test on unordered 2 x J contingency tables is proposed based on the network algorithm described by Mehta and Patel (1980, 1983). When either all or some of the column sums are equal, this method substantially reduces the computational effort needed to obtain the exact p-value. The principal computational efficiency is gained from the idea that the network size could be reduced by multiplying the probabilities of equivalent tables in which the first row entries are permutation of each other rather than creating them repeatedly and summing up their probabilities. The ranges of the nodes in the network and the ranges of the arcs emanating from each node to the nodes at the succeeding stages are redefined, so that the algorithm creates only the representatives of equivalent tables which are permutationally distinct without missing any possible table. An equation to calculate the numbers of equivalent tables is given. This method is also applicable to exact Pearson chi-squared and exact likelihood ratio tests. Some numerical examples are presented to compare the computational time of the improved algorithm with the original network algorithm. {\copyright} 1997 Elsevier Science B.V.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/CZ7SRTCY/Shao - 1997 - An efficient algorithm for the exact test on unord.pdf}
}

@inproceedings{sharmaDetectingSimpsonParadox2022,
  title = {Detecting {{Simpson}}'s {{Paradox}}: {{A Step Towards Fairness}} in~{{Machine Learning}}},
  shorttitle = {Detecting {{Simpson}}'s {{Paradox}}},
  booktitle = {New {{Trends}} in {{Database}} and {{Information Systems}}},
  author = {Sharma, Rahul and Kaushik, Minakshi and Peious, Sijo Arakkal and Bertl, Markus and Vidyarthi, Ankit and Kumar, Ashwani and Draheim, Dirk},
  editor = {Chiusano, Silvia and Cerquitelli, Tania and Wrembel, Robert and N{\o}rv{\aa}g, Kjetil and Catania, Barbara and {Vargas-Solar}, Genoveva and Zumpano, Ester},
  year = {2022},
  series = {Communications in {{Computer}} and {{Information Science}}},
  pages = {67--76},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-031-15743-1_7},
  abstract = {In the last two decades, artificial intelligence (AI) and machine learning (ML) have grown tremendously. However, understanding and assessing the impacts of causality and statistical paradoxes are still some of the critical challenges in their domains. Currently, these terms are widely discussed within the context of explainable AI (XAI) and algorithmic fairness. However, they are still not in the mainstream AI and ML application development scenarios. In this paper, first, we discuss the impact of Simpson's paradox on linear trends, i.e., on continuous values, and then we demonstrate its effects via three benchmark training datasets used in ML. Next, we provide an algorithm for detecting Simpson's paradox. The algorithm has experimented with the three datasets and appears beneficial in detecting the cases of Simpson's paradox in continuous values. In future, the algorithm can be utilized in designing a certain next-generation platform for fairness in ML.},
  isbn = {978-3-031-15743-1},
  langid = {english},
  keywords = {Artificial intelligence,Big data,Data science,Explainable AI,Machine learning,Simpson's paradox}
}

@inproceedings{sharmaDetectingSimpsonParadox2022a,
  title = {Detecting {{Simpson}}'s {{Paradox}}: {{A Step Towards Fairness}} in {{Machine Learning}}},
  shorttitle = {Detecting {{Simpson}}'s {{Paradox}}},
  booktitle = {New {{Trends}} in {{Database}} and {{Information Systems}}},
  author = {Sharma, Rahul and Kaushik, Minakshi and Peious, Sijo Arakkal and Bertl, Markus and Vidyarthi, Ankit and Kumar, Ashwani and Draheim, Dirk},
  year = {2022},
  pages = {67--76},
  publisher = {Springer, Cham},
  issn = {1865-0937},
  doi = {10.1007/978-3-031-15743-1_7},
  urldate = {2023-12-29},
  abstract = {In the last two decades, artificial intelligence (AI) and machine learning (ML) have grown tremendously. However, understanding and assessing the impacts of causality and statistical paradoxes are still some of the critical challenges in their domains. Currently,...},
  isbn = {978-3-031-15743-1},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/SWL5MSAX/Sharma et al. - 2022 - Detecting Simpson’s Paradox A Step Towards Fairne.pdf}
}

@article{sherertz1987impact,
  title = {Impact of Air Filtration on Nosocomial {{Aspergillus}} Infections: Unique Risk of Bone Marrow Transplant Recipients},
  author = {Sherertz, Robert J and Belani, Anusha and Kramer, Barnett S and Elfenbein, Gerald J and Weiner, Roy S and Sullivan, Marsha L and Thomas, Ronald G and Samsa, Gregory P},
  year = {1987},
  journal = {The American journal of medicine},
  volume = {83},
  number = {4},
  pages = {709--718},
  publisher = {Elsevier}
}

@article{sheridan1991analysis,
  title = {An Analysis of Methods of Communication in Clinical Trials},
  author = {Sheridan, Lenore and Thomas, Ronald G},
  year = {1991},
  journal = {Controlled Clinical Trials},
  volume = {12},
  number = {5},
  pages = {711},
  publisher = {Elsevier}
}

@article{shiGrayMatterAtrophy2013,
  title = {Gray Matter Atrophy in Progressive Supranuclear Palsy: Meta-Analysis of Voxel-Based Morphometry Studies},
  shorttitle = {Gray Matter Atrophy in Progressive Supranuclear Palsy},
  author = {Shi, Hai Cun and Zhong, Jian Guo and Pan, Ping Lei and Xiao, Pei Rong and Shen, Yuan and Wu, Li Juan and Li, Hua Liang and Song, Yuan Ying and He, Gui Xiang and Li, Hong Ye},
  year = {2013},
  month = jul,
  journal = {Neurological Sciences: Official Journal of the Italian Neurological Society and of the Italian Society of Clinical Neurophysiology},
  volume = {34},
  number = {7},
  pages = {1049--1055},
  issn = {1590-3478},
  doi = {10.1007/s10072-013-1406-9},
  abstract = {Voxel-based morphometry (VBM) studies have provided cumulative evidence of gray matter (GM) atrophy in patients with progressive supranuclear palsy (PSP) relative to healthy controls (HC). However, not all findings have been entirely concordant. Herein, we performed a quantitative meta-analysis study in order to consistently quantify GM anomalies in PSP. We conducted a systematic search for VBM studies of PSP patients and HC using PubMed and Embase databases from January 2000 to May 2012. Meta-analysis of these VBM studies was performed using a newly improved voxel-based meta-analytic technique, effect-size signed differential mapping. A total of 9 cross-sectional VBM studies that involved 143 PSP patients and 216 HC subjects met the inclusion criteria. Considerable regional GM volume decrease was detected in the thalamus, basal ganglia, midbrain, insular cortex, and frontal cortex. These findings remained largely unchanged following jackknife sensitivity analyses. The present meta-analysis provided evidence of PSP-specific GM atrophy. This finding might help contribute to our understanding of the neurobiological basis underlying PSP.},
  langid = {english},
  pmid = {23543378},
  keywords = {Animals,Atrophy,Brain Mapping,Cerebral Cortex,Clinical Trials as Topic,Humans,Supranuclear Palsy Progressive}
}

@article{shoeibiPreclinicalPhasePhase2018,
  title = {Preclinical, Phase {{I}}, and Phase {{II}} Investigational Clinical Trials for Treatment of Progressive Supranuclear Palsy},
  author = {Shoeibi, Ali and Olfati, Nahid and Litvan, Irene},
  year = {2018},
  month = apr,
  journal = {Expert Opinion on Investigational Drugs},
  volume = {27},
  number = {4},
  pages = {349--361},
  issn = {1744-7658},
  doi = {10.1080/13543784.2018.1460356},
  abstract = {INTRODUCTION: Our understanding of the pathological basis of progressive supranuclear palsy (PSP), as the most common atypical parkinsonian syndrome, has greatly increased in recent years and a number of disease-modifying therapies are under evaluation as a result of these advances. AREAS COVERED: In this review, we discuss disease-modifying therapeutic options which are currently under evaluation or have been evaluated in preclinical or clinical trials based on their targeted pathophysiologic process. The pathophysiologic mechanisms are broadly divided into three main categories: genetic mechanisms, abnormal post-translational modifications of tau protein, and transcellular tau spread. EXPERT OPINION: Once the best therapeutic approaches are identified, it is likely that some combination of interventions will need to be evaluated, but this will take time. It is critical to treat patients at early stages, and development of the Movement Disorder Society PSP diagnostic criteria is an important step in this direction. In addition, development of biological biomarkers such as tau PET and further refinement of tau ligands may help both diagnose early and measure disease progression. In the meantime, a comprehensive, personalized interdisciplinary approach to this disease is absolutely necessary.},
  langid = {english},
  pmid = {29602288},
  keywords = {Animals,Biomarkers,clinical trial,Clinical Trials Phase I as Topic,Clinical Trials Phase II as Topic,Disease Progression,Drug Design,Drug Evaluation Preclinical,Drugs Investigational,Humans,neurodegenerative disorder,Progressive supranuclear palsy,Protein Processing Post-Translational,Supranuclear Palsy Progressive,tau Proteins,tauopathy},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/shoeibi et al_2018_preclinical, phase i, and phase ii investigational clinical trials for2.pdf}
}

@article{shoeibiPreclinicalPhasePhase2018a,
  title = {Preclinical, Phase {{I}}, and Phase {{II}} Investigational Clinical Trials for Treatment of Progressive Supranuclear Palsy},
  author = {Shoeibi, Ali and Olfati, Nahid and Litvan, Irene},
  year = {2018},
  month = apr,
  journal = {Expert Opinion on Investigational Drugs},
  volume = {27},
  number = {4},
  pages = {349--361},
  issn = {1744-7658},
  doi = {10.1080/13543784.2018.1460356},
  abstract = {INTRODUCTION: Our understanding of the pathological basis of progressive supranuclear palsy (PSP), as the most common atypical parkinsonian syndrome, has greatly increased in recent years and a number of disease-modifying therapies are under evaluation as a result of these advances. AREAS COVERED: In this review, we discuss disease-modifying therapeutic options which are currently under evaluation or have been evaluated in preclinical or clinical trials based on their targeted pathophysiologic process. The pathophysiologic mechanisms are broadly divided into three main categories: genetic mechanisms, abnormal post-translational modifications of tau protein, and transcellular tau spread. EXPERT OPINION: Once the best therapeutic approaches are identified, it is likely that some combination of interventions will need to be evaluated, but this will take time. It is critical to treat patients at early stages, and development of the Movement Disorder Society PSP diagnostic criteria is an important step in this direction. In addition, development of biological biomarkers such as tau PET and further refinement of tau ligands may help both diagnose early and measure disease progression. In the meantime, a comprehensive, personalized interdisciplinary approach to this disease is absolutely necessary.},
  langid = {english},
  pmid = {29602288},
  keywords = {Animals,Biomarkers,clinical trial,Clinical Trials Phase I as Topic,Clinical Trials Phase II as Topic,Disease Progression,Drug Design,Drug Evaluation Preclinical,Drugs Investigational,Humans,neurodegenerative disorder,Progressive supranuclear palsy,Protein Processing Post-Translational,Supranuclear Palsy Progressive,tau Proteins,tauopathy},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/shoeibi et al_2018_preclinical, phase i, and phase ii investigational clinical trials for.pdf}
}

@article{Shong2016,
  title = {R Es e a Rc h {\textbar} r e Po r Ts 2.},
  author = {{s hong}},
  year = {2016},
  volume = {352},
  number = {6286},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/s hong_2016_r es e a rc h r e po r ts 2.pdf}
}

@article{siderowfProgressiveSupranuclearPalsy2003,
  title = {Progressive Supranuclear Palsy: {{Setting}} the Scene for Therapeutic Trials},
  shorttitle = {Progressive Supranuclear Palsy},
  author = {Siderowf, Andrew and Quinn, Niall P.},
  year = {2003},
  month = mar,
  journal = {Neurology},
  volume = {60},
  number = {6},
  pages = {892--893},
  issn = {1526-632X},
  doi = {10.1212/01.wnl.0000059563.84990.db},
  langid = {english},
  pmid = {12654948},
  keywords = {Clinical Trials as Topic,Cohort Studies,Disease Progression,Humans,Supranuclear Palsy Progressive}
}

@article{simonSparseGroupLasso2013,
  title = {A {{Sparse-Group Lasso}}},
  author = {Simon, Noah and Friedman, Jerome and Hastie, Trevor and Tibshirani, Robert},
  year = {2013},
  journal = {Journal of Computational and Graphical Statistics},
  volume = {22},
  number = {2},
  pages = {231--245},
  issn = {1537-2715},
  doi = {10.1080/10618600.2012.681250},
  abstract = {For high-dimensional supervised learning problems, often using problem-specific assumptions can lead to greater accuracy. For problems with grouped covariates, which are believed to have sparse effects both on a group and within group level, we introduce a reg-ularized model for linear regression with 1 and 2 penalties. We discuss the sparsity and other regularization properties of the optimal fit for this model, and show that it has the desired effect of group-wise and within group sparsity. We propose an algorithm to fit the model via accelerated generalized gradient descent, and extend this model and algorithm to convex loss functions. We also demonstrate the efficacy of our model and the efficiency of our algorithm on simulated data. This article has online supplementary material.},
  keywords = {Model,Nesterov,Penalize,Regression,Regularize},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/simon et al_2013_a sparse-group lasso.pdf}
}

@article{simSizePilotStudy2012,
  title = {The Size of a Pilot Study for a Clinical Trial Should Be Calculated in Relation to Considerations of Precision and Efficiency},
  author = {Sim, Julius and Lewis, Martyn},
  year = {2012},
  month = mar,
  journal = {Journal of Clinical Epidemiology},
  volume = {65},
  number = {3},
  pages = {301--308},
  issn = {08954356},
  doi = {10.1016/j.jclinepi.2011.07.011},
  urldate = {2023-08-01},
  abstract = {Objective: To investigate methods to determine the size of a pilot study to inform a power calculation for a randomized controlled trial (RCT) using an interval/ratio outcome measure. Study Design: Calculations based on confidence intervals (CIs) for the sample standard deviation (SD). Results: Based on CIs for the sample SD, methods are demonstrated whereby (1) the observed SD can be adjusted to secure the desired level of statistical power in the main study with a specified level of confidence; (2) the sample for the main study, if calculated using the observed SD, can be adjusted, again to obtain the desired level of statistical power in the main study; (3) the power of the main study can be calculated for the situation in which the SD in the pilot study proves to be an underestimate of the true SD; and (4) an ``efficient'' pilot size can be determined to minimize the combined size of the pilot and main RCT. Conclusion: Trialists should calculate the appropriate size of a pilot study, just as they should the size of the main RCT, taking into account the twin needs to demonstrate efficiency in terms of recruitment and to produce precise estimates of treatment effect. {\'O} 2012 Elsevier Inc. All rights reserved.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/5LI3P8J3/Sim and Lewis - 2012 - The size of a pilot study for a clinical trial sho.pdf}
}

@misc{SimulationMethodsEstimate,
  title = {Simulation Methods to Estimate Design Power: An Overview for Applied Research {\textbar} {{BMC Medical Research Methodology}} {\textbar} {{Full Text}}},
  urldate = {2023-07-21},
  howpublished = {https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/1471-2288-11-94},
  file = {/Users/zenn/Zotero/storage/GATTPYF2/1471-2288-11-94.html}
}

@inproceedings{singer2002adcs,
  title = {The {{ADCS}} Clinical Trial of Melatonin for the Sleep Disturbance of {{Alzheimer}}'s Disease.},
  booktitle = {American Journal of Geriatric Psychiatry},
  author = {Singer, C and Tractenberg, R and Kaye, J and Schafe, K and Gamst, A and Grundman, M and Thomas, R and Thal, L},
  year = {2002},
  volume = {10},
  pages = {65--65},
  publisher = {AMER PSYCHIATRIC PRESS, INC 1400 K ST, NW, STE 1101, WASHINGTON, DC 20005 USA}
}

@inproceedings{singer2002adcs,
  title = {The {{ADCS}} Clinical Trial of Melatonin for the Sleep Disturbance of Alzheimer's Disease: {{Case}} Report of an Unusual Sleep/Wake Cycle and Response to Melatonin.},
  booktitle = {American Journal of Geriatric Psychiatry},
  author = {Singer, C and Colling, E and Tractenberg, R and Grundman, M and Gamst, A and Thomas, R and Thal, L},
  year = {2002},
  volume = {10},
  pages = {92--92},
  publisher = {AMER PSYCHIATRIC PRESS, INC 1400 K ST, NW, STE 1101, WASHINGTON, DC 20005 USA}
}

@article{singer2003multicenter,
  title = {A Multicenter, Placebo-Controlled Trial of Melatonin for Sleep Disturbance in {{Alzheimer}}'s Disease},
  author = {Singer, Clifford and Tractenberg, Rochelle E and Kaye, Jeffrey and Schafer, Kim and Gamst, Anthony and Grundman, Michael and Thomas, Ronald and Thal, Leon J},
  year = {2003},
  journal = {Sleep},
  volume = {26},
  number = {7},
  pages = {893--901},
  publisher = {Oxford University Press}
}

@article{Smith2014,
  title = {An Interactive {{Bayesian}} Model for Prediction of Lymph Node Ratio and Survival in Pancreatic Cancer Patients.},
  author = {Smith, Brian J. and Mezhir, James J.},
  year = {2014},
  journal = {Journal of the American Medical Informatics Association : JAMIA},
  volume = {21},
  number = {e2},
  issn = {1527974X},
  doi = {10.1136/amiajnl-2013-002171},
  abstract = {Regional lymph node status has long been used as a dichotomous predictor of clinical outcomes in cancer patients. More recently, interest has turned to the prognostic utility of lymph node ratio (LNR), quantified as the proportion of positive nodes examined. However, statistical tools for the joint modeling of LNR and its effect on cancer survival are lacking. Data were obtained from the NCI SEER cancer registry on 6400 patients diagnosed with pancreatic ductal adenocarcinoma from 2004 to 2010 and who underwent radical oncologic resection. A novel Bayesian statistical approach was developed and applied to model simultaneously patients' true, but unobservable, LNR statuses and overall survival. New web development tools were then employed to create an interactive web application for individualized patient prediction. Histologic grade and T and M stages were important predictors of LNR status. Significant predictors of survival included age, gender, marital status, grade, histology, T and M stages, tumor size, and radiation therapy. LNR was found to have a highly significant, non-linear effect on survival. Furthermore, predictive performance of the survival model compared favorably to those from studies with more homogeneous patients and individualized predictors. We provide a new approach and tool set for the prediction of LNR and survival that are generally applicable to a host of cancer types, including breast, colon, melanoma, and stomach. Our methods are illustrated with the development of a validated model and web applications for the prediction of survival in a large set of pancreatic cancer patients. Published by the BMJ Publishing Group Limited. For permission to use (where not already granted under a licence) please go to http://group.bmj.com/group/rights-licensing/permissions.},
  pmid = {24444460},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/smith_mezhir_2014_an interactive bayesian model for prediction of lymph node ratio and survival.pdf}
}

@article{smithStructuralImagingEarly2012,
  title = {Structural Imaging in Early Pre-States of Dementia},
  author = {Smith, Charles D.},
  year = {2012},
  journal = {Biochimica et Biophysica Acta (BBA) - Molecular Basis of Disease},
  volume = {1822},
  number = {3},
  pages = {317--324},
  issn = {09254439},
  doi = {10.1016/j.bbadis.2011.07.002},
  urldate = {2016-10-22},
  abstract = {In this review focus is on structural imaging in the Alzheimer's disease (AD) pre-states, particularly cognitively normal (CN) persons at future dementia risk. Findings in mild cognitive impairment (MCI) are described here only for comparison with CN. Cited literature evidence and commentary address issues of structural imaging alterations in CN that precede MCI and AD, regional patterns of such alterations, and the time relationship between structural imaging alterations and the appearance of symptoms of AD, issues relevant to the conduct of future AD prevention trials. This article is part of a Special Issue entitled: Imaging Brain Aging and Neurodegenerative disease.},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/smith_2012_structural imaging in early pre-states of dementia.pdf}
}

@article{sokolowskiBoundsHalfGraph2021,
  title = {Bounds on Half Graph Orders in Powers of Sparse Graphs},
  author = {Soko{\l}owski, Marek},
  year = {2021},
  month = mar,
  journal = {arXiv:2103.06218 [cs, math]},
  eprint = {2103.06218},
  primaryclass = {cs, math},
  urldate = {2021-03-11},
  abstract = {Half graphs and their variants, such as ladders, semi-ladders and co-matchings, are combinatorial objects that encode total orders in graphs. Works by Adler and Adler (Eur. J. Comb.; 2014) and Fabia{\textbackslash}'nski et al. (STACS; 2019) prove that in the powers of sparse graphs, one cannot find arbitrarily large objects of this kind. However, these proofs either are non-constructive, or provide only loose upper bounds on the orders of half graphs and semi-ladders. In this work we provide nearly tight asymptotic lower and upper bounds on the maximum order of half graphs, parameterized on the distance, in the following classes of sparse graphs: planar graphs, graphs with bounded maximum degree, graphs with bounded pathwidth or treewidth, and graphs excluding a fixed clique as a minor. The most significant part of our work is the upper bound for planar graphs. Here, we employ techniques of structural graph theory to analyze semi-ladders in planar graphs through the notion of cages, which expose a topological structure in semi-ladders. As an essential building block of this proof, we also state and prove a new structural result, yielding a fully polynomial bound on the neighborhood complexity in the class of planar graphs.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Data Structures and Algorithms,Mathematics - Combinatorics},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/sokołowski_2021_bounds on half graph orders in powers of sparse graphs.pdf;/Users/zenn/Zotero/storage/SDMY5SHT/2103.html}
}

@article{Sørlie2001,
  title = {Gene Expression Patterns of Breast Carcinomas Distinguish Tumor Subclasses with Clinical Implications},
  author = {S{\o}rlie, Therese and Perou, Charles M. and Tibshirani, Robert and Aas, Turid and Geisler, Stephanie and Johnsen, Hilde and Hastie, Trevor and Eisen, Michael B. and Van De Rijn, Matt and Jeffrey, Stefanie S. and Thorsen, Thor and Quist, Hanne and Matese, John C. and Brown, Patrick O. and Botstein, David and L{\o}nning, Per Eystein and {B{\o}rresen-Dale}, Anne Lise},
  year = {2001},
  journal = {Proceedings of the National Academy of Sciences of the United States of America},
  volume = {98},
  number = {19},
  pages = {10869--10874},
  issn = {00278424},
  doi = {10.1073/pnas.191367098},
  abstract = {The purpose of this study was to classify breast carcinomas based on variations in gene expression patterns derived from cDNA microarrays and to correlate tumor characteristics to clinical outcome. A total of 85 cDNA microarray experiments representing 78 cancers, three fibroadenomas, and four normal breast tissues were analyzed by hierarchical clustering. As reported previously, the cancers could be classified into a basal epithelial-like group, an ERBB2-overexpressing group and a normal breast-like group based on variations in gene expression. A novel finding was that the previously characterized luminal epithelial/estrogen receptor-positive group could be divided into at least two subgroups, each with a distinctive expression profile. These subtypes proved to be reasonably robust by clustering using two different gene sets: first, a set of 456 cDNA clones previously selected to reflect intrinsic properties of the tumors and, second, a gene set that highly correlated with patient outcome. Survival analyses on a subcohort of patients with locally advanced breast cancer uniformly treated in a prospective study showed significantly different outcomes for the patients belonging to the various groups, including a poor prognosis for the basal-like subtype and a significant difference in outcome for the two estrogen receptor-positive groups.},
  pmid = {11553815},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/sørlie et al_2001_gene expression patterns of breast carcinomas distinguish tumor subclasses with.pdf}
}

@article{sperlingA4StudyStopping2014,
  title = {The {{A4 Study}}: {{Stopping AD Before Symptoms Begin}}?},
  shorttitle = {The {{A4 Study}}},
  author = {Sperling, Reisa A. and Rentz, Dorene M. and Johnson, Keith A. and Karlawish, Jason and Donohue, Michael and Salmon, David P. and Aisen, Paul},
  year = {2014},
  month = mar,
  journal = {Science Translational Medicine},
  volume = {6},
  number = {228},
  pages = {228fs13-228fs13},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/scitranslmed.3007941},
  urldate = {2022-10-20},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/sperling et al_2014_the a4 study.pdf}
}

@article{stallardSeamlessPhaseII2011,
  title = {Seamless Phase {{II}}/{{III}} Designs},
  author = {Stallard, Nigel and Todd, Susan},
  year = {2011},
  journal = {Statistical methods in medical research},
  volume = {20},
  number = {6},
  pages = {623--634},
  publisher = {Sage Publications Sage UK: London, England},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/stallard_todd_2011_seamless phase ii-iii designs.pdf;/Users/zenn/Zotero/storage/S4R7UI56/0962280210379035.html}
}

@article{stamelouAtypicalParkinsonismNew2016,
  title = {Atypical Parkinsonism - New Advances},
  author = {Stamelou, Maria and Bhatia, Kailash P.},
  year = {2016},
  month = aug,
  journal = {Current Opinion in Neurology},
  volume = {29},
  number = {4},
  pages = {480--485},
  issn = {1473-6551},
  doi = {10.1097/WCO.0000000000000355},
  abstract = {PURPOSE OF REVIEW: This update discusses novel aspects on genetics, pathophysiology and therapeutic approaches for atypical parkinsonism (progressive supranuclear palsy, corticobasal degeneration and multiple system atrophy) published in the last 2 years. RECENT FINDINGS: In terms of genetics, in progressive supranuclear palsy and corticobasal degeneration new risk loci have been identified but also their possible association to disease pathogenesis. In multiple system atrophy, there is still a debate as to whether COQ2 variants are associated with disease, at least in non-Asian population, whereas at the same time evidence of coenzyme Q10 deficiency in serum and brains of MSA patients has been reported. In terms of pathogenesis, the 'prion' hypothesis has prevailed in the last years in the literature, and the first clinical studies based on such disease mechanisms are already in phase I. Despite all these discoveries, clinical diagnosis still remains poor, and phenotypic variability is reported much higher than previously thought. A plethora of studies testing possible neuroprotective agents are currently ongoing. SUMMARY: The knowledge on all aspects of atypical parkinsonism has increased tremendously in the last 2 years, leading the field closer to the understanding of the pathophysiology of these diseases, and to the discovery of a neuroprotective treatment.},
  langid = {english},
  pmid = {27272977},
  keywords = {Clinical Trials as Topic,Humans,Multiple System Atrophy,Parkinsonian Disorders,Prion Diseases,Supranuclear Palsy Progressive,Tauopathies}
}

@article{stamelouPowerCalculationsPlacebo2016,
  title = {Power Calculations and Placebo Effect for Future Clinical Trials in Progressive Supranuclear Palsy},
  author = {Stamelou, Maria and Sch{\"o}pe, Jakob and Wagenpfeil, Stefan and Del Ser, Teodoro and Bang, Jee and Lobach, Iryna Y. and Luong, Phi and Respondek, Gesine and Oertel, Wolfgang H. and Boxer, AdamL and H{\"o}glinger, G{\"u}nter U. and {AL-108-231 Investigators, Tauros Investigators, and MDS-Endorsed PSP Study Group}},
  year = {2016},
  month = may,
  journal = {Movement Disorders: Official Journal of the Movement Disorder Society},
  volume = {31},
  number = {5},
  pages = {742--747},
  issn = {1531-8257},
  doi = {10.1002/mds.26580},
  abstract = {BACKGROUND: Two recent randomized, placebo-controlled trials of putative disease-modifying agents (davunetide, tideglusib) in progressive supranuclear palsy (PSP) failed to show efficacy, but generated data relevant for future trials. METHODS: We provide sample size calculations based on data collected in 187 PSP patients assigned to placebo in these trials. A placebo effect was calculated. RESULTS: The total PSP-Rating Scale required the least number of patients per group (N\,=\,51) to detect a 50\% change in the 1-year progression and 39 when including patients with {$\leq$} 5 years disease duration. The Schwab and England Activities of Daily Living required 70 patients per group and was highly correlated with the PSP-Rating Scale. A placebo effect was not detected in these scales. CONCLUSIONS: We propose the 1-year PSP-Rating Scale score change as the single primary readout in clinical neuroprotective or disease-modifying trials. The Schwab and England Activities of Daily Living could be used as a secondary outcome. {\copyright} 2016 International Parkinson and Movement Disorder Society.},
  langid = {english},
  pmcid = {PMC5289149},
  pmid = {26948290},
  keywords = {Activities of Daily Living,clinical trials,Humans,Oligopeptides,Outcome Assessment Health Care,placebo effect,Placebo Effect,power calculation,progressive supranuclear palsy,Randomized Controlled Trials as Topic,rate of progression,Research Design,Sample Size,Severity of Illness Index,Supranuclear Palsy Progressive,Thiadiazoles},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/stamelou et al_2016_power calculations and placebo effect for future clinical trials in progressive4.pdf}
}

@article{stamelouPowerCalculationsPlacebo2016a,
  title = {Power Calculations and Placebo Effect for Future Clinical Trials in Progressive Supranuclear Palsy},
  author = {Stamelou, Maria and Sch{\"o}pe, Jakob and Wagenpfeil, Stefan and Del Ser, Teodoro and Bang, Jee and Lobach, Iryna Y. and Luong, Phi and Respondek, Gesine and Oertel, Wolfgang H. and Boxer, AdamL and H{\"o}glinger, G{\"u}nter U. and {AL-108-231 Investigators, Tauros Investigators, and MDS-Endorsed PSP Study Group}},
  year = {2016},
  month = may,
  journal = {Movement Disorders: Official Journal of the Movement Disorder Society},
  volume = {31},
  number = {5},
  pages = {742--747},
  issn = {1531-8257},
  doi = {10.1002/mds.26580},
  abstract = {BACKGROUND: Two recent randomized, placebo-controlled trials of putative disease-modifying agents (davunetide, tideglusib) in progressive supranuclear palsy (PSP) failed to show efficacy, but generated data relevant for future trials. METHODS: We provide sample size calculations based on data collected in 187 PSP patients assigned to placebo in these trials. A placebo effect was calculated. RESULTS: The total PSP-Rating Scale required the least number of patients per group (N\,=\,51) to detect a 50\% change in the 1-year progression and 39 when including patients with {$\leq$} 5 years disease duration. The Schwab and England Activities of Daily Living required 70 patients per group and was highly correlated with the PSP-Rating Scale. A placebo effect was not detected in these scales. CONCLUSIONS: We propose the 1-year PSP-Rating Scale score change as the single primary readout in clinical neuroprotective or disease-modifying trials. The Schwab and England Activities of Daily Living could be used as a secondary outcome. {\copyright} 2016 International Parkinson and Movement Disorder Society.},
  langid = {english},
  pmcid = {PMC5289149},
  pmid = {26948290},
  keywords = {Activities of Daily Living,clinical trials,Humans,Oligopeptides,Outcome Assessment Health Care,placebo effect,Placebo Effect,power calculation,progressive supranuclear palsy,Randomized Controlled Trials as Topic,rate of progression,Research Design,Sample Size,Severity of Illness Index,Supranuclear Palsy Progressive,Thiadiazoles},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/stamelou et al_2016_power calculations and placebo effect for future clinical trials in progressive3.pdf}
}

@article{stamelouPowerCalculationsPlacebo2016b,
  title = {Power Calculations and Placebo Effect for Future Clinical Trials in Progressive Supranuclear Palsy},
  author = {Stamelou, Maria and Sch{\"o}pe, Jakob and Wagenpfeil, Stefan and Del Ser, Teodoro and Bang, Jee and Lobach, Iryna Y. and Luong, Phi and Respondek, Gesine and Oertel, Wolfgang H. and Boxer, AdamL and H{\"o}glinger, G{\"u}nter U. and {AL-108-231 Investigators, Tauros Investigators, and MDS-Endorsed PSP Study Group}},
  year = {2016},
  month = may,
  journal = {Movement Disorders: Official Journal of the Movement Disorder Society},
  volume = {31},
  number = {5},
  pages = {742--747},
  issn = {1531-8257},
  doi = {10.1002/mds.26580},
  abstract = {BACKGROUND: Two recent randomized, placebo-controlled trials of putative disease-modifying agents (davunetide, tideglusib) in progressive supranuclear palsy (PSP) failed to show efficacy, but generated data relevant for future trials. METHODS: We provide sample size calculations based on data collected in 187 PSP patients assigned to placebo in these trials. A placebo effect was calculated. RESULTS: The total PSP-Rating Scale required the least number of patients per group (N\,=\,51) to detect a 50\% change in the 1-year progression and 39 when including patients with {$\leq$} 5 years disease duration. The Schwab and England Activities of Daily Living required 70 patients per group and was highly correlated with the PSP-Rating Scale. A placebo effect was not detected in these scales. CONCLUSIONS: We propose the 1-year PSP-Rating Scale score change as the single primary readout in clinical neuroprotective or disease-modifying trials. The Schwab and England Activities of Daily Living could be used as a secondary outcome. {\copyright} 2016 International Parkinson and Movement Disorder Society.},
  langid = {english},
  pmcid = {PMC5289149},
  pmid = {26948290},
  keywords = {Activities of Daily Living,clinical trials,Humans,Oligopeptides,Outcome Assessment Health Care,placebo effect,Placebo Effect,power calculation,progressive supranuclear palsy,Randomized Controlled Trials as Topic,rate of progression,Research Design,Sample Size,Severity of Illness Index,Supranuclear Palsy Progressive,Thiadiazoles},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/stamelou et al_2016_power calculations and placebo effect for future clinical trials in progressive2.pdf}
}

@article{stamelouPowerCalculationsPlacebo2016c,
  title = {Power Calculations and Placebo Effect for Future Clinical Trials in Progressive Supranuclear Palsy},
  author = {Stamelou, Maria and Sch{\"o}pe, Jakob and Wagenpfeil, Stefan and Del Ser, Teodoro and Bang, Jee and Lobach, Iryna Y. and Luong, Phi and Respondek, Gesine and Oertel, Wolfgang H. and Boxer, AdamL and H{\"o}glinger, G{\"u}nter U. and {AL-108-231 Investigators, Tauros Investigators, and MDS-Endorsed PSP Study Group}},
  year = {2016},
  month = may,
  journal = {Movement Disorders: Official Journal of the Movement Disorder Society},
  volume = {31},
  number = {5},
  pages = {742--747},
  issn = {1531-8257},
  doi = {10.1002/mds.26580},
  abstract = {BACKGROUND: Two recent randomized, placebo-controlled trials of putative disease-modifying agents (davunetide, tideglusib) in progressive supranuclear palsy (PSP) failed to show efficacy, but generated data relevant for future trials. METHODS: We provide sample size calculations based on data collected in 187 PSP patients assigned to placebo in these trials. A placebo effect was calculated. RESULTS: The total PSP-Rating Scale required the least number of patients per group (N\,=\,51) to detect a 50\% change in the 1-year progression and 39 when including patients with {$\leq$} 5 years disease duration. The Schwab and England Activities of Daily Living required 70 patients per group and was highly correlated with the PSP-Rating Scale. A placebo effect was not detected in these scales. CONCLUSIONS: We propose the 1-year PSP-Rating Scale score change as the single primary readout in clinical neuroprotective or disease-modifying trials. The Schwab and England Activities of Daily Living could be used as a secondary outcome. {\copyright} 2016 International Parkinson and Movement Disorder Society.},
  langid = {english},
  pmcid = {PMC5289149},
  pmid = {26948290},
  keywords = {Activities of Daily Living,clinical trials,Humans,Oligopeptides,Outcome Assessment Health Care,placebo effect,Placebo Effect,power calculation,progressive supranuclear palsy,Randomized Controlled Trials as Topic,rate of progression,Research Design,Sample Size,Severity of Illness Index,Supranuclear Palsy Progressive,Thiadiazoles},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/stamelou et al_2016_power calculations and placebo effect for future clinical trials in progressive.pdf}
}

@misc{StatisticalAspectsAnalysis,
  title = {Statistical {{Aspects}} of the {{Analysis}} of {{Data From Retrospective Studies}} of {{Disease}} {\textbar} {{JNCI}}: {{Journal}} of the {{National Cancer Institute}} {\textbar} {{Oxford Academic}}},
  urldate = {2023-08-18},
  howpublished = {https://academic.oup.com/jnci/article/22/4/719/900746?login=true}
}

@article{stekhovenMissForestNonparametricMissing2012,
  title = {{{MissForest}}---Non-Parametric Missing Value Imputation for Mixed-Type Data},
  author = {Stekhoven, Daniel J. and B{\"u}hlmann, Peter},
  year = {2012},
  month = jan,
  journal = {Bioinformatics},
  volume = {28},
  number = {1},
  pages = {112--118},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/btr597},
  urldate = {2023-04-15},
  abstract = {Motivation: Modern data acquisition based on high-throughput technology is often facing the problem of missing data. Algorithms commonly used in the analysis of such large-scale data often depend on a complete set. Missing value imputation offers a solution to this problem. However, the majority of available imputation methods are restricted to one type of variable only: continuous or categorical. For mixed-type data, the different types are usually handled separately. Therefore, these methods ignore possible relations between variable types. We propose a non-parametric method which can cope with different types of variables simultaneously.Results: We compare several state of the art methods for the imputation of missing values. We propose and evaluate an iterative imputation method (missForest) based on a random forest. By averaging over many unpruned classification or regression trees, random forest intrinsically constitutes a multiple imputation scheme. Using the built-in out-of-bag error estimates of random forest, we are able to estimate the imputation error without the need of a test set. Evaluation is performed on multiple datasets coming from a diverse selection of biological fields with artificially introduced missing values ranging from 10\% to 30\%. We show that missForest can successfully handle missing values, particularly in datasets including different types of variables. In our comparative study, missForest outperforms other methods of imputation especially in data settings where complex interactions and non-linear relations are suspected. The out-of-bag imputation error estimates of missForest prove to be adequate in all settings. Additionally, missForest exhibits attractive computational efficiency and can cope with high-dimensional data.Availability: The {$\mathbb{R}$} package missForest is freely available from http://stat.ethz.ch/CRAN/.Contact:stekhoven@stat.math.ethz.ch; buhlmann@stat.math.ethz.ch},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/stekhoven_bühlmann_2012_missforest—non-parametric missing value imputation for mixed-type data.pdf;/Users/zenn/Zotero/storage/YY33B5U3/219101.html}
}

@article{stephensonBeginningWasCommand,
  title = {In the {{Beginning}} Was the {{Command Line}}},
  author = {Stephenson, Neal},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/REF7DVGS/command1.pdf}
}

@article{stoffelPartR2PartitioningGeneralized2021,
  title = {{{partR2}} : Partitioning {{R}} {\textsuperscript{2}} in Generalized Linear Mixed Models},
  shorttitle = {{{partR2}}},
  author = {Stoffel, Martin A. and Nakagawa, Shinichi and Schielzeth, Holger},
  year = {2021},
  month = may,
  journal = {PeerJ},
  volume = {9},
  pages = {e11414},
  issn = {2167-8359},
  doi = {10.7717/peerj.11414},
  urldate = {2022-10-31},
  abstract = {The coefficient of determination R2 quantifies the amount of variance explained by regression coefficients in a linear model. It can be seen as the fixed-effects complement to the repeatability R (intra-class correlation) for the variance explained by random effects and thus as a tool for variance decomposition. The R2 of a model can be further partitioned into the variance explained by a particular predictor or a combination of predictors using semi-partial (part) R2 and structure coefficients, but this is rarely done due to a lack of software implementing these statistics. Here, we introduce partR2, an R package that quantifies part R2 for fixed effect predictors based on (generalized) linear mixed-effect model fits. The package iteratively removes predictors of interest from the model and monitors the change in the variance of the linear predictor. The difference to the full model gives a measure of the amount of variance explained uniquely by a particular predictor or a set of predictors. partR2 also estimates structure coefficients as the correlation between a predictor and fitted values, which provide an estimate of the total contribution of a fixed effect to the overall prediction, independent of other predictors. Structure coefficients can be converted to the total variance explained by a predictor, here called `inclusive' R2, as the square of the structure coefficients times total R2. Furthermore, the package reports beta weights (standardized regression coefficients). Finally, partR2 implements parametric bootstrapping to quantify confidence intervals for each estimate. We illustrate the use of partR2 with real example datasets for Gaussian and binomial GLMMs and discuss interactions, which pose a specific challenge for partitioning the explained variance among predictors.},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/stoffel et al_2021_partr2.pdf}
}

@article{storerDesignAnalysisPhase1989,
  title = {Design and {{Analysis}} of {{Phase I Clinical Trials}}},
  author = {Storer, Barry E.},
  year = {1989},
  journal = {Biometrics},
  volume = {45},
  number = {3},
  eprint = {2531693},
  eprinttype = {jstor},
  pages = {925--937},
  publisher = {[Wiley, International Biometric Society]},
  issn = {0006-341X},
  doi = {10.2307/2531693},
  urldate = {2024-03-19},
  abstract = {The Phase I clinical trial is a study intended to estimate the so-called maximum tolerable dose (MTD) of a new drug. Although there exists more or less a standard type of design for such trials, its development has been largely ad hoc. As usually implemented, the trial design has no intrinsic property that provides a generally satisfactory basis for estimation of the MTD. In this paper, the standard design and several simple alternatives are compared with regard to the conservativeness of the design and with regard to point and interval estimation of an MTD (33rd percentile) with small sample sizes. Using a Markov chain representation, we found several designs to be nearly as conservative as the standard design in terms of the proportion of patients entered at higher dose levels. In Monte Carlo simulations, two two-stage designs are found to provide reduced bias in maximum likelihood estimation of the MTD in less than ideal dose-response settings. Of the three methods considered for determining confidence intervals-the delta method, a method based on Fieller's theorem, and a likelihood ratio method-none was able to provide both usefully narrow intervals and coverage probabilities close to nominal.},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/storer_1989_design and analysis of phase i clinical trials.pdf}
}

@article{streetProgressionAtypicalParkinsonian2023,
  title = {Progression of Atypical Parkinsonian Syndromes: {{PROSPECT-M-UK}} Study Implications for Clinical Trials},
  shorttitle = {Progression of Atypical Parkinsonian Syndromes},
  author = {Street, Duncan and Jabbari, Edwin and Costantini, Alyssa and Jones, P. Simon and Holland, Negin and Rittman, Timothy and Jensen, Marte T. and Chelban, Viorica and Goh, Yen Y. and Guo, Tong},
  year = {2023},
  journal = {Brain},
  volume = {146},
  number = {8},
  pages = {3232--3242},
  publisher = {Oxford University Press US},
  urldate = {2024-06-05},
  file = {/Users/zenn/Zotero/storage/D768HGMT/Street et al. - 2023 - Progression of atypical parkinsonian syndromes PR.pdf}
}

@article{streetProgressionAtypicalParkinsonian2023a,
  title = {Progression of Atypical Parkinsonian Syndromes: {{PROSPECT-M-UK}} Study Implications for Clinical Trials},
  shorttitle = {Progression of Atypical Parkinsonian Syndromes},
  author = {Street, Duncan and Jabbari, Edwin and Costantini, Alyssa and Jones, P Simon and Holland, Negin and Rittman, Timothy and Jensen, Marte T and Chelban, Viorica and Goh, Yen Y and Guo, Tong and Heslegrave, Amanda J and Roncaroli, Federico and Klein, Johannes C and Ansorge, Olaf and Allinson, Kieren S J and Jaunmuktane, Zane and Revesz, Tamas and Warner, Thomas T and Lees, Andrew J and Zetterberg, Henrik and Russell, Lucy L and Bocchetta, Martina and Rohrer, Jonathan D and Burn, David J and Pavese, Nicola and Gerhard, Alexander and Kobylecki, Christopher and Leigh, P Nigel and Church, Alistair and Hu, Michele T M and Houlden, Henry and Morris, Huw and Rowe, James B},
  year = {2023},
  month = aug,
  journal = {Brain},
  volume = {146},
  number = {8},
  pages = {3232--3242},
  issn = {0006-8950},
  doi = {10.1093/brain/awad105},
  urldate = {2024-06-05},
  abstract = {The advent of clinical trials of disease-modifying agents for neurodegenerative disease highlights the need for evidence-based end point selection. Here we report the longitudinal PROSPECT-M-UK study of progressive supranuclear palsy (PSP), corticobasal syndrome (CBS), multiple system atrophy (MSA) and related disorders, to compare candidate clinical trial end points.In this multicentre UK study, participants were assessed with serial questionnaires, motor examination, neuropsychiatric and MRI assessments at baseline, 6 and 12 months. Participants were classified by diagnosis at baseline and study end, into Richardson syndrome, PSP-subcortical (PSP-parkinsonism and progressive gait freezing subtypes), PSP-cortical (PSP-frontal, PSP-speech and language and PSP-CBS subtypes), MSA-parkinsonism, MSA-cerebellar, CBS with and without evidence of Alzheimer's disease pathology and indeterminate syndromes. We calculated annual rate of change, with linear mixed modelling and sample sizes for clinical trials of disease-modifying agents, according to group and assessment type.Two hundred forty-three people were recruited [117 PSP, 68 CBS, 42 MSA and 16 indeterminate; 138 (56.8\%) male; age at recruitment 68.7 {\textpm} 8.61 years]. One hundred and fifty-nine completed the 6-month assessment (82 PSP, 27 CBS, 40 MSA and 10 indeterminate) and 153 completed the 12-month assessment (80 PSP, 29 CBS, 35 MSA and nine indeterminate). Questionnaire, motor examination, neuropsychiatric and neuroimaging measures declined in all groups, with differences in longitudinal change between groups. Neuroimaging metrics would enable lower sample sizes to achieve equivalent power for clinical trials than cognitive and functional measures, often achieving N \&lt; 100 required for 1-year two-arm trials (with 80\% power to detect 50\% slowing). However, optimal outcome measures were disease-specific.In conclusion, phenotypic variance within PSP, CBS and MSA is a major challenge to clinical trial design. Our findings provide an evidence base for selection of clinical trial end points, from potential functional, cognitive, clinical or neuroimaging measures of disease progression.},
  file = {/Users/zenn/Zotero/storage/VDKWFA7B/Street et al. - 2023 - Progression of atypical parkinsonian syndromes PR.pdf;/Users/zenn/Zotero/storage/KW455XJ7/7091433.html}
}

@article{strobelAtableCreateTables2019,
  title = {Atable: {{Create Tables}} for {{Clinical Trial Reports}}},
  shorttitle = {Atable},
  author = {Str{\"o}bel, Armin},
  year = {2019},
  journal = {The R Journal},
  volume = {11},
  number = {1},
  pages = {137},
  issn = {2073-4859},
  doi = {10.32614/RJ-2019-001},
  urldate = {2024-05-08},
  abstract = {Examining distributions of variables is the first step in the analysis of a clinical trial before more specific modelling can begin. Reporting these results to stakeholders of the trial is an essential part of a statistician's work. The atable package facilitates these steps by offering easy-to-use but still flexible functions.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/HT9354EA/RJ-2019-001-1.pdf}
}

@article{strobelAtableCreateTables2019a,
  title = {Atable: {{Create Tables}} for {{Clinical Trial Reports}}},
  shorttitle = {Atable},
  author = {Str{\"o}bel, Armin},
  year = {2019},
  journal = {The R Journal},
  volume = {11},
  number = {1},
  pages = {137--148},
  issn = {2073-4859},
  urldate = {2024-05-08},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/2RDKPYUC/index.html}
}

@article{strobelAtableCreateTables2019b,
  title = {Atable: Create Tables for Clinical Trial Reports},
  shorttitle = {Atable},
  author = {Str{\"o}bel, Armin},
  year = {2019},
  journal = {age},
  volume = {149},
  pages = {153},
  urldate = {2024-05-08}
}

@article{sturdevantStatisticalMethodsTesting2021,
  title = {Statistical Methods for Testing Carryover Effects: {{A}} Mixed Effects Model Approach},
  shorttitle = {Statistical Methods for Testing Carryover Effects},
  author = {Sturdevant, S. Gwynn and Lumley, Thomas},
  year = {2021},
  month = jun,
  journal = {Contemporary Clinical Trials Communications},
  volume = {22},
  pages = {100711},
  issn = {2451-8654},
  doi = {10.1016/j.conctc.2021.100711},
  urldate = {2023-12-13},
  abstract = {Carryover, or the effects of treatment after it ceases, has been largely ignored in statistical literature except as a nuisance parameter. When testing for carryover, comparing cumulative incidence rates is biased when diagnosis is based on a noisy measurement crossing a threshold (such as in blood pressure) then followed by open-label treatment. This issue was raised in the context of preventing hypertension by the TROPHY trial. We show that modelling the noisy measurement itself using linear mixed effect models, then computing the expected proportion over the threshold, gives valid tests and consistent estimates. The key insight is that the data made unavailable by open-label treatment after diagnosis are missing at random. We demonstrate the analysis in simulations based on a large set of blood pressure measurements from a New Zealand healthcare organisation and show that properly specified random effects models accurately estimate carryover effects even in the presence of data censored at diagnosis.},
  keywords = {Blood pressure,Censoring,Cholesterol,Diabetes,Hypertension,Linear mixed model,Longitudinal data,Measurement error},
  file = {/Users/zenn/Zotero/storage/6ZPRRYUG/Sturdevant and Lumley - 2021 - Statistical methods for testing carryover effects.pdf;/Users/zenn/Zotero/storage/QJFPHVWL/S2451865421000132.html}
}

@article{su2019f4,
  title = {F4-04-03: {{RELATIONSHIPS BETWEEN BASELINE BRAIN IMAGING BIOMARKER MEASUREMENTS AND AGE IN THE API AUTOSOMAL DOMINANT ALZHEIMER}}'{{S DISEASE COLOMBIA TRIAL}}},
  author = {Su, Yi and {Rios-Romenets}, Silvia and Tariot, Pierre N and Sink, Kaycee and Clayton, David and Hu, Nan and Guthrie, Heather and Smith, Jillian and Cho, William and Langbaum, Jessica B and others},
  year = {2019},
  journal = {Alzheimer's \& Dementia},
  volume = {15},
  pages = {P1223--P1224}
}

@article{subramanianAverageTreatmentEffect2018,
  title = {The ``Average'' Treatment Effect: {{A}} Construct Ripe for Retirement. {{A}} Commentary on {{Deaton}} and {{Cartwright}}},
  shorttitle = {The ``Average'' Treatment Effect},
  author = {Subramanian, S. V. and Kim, Rockli and Christakis, Nicholas A.},
  year = {2018},
  journal = {Social science \& medicine},
  volume = {210},
  pages = {77--82},
  publisher = {Elsevier},
  file = {/Users/zenn/Zotero/storage/QVHEE7XF/S0277953618301941.html}
}

@article{suissaExactUnconditionalSample1985,
  title = {Exact {{Unconditional Sample Sizes}} for the 2 {{Times}} 2 {{Binomial Trial}}},
  author = {Suissa, Samy and Shuster, Jonathan J.},
  year = {1985},
  journal = {Journal of the Royal Statistical Society: Series A (General)},
  volume = {148},
  number = {4},
  pages = {317--327},
  issn = {2397-2327},
  doi = {10.2307/2981892},
  urldate = {2024-07-06},
  abstract = {Exact attained significance level and sample size methods are developed for use with the unconditional Z statistic in the 2 times 2 contingency table from two independent binomial samples of equal size. The resulting sample sizes tend to be smaller than those required by tables for the exact conditional test. Moreover, the proposed exact Z test is uniformly more powerful than the exact conditional test for {$\alpha$} = 0.01, 0.025 and 0.05, and common sample size n = 10(1)150, the only combinations of {$\alpha$} and n considered herein. These methods therefore provide an exact approach to unconditional tests which, in contrast to the conditional ones, are easily explained to and under-stood by non-statisticians. This paper is the first for which sample size calculations are made based on exact unconditional tests for any situation in which no ancillary statistic exists for the nuisance parameter.},
  copyright = {{\copyright} 1985 Royal Statistical Society},
  langid = {english},
  keywords = {ancillary statistics,conditionality principle,exact unconditional test,fisher's exact test,power,two by two contingency tables},
  file = {/Users/zenn/Zotero/storage/AK4ENDLK/2981892.html}
}

@article{suissaExactUnconditionalSample1985a,
  title = {Exact {{Unconditional Sample Sizes}} for the 2 {{Times}} 2 {{Binomial Trial}}},
  author = {Suissa, Samy and Shuster, Jonathan J.},
  year = {1985},
  journal = {Journal of the Royal Statistical Society: Series A (General)},
  volume = {148},
  number = {4},
  pages = {317--327},
  issn = {2397-2327},
  doi = {10.2307/2981892},
  urldate = {2024-07-06},
  abstract = {Exact attained significance level and sample size methods are developed for use with the unconditional Z statistic in the 2 times 2 contingency table from two independent binomial samples of equal size. The resulting sample sizes tend to be smaller than those required by tables for the exact conditional test. Moreover, the proposed exact Z test is uniformly more powerful than the exact conditional test for {$\alpha$} = 0.01, 0.025 and 0.05, and common sample size n = 10(1)150, the only combinations of {$\alpha$} and n considered herein. These methods therefore provide an exact approach to unconditional tests which, in contrast to the conditional ones, are easily explained to and under-stood by non-statisticians. This paper is the first for which sample size calculations are made based on exact unconditional tests for any situation in which no ancillary statistic exists for the nuisance parameter.},
  langid = {english},
  keywords = {ancillary statistics,conditionality principle,exact unconditional test,fisher's exact test,power,two by two contingency tables},
  file = {/Users/zenn/Zotero/storage/ZAHKAH96/2981892.html}
}

@article{suissaExactUnconditionalSample1985b,
  title = {Exact {{Unconditional Sample Sizes}} for the 2 {\texttimes} 2 {{Binomial Trial}}},
  author = {Suissa, Samy and Shuster, Jonathan J.},
  year = {1985},
  journal = {Journal of the Royal Statistical Society. Series A (General)},
  volume = {148},
  number = {4},
  eprint = {2981892},
  eprinttype = {jstor},
  pages = {317--327},
  publisher = {[Royal Statistical Society, Wiley]},
  issn = {0035-9238},
  doi = {10.2307/2981892},
  urldate = {2024-07-06},
  abstract = {Exact attained significance level and sample size methods are developed for use with the unconditional Z statistic in the 2 {\texttimes} 2 contingency table from two independent binomial samples of equal size. The resulting sample sizes tend to be smaller than those required by tables for the exact conditional test. Moreover, the proposed exact Z test is uniformly more powerful than the exact conditional test for {$\alpha$} = 0.01, 0.025 and 0.05, and common sample size n = 10(1)150, the only combinations of {$\alpha$} and n considered herein. These methods therefore provide an exact approach to unconditional tests which, in contrast to the conditional ones, are easily explained to and understood by non-statisticians. This paper is the first for which sample size calculations are made based on exact unconditional tests for any situation in which no ancillary statistic exists for the nuisance parameter.},
  file = {/Users/zenn/Zotero/storage/USUN64WS/Suissa and Shuster - 1985 - Exact Unconditional Sample Sizes for the 2 × 2 Bin.pdf}
}

@article{sunRecursiveTestHardyWeinberg2021,
  title = {Recursive {{Test}} of {{Hardy-Weinberg Equilibrium}} in {{Tetraploids}}},
  author = {Sun, Lidan and Gan, Jingwen and Jiang, Libo and Wu, Rongling},
  year = {2021},
  month = jun,
  journal = {Trends in Genetics},
  volume = {37},
  number = {6},
  pages = {504--513},
  issn = {0168-9525},
  doi = {10.1016/j.tig.2020.11.006},
  urldate = {2023-02-09},
  abstract = {Testing for deviations from Hardy-Weinberg equilibrium (HWE) can provide fundamental information about genetic variation and evolutionary processes in natural populations. In contrast to diploids, where genotype frequencies remain constant after a single episode of random mating, polyploids, characterized by polysomic inheritance, approach HWE gradually. Here, we mathematically show the asymptotic trajectory of tetraploid equilibrium from any initial genotype frequencies. We formulate a statistical framework to test and estimate the degree of deviation from HWE at individual loci in allotetraploids and autotetraploids. Knowledge about HWE test fills an important gap in population genetic studies of tetraploids related to their evolution and ecology.},
  langid = {english},
  keywords = {double reduction,EM algorithm,Hardy-Weinberg equilibrium,polyploid,statistical test},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/sun et al_2021_recursive test of hardy-weinberg equilibrium in tetraploids.pdf;/Users/zenn/Zotero/storage/ZDFSF65G/S0168952520303115.html}
}

@article{suzukiMechanismsUncertaintyRandomized2018,
  title = {Mechanisms and Uncertainty in Randomized Controlled Trials: {{A}} Commentary on {{Deaton}} and {{Cartwright}}},
  shorttitle = {Mechanisms and Uncertainty in Randomized Controlled Trials},
  author = {Suzuki, Etsuji and VanderWeele, Tyler J.},
  year = {2018},
  journal = {Social science \& medicine},
  volume = {210},
  pages = {83--85},
  publisher = {Elsevier BV},
  file = {/Users/zenn/Zotero/storage/JH5J5FCV/Suzuki and VanderWeele - 2018 - Mechanisms and uncertainty in randomized controlle.pdf}
}

@article{sverdlovSelectingRandomizationMethod2024,
  title = {Selecting a Randomization Method for a Multi-Center Clinical Trial with Stochastic Recruitment Considerations},
  author = {Sverdlov, Oleksandr and Ryeznik, Yevgen and Anisimov, Volodymyr and Kuznetsova, Olga M. and Knight, Ruth and Carter, Kerstine and Drescher, Sonja and Zhao, Wenle},
  year = {2024},
  month = feb,
  journal = {BMC Medical Research Methodology},
  volume = {24},
  number = {1},
  pages = {52},
  issn = {1471-2288},
  doi = {10.1186/s12874-023-02131-z},
  urldate = {2024-06-15},
  abstract = {The design of a multi-center randomized controlled trial (RCT) involves multiple considerations, such as the choice of the sample size, the number of centers and their geographic location, the strategy for recruitment of study participants, amongst others. There are plenty of methods to sequentially randomize patients in a multi-center RCT, with or without considering stratification factors. The goal of this paper is to perform a systematic assessment of such randomization methods for a multi-center 1:1 RCT assuming a competitive policy for the patient recruitment process.},
  langid = {english},
  keywords = {Allocation randomness,Maximum tolerated imbalance,Multi-center clinical trial,Poisson-gamma model,Recruitment time},
  file = {/Users/zenn/Zotero/storage/UN5TASF7/Sverdlov et al. - 2024 - Selecting a randomization method for a multi-cente.pdf}
}

@article{sysoevSmoothedMonotonicRegression2019,
  title = {A Smoothed Monotonic Regression via {{L2}} Regularization},
  author = {Sysoev, Oleg and Burdakov, Oleg},
  year = {2019},
  month = apr,
  journal = {Knowledge and Information Systems},
  volume = {59},
  number = {1},
  pages = {197--218},
  issn = {0219-3116},
  doi = {10.1007/s10115-018-1201-2},
  urldate = {2024-04-03},
  abstract = {Monotonic regression is a standard method for extracting a monotone function from non-monotonic data, and it is used in many applications. However, a known drawback of this method is that its fitted response is a piecewise constant function, while practical response functions are often required to be continuous. The method proposed in this paper achieves monotonicity and smoothness of the regression by introducing an L2 regularization term. In order to achieve a low computational complexity and at the same time to provide a high predictive power of the method, we introduce a probabilistically motivated approach for selecting the regularization parameters. In addition, we present a technique for correcting inconsistencies on the boundary. We show that the complexity of the proposed method is \$\$O(n{\textasciicircum}2)\$\$. Our simulations demonstrate that when the data are large and the expected response is a complicated function (which is typical in machine learning applications) or when there is a change point in the response, the proposed method has a higher predictive power than many of the existing methods.},
  langid = {english},
  keywords = {Kernel smoothing,Monotonic regression,Penalized regression,Probabilistic learning},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/sysoev_burdakov_2019_a smoothed monotonic regression via l2 regularization.pdf}
}

@article{takemuraCharacterizationsMinimalMarkov2004,
  title = {Some Characterizations of Minimal {{Markov}} Basis for Sampling from Discrete Conditional Distributions},
  author = {Takemura, Akimichi and Aoki, Satoshi},
  year = {2004},
  month = mar,
  journal = {Annals of the Institute of Statistical Mathematics},
  volume = {56},
  number = {1},
  pages = {1--17},
  issn = {1572-9052},
  doi = {10.1007/BF02530522},
  urldate = {2022-11-05},
  abstract = {In this paper we given some basic characterizations of minimal Markov basis for a connected Markov chain, which is used for performing exact tests in discrete exponential families given a sufficient statistic. We also give a necessary and sufficient condition for uniqueness of minimal Markov basis. A general algebraic algorithm for constructing a connected Markov chain was given by Diaconis and Sturmfels (1998,The Annals of Statistics,26, 363--397). Their algorithm is based on computing Gr{\"o}bner basis for a certain ideal in a polynomial ring, which can be carried out by using available computer algebra packages. However structure and interpretation of Gr{\"o}bner basis produced by the packages are sometimes not clear, due to the lack of symmetry and minimality in Gr{\"o}bner basis computation. Our approach clarifies partially ordered structure of minimal Markov basis.},
  langid = {english},
  keywords = {Contingency tables,exact tests,Markov chain Monte Carlo},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/takemura_aoki_2004_some characterizations of minimal markov basis for sampling from discrete2.pdf;/Users/zenn/Zotero/storage/8YTGIY65/BF02530522.html}
}

@article{takiSignificance123IMIBGScintigraphy2004,
  title = {Significance of {{123I-MIBG}} Scintigraphy as a Pathophysiological Indicator in the Assessment of {{Parkinson}}'s Disease and Related Disorders: It Can Be a Specific Marker for {{Lewy}} Body Disease},
  shorttitle = {Significance of {{123I-MIBG}} Scintigraphy as a Pathophysiological Indicator in the Assessment of {{Parkinson}}'s Disease and Related Disorders},
  author = {Taki, Junichi and Yoshita, Mitsuhiro and Yamada, Masahito and Tonami, Norihisa},
  year = {2004},
  month = sep,
  journal = {Annals of Nuclear Medicine},
  volume = {18},
  number = {6},
  pages = {453--461},
  issn = {0914-7187},
  doi = {10.1007/BF02984560},
  abstract = {Recently, reliable and clear evidence for the usefulness of 123I-MIBG scintigraphy in the diagnosis of Parkinson's disease (PD) has been accumulated and it has become increasingly popular as one of the most accurate means of diagnosing the disease. PD, one of the most common neurodegenerative disorders, is characterized by resting tremor, rigidity, bradykinesia or akinesia, and postural instability. The disease is characterized pathologically by distinctive neuronal inclusions called Lewy bodies in many surviving cells of dopaminergic neurons of the substantia nigra pars compacta and other specific brain regions. Furthermore Lewy body type degeneration in the cardiac plexus has been observed in PD. In PD, cardiac MIBG uptake is reduced markedly even in the early disease stages; therefore, MIBG imaging can be used as an indicator of the presence of PD rather than disease severity. Other parkinsonian syndromes such as multiple system atrophy, progressive supranuclear palsy, and corticobasal degeneration demonstrate normal cardiac MIBG uptake or only mild reduction of MIBG uptake, indicating that MIBG imaging is a powerful method to differentiate PD from other parkinsonian syndromes. Dementia with Lewy bodies (DLB) also shows severe reduction of MIBG uptake, whereas Alzheimer's disease (AD) demonstrates normal MIBG uptake, permitting differentiation of DLB from AD using MIBG scintigraphy. In pure autonomic failure, which shares similar pathological findings with PD and is thought to be associated with diffuse loss of sympathetic terminal innervation, cardiac MIBG uptake also decreases markedly. Considering all the data together, marked reduction of cardiac MIBG uptake seems to be a specific marker of Lewy body disease and thus extremely useful in the differentiation from other diseases with similar symptoms without Lewy bodies.},
  langid = {english},
  pmid = {15515743},
  keywords = {3-Iodobenzylguanidine,Animals,Autonomic Nervous System,Brain,Clinical Trials as Topic,Humans,Lewy Body Disease,Neurodegenerative Diseases,Parkinson Disease,Radionuclide Imaging,Radiopharmaceuticals}
}

@article{tanaka1998association,
  title = {Association of {{CYP2D}} Microsatellite Polymorphism with {{Lewy}} Body Variant of {{Alzheimer}}'s Disease},
  author = {Tanaka, S and Chen, X and Xia, Y and Kang, {\relax DE} and Matoh, N and Sundsmo, M and Thomas, {\relax RG} and Katzman, R and Thal, {\relax LJ} and Trojanowski, {\relax JQ} and others},
  year = {1998},
  journal = {Neurology},
  volume = {50},
  number = {6},
  pages = {1556--1562},
  publisher = {Wolters Kluwer Health, Inc. on behalf of the American Academy of Neurology}
}

@article{tariot2004p1,
  title = {P1-322 {{A}} Multicenter, Randomized, Double-Blind, Placebo-Controlled Trial of Valproate for Agitation Associated with Dementia},
  author = {Tariot, Pierre N and Thal, Leon and Jakimovich, Laura and Thomas, Ronald and Raman, Rema},
  year = {2004},
  journal = {Neurobiology of Aging},
  number = {25},
  pages = {S189}
}

@article{tariot2005divalproex,
  title = {Divalproex Sodium in Nursing Home Residents with Possible or Probable {{Alzheimer}} Disease Complicated by Agitation: A Randomized, Controlled Trial},
  author = {Tariot, Pierre N and Raman, Rema and Jakimovich, Laura and Schneider, Lon and Porsteinsson, Anton and Thomas, Ronald and Mintzer, Jacobo and Brenner, Ronald and Schafer, Kim and Thal, Leon},
  year = {2005},
  journal = {The American journal of geriatric psychiatry},
  volume = {13},
  number = {11},
  pages = {942--949},
  publisher = {Elsevier}
}

@article{tariot2009o1,
  title = {O1-04-03: {{The ADCS}} Valproate Neuroprotection Trial: {{Primary}} Efficacy and Safety Results},
  author = {Tariot, Pierre N and Aisen, Paul and Cummings, Jeffrey and Jakimovich, Laura and Schneider, Lon and Thomas, Ronald and Becerra, Lida and Loy, Rebekah},
  year = {2009},
  journal = {Alzheimer's \& Dementia},
  volume = {5},
  number = {4S\_Part\_3},
  pages = {P84--P85}
}

@article{tariot2011chronic,
  title = {Chronic Divalproex Sodium to Attenuate Agitation and Clinical Progression of {{Alzheimer}} Disease},
  author = {Tariot, Pierre N and Schneider, Lon S and Cummings, Jeffrey and Thomas, Ronald G and Raman, Rema and Jakimovich, Laura J and Loy, Rebekah and Bartocci, Barbara and Fleisher, Adam and Ismail, M Saleem and others},
  year = {2011},
  journal = {Archives of General Psychiatry},
  volume = {68},
  number = {8},
  pages = {853--861},
  publisher = {American Medical Association}
}

@inproceedings{tariot2016alzheimer,
  title = {The Alzheimer's Prevention Initiative Generation Study: {{A}} Preclinical Trial in {{APOE4}} Homozygotes},
  booktitle = {{{NEUROPSYCHOPHARMACOLOGY}}},
  author = {Tariot, Pierre and Langbaum, Jessica and Schneider, Lon and Thomas, Ronald G and Graf, Ana and {Lopez-Lopez}, Cristina and Caputo, Angelika and Lenz, Robert and Vargas, Gabriel and Reiman, Eric M},
  year = {2016},
  volume = {41},
  pages = {S139--S139},
  publisher = {NATURE PUBLISHING GROUP MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND}
}

@inproceedings{tariot2017alzheimer,
  title = {The Alzheimer's Prevention Initiative ({{API}}) Generation Program: {{Evaluating}} the Efficacy of the {{BACE-1}} Inhibitor {{CNP520}} in Preclinical Alzheimer's Disease},
  booktitle = {{{NEUROPSYCHOPHARMACOLOGY}}},
  author = {Tariot, Pierre and {Lopez-Lopez}, Cristina and Caputo, Angelika and Thomas, Ronald G and Langbaum, Jessica and Lenz, Robert and Vargas, Gabriel and Viglietta, Vissia and Reiman, Eric M and Graf, Ana},
  year = {2017},
  volume = {42},
  pages = {S143--S144},
  publisher = {NATURE PUBLISHING GROUP MACMILLAN BUILDING, 4 CRINAN ST, LONDON N1 9XW, ENGLAND}
}

@article{tariot2018alzheimer,
  title = {The {{Alzheimer}}'s {{Prevention Initiative Autosomal-Dominant Alzheimer}}'s {{Disease Trial}}: {{A}} Study of Crenezumab versus Placebo in Preclinical {{PSEN1 E280A}} Mutation Carriers to Evaluate Efficacy and Safety in the Treatment of Autosomal-Dominant {{Alzheimer}}'s Disease, Including a Placebo-Treated Noncarrier Cohort},
  author = {Tariot, Pierre N and Lopera, Francisco and Langbaum, Jessica B and Thomas, Ronald G and Hendrix, Suzanne and Schneider, Lon S and {Rios-Romenets}, Silvia and Giraldo, Margarita and Acosta, Natalia and Tobon, Carlos and others},
  year = {2018},
  journal = {Alzheimer's \& Dementia: Translational Research \& Clinical Interventions},
  volume = {4},
  pages = {150--160},
  publisher = {No longer published by Elsevier}
}

@article{tariot2019f4,
  title = {F4-04-01: {{TRIAL DESIGN}}, {{DATA SHARING RISK MITIGATION}}, {{AND BASELINE CLINICAL AND COGNITIVE DATA FROM THE API AUTOSOMAL DOMINANT ALZHEIMER}}'{{S DISEASE COLOMBIA TRIAL}}},
  author = {Tariot, Pierre N and Lopera, Francisco and Sink, Kaycee and Hu, Nan and Guthrie, Heather and Smith, Jillian and Cho, William and Langbaum, Jessica B and Thomas, Ronald G and Giraldo, Margarita and others},
  year = {2019},
  journal = {Alzheimer's \& Dementia},
  volume = {15},
  pages = {P1222--P1223}
}

@article{tenkateConsistencyTreatmentEffects2024,
  title = {Consistency between {{Treatment Effects}} on {{Clinical}} and {{Brain Atrophy Outcomes}} in {{Alzheimer}}'s {{Disease Trials}}},
  author = {{ten Kate}, M. and Barkhof, F. and Schwarz, Adam J.},
  year = {2024},
  month = jan,
  journal = {The Journal of Prevention of Alzheimer's Disease},
  volume = {11},
  number = {1},
  pages = {38--47},
  issn = {2426-0266},
  doi = {10.14283/jpad.2023.92},
  urldate = {2024-02-04},
  abstract = {Longitudinal changes in volumetric MRI outcome measures have been shown to correlate well with longitudinal changes in clinical instruments and have been widely used as biomarker outcomes in clinical trials for Alzheimer's disease (AD). While instances of discordant findings have been noted in some trials, especially the recent amyloid-removing therapies, the overall relationship between treatment effects on brain atrophy and clinical outcomes, and how it might depend on treatment target or mechanism, clinical instrument or imaging variable is not yet clear.},
  langid = {english},
  keywords = {Alzheimer's disease,atrophy,cognition,linical trials},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/ten kate et al_2024_consistency between treatment effects on clinical and brain atrophy outcomes in.pdf}
}

@article{teri2000treatment,
  title = {Treatment of Agitation in {{AD}}: A Randomized, Placebo-Controlled Clinical Trial},
  author = {Teri, Linda and Logsdon, {\relax RG} and Peskind, E and Raskind, M and Weiner, {\relax MF} and Tractenberg, {\relax RE} and Foster, {\relax NL} and Schneider, {\relax LS} and Sano, M and Whitehouse, P and others},
  year = {2000},
  journal = {Neurology},
  volume = {55},
  number = {9},
  pages = {1271--1278},
  publisher = {Wolters Kluwer Health, Inc. on behalf of the American Academy of Neurology}
}

@article{thal1997tacrine,
  title = {Tacrine and Nursing Home Placement},
  author = {Thal, Leon J and Thomas, Ronald G and Sano, Mary},
  year = {1997},
  journal = {Neurology},
  volume = {49},
  number = {3},
  pages = {897--898},
  publisher = {Wolters Kluwer Health, Inc. on behalf of the American Academy of Neurology}
}

@article{thal2003estrogen,
  title = {Estrogen Levels Do Not Correlate with Improvement in Cognition},
  author = {Thal, Leon J and Thomas, Ronald G and Mulnard, Ruth and Sano, Mary and Grundman, Michael and Schneider, Lon},
  year = {2003},
  journal = {Archives of Neurology},
  volume = {60},
  number = {2},
  pages = {209--212},
  publisher = {American Medical Association}
}

@article{thal2003idebenone,
  title = {Idebenone Treatment Fails to Slow Cognitive Decline in {{Alzheimer}}'s Disease},
  author = {Thal, {\relax LJ} and Grundman, M and Berg, J and Ernstrom, K and Margolin, R and Pfeiffer, E and Weiner, {\relax MF} and Zamrini, E and Thomas, {\relax RG}},
  year = {2003},
  journal = {Neurology},
  volume = {61},
  number = {11},
  pages = {1498--1502},
  publisher = {Wolters Kluwer Health, Inc. on behalf of the American Academy of Neurology}
}

@article{thal2005o2,
  title = {[{{O2-01-01}}]: {{Donepezil}} and Vitamin {{E}} in the Progression of Mild Cognitive Impairment to {{Alzheimer}}'s Disease: {{A}} Hazard-Ratio Analysis},
  author = {Thal, Leon J and Thomas, Ronald G and Grundman, Michael and Bennett, David A and Doody, Rachelle S and Ferris, Steven H and Galasko, Douglas R and Jin, Shelia and Levey, Allan I and Petersen, Ronald C},
  year = {2005},
  journal = {Alzheimer's \& Dementia},
  volume = {1},
  pages = {S93--S94}
}

@inproceedings{thomas1987there,
  title = {Is There Dependence between Sites for Continued Success or Restenosis after Successful Multisite Coronary Angioplasty},
  booktitle = {Circulation},
  author = {Thomas, {\relax RG} and Black, A and Lin, S and Chin, H and Weintraub, {\relax WS}},
  year = {1987},
  volume = {76},
  pages = {214--214},
  publisher = {AMER HEART ASSOC 7272 GREENVILLE AVENUE, DALLAS, TX 75231-4596}
}

@article{thomas1989exact,
  title = {Exact Sample Size Calculations for 2{{ times}} 2 Comparative Trials When the Outcome Proportions Are Small},
  author = {Thomas, Ronald G},
  year = {1989},
  journal = {Controlled Clinical Trials},
  volume = {10},
  number = {3},
  pages = {347},
  publisher = {Elsevier}
}

@article{thomas1990data,
  title = {Data Monitoring through Stochastic Curtailing When the Outcome Proportions Are Small: {{An}} Exact Approach},
  author = {Thomas, Ronald G},
  year = {1990},
  journal = {Controlled Clinical Trials},
  volume = {11},
  number = {4},
  pages = {264},
  publisher = {Elsevier}
}

@article{thomas1992algorithm,
  title = {An Algorithm for the Rapid Evaluation of the Power Function for {{Fisher}}'s {{Exact Test}}},
  author = {Thomas, Ronald G and Conlon, Michael},
  year = {1992},
  journal = {Journal of statistical computation and simulation},
  volume = {44},
  number = {1-2},
  pages = {63--73},
  publisher = {{Gordon and Breach Science Publishers}}
}

@article{thomas1992sample,
  title = {Sample Size Determination Based on {{Fisher}}'s Exact Test for Use in 2 x 2 Comparative Trials with Low Event Rates},
  author = {Thomas, Ronald G and Conlon, Michael},
  year = {1992},
  journal = {Controlled clinical trials},
  volume = {13},
  number = {2},
  pages = {134--147},
  publisher = {Elsevier}
}

@article{thomas1995spanish,
  title = {The Spanish Instrument Protocol: A Study to Evaluate Treatment Efficacy Instruments for Spanish-Speaking Patients with Alzheimer's Disease},
  author = {Thomas, {\relax RG} and Jin, S and Schafer, K and Schittini, M and Grundman, M and Ferris, {\relax SH}},
  year = {1995},
  journal = {Alzheimer Disease and Associated Disorders},
  volume = {11},
  number = {2},
  pages = {S57--S64}
}

@article{thomas1996a32,
  title = {A32 Computer-Aided Clinical Monitoring: {{Results}} of a Controlled Experiment},
  author = {Thomas, Ronald G and Schafer, Kimberly and Woodbury, Peter and White, Beverly and Mackell, Joan and Lambert, Angie and Scattini, Mario},
  year = {1996},
  journal = {Controlled Clinical Trials},
  volume = {2},
  number = {17},
  pages = {S56--S57}
}

@article{thomas2000analysis,
  title = {Analysis of Longitudinal Data in an {{Alzheimer}}'s Disease Clinical Trial},
  author = {Thomas, Ronald G and Berg, Julie D and Sano, Mary and Thal, Leon},
  year = {2000},
  journal = {Statistics in medicine},
  volume = {19},
  number = {11-12},
  pages = {1433--1440},
  publisher = {Wiley Online Library}
}

@article{thomas2012p3,
  title = {P3-383: {{ADCS}} Data Sharing},
  author = {Thomas, Ronald and Jimenez, Gustavo and Brewer, James and Rissman, Robert A and Aisen, Paul},
  year = {2012},
  journal = {Alzheimer's \& Dementia},
  volume = {8},
  number = {4S\_Part\_16},
  pages = {P590--P590}
}

@article{thomas2013p3,
  title = {P3--295: {{The}} Placebo Data Analysis in Alzheimer's Disease ({{AD}}) and Mild Cognitive Impairment ({{MCI}}) Clinical Trials Project: {{Overview}} of Progress in Trial Data Collection, and Key Findings from the Pooled Alzheimer's Disease Trial Datasets},
  author = {Thomas, Ronald and Petersen, Ronald and Siuciak, Judith and Carrillo, Maria and Albert, Marilyn and Aisen, Paul and Initiative, Alzheimer's Disease Neuroimaging and Team, Foundation for NIH Biomarkers Consortium AD MCI Placebo Data Project},
  year = {2013},
  journal = {Alzheimer's \& Dementia},
  volume = {9},
  pages = {P665--P665}
}

@article{thomas2016longitudinal,
  title = {Longitudinal Decline in Mild-to-Moderate {{Alzheimer}}'s Disease: Analyses of Placebo Data from Clinical Trials},
  author = {Thomas, Ronald G and Albert, Marilyn and Petersen, Ronald C and Aisen, Paul S},
  year = {2016},
  journal = {Alzheimer's \& Dementia},
  volume = {12},
  number = {5},
  pages = {598--603},
  publisher = {No longer published by Elsevier}
}

@article{thomasAlgorithmRapidEvaluation1992,
  title = {An Algorithm for the Rapid Evaluation of the Power Function for Fisher's Exact Test},
  author = {Thomas, Ronald G. and Conlon, Michael},
  year = {1992},
  month = dec,
  journal = {Journal of Statistical Computation and Simulation},
  volume = {44},
  number = {1-2},
  pages = {63--73},
  publisher = {Taylor \& Francis},
  issn = {0094-9655},
  doi = {10.1080/00949659208811449},
  urldate = {2023-07-21},
  abstract = {A new algorithm is introduced for the calculation of the power function for Fisher's Exact Test for 2 {\texttimes} 2 tables. The algorithm restricts its calculations to a very small subset of the sample space, obtaining an accurate answer in reasonable time. The algorithm is feasible for very large sample sizes.},
  keywords = {Algorithm,Fisher's Exact Test,Power},
  file = {/Users/zenn/Zotero/storage/JQ3VELNB/Thomas and Conlon - 1992 - An algorithm for the rapid evaluation of the power.pdf}
}

@article{thomasLongitudinalDeclineMildtomoderate2016,
  title = {Longitudinal Decline in Mild-to-Moderate {{Alzheimer}}'s Disease: {{Analyses}} of Placebo Data from Clinical Trials},
  author = {Thomas, Ronald G. and Albert, Marilyn and Petersen, Ronald C. and Aisen, Paul S.},
  year = {2016},
  month = may,
  journal = {Alzheimer's and Dementia},
  volume = {12},
  number = {5},
  pages = {598--603},
  issn = {15525279},
  doi = {10.1016/j.jalz.2016.01.002},
  abstract = {Introduction Accurate estimates of cognitive and clinical decline rates are essential to the design of clinical trials in Alzheimer's disease (AD) dementia. Methods To investigate the trajectories of individuals enrolled in therapeutic trials in mild-to-moderate AD, we analyzed the placebo arm data from 20 clinical trials including over 4500 subjects. We analyzed decline as measured by two cognitive instruments, the cognitive subscale of the Alzheimer's Disease Assessment Scale (ADAScog) and the Mini-Mental State Examination, and one clinical rating scale, the Clinical Dementia Rating Sum of Boxes. Results Trajectories were generally similar across trials and nearly linear. Greater cognitive impairment at baseline, younger age, and greater education were associated with increased rate of cognitive decline. Effect sizes for the ADAScog were generated as a function of population characteristics. Discussion These data will inform the design of future studies of potential disease-modifying therapies for mild-to-moderate AD dementia.},
  pmid = {26917500},
  keywords = {Alzheimer's dementia,Cognitive assessment,Therapeutic trials},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/thomas et al_2016_longitudinal decline in mild-to-moderate alzheimer's disease.pdf}
}

@article{thompsonBryostatinPlaceboControlledTrials2022,
  title = {Bryostatin {{Placebo-Controlled Trials Indicate Cognitive Restoration Above Baseline}} for {{Advanced Alzheimer}}'s {{Disease}} in the {{Absence}} of {{Memantine1}}},
  author = {Thompson, Richard E and Tuchman, Alan J and Alkon, Daniel L},
  year = {2022},
  journal = {Journal of Alzheimer's Disease},
  volume = {86},
  number = {3},
  pages = {1221--1229},
  issn = {13872877},
  doi = {10.3233/jad-215545},
  urldate = {2022-04-20},
  abstract = {Background: In pre-clinical studies of Alzheimer's disease (AD) transgenic mice, bryostatin restored synaptic connections, prevented neuronal death, reduced amyloid plaques, and reduced neurofibrillary tangles. Objective: Within pre-specified cohorts of advanced AD patients in two double-blind placebo-controlled bryostatin Phase II trials, to conduct exploratory statistical analyses of patients with identical conditions of enrollment and treatment. Methods: Severe Impairment Battery (SIB) scores above baseline at 5, 9, and 13 weeks were analyzed initially in the complete cases, with multiple imputation methods based on an iterative Markov chain Monte Carlo algorithm used for missing SIB scores. To mitigate confounding by a chance imbalance of 4.9 SIB baseline scores (Study \#203), each patient was used as their own control with differences in 13-week SIB from baseline in single trial and pooled analyses to measure benefit at 13 weeks using general estimating equations (GEE) modeling. Results: Patients treated with bryostatin pre-specified at Mini-Mental State Examination scores 10-14, without memantine, showed baseline balance, complete safety, and SIB improvements at 13 weeks with multiple imputation analysis: Study \#203 = 4.1 SIB points above baseline (p = 0.005), and Study \#202 = 4.2 SIB points above baseline (p = 0.016). An increased power (N = 95) 'pooled analysis' showed an increased SIB over time and a higher mean SIB at 13 weeks in the bryostatin treatment group (p {$<$} 0.001) but not significant (NS) for the placebo patients. Conclusion: Pre-specified exploratory analyses for the individual trials and the pooled trials confirmed significant bryostatin-induced improvement over baseline (treatment p {$<$} 0.001, placebo NS).},
  pmid = {35124654},
  keywords = {Alzheimer's disease,bryostatin,cognitive improvement above baseline,double-blind,pooled analysis,randomized trials,therapeutics},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/thompson et al_2022_bryostatin placebo-controlled trials indicate cognitive restoration above.pdf}
}

@article{thorlundKeyDesignConsiderations2018,
  title = {Key Design Considerations for Adaptive Clinical Trials: A Primer for Clinicians},
  author = {Thorlund, Kristian and Haggstrom, Jonas and Park, Jay Jh and Mills, Edward J},
  year = {2018},
  journal = {BMJ},
  volume = {360},
  pages = {698},
  doi = {10.1136/bmj.k698},
  urldate = {2021-03-23},
  keywords = {c60},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/thorlund et al_2018_key design considerations for adaptive clinical trials.pdf}
}

@misc{tierneySimpleGuideS32016,
  title = {A {{Simple Guide}} to {{S3 Methods}}},
  author = {Tierney, Nicholas},
  year = {2016},
  month = aug,
  number = {arXiv:1608.07161},
  eprint = {1608.07161},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-05-20},
  abstract = {Writing functions in R is an important skill for anyone using R. S3 methods allow for functions to be generalised across different classes and are easy to implement. Whilst many R users are be adept at creating their own functions, it seems that there is room for many more to take advantage of R's S3 methods. This paper provides a simple and targeted guide to explain what S3 methods are, why people should them, and how they can do it.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Programming Languages},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/tierney_2016_a simple guide to s3 methods.pdf;/Users/zenn/Zotero/storage/352SNQFC/1608.html}
}

@article{toddInterimAnalysesSequential2001,
  title = {Interim Analyses and Sequential Designs in Phase {{III}} Studies},
  author = {Todd, Susan and Whitehead, Anne and Stallard, Nigel and Whitehead, John},
  year = {2001},
  journal = {British journal of clinical pharmacology},
  volume = {51},
  number = {5},
  pages = {394--399},
  publisher = {Wiley Online Library},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/todd et al_2001_interim analyses and sequential designs in phase iii studies.pdf;/Users/zenn/Zotero/storage/XYT8YM6U/j.1365-2125.2001.01382.html}
}

@article{tomassenAmyloidvAPOEGenotype2022,
  title = {Amyloid-{$\beta$} and {{APOE}} Genotype Predict Memory Decline in Cognitively Unimpaired Older Individuals Independently of {{Alzheimer}}'s Disease Polygenic Risk Score},
  author = {Tomassen, Jori and {den Braber}, Anouk and {van der Lee}, Sven J. and Reus, Lianne M. and Konijnenberg, Elles and Carter, Stephen F. and Yaqub, Maqsood and {van Berckel}, Bart N.M. and Collij, Lyduine E. and Boomsma, Dorret I. and {de Geus}, Eco J.C. and Scheltens, Philip and Herholz, Karl and Tijms, Betty M. and Visser, Pieter Jelle},
  year = {2022},
  month = dec,
  journal = {BMC Neurology},
  volume = {22},
  number = {1},
  pages = {484},
  issn = {1471-2377},
  doi = {10.1186/s12883-022-02925-6},
  urldate = {2023-01-16},
  abstract = {What combination of risk factors for Alzheimer's disease (AD) are most predictive of cognitive decline in cognitively unimpaired individuals remains largely unclear. We studied associations between APOE genotype, AD-Polygenic Risk Scores (AD-PRS), amyloid-{$\beta$} pathology and decline in cognitive functioning over time in a large sample of cognitively unimpaired older individuals.},
  keywords = {Amyloid-,APOE genotype,Cognitive decline,Longitudinal design,Neuropsychology,Polygenic risk score,Preclinical Alzheimer's disease},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/tomassen et al_2022_amyloid-β and apoe genotype predict memory decline in cognitively unimpaired.pdf;/Users/zenn/Zotero/storage/3ECPE937/s12883-022-02925-6.html}
}

@article{touloumiImpactMissingData2001,
  title = {Impact of Missing Data Due to Drop-Outs on Estimators for Rates of Change in Longitudinal Studies: {{A}} Simulation Study},
  author = {Touloumi, G. and Babiker, A. G. and Pocock, S. J. and Darbyshire, J. H.},
  year = {2001},
  month = dec,
  journal = {Statistics in Medicine},
  volume = {20},
  number = {24},
  pages = {3715--3728},
  issn = {02776715},
  doi = {10.1002/SIM.1114},
  urldate = {2021-11-06},
  abstract = {Many cohort studies and clinical trials are designed to compare rates of change over time in one or more disease markers in several groups. One major problem in such longitudinal studies is missing data due to patient drop-out. The bias and efficiency of six different methods to estimate rates of changes in longitudinal studies with incomplete observations were compared: generalized estimating equation estimates (GEE) proposed by Liang and Zeger (1986); unweighted average of ordinary least squares (OLSE) of individual rates of change (UWLS); weighted average of OLSE (WLS); conditional linear model estimates (CLE), a covariate type estimates proposed by Wu and Bailey (1989); random effect (RE), and joint multivariate RE (JMRE) estimates. The latter method combines a linear RE model for the underlying pattern of the marker with a log-normal survival model for informative drop-out process. The performance of these methods in the presence of missing data completely at random (MCAR), at random (MAR) and non-ignorable (NIM) were compared in simulation studies. Data for the disease marker were generated under the linear random effects model with parameter values derived from realistic examples in HIV infection. Rates of drop-out, assumed to increase over time, were allowed to be independent of marker values or to depend either only on previous marker values or on both previous and current marker values. Under MACR all six methods yielded unbiased estimates of both group mean rates and between-group difference. However, the cross-sectional view of the data in the GEE method resulted in seriously biased estimates under MAR and NIM drop-out process. The bias in the estimates ranged from 30 per cent to 50 per cent. The degree of bias in the GEE estimates increases with the severity of non-randomness and with the proportion of MAR data. Under MCAR and MAR all the other five methods performed relatively well. RE and JMRE estimates were more efficient (that is, had smaller variance) than UWLS, WLS and CL estimates. Under NIM, WLS and particularly RE estimates tended to underestimate the average rate of marker change (bias {$\approx$} 10 per cent). Under NIM, UWLS, CL and JMRE performed better in terms of bias (3-5 per cent) with the JMRE giving the most efficient estimates. Given that markers are key variables related to disease progression, missing marker data are likely to be at least MAR. Thus, the GEE method may not be appropriate for analysing such longitudinal marker data. The potential biases due to incomplete data require greater recognition in reports of longitudinal studies. Sensitivity analyses to assess the effect of drop-outs on inferences about the target parameters are important. Copyright {\copyright} 2001 John Wiley \& Sons, Ltd.},
  pmid = {11782028},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/touloumi et al_2001_impact of missing data due to drop-outs on estimators for rates of change in.pdf}
}

@article{tractenberg1998agreement,
  title = {Agreement on {{CDR}} Ratings by Committee},
  author = {Tractenberg, Rochelle and Schafer, Kimberly and Thomas, Ron and Morris, John C},
  year = {1998},
  journal = {Controlled Clinical Trials},
  volume = {19},
  number = {3},
  pages = {S89},
  publisher = {Elsevier}
}

@article{tractenberg2000prevalence,
  title = {Prevalence of Symptoms on the {{CERAD}} Behavior Rating Scale for Dementia in Normal Elderly Subjects and {{Alzheimer}}'s Disease Patients},
  author = {Tractenberg, Rochelle E and Patterson, Marian and Weiner, Myron F and Teri, Linda and Grundman, Michael and Thomas, Ronald G and Thal, Leon J},
  year = {2000},
  journal = {The Journal of neuropsychiatry and clinical neurosciences},
  volume = {12},
  number = {4},
  pages = {472--479},
  publisher = {American Psychiatric Publishing}
}

@article{tractenberg2000qualifying,
  title = {Qualifying Change: A Method for Defining Clinically Meaningful Outcomes of Change Score Computation},
  author = {Tractenberg, Rochelle E and Jin, Shelia and Patterson, Marian and Schneider, Lon S and Gamst, Anthony and Thomas, Ronald G and Thal, Leon J},
  year = {2000},
  journal = {Journal of the American Geriatrics Society},
  volume = {48},
  number = {11},
  pages = {1478--1482},
  publisher = {Blackwell Publishing Ltd Oxford, UK}
}

@article{tractenberg2001frequency,
  title = {Frequency of Behavioral Symptoms Characterizes Agitation in {{Alzheimer}}'s Disease},
  author = {Tractenberg, Rochelle E and Gamst, Anthony and Weiner, Myron F and Koss, Elisabeth and Thomas, Ronald G and Teri, Linda and Thal, Leon},
  year = {2001},
  journal = {International journal of geriatric psychiatry},
  volume = {16},
  number = {9},
  pages = {886--891},
  publisher = {John Wiley \& Sons, Ltd. Chichester, UK}
}

@article{tractenberg2002investigating,
  title = {Investigating Emergent Symptomatology as an Outcome Measure in a Behavioral Study of {{Alzheimer}}'s Disease},
  author = {Tractenberg, Rochelle E and Gamst, Anthony and Thomas, Ronald G and Patterson, Marian and Schneider, Lon S and Thal, Leon J},
  year = {2002},
  journal = {The Journal of neuropsychiatry and clinical neurosciences},
  volume = {14},
  number = {3},
  pages = {303--310},
  publisher = {American Psychiatric Publishing}
}

@article{trialsOptimalTwoStageDesigns,
  title = {Optimal {{Two-Stage Designs}} for {{Phase II Clinical Trials}}},
  author = {Trials, R Simon - Controlled Clinical and 1989, undefined},
  journal = {statsols.com},
  urldate = {2022-01-31},
  abstract = {The primary objective of a phase II clinical trial of a new drug or regimen is to determine whether it has sufficient biological activity against the disease under study to warrant more extensive development. Such trials are often conducted in a multi-institution setting where designs of more than two stages are difficult to manage. This paper presents two-stage designs that are optimal in the sense that the expected sample size is minimized if the regimen has low activity subject to constraints upon the size of the type 1 and type 2 errors. Two-stage designs which minimize the maximum sample size are also determined. Optimum and "minimax" designs for a range of design parameters are tabulated. These designs can also be used for pilot studies of new regimens where toxicity is the endpoint of interest.},
  keywords = {clinical trials,optimization,phase II trials},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/trials_1989_optimal two-stage designs for phase ii clinical trials.pdf}
}

@article{truscottCaseGrammarCorrection1996,
  title = {The Case against Grammar Correction in {{L2}} Writing Classes},
  author = {Truscott, John},
  year = {1996},
  journal = {Language Learning},
  volume = {46},
  number = {2},
  pages = {327--369},
  issn = {00238333},
  doi = {10.1111/j.1467-1770.1996.tb01238.x},
  abstract = {The paper argues that grammar correction in L2 writing classes should be abandoned, for the following reasons: (a) Substantial research shows it to be ineffective and none shows it to be helpful in any interesting sense; (b) for both theoretical and practical reasons, one can expect it to be ineffective; and (c) it has harmful effects. I also consider and reject a number of arguments previously offered in favor of grammar correction.},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/truscott_1996_the case against grammar correction in l2 writing classes.pdf}
}

@article{tsaiClinicalTrialsCurrent2014,
  title = {Clinical Trials: Past, Current, and Future for Atypical {{Parkinsonian}} Syndromes},
  shorttitle = {Clinical Trials},
  author = {Tsai, Richard M. and Boxer, Adam L.},
  year = {2014},
  month = apr,
  journal = {Seminars in Neurology},
  volume = {34},
  number = {2},
  pages = {225--234},
  issn = {1098-9021},
  doi = {10.1055/s-0034-1381739},
  abstract = {There are currently no effective Food and Drug Administration-approved treatments for atypical parkinsonian disorders such as progressive supranuclear palsy, corticobasal degeneration, dementia with Lewy bodies, or multiple system atrophy. Previous treatment trials for these disorders were focused on symptomatic support and did not affect disease progression. Recent breakthroughs in neuropathology and pathophysiology have allowed a new understanding of these disorders and investigation into potentially disease modifying therapies. Randomized, placebo-controlled clinical trials of these disorders will be reviewed here. Suggestions for future therapeutic targets and clinical trial design (with a focus on progressive supranuclear palsy) will also be provided.},
  langid = {english},
  pmcid = {PMC4920046},
  pmid = {24963682},
  keywords = {Clinical Trials as Topic,Humans,Multiple System Atrophy,Parkinsonian Disorders,Supranuclear Palsy Progressive,United States},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/tsai_boxer_2014_clinical trials2.pdf}
}

@article{tsaiClinicalTrialsCurrent2014a,
  title = {Clinical Trials: Past, Current, and Future for Atypical {{Parkinsonian}} Syndromes},
  shorttitle = {Clinical Trials},
  author = {Tsai, Richard M. and Boxer, Adam L.},
  year = {2014},
  month = apr,
  journal = {Seminars in Neurology},
  volume = {34},
  number = {2},
  pages = {225--234},
  issn = {1098-9021},
  doi = {10.1055/s-0034-1381739},
  abstract = {There are currently no effective Food and Drug Administration-approved treatments for atypical parkinsonian disorders such as progressive supranuclear palsy, corticobasal degeneration, dementia with Lewy bodies, or multiple system atrophy. Previous treatment trials for these disorders were focused on symptomatic support and did not affect disease progression. Recent breakthroughs in neuropathology and pathophysiology have allowed a new understanding of these disorders and investigation into potentially disease modifying therapies. Randomized, placebo-controlled clinical trials of these disorders will be reviewed here. Suggestions for future therapeutic targets and clinical trial design (with a focus on progressive supranuclear palsy) will also be provided.},
  langid = {english},
  pmcid = {PMC4920046},
  pmid = {24963682},
  keywords = {Clinical Trials as Topic,Humans,Multiple System Atrophy,Parkinsonian Disorders,Supranuclear Palsy Progressive,United States},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/tsai_boxer_2014_clinical trials.pdf}
}

@article{tsaiTherapyClinicalTrials2016,
  title = {Therapy and Clinical Trials in Frontotemporal Dementia: Past, Present, and Future},
  shorttitle = {Therapy and Clinical Trials in Frontotemporal Dementia},
  author = {Tsai, Richard M. and Boxer, Adam L.},
  year = {2016},
  month = aug,
  journal = {Journal of Neurochemistry},
  volume = {138 Suppl 1},
  number = {Suppl 1},
  pages = {211--221},
  issn = {1471-4159},
  doi = {10.1111/jnc.13640},
  abstract = {Frontotemporal dementia (FTD) is a common form of dementia with heterogeneous clinical presentations and distinct clinical syndromes. This article will review currently available therapies for FTD, its related disorders and their clinical evidence. It will also discuss recent advancements in FTD pathophysiology, treatment development, biomarker advancement and their relation to recently completed or~currently ongoing clinical trials as well as future implications. Frontotemporal dementia (FTD) is a type of dementia with distinct clinical syndromes. Current treatments involve off-label use of medications for symptomatic management and cannot modify disease course. Advancements in FTD pathophysiology, genetics, and biomarkers have led to development of small molecules targeting the underlying pathology in hopes of achieving a disease-modifying effect. This article will review current therapies for FTD, discuss advancements in FTD pathophysiology, therapy development, biomarker advancement, their relation to recent clinical trials and future implications. This article is part of the Frontotemporal Dementia special issue.},
  langid = {english},
  pmcid = {PMC5217534},
  pmid = {27306957},
  keywords = {10th International Conference on Frontotemporal Dementia,behavioral variant frontotemporal dementia (bvFTD),Biomarkers,C9ORF72,clinical trials,Clinical Trials as Topic,frontotemporal dementia,Frontotemporal Dementia,Humans,primary progressive aphasia (PPA),progressive supranuclear palsy (PSP),tau,TDP-43,treatment},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/tsai_boxer_2016_therapy and clinical trials in frontotemporal dementia.pdf}
}

@article{Turner2015,
  title = {A Randomized, Double-Blind, Placebo-Controlled Trial of Resveratrol for {{Alzheimer}} Disease},
  author = {Turner, R. Scott and Thomas, Ronald G. and Craft, Suzanne and {van Dyck}, Christopher H. and Mintzer, Jacobo and Reynolds, Brigid A. and Brewer, James B. and Rissman, Robert A. and Raman, Rema and Aisen, Paul S.},
  year = {2015},
  month = oct,
  journal = {Neurology},
  volume = {85},
  number = {16},
  pages = {1383--1391},
  issn = {0028-3878},
  doi = {10.1212/WNL.0000000000002035},
  abstract = {Objective: A randomized, placebo-controlled, double-blind, multicenter 52-week phase 2 trial of resveratrol in individuals with mild to moderate Alzheimer disease (AD) examined its safety and tolerability and effects on biomarker (plasma A{$\beta$}40 and A{$\beta$}42, CSF A{$\beta$}40, A{$\beta$}42, tau, and phospho-tau 181) and volumetric MRI outcomes (primary outcomes) and clinical outcomes (secondary outcomes). Methods: Participants (n 119) were randomized to placebo or resveratrol 500 mg orally once daily (with dose escalation by 500-mg increments every 13 weeks, ending with 1,000 mg twice daily). Brain MRI and CSF collection were performed at baseline and after completion of treatment. Detailed pharmacokinetics were performed on a subset (n 15) at baseline and weeks 13, 26, 39, and 52. Results: Resveratrol and its major metabolites were measurable in plasma and CSF. The most common adverse events were nausea, diarrhea, and weight loss. CSF A{$\beta$}40 and plasma A{$\beta$}40 levels declined more in the placebo group than the resveratrol-treated group, resulting in a significant difference at week 52. Brain volume loss was increased by resveratrol treatment compared to placebo. Conclusions: Resveratrol was safe and well-tolerated. Resveratrol and its major metabolites penetrated the blood-brain barrier to have CNS effects. Further studies are required to interpret the biomarker changes associated with resveratrol treatment. Classification of evidence: This study provides Class II evidence that for patients with AD resveratrol is safe, well-tolerated, and alters some AD biomarker trajectories. The study is rated Class II because more than 2 primary outcomes were designated.},
  pmid = {26362286},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/turner et al_2015_a randomized, double-blind, placebo-controlled trial of resveratrol for.pdf}
}

@article{turner2015randomized,
  title = {A Randomized, Double-Blind, Placebo-Controlled Trial of Resveratrol for {{Alzheimer}} Disease},
  author = {Turner, R Scott and Thomas, Ronald G and Craft, Suzanne and Van Dyck, Christopher H and Mintzer, Jacobo and Reynolds, Brigid A and Brewer, James B and Rissman, Robert A and Raman, Rema and Aisen, Paul S and others},
  year = {2015},
  journal = {Neurology},
  volume = {85},
  number = {16},
  pages = {1383--1391},
  publisher = {Wolters Kluwer Health, Inc. on behalf of the American Academy of Neurology}
}

@misc{turner2015resveratrol,
  title = {Resveratrol Is Safe and Well-Tolerated in Individuals with Mild-Moderate Dementia Due to {{Alzheimer}}'s Disease.({{S33}}. 009)},
  author = {Turner, R and Thomas, Ronald and Craft, Suzanne and {van Dyck}, Christopher and Mintzer, Jacobo and Reynolds, Brigid and Brewer, James and Rissman, Robert and Raman, Rema and Aisen, Paul},
  year = {2015},
  publisher = {Wolters Kluwer Health, Inc. on behalf of the American Academy of Neurology}
}

@article{tyrell1990p,
  title = {˙ {{P-08 An}} Analysis of Data Collection Mechanisms},
  author = {Tyrell, Doris and Cline, Dorothy R and Thomas, Ronald G},
  year = {1990},
  journal = {Controlled Clinical Trials},
  volume = {11},
  number = {4},
  pages = {280},
  publisher = {Elsevier}
}

@article{umbrichtLetterEditor2020,
  title = {Letter to the {{Editor}}},
  author = {Umbricht, D and Umbricht, Daniel},
  year = {2020},
  journal = {The Journal of Prevention of Alzheimer's Disease-JPAD},
  volume = {7},
  number = {4},
  pages = {299--300},
  doi = {10.14283/jpad.2020.34},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/umbricht_umbricht_2020_letter to the editor.pdf}
}

@misc{UnderstandingVariationSets,
  title = {Understanding {{Variation}} in {{Sets}} of {{N-of-1 Trials}} {\textbar} {{PLOS ONE}}},
  urldate = {2024-02-14},
  howpublished = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0167167},
  file = {/Users/zenn/Zotero/storage/9XPWMG6N/article.html}
}

@article{valzExactInferenceKendall1994,
  title = {Exact {{Inference}} for {{Kendall}}'s {{{\emph{S}}}} and {{Spearman}}'s {$\rho$} with {{Extension}} to {{Fisher}}'s {{Exact Test}} in {\emph{r}} {\texttimes} {\emph{c}} {{Contingency Tables}}},
  author = {Valz, Paul D. and Thompson, Mary E.},
  year = {1994},
  month = dec,
  journal = {Journal of Computational and Graphical Statistics},
  volume = {3},
  number = {4},
  pages = {459--472},
  issn = {1061-8600, 1537-2715},
  doi = {10.1080/10618600.1994.10474658},
  urldate = {2024-05-01},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/SEVAKZIC/Exact Inference for Kendall s S and Spearman s with Extension to Fisher s Exact Test in r c Contingency Tables.pdf}
}

@article{valzExactInferenceKendall1994a,
  title = {Exact {{Inference}} for {{Kendall}}'s {{S}} and {{Spearman}}'s {$\rho$} with {{Extension}} to {{Fisher}}'s {{Exact Test}} in r {\texttimes} c {{Contingency Tables}}},
  author = {Valz, Paul D. and Thompson, Mary E.},
  year = {1994},
  month = dec,
  journal = {Journal of Computational and Graphical Statistics},
  publisher = {Taylor \& Francis Group},
  issn = {1061-8600},
  urldate = {2024-05-01},
  abstract = {We formulate the problem of exact inference for Kendall's S and Spearman's D algebraically, using a general recursion formula developed by Smid for the score S with ties in both rankings. Analogous...},
  copyright = {Copyright Taylor and Francis Group, LLC},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/8PAKPVI3/10618600.1994.html}
}

@article{vanaukenTypeErrorConvergence2021,
  title = {Type {{I}} Error Convergence of Three Hypothesis Tests for Small {{RxC}} Contingency Tables},
  author = {Van Auken, R. M. and Kebschull, S. A.},
  editor = {Hu, Yueqing},
  year = {2021},
  month = jan,
  journal = {RMS: Research in Mathematics \& Statistics},
  volume = {8},
  number = {1},
  pages = {1934959},
  publisher = {Taylor \& Francis},
  issn = {null},
  doi = {10.1080/27658449.2021.1934959},
  urldate = {2023-09-12},
  abstract = {Many statistical software packages provide hypothesis tests for the independence or association between the rows and columns of a R{\texttimes}C contingency table. However, insufficient guidance is available about the accuracy and domains-of-validity of some tests that are based on assumptions or approximations. This paper assesses the accuracy of the p-values for three tests of small R{\texttimes}C tables using Monte Carlo simulations and quantile regression. Results for the Fisher-Freeman-Halton exact tests indicate the p-value accuracy depends on the number of possible unique nominal probabilities. Results for the Pearson chi-square test indicate the p-value accuracy depends on the number of possible unique nominal probabilities and the expected cell counts. Results for the Goodman-Kruskal gamma test indicate the p-value accuracy depends on the number of possible unique ordinal probabilities, the expected cell counts, and the total cell counts. Empirical models for the accuracy of these tests and recommended domain-of-validity criteria are provided.},
  keywords = {Association,independence,Monte Carlo simulation,P-value,Type I error},
  file = {/Users/zenn/Zotero/storage/8JXLM8UP/Van Auken and Kebschull - 2021 - Type I error convergence of three hypothesis tests.pdf}
}

@article{vanbokhovenAlzheimerDiseaseDrug2021,
  title = {The {{Alzheimer}}'s Disease Drug Development Landscape},
  author = {{van Bokhoven}, Pieter and {de Wilde}, Arno and Vermunt, Lisa and Leferink, Prisca S. and Heetveld, Sasja and Cummings, Jeffrey and Scheltens, Philip and Vijverberg, Everard G. B.},
  year = {2021},
  month = nov,
  journal = {Alzheimer's Research \& Therapy 2021 13:1},
  volume = {13},
  number = {1},
  pages = {1--9},
  publisher = {BioMed Central},
  issn = {1758-9193},
  doi = {10.1186/S13195-021-00927-Z},
  urldate = {2021-11-17},
  abstract = {Alzheimer's disease (AD) is a devastating neurodegenerative disease leading to dementia. The field has made significant progress over the last 15 years. AD diagnosis has shifted from syndromal, based on signs and symptoms, to a biomarker construct based on the pathological hallmarks of the disease: amyloid {$\beta$} deposition, pathologic tau, and neurodegeneration. Numerous genetic risk factors for sporadic AD have been identified, providing further insight into the molecular underpinnings of the disease. For the last two decades, however, drug development for AD has been proven to be particularly challenging. Here, we provide a unique overview of the drug development landscape for AD. By comparing preclinical and clinical drug development pipelines, we aim to describe trends and differences regarding target classes and therapeutic modalities in preclinical and clinical development. We analyzed proprietary and public databases and company websites for drugs in preclinical development for AD by the pharmaceutical industry and major clinical trial registries for drugs in clinical development for AD. Drugs were categorized by target class and treatment modality. We found a higher proportion of preclinical interventions targeting molecular pathways associated with sporadic AD genetic risk variants, compared to clinical stage interventions. These include apolipoprotein E (ApoE) and lipids, lysosomal/endosomal targets, and proteostasis. Further, we observed a trend suggesting that more traditional therapeutic modalities are developed for these novel targets, while more novel treatment modalities such as gene therapies and enzyme treatments are in development for more traditional targets such as amyloid {$\beta$} and tau. Interestingly, the percentage of amyloid {$\beta$} targeting therapies in preclinical development (19.2\%) is even higher than the percentage in clinical development (10.7\%), indicating that diversification away from interventions targeting amyloid-beta has not materialized. Inflammation is the second most popular target class in both preclinical and clinical development. Our observations show that the AD drug development pipeline is diversifying in terms of targets and treatment modalities, while amyloid-targeting therapies remain a prominent avenue of development as well. To further advance AD drug development, novel companion diagnostics are needed that are directed at disease mechanisms related to genetic risk factors of AD, both for patient stratification and assessment of therapeutic efficacy in clinical trials.},
  isbn = {1319502100927},
  keywords = {Geriatric Psychiatry,Geriatrics/Gerontology,Neurology,Neurosciences,Risk factors,Time-to-event analysis,Vascular dementia},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/van bokhoven et al_2021_the alzheimer’s disease drug development landscape.pdf}
}

@article{vanderplasPenguinsGoParallel2023,
  title = {Penguins {{Go Parallel}}: {{A Grammar}} of {{Graphics Framework}} for {{Generalized Parallel Coordinate Plots}}},
  shorttitle = {Penguins {{Go Parallel}}},
  author = {VanderPlas, Susan and Ge, Yawei and Unwin, Antony and Hofmann, Heike},
  year = {2023},
  month = oct,
  journal = {Journal of Computational and Graphical Statistics},
  volume = {32},
  number = {4},
  pages = {1572--1587},
  issn = {1061-8600, 1537-2715},
  doi = {10.1080/10618600.2023.2195462},
  urldate = {2023-12-29},
  abstract = {Parallel Coordinate Plots (PCP) are a valuable tool for exploratory data analysis of high-dimensional numerical data. The use of PCPs is limited when working with categorical variables or a mix of categorical and continuous variables. In this article, we propose Generalized Parallel Coordinate Plots (GPCP) to extend the ability of PCPs from just numeric variables to dealing seamlessly with a mix of categorical and numeric variables in a single plot. In this process we find that existing solutions for categorical values only, such as hammock plots or parsets become edge cases in the new framework. By focusing on individual observations rather than a marginal frequency we gain additional flexibility. The resulting approach is implemented in the R package ggpcp. Supplementary materials for this article are available online.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/P9VKETIJ/VanderPlas et al. - 2023 - Penguins Go Parallel A Grammar of Graphics Framew.pdf}
}

@article{vanderplasPenguinsGoParallel2023a,
  title = {Penguins {{Go Parallel}}: {{A Grammar}} of {{Graphics Framework}} for {{Generalized Parallel Coordinate Plots}}},
  shorttitle = {Penguins {{Go Parallel}}},
  author = {VanderPlas, Susan and Ge, Yawei and Unwin, Antony and Hofmann, Heike},
  year = {2023},
  month = oct,
  journal = {Journal of Computational and Graphical Statistics},
  volume = {32},
  number = {4},
  pages = {1572--1587},
  issn = {1061-8600, 1537-2715},
  doi = {10.1080/10618600.2023.2195462},
  urldate = {2023-12-29},
  abstract = {Parallel Coordinate Plots (PCP) are a valuable tool for exploratory data analysis of high-dimensional numerical data. The use of PCPs is limited when working with categorical variables or a mix of categorical and continuous variables. In this article, we propose Generalized Parallel Coordinate Plots (GPCP) to extend the ability of PCPs from just numeric variables to dealing seamlessly with a mix of categorical and numeric variables in a single plot. In this process we find that existing solutions for categorical values only, such as hammock plots or parsets become edge cases in the new framework. By focusing on individual observations rather than a marginal frequency we gain additional flexibility. The resulting approach is implemented in the R package ggpcp. Supplementary materials for this article are available online.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/4CSWYDYD/VanderPlas et al. - 2023 - Penguins Go Parallel A Grammar of Graphics Framew.pdf}
}

@article{vandevredeFourRepeatTauopathiesCurrent2020,
  title = {Four-{{Repeat Tauopathies}}: {{Current Management}} and {{Future Treatments}}},
  shorttitle = {Four-{{Repeat Tauopathies}}},
  author = {VandeVrede, Lawren and Ljubenkov, Peter A. and Rojas, Julio C. and Welch, Ariane E. and Boxer, Adam L.},
  year = {2020},
  month = oct,
  journal = {Neurotherapeutics: The Journal of the American Society for Experimental NeuroTherapeutics},
  volume = {17},
  number = {4},
  pages = {1563--1581},
  issn = {1878-7479},
  doi = {10.1007/s13311-020-00888-5},
  abstract = {Four-repeat tauopathies are a neurodegenerative disease characterized by brain parenchymal accumulation of a specific isoform of the protein tau, which gives rise to a wide breadth of clinical syndromes encompassing diverse symptomatology, with the most common syndromes being progressive supranuclear palsy-Richardson's and corticobasal syndrome. Despite the lack of effective disease-modifying therapies, targeted treatment of symptoms can improve quality of life for patients with 4-repeat tauopathies. However, managing these symptoms can be a daunting task, even for those familiar with the diseases, as they span motor, sensory, cognitive, affective, autonomic, and behavioral domains. This review describes current approaches to symptomatic management of common clinical symptoms in 4-repeat tauopathies with a focus on practical patient management, including pharmacologic and nonpharmacologic strategies, and concludes with a discussion of the history and future of disease-modifying therapeutics and clinical trials in this population.},
  langid = {english},
  pmcid = {PMC7851277},
  pmid = {32676851},
  keywords = {4R-tauopathy (4R-tau),atypical parkinsonism,Clinical Trials as Topic,corticobasal degeneration (CBD),corticobasal syndrome (CBS),Disease Management,Forecasting,Humans,Motor Disorders,progressive supranuclear palsy (PSP),Richardson's syndrome (PSP-RS),Tauopathies,Treatment Outcome},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/vandevrede et al_2020_four-repeat tauopathies.pdf}
}

@article{vandevredeOpenLabelPhaseFutility2020,
  title = {Open-{{Label Phase}} 1 {{Futility Studies}} of {{Salsalate}} and {{Young Plasma}} in {{Progressive Supranuclear Palsy}}},
  author = {VandeVrede, Lawren and Dale, Marian L. and Fields, Scott and Frank, Megan and Hare, Emma and Heuer, Hilary W. and Keith, Kellie and Koestler, Mary and Ljubenkov, Peter A. and McDermott, Dana and Ohanesian, Noelle and Richards, Jennifer and Rojas, Julio C. and Thijssen, Elisabeth H. and Walsh, Christine and Wang, Ping and Wolf, Amy and Quinn, Joseph F. and Tsai, Richard and Boxer, Adam L.},
  year = {2020},
  journal = {Movement Disorders Clinical Practice},
  volume = {7},
  number = {4},
  pages = {440--447},
  issn = {2330-1619},
  doi = {10.1002/mdc3.12940},
  urldate = {2024-04-23},
  abstract = {Background Progressive supranuclear palsy (PSP) is a neurodegenerative disease without approved therapies, and therapeutics are often tried off-label in the hope of slowing disease progression. Results from these experiences are seldom shared, which limits evidence-based knowledge to guide future treatment decisions. Objectives To describe an open-label experience, including safety/tolerability, and longitudinal changes in biomarkers of disease progression in PSP-Richardson's syndrome (PSP-RS) patients treated with either salsalate or young plasma and compare to natural history data from previous multicenter studies. Methods For 6 months, 10 PSP-RS patients received daily salsalate 2,250 mg, and 5 patients received monthly infusions of four units of young plasma. Every 3 months, clinical severity was assessed with the Progressive Supranuclear Palsy Rating Scale (PSPRS), and MRI was obtained for volumetric measurement of midbrain. A range of exploratory biomarkers, including cerebrospinal fluid levels of neurofilament light chain, were collected at baseline and 6 months. Interventional data were compared to historical PSP-RS patients from the davunetide clinical trial and the 4-Repeat Tauopathy Neuroimaging Initiative. Results Salsalate and young plasma were safe and well tolerated. PSPRS change from baseline (mean {\textpm} standard deviation [SD]) was similar in salsalate (+5.6 {\textpm} 9.6), young plasma (+5.0 {\textpm} 7.1), and historical controls (+5.6 {\textpm} 7.1), and change in midbrain volume (cm3 {\textpm} SD) did not differ between salsalate (--0.07 {\textpm} 0.03), young plasma (--0.06 {\textpm} 0.03), and historical controls (--0.06 {\textpm} 0.04). No differences were observed between groups on any exploratory endpoint. Conclusions Neither salsalate nor young plasma had a detectable effect on disease progression in PSP-RS. Focused open-label clinical trials incorporating historical clinical, neuropsychological, fluid, and imaging biomarkers provide useful preliminary data about the promise of novel PSP-directed therapies.},
  copyright = {{\copyright} 2020 International Parkinson and Movement Disorder Society},
  langid = {english},
  keywords = {4RTNI,progressive supranuclear palsy (PSP),PSPRS,salsalate,young plasma},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/vandevrede et al_2020_open-label phase 1 futility studies of salsalate and young plasma in.pdf;/Users/zenn/Zotero/storage/SYABZ35W/mdc3.html}
}

@article{vandevredeTargetingTauClinical2020,
  title = {Targeting Tau: {{Clinical}} Trials and Novel Therapeutic Approaches},
  shorttitle = {Targeting Tau},
  author = {VandeVrede, Lawren and Boxer, Adam L. and Polydoro, Manuela},
  year = {2020},
  month = jul,
  journal = {Neuroscience Letters},
  volume = {731},
  pages = {134919},
  issn = {1872-7972},
  doi = {10.1016/j.neulet.2020.134919},
  abstract = {Tauopathies are a group of over 20 clinicopathological neurodegenerative diseases including Alzheimer's disease (AD), the most common type of dementia, progressive supranuclear palsy, Pick's disease, corticobasal degeneration, among others. Tauopathies are defined by neurodegeneration and the presence of tau aggregates in affected brains regions. Interestingly, regional tau aggregation burden correlates with clinical phenotype and predicts cognitive status. Autosomal dominant mutations in the MAPT gene lead to tau deposition and clinical FTD syndromes with cognitive, behavioral, and motor impairment. Polymorphisms in or around the MAPT gene have also been strongly linked to other proteinopathies including synucleinopathies. Taken together these findings suggests that tau plays a critical role in neurodegeneration and proteinopathies, supporting the idea that tau targeted approaches can be disease-modifying and lead to clinically meaningful benefits in slowing or reversing disease progression. Increasingly, human clinical trials are testing this hypothesis. This article reviews tau-targeted therapies tested in clinical trials as well as agents currently in active development based on publicly disclosed information. We describe the therapeutic approaches of these trials based on the potential pathogenic mechanism they target.},
  langid = {english},
  pmcid = {PMC9212860},
  pmid = {32380145},
  keywords = {Alzheimer Disease,Alzheimer's disease,Brain,Clinical Trials as Topic,Corticobasal degeneration,Frontotemporal dementia,Frontotemporal Dementia,Humans,Parkinsonism,Pick's disease,Progressive supranuclear palsy,Tau,tau Proteins,Tauopathies},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/vandevrede et al_2020_targeting tau2.pdf}
}

@article{vandevredeTargetingTauClinical2020a,
  title = {Targeting Tau: {{Clinical}} Trials and Novel Therapeutic Approaches},
  shorttitle = {Targeting Tau},
  author = {VandeVrede, Lawren and Boxer, Adam L. and Polydoro, Manuela},
  year = {2020},
  month = jul,
  journal = {Neuroscience Letters},
  volume = {731},
  pages = {134919},
  issn = {1872-7972},
  doi = {10.1016/j.neulet.2020.134919},
  abstract = {Tauopathies are a group of over 20 clinicopathological neurodegenerative diseases including Alzheimer's disease (AD), the most common type of dementia, progressive supranuclear palsy, Pick's disease, corticobasal degeneration, among others. Tauopathies are defined by neurodegeneration and the presence of tau aggregates in affected brains regions. Interestingly, regional tau aggregation burden correlates with clinical phenotype and predicts cognitive status. Autosomal dominant mutations in the MAPT gene lead to tau deposition and clinical FTD syndromes with cognitive, behavioral, and motor impairment. Polymorphisms in or around the MAPT gene have also been strongly linked to other proteinopathies including synucleinopathies. Taken together these findings suggests that tau plays a critical role in neurodegeneration and proteinopathies, supporting the idea that tau targeted approaches can be disease-modifying and lead to clinically meaningful benefits in slowing or reversing disease progression. Increasingly, human clinical trials are testing this hypothesis. This article reviews tau-targeted therapies tested in clinical trials as well as agents currently in active development based on publicly disclosed information. We describe the therapeutic approaches of these trials based on the potential pathogenic mechanism they target.},
  langid = {english},
  pmcid = {PMC9212860},
  pmid = {32380145},
  keywords = {Alzheimer Disease,Alzheimer's disease,Brain,Clinical Trials as Topic,Corticobasal degeneration,Frontotemporal dementia,Frontotemporal Dementia,Humans,Parkinsonism,Pick's disease,Progressive supranuclear palsy,Tau,tau Proteins,Tauopathies},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/vandevrede et al_2020_targeting tau.pdf}
}

@article{vellas2012alzheimer,
  title = {Alzheimer's Disease Therapeutic Trials: {{EU}}/{{US Task Force}} Report on Recruitment, Retention, and Methodology},
  author = {Vellas, B and Hampel, H and {Roug{\'e}-Bugat}, {\relax ME} and Grundman, M and Andrieu, S and {Abu-Shakra}, S and Bateman, R and Berman, R and Black, R and Carrillo, M and others},
  year = {2012},
  journal = {The journal of nutrition, health \& aging},
  volume = {16},
  number = {4},
  pages = {339--345},
  publisher = {Springer-Verlag}
}

@article{Verbeek1985,
  title = {A Survey of Algorithms for Exact Distributions of Test Statistics In{$<$} i{$>$} R{\texttimes}{$<$} i{$>$} c Contingency Tables with Fixed Margins},
  author = {Verbeek, A and Kroonenberg, {\relax PM}},
  year = {1985},
  journal = {Computational Statistics \& Data Analysis},
  urldate = {2013-12-22},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/verbeek_kroonenberg_1985_a survey of algorithms for exact distributions of test statistics in i.pdf}
}

@article{verdeNeurofilamentLightChain2021,
  title = {Neurofilament {{Light Chain}} as {{Biomarker}} for {{Amyotrophic Lateral Sclerosis}} and {{Frontotemporal Dementia}}},
  author = {Verde, Federico and Otto, Markus and Silani, Vincenzo},
  year = {2021},
  month = jun,
  journal = {Frontiers in Neuroscience},
  volume = {15},
  publisher = {Frontiers Media S.A.},
  issn = {1662453X},
  doi = {10.3389/FNINS.2021.679199/FULL},
  urldate = {2021-11-16},
  abstract = {Amyotrophic lateral sclerosis (ALS) and frontotemporal dementia (FTD) are two related currently incurable neurodegenerative diseases. ALS is characterized by degeneration of upper and lower motor neurons causing relentless paralysis of voluntary muscles, whereas in FTD, progressive atrophy of the frontal and temporal lobes of the brain results in deterioration of cognitive functions, language, personality, and behavior. In contrast to Alzheimer's disease (AD), ALS and FTD still lack a specific neurochemical biomarker reflecting neuropathology ex vivo. However, in the past 10 years, considerable progress has been made in the characterization of neurofilament light chain (NFL) as cerebrospinal fluid (CSF) and blood biomarker for both diseases. NFL is a structural component of the axonal cytoskeleton and is released into the CSF as a consequence of axonal damage or degeneration, thus behaving in general as a relatively non-specific marker of neuroaxonal pathology. However, in ALS, the elevation of its CSF levels exceeds that observed in most other neurological diseases, making it useful for the discrimination from mimic conditions and potentially worthy of consideration for introduction into diagnostic criteria. Moreover, NFL correlates with disease progression rate and is negatively associated with survival, thus providing prognostic information. In FTD patients, CSF NFL is elevated compared with healthy individuals and, to a lesser extent, patients with other forms of dementia, but the latter difference is not sufficient to enable a satisfying diagnostic performance at individual patient level. However, also in FTD, CSF NFL correlates with several measures of disease severity. Due to technological progress, NFL can now be quantified also in peripheral blood, where it is present at much lower concentrations compared with CSF, thus allowing less invasive sampling, scalability, and longitudinal measurements. The latter has promoted innovative studies demonstrating longitudinal kinetics of NFL in presymptomatic individuals harboring gene mutations causing ALS and FTD. Especially in ALS, NFL levels are generally stable over time, which, together with their correlation with progression rate, makes NFL an ideal pharmacodynamic biomarker for therapeutic trials. In this review, we illustrate the significance of NFL as biomarker for ALS and FTD and discuss unsolved issues and potential for future developments.},
  keywords = {amyotrophic lateral sclerosis,biomarkers,cerebrospinal fluid,frontotemporal dementia,neurofilament light chain},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/verde et al_2021_neurofilament light chain as biomarker for amyotrophic lateral sclerosis and.pdf}
}

@article{vickersHowManyRepeated2003,
  title = {How Many Repeated Measures in Repeated Measures Designs? {{Statistical}} Issues for Comparative Trials},
  shorttitle = {How Many Repeated Measures in Repeated Measures Designs?},
  author = {Vickers, Andrew J.},
  year = {2003},
  month = oct,
  journal = {BMC Medical Research Methodology},
  volume = {3},
  number = {1},
  pages = {22},
  issn = {1471-2288},
  doi = {10.1186/1471-2288-3-22},
  urldate = {2023-08-29},
  abstract = {In many randomized and non-randomized comparative trials, researchers measure a continuous endpoint repeatedly in order to decrease intra-patient variability and thus increase statistical power. There has been little guidance in the literature as to selecting the optimal number of repeated measures.},
  keywords = {Chronic Postoperative Pain,Decrease Sample Size,Marginal Benefit,Repeat Assessment,Repeat Measure Design},
  file = {/Users/zenn/Zotero/storage/362SESQ2/Vickers - 2003 - How many repeated measures in repeated measures de.pdf;/Users/zenn/Zotero/storage/N5N4CYS4/1471-2288-3-22.html}
}

@article{vihinenNoMoreHidden2015,
  title = {No More Hidden Solutions in Bioinformatics},
  author = {Vihinen, Mauno},
  year = {2015},
  month = may,
  journal = {Nature},
  volume = {521},
  number = {7552},
  pages = {261},
  publisher = {Nature Publishing Group},
  issn = {14764687},
  doi = {10.1038/521261A},
  urldate = {2022-06-09},
  pmid = {25993922},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/vihinen_2015_no more hidden solutions in bioinformatics.pdf}
}

@article{Vila-castelar2020,
  title = {The {{Latin American Spanish}} Version of the {{Face-Name Associative Memory Exam}} Is Sensitive to Cognitive and Pathological Changes in Preclinical Autosomal Dominant {{Alzheimer}} ' s Disease},
  author = {{Vila-castelar}, Clara and Mu{\~n}oz, Nathalia and Papp, Kathryn V and Amariglio, Rebecca E and Baena, Ana and {Guzm{\'a}n-v{\'e}lez}, Edmarie and Bocanegra, Yamile and Sanchez, Justin S and Reiman, Eric M and Johnson, Keith A and Sperling, Reisa A and Lopera, Francisco and Rentz, Dorene M and Quiroz, Yakeel T},
  year = {2020},
  journal = {Alzheimer's Research \& therapy},
  pages = {1--11},
  publisher = {Alzheimer's Research \& Therapy},
  keywords = {alzheimer,Alzheimer's disease,associative memory,Associative memory,autosomal dominant alzheimer,Autosomal dominant Alzheimer's disease,Imaging,neuropsychology,Neuropsychology,PET,s disease},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/vila-castelar et al_2020_the latin american spanish version of the face-name associative memory exam is.pdf}
}

@article{vila-castelarSexDifferencesCognitive2022a,
  title = {Sex Differences in Cognitive Resilience in Preclinical Autosomal-Dominant {{Alzheimer}}'s Disease Carriers and Non-Carriers: {{Baseline}} Findings from the {{API ADAD Colombia Trial}}},
  shorttitle = {Sex Differences in Cognitive Resilience in Preclinical Autosomal-Dominant {{Alzheimer}}'s Disease Carriers and Non-Carriers},
  author = {{Vila-Castelar}, Clara and Tariot, Pierre N. and Sink, Kaycee M. and Clayton, David and Langbaum, Jessica B. and Thomas, Ronald G. and Chen, Yinghua and Su, Yi and Chen, Kewei and Hu, Nan and {Giraldo-Chica}, Margarita and Tob{\'o}n, Carlos and {Acosta-Baena}, Natalia and Luna, Ernesto and Londo{\~n}o, Marisol and Ospina, Paula and Tirado, Victoria and Mu{\~n}oz, Claudia and Henao, Eliana and Bocanegra, Yamile and Alvarez, Sergio and {Rios-Romenets}, Silvia and Ghisays, Valentina and Goradia, Dhruman and Lee, Wendy and Luo, Ji and {Malek-Ahmadi}, Michael H. and Protas, Hillary D. and Lopera, Francisco and Reiman, Eric M. and Quiroz, Yakeel T. and {API ADAD Colombia Trial Group}},
  year = {2022},
  month = nov,
  journal = {Alzheimer's \& Dementia: The Journal of the Alzheimer's Association},
  volume = {18},
  number = {11},
  pages = {2272--2282},
  issn = {1552-5279},
  doi = {10.1002/alz.12552},
  abstract = {INTRODUCTION: Females may have greater susceptibility to Alzheimer's disease (AD)-pathology. We examined the effect of sex on pathology, neurodegeneration, and memory in cognitively-unimpaired Presenilin-1 (PSEN1) E280A mutation carriers and non-carriers. METHODS: We analyzed baseline data from 167 mutation carriers and 75 non-carriers (ages 30 to 53) from the Alzheimer's Prevention Initiative Autosomal Dominant AD Trial, including florbetapir- and fludeoxyglucose-PET, MRI based hippocampal volume and cognitive testing. RESULTS: Females exhibited better delayed recall than males, controlling for age, precuneus glucose metabolism, and mutation status, although the effect was not significant among PSEN1 mutation carriers only. APOE {$\epsilon$}4 did not modify the effect of sex on AD biomarkers and memory. DISCUSSION: Our findings suggest that, among cognitively-unimpaired individuals at genetic risk for autosomal-dominant AD, females may have greater cognitive resilience to AD pathology and neurodegeneration than males. Further investigation of sex-specific differences in autosomal-dominant AD is key to elucidating mechanisms of AD risk and resilience.},
  langid = {english},
  pmcid = {PMC9339586},
  pmid = {35103388},
  keywords = {Adult,Alzheimer Disease,Alzheimer's disease,autosomal-dominant Alzheimer's disease,cognition,Cognition,Colombia,Female,Humans,Male,Middle Aged,neurodegeneration,Neuropsychological Tests,pathology,preclinical,Presenilin-1,Sex Characteristics,sex differences}
}

@article{vila2020sex,
  title = {Sex Differences in Neurodegeneration and Memory Performance in Preclinical Autosomal Dominant {{Alzheimer}}'s Disease: {{Baseline}} Findings from the {{API ADAD}} Trial: {{Intersections}} of Sex/Gender and Race/Ethnicity in Cognitive Aging and {{Alzheimer}}'s Disease Trajectories},
  author = {{Vila-Castelar}, Clara and Tariot, Pierre N and Sink, Kaycee M and Clayton, David and Langbaum, Jessica B and Thomas, Ronald G and Chen, Yinghua and Su, Yi and Hu, Nan and {Giraldo-Chica}, Margarita and others},
  year = {2020},
  journal = {Alzheimer's \& Dementia},
  volume = {16},
  pages = {e041225}
}

@article{vila2022sex,
  title = {Sex Differences in Cognitive Resilience in Preclinical Autosomal-Dominant {{Alzheimer}}'s Disease Carriers and Non-Carriers: {{Baseline}} Findings from the {{API ADAD Colombia Trial}}},
  author = {{Vila-Castelar}, Clara and Tariot, Pierre N and Sink, Kaycee M and Clayton, David and Langbaum, Jessica B and Thomas, Ronald G and Chen, Yinghua and Su, Yi and Chen, Kewei and Hu, Nan and others},
  year = {2022},
  journal = {Alzheimer's \& Dementia}
}

@misc{VisualizationBrainStatistics,
  title = {Visualization of {{Brain Statistics With R Packages}} Ggseg and Ggseg3d},
  doi = {10.1177/2515245920928009},
  urldate = {2024-04-17},
  howpublished = {https://journals.sagepub.com/doi/epub/10.1177/2515245920928009},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/E9IAEK4Y/Visualization of Brain Statistics With R Packages .pdf;/Users/zenn/Zotero/storage/5UHGBBCN/2515245920928009.html}
}

@article{vivashSodiumSelenateDiseasemodifying2021,
  title = {Sodium Selenate as a Disease-Modifying Treatment for Progressive Supranuclear Palsy: Protocol for a Phase 2, Randomised, Double-Blind, Placebo-Controlled Trial},
  shorttitle = {Sodium Selenate as a Disease-Modifying Treatment for Progressive Supranuclear Palsy},
  author = {Vivash, Lucy and Bertram, Kelly L. and Malpas, Charles B. and Marotta, Cassandra and Harding, Ian H. and Kolbe, Scott and Fielding, Joanne and Clough, Meaghan and Lewis, Simon J. G. and Tisch, Stephen and Evans, Andrew H. and O'Sullivan, John D. and Kimber, Thomas and Darby, David and Churilov, Leonid and Law, Meng and Hovens, Christopher M. and Velakoulis, Dennis and O'Brien, Terence J.},
  year = {2021},
  month = dec,
  journal = {BMJ open},
  volume = {11},
  number = {12},
  pages = {e055019},
  issn = {2044-6055},
  doi = {10.1136/bmjopen-2021-055019},
  abstract = {INTRODUCTION: Progressive supranuclear palsy (PSP) is a neurodegenerative disorder for which there are currently no disease-modifying therapies. The neuropathology of PSP is associated with the accumulation of hyperphosphorylated tau in the brain. We have previously shown that protein phosphatase 2 activity in the brain is upregulated by sodium selenate, which enhances dephosphorylation. Therefore, the objective of this study is to evaluate the efficacy and safety of sodium selenate as a disease-modifying therapy for PSP. METHODS AND ANALYSIS: This will be a multi-site, phase 2b, double-blind, placebo-controlled trial of sodium selenate. 70 patients will be recruited at six Australian academic hospitals and research institutes. Following the confirmation of eligibility at screening, participants will be randomised (1:1) to receive 52 weeks of active treatment (sodium selenate; 15\,mg three times a day) or matching placebo. Regular safety and efficacy visits will be completed throughout the study period. The primary study outcome is change in an MRI volume composite (frontal lobe+midbrain-3rd ventricle) over the treatment period. Analysis will be with a general linear model (GLM) with the MRI composite at 52 weeks as the dependent variable, treatment group as an independent variable and baseline MRI composite as a covariate. Secondary outcomes are change in PSP rating scale, clinical global impression of change (clinician) and change in midbrain mean diffusivity. These outcomes will also be analysed with a GLM as above, with the corresponding baseline measure entered as a covariate. Secondary safety and tolerability outcomes are frequency of serious adverse events, frequency of down-titration occurrences and frequency of study discontinuation. Additional, as yet unplanned, exploratory outcomes will include analyses of other imaging, cognitive and biospecimen measures. ETHICS AND DISSEMINATION: The study was approved by the Alfred Health Ethics Committee (594/20). Each participant or their legally authorised representative and their study partner will provide written informed consent at trial commencement. The results of the study will be presented at national and international conferences and published in peer-reviewed journals. TRIAL REGISTRATION NUMBER: Australian New Zealand Clinical Trials Registry (ACTRN12620001254987).},
  langid = {english},
  pmcid = {PMC8679117},
  pmid = {34916328},
  keywords = {Australia,clinical trials,Clinical Trials Phase II as Topic,Double-Blind Method,Humans,neurology,Parkinson's disease,Randomized Controlled Trials as Topic,Selenic Acid,Supranuclear Palsy Progressive,Treatment Outcome},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/vivash et al_2021_sodium selenate as a disease-modifying treatment for progressive supranuclear2.pdf}
}

@article{vivashSodiumSelenateDiseasemodifying2021a,
  title = {Sodium Selenate as a Disease-Modifying Treatment for Progressive Supranuclear Palsy: Protocol for a Phase 2, Randomised, Double-Blind, Placebo-Controlled Trial},
  shorttitle = {Sodium Selenate as a Disease-Modifying Treatment for Progressive Supranuclear Palsy},
  author = {Vivash, Lucy and Bertram, Kelly L. and Malpas, Charles B. and Marotta, Cassandra and Harding, Ian H. and Kolbe, Scott and Fielding, Joanne and Clough, Meaghan and Lewis, Simon J. G. and Tisch, Stephen and Evans, Andrew H. and O'Sullivan, John D. and Kimber, Thomas and Darby, David and Churilov, Leonid and Law, Meng and Hovens, Christopher M. and Velakoulis, Dennis and O'Brien, Terence J.},
  year = {2021},
  month = dec,
  journal = {BMJ open},
  volume = {11},
  number = {12},
  pages = {e055019},
  issn = {2044-6055},
  doi = {10.1136/bmjopen-2021-055019},
  abstract = {INTRODUCTION: Progressive supranuclear palsy (PSP) is a neurodegenerative disorder for which there are currently no disease-modifying therapies. The neuropathology of PSP is associated with the accumulation of hyperphosphorylated tau in the brain. We have previously shown that protein phosphatase 2 activity in the brain is upregulated by sodium selenate, which enhances dephosphorylation. Therefore, the objective of this study is to evaluate the efficacy and safety of sodium selenate as a disease-modifying therapy for PSP. METHODS AND ANALYSIS: This will be a multi-site, phase 2b, double-blind, placebo-controlled trial of sodium selenate. 70 patients will be recruited at six Australian academic hospitals and research institutes. Following the confirmation of eligibility at screening, participants will be randomised (1:1) to receive 52 weeks of active treatment (sodium selenate; 15\,mg three times a day) or matching placebo. Regular safety and efficacy visits will be completed throughout the study period. The primary study outcome is change in an MRI volume composite (frontal lobe+midbrain-3rd ventricle) over the treatment period. Analysis will be with a general linear model (GLM) with the MRI composite at 52 weeks as the dependent variable, treatment group as an independent variable and baseline MRI composite as a covariate. Secondary outcomes are change in PSP rating scale, clinical global impression of change (clinician) and change in midbrain mean diffusivity. These outcomes will also be analysed with a GLM as above, with the corresponding baseline measure entered as a covariate. Secondary safety and tolerability outcomes are frequency of serious adverse events, frequency of down-titration occurrences and frequency of study discontinuation. Additional, as yet unplanned, exploratory outcomes will include analyses of other imaging, cognitive and biospecimen measures. ETHICS AND DISSEMINATION: The study was approved by the Alfred Health Ethics Committee (594/20). Each participant or their legally authorised representative and their study partner will provide written informed consent at trial commencement. The results of the study will be presented at national and international conferences and published in peer-reviewed journals. TRIAL REGISTRATION NUMBER: Australian New Zealand Clinical Trials Registry (ACTRN12620001254987).},
  langid = {english},
  pmcid = {PMC8679117},
  pmid = {34916328},
  keywords = {Australia,clinical trials,Clinical Trials Phase II as Topic,Double-Blind Method,Humans,neurology,Parkinson's disease,Randomized Controlled Trials as Topic,Selenic Acid,Supranuclear Palsy Progressive,Treatment Outcome},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/vivash et al_2021_sodium selenate as a disease-modifying treatment for progressive supranuclear.pdf}
}

@article{waegemanScalabilityOrderedMulticlass2008,
  title = {On the Scalability of Ordered Multi-Class {{ROC}} Analysis},
  author = {Waegeman, Willem and De Baets, Bernard and Boullart, Luc},
  year = {2008},
  journal = {Computational Statistics \& Data Analysis},
  volume = {52},
  number = {7},
  pages = {3371--3388},
  publisher = {Elsevier},
  urldate = {2024-06-21}
}

@article{wagesContinualReassessmentMethod2011,
  title = {Continual {{Reassessment Method}} for {{Partial Ordering}}},
  author = {Wages, Nolan A. and Conaway, Mark R. and O'Quigley, John},
  year = {2011},
  month = dec,
  journal = {Biometrics},
  volume = {67},
  number = {4},
  pages = {1555--1563},
  issn = {0006-341X},
  doi = {10.1111/j.1541-0420.2011.01560.x},
  urldate = {2024-03-19},
  abstract = {Much of the statistical methodology underlying the experimental design of phase 1 trials in oncology is intended for studies involving a single cytotoxic agent. The goal of these studies is to estimate the maximally tolerated dose, the highest dose that can be administered with an acceptable level of toxicity. A fundamental assumption of these methods is monotonicity of the dose--toxicity curve. This is a reasonable assumption for single-agent trials in which the administration of greater doses of the agent can be expected to produce dose-limiting toxicities in increasing proportions of patients. When studying multiple agents, the assumption may not hold because the ordering of the toxicity probabilities could possibly be unknown for several of the available drug combinations. At the same time, some of the orderings are known and so we describe the whole situation as that of a partial ordering. In this article, we propose a new two-dimensional dose-finding method for multiple-agent trials that simplifies to the continual reassessment method (CRM), introduced by O'Quigley, Pepe, and Fisher (1990, Biometrics ~46, 33--48), when the ordering is fully known. This design enables us to relax the assumption of a monotonic dose--toxicity curve. We compare our approach and some simulation results to a CRM design in which the ordering is known as well as to other suggestions for partial orders.},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/wages et al_2011_continual reassessment method for partial ordering.pdf;/Users/zenn/Zotero/storage/FPL7ZLVJ/7381144.html}
}

@article{waleedDesignConsiderationsIncorporating2021,
  title = {Some Design Considerations Incorporating Early Futility for {\textsc{Single-arm}} Clinical Trials with Time-to-event Primary Endpoints Using {{Weibull}} Distribution},
  shorttitle = {Some Design Considerations Incorporating Early Futility For},
  author = {Waleed, Muhammad and He, Jianghua and Phadnis, Milind A.},
  year = {2021},
  month = may,
  journal = {Pharmaceutical Statistics},
  volume = {20},
  number = {3},
  pages = {610--644},
  issn = {1539-1604, 1539-1612},
  doi = {10.1002/pst.2097},
  urldate = {2023-04-14},
  abstract = {Sample size calculation is an essential component of the planning phase of a clinical trial. In the context of single-arm clinical trials with time-to-event (TTE) endpoints, only a few options with limited design features are available. Motivated from ethical or practical considerations, two-stage designs are implemented for single-arm studies to obtain early evidence of futility. A major drawback of such designs is that early stopping may only occur at the conclusion of the first stage, even if lack of efficacy becomes apparent at any other time point over the course of the clinical trial. In this manuscript, we attempt to fill some existing gaps in the literature related to single-arm clinical trials with TTE endpoints. We propose a parametric maximum likelihood estimatebased test whose variance component accounts for the expected proportion of loss to follow-up and different accrual patterns (early, late, or uniform accrual). For the proposed method, we present three stochastic curtailment methods (conditional power, predictive power, Bayesian predictive probability) which can be employed for efficacy or futility testing purposes. Finally, we discuss the implementation of group sequential designs for obtaining an early evidence of efficacy or futility at pre-planned timings of interim analyses. Through extensive simulations, it is shown that our proposed method performs well for designing these studies with moderate to large sample sizes. Some examples are presented to demonstrate various aspects of the stochastic curtailment and repeated significance testing methods presented in this manuscript.},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/waleed et al_2021_some design considerations incorporating early futility for span.pdf}
}

@article{walkerConditionalPowerAid2018,
  title = {Conditional Power as an Aid in Making Interim Decisions in Observational Studies},
  author = {Walker, Alexander Muir},
  year = {2018},
  month = sep,
  journal = {European Journal of Epidemiology},
  volume = {33},
  number = {9},
  pages = {777--784},
  publisher = {Springer Netherlands},
  issn = {15737284},
  doi = {10.1007/S10654-018-0413-9/TABLES/2},
  urldate = {2022-01-30},
  abstract = {Conditional power combines the findings of a partially completed study with assumptions about the future. The goal is to estimate the probability that the eventual study result will be incompatible with a criterion value, such as acceptable risk or the null hypothesis. Some history and motivation for conditional power calculations are provided, with examples illustrating the application to drug safety studies. This is an expository article suggesting that conditional power, which is well-established in clinical trials research, also has application to observational studies. The utility may be highest in regulatory settings where resources are limited and interim decisions have to be made accurately in the shortest possible time.},
  pmid = {29808341},
  keywords = {Curtailed testing,Stochastic curtailment,Study management,Unplanned termination},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/walker_2018_conditional power as an aid in making interim decisions in observational studies.pdf}
}

@article{walterProbabilityDensityEstimation1979,
  title = {Probability {{Density Estimation Using Delta Sequences}}},
  author = {Walter, G. and Blum, J.},
  year = {1979},
  journal = {The Annals of Statistics},
  volume = {7},
  number = {2},
  eprint = {2958814},
  eprinttype = {jstor},
  pages = {328--340},
  publisher = {Institute of Mathematical Statistics},
  issn = {0090-5364},
  urldate = {2023-03-01},
  abstract = {Let X1, X2, {$\cdots$}, Xn be i.i.d. random variables with common density function f. A method of density estimation based on "delta sequences" is studied and mean square rates established. This method generalizes certain others including kernel estimators, orthogonal series estimators, Fourier transform estimators, and the histogram. Rates are obtained for densities in Sobolev spaces and for densities satisfying Lipschitz conditions. The former generalizes some results of Wahba who also showed the rates obtained are the best possible. The rates obtained in the latter case have been shown to be the best possible by Farrell. This is shown independently by giving examples for which the rates are exact. Finally, a necessary and sufficient condition for asymptotic unbiasedness for continuous densities is given.},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/walter_blum_1979_probability density estimation using delta sequences.pdf}
}

@article{Wang2007,
  title = {Statistics in {{Medicine}} --- {{Reporting}} of {{Subgroup Analyses}} in {{Clinical Trials}}},
  author = {Wang, Rui and Lagakos, Stephen W. and Ware, James H. and Hunter, David J. and Drazen, Jeffrey M.},
  year = {2007},
  month = oct,
  journal = {New England Journal of Medicine},
  volume = {357},
  number = {21},
  pages = {2189--2194},
  publisher = {Massachusetts Medical Society},
  issn = {0028-4793},
  doi = {10.1056/nejmsr077003},
  urldate = {2021-08-03},
  abstract = {The analysis of subgroups is often used as a way to glean additional information from data sets. The strengths and weaknesses of this approach and new Journal policies concerning the reporting of subgroup analyses are discussed in this article.},
  pmid = {18032770},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/wang et al_2007_statistics in medicine — reporting of subgroup analyses in clinical trials.pdf}
}

@article{wangAccurateUltraEfficientPValue2023,
  title = {Accurate and {{Ultra-Efficient}} p-{{Value Calculation}} for {{Higher Criticism Tests}}},
  author = {Wang, Wenjia and Fang, Yusi and Chang, Chung and Tseng, George C.},
  year = {2023},
  journal = {Journal of Computational and Graphical Statistics},
  volume = {0},
  number = {0},
  pages = {1--14},
  publisher = {Taylor \& Francis},
  issn = {1061-8600},
  doi = {10.1080/10618600.2023.2270720},
  urldate = {2023-12-15},
  abstract = {In modern data science, higher criticism (HC) method is effective for detecting rare and weak signals. The computation, however, has long been an issue when the number of p-values combined (K) and/or the number of repeated HC tests (N) are large. Some computing methods have been developed, but they all have significant shortcomings, especially when a stringent significance level is required. In this article, we propose an accurate and highly efficient computing strategy for four variations of HC. Specifically, we propose an unbiased cross-entropy-based importance sampling method (ISCE) to benchmark all existing computing methods, and develop a modified SetTest method (MST) that resolves numerical issues of the existing SetTest approach. We further develop an ultra-fast approach (UFI) combining pre-calculated statistical tables and cubic spline interpolation. Finally, following extensive simulations, we provide a computing strategy integrating MST, UFI, and other existing methods with R package ``HCp'' for virtually any K and small p-values ({$\sim$}10-20). The method is applied to a COVID-19 disease surveillance example for spatio-temporal outbreak detection from case numbers of 804 days in 3342 counties in the United States. Results confirm viability of the computing strategy for large-scale inferences. Supplementary materials for this article are available online.},
  keywords = {Analytical approximation,Asymptotic rare and weak model,Higher criticism,Importance sampling,p-value computation},
  file = {/Users/zenn/Zotero/storage/PFMSU4R4/Wang et al. - 2023 - Accurate and Ultra-Efficient p-Value Calculation f.pdf}
}

@article{wangAnalysisCovarianceRandomized2019,
  title = {Analysis of Covariance in Randomized Trials: {{More}} Precision and Valid Confidence Intervals, without Model Assumptions},
  shorttitle = {Analysis of Covariance in Randomized Trials},
  author = {Wang, Bingkai and Ogburn, Elizabeth L. and Rosenblum, Michael},
  year = {2019},
  journal = {Biometrics},
  volume = {75},
  number = {4},
  pages = {1391--1400},
  issn = {1541-0420},
  doi = {10.1111/biom.13062},
  urldate = {2023-05-06},
  abstract = {``Covariate adjustment'' in the randomized trial context refers to an estimator of the average treatment effect that adjusts for chance imbalances between study arms in baseline variables (called ``covariates''). The baseline variables could include, for example, age, sex, disease severity, and biomarkers. According to two surveys of clinical trial reports, there is confusion about the statistical properties of covariate adjustment. We focus on the analysis of covariance (ANCOVA) estimator, which involves fitting a linear model for the outcome given the treatment arm and baseline variables, and trials that use simple randomization with equal probability of assignment to treatment and control. We prove the following new (to the best of our knowledge) robustness property of ANCOVA to arbitrary model misspecification: Not only is the ANCOVA point estimate consistent (as proved by Yang and Tsiatis, 2001) but so is its standard error. This implies that confidence intervals and hypothesis tests conducted as if the linear model were correct are still asymptotically valid even when the linear model is arbitrarily misspecified, for example, when the baseline variables are nonlinearly related to the outcome or there is treatment effect heterogeneity. We also give a simple, robust formula for the variance reduction (equivalently, sample size reduction) from using ANCOVA. By reanalyzing completed randomized trials for mild cognitive impairment, schizophrenia, and depression, we demonstrate how ANCOVA can achieve variance reductions of 4 to 32\%.},
  langid = {english},
  keywords = {imbalance,relative efficiency,robustness},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/wang et al_2019_analysis of covariance in randomized trials.pdf;/Users/zenn/Zotero/storage/XBU67QF4/biom.html}
}

@article{wangNovelCognitiveDisease2018,
  title = {A Novel Cognitive Disease Progression Model for Clinical Trials in Autosomal-Dominant {{Alzheimer}}'s Disease},
  author = {Wang, Guoqiao and Berry, Scott and Xiong, Chengjie and Hassenstab, Jason and Quintana, Melanie and McDade, Eric M. and Delmar, Paul and Vestrucci, Matteo and Sethuraman, Gopalan and Bateman, Randall J. and Unit, For the Dominantly Inherited Alzheimer Network Trials},
  year = {2018},
  journal = {Statistics in Medicine},
  volume = {37},
  number = {21},
  pages = {3047--3055},
  issn = {1097-0258},
  doi = {10.1002/sim.7811},
  urldate = {2023-01-13},
  abstract = {Clinical trial outcomes for Alzheimer's disease are typically analyzed by using the mixed model for repeated measures (MMRM) or similar models that compare an efficacy scale change from baseline between treatment arms with or without participants' disease stage as a covariate. The MMRM focuses on a single-point fixed follow-up duration regardless of the exposure for each participant. In contrast to these typical models, we have developed a novel semiparametric cognitive disease progression model (DPM) for autosomal dominant Alzheimer's disease based on the Dominantly Inherited Alzheimer Network (DIAN) observational study. This model includes 3 novel features, in which the DPM (1) aligns and compares participants by disease stage, (2) uses a proportional treatment effect similar to the concept of the Cox proportional hazard ratio, and (3) incorporates extended follow-up data from participants with different follow-up durations using all data until last participant visit. We present the DPM model developed by using the DIAN observational study data and demonstrate through simulation that the cognitive DPM used in hypothetical intervention clinical trials produces substantial gains in power compared with the MMRM.},
  langid = {english},
  keywords = {Alzheimer's disease,disease progression model,mixed effects model for repeated measures,proportional treatment effect},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/wang et al_2018_a novel cognitive disease progression model for clinical trials in.pdf;/Users/zenn/Zotero/storage/33W6TI7P/sim.html}
}

@article{wangOptimalConfidenceIntervals2023,
  title = {Optimal Confidence Intervals for the Relative Risk and Odds Ratio},
  author = {Wang, Weizhen and Lu, Shuiyun and Xie, Tianfa},
  year = {2023},
  journal = {Statistics in Medicine},
  volume = {42},
  number = {3},
  pages = {281--296},
  issn = {1097-0258},
  doi = {10.1002/sim.9617},
  urldate = {2023-07-21},
  abstract = {The relative risk and odds ratio are widely used in many fields, including biomedical research, to compare two treatments. Extensive research has been done to infer the two parameters through approximate or exact confidence intervals. However, these intervals may be liberal or conservative. A natural question is whether the intervals can be further improved in maintaining the correct confidence coefficient of an approximate interval or shortening an exact but conservative interval. In this article, when two independent binomials are observed we offer an effort to improve any of the existing intervals by applying the h{\textbackslash} h {\textbackslash}-function method. In particular, if the given interval is approximate, then the improved interval is exact; if the given interval is exact, then the improved interval is a subset of the given interval. This method is also applied multiple times to the improved intervals until the final resultant interval cannot be shortened any further. To demonstrate the effectiveness of the method, we use three real datasets to illustrate in detail how several good intervals in practice are improved. Two exact intervals are then recommended for estimating each of the two parameters in different scenarios.},
  langid = {english},
  keywords = {binomial distribution,infimum coverage probability,interval length,subset,the h$ h $-function method}
}

@article{wangPowerDesignIssues2019,
  title = {Power and {{Design Issues}} in {{Crossover-Based N-Of-1 Clinical Trials}} with {{Fixed Data Collection Periods}}},
  author = {Wang, Yanpin and Schork, Nicholas J.},
  year = {2019},
  month = sep,
  journal = {Healthcare},
  volume = {7},
  number = {3},
  pages = {84},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2227-9032},
  doi = {10.3390/healthcare7030084},
  urldate = {2023-12-13},
  abstract = {``N-of-1,'' or single subject, clinical trials seek to determine if an intervention strategy is more efficacious for an individual than an alternative based on an objective, empirical, and controlled study. The design of such trials is typically rooted in a simple crossover strategy with multiple intervention response evaluation periods. The effect of serial correlation between measurements, the number of evaluation periods, the use of washout periods, heteroscedasticity (i.e., unequal variances among responses to the interventions) and intervention-associated carry-over phenomena on the power of such studies is crucially important for putting the yield and feasibility of N-of-1 trial designs into context. We evaluated the effect of these phenomena on the power of different designs for N-of-1 trials using analytical theory based on standard likelihood principles assuming an autoregressive lag 1, i.e., AR(1), serial correlation structure among the measurements as well as simulation studies. By evaluating the power to detect effects in many different settings, we show that the influence of serial correlation and heteroscedasticity on power can be substantial, but can also be mitigated to some degree through the use of appropriate multiple evaluation periods. We also show that the detection of certain types of carry-over effects can be heavily influenced by design considerations as well.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {Efficacy,human clinical studies,interventions,linear models},
  file = {/Users/zenn/Zotero/storage/BLUIW8UX/Wang and Schork - 2019 - Power and Design Issues in Crossover-Based N-Of-1 .pdf}
}

@article{wangProportionalConstrainedLongitudinal2022,
  title = {Proportional Constrained Longitudinal Data Analysis Models for Clinical Trials in Sporadic {{Alzheimer}}'s Disease},
  author = {Wang, Guoqiao and Liu, Lei and Li, Yan and Aschenbrenner, Andrew J. and Bateman, Randall J. and Delmar, Paul and Schneider, Lon S. and Kennedy, Richard E. and Cutter, Gary R. and Xiong, Chengjie},
  year = {2022},
  month = jan,
  journal = {Alzheimer's \& Dementia: Translational Research \& Clinical Interventions},
  volume = {8},
  number = {1},
  issn = {2352-8737, 2352-8737},
  doi = {10.1002/trc2.12286},
  urldate = {2022-10-19},
  abstract = {Introduction: Clinical trials for sporadic Alzheimer's disease generally use mixed models for repeated measures (MMRM) or, to a lesser degree, constrained longitudinal data analysis models (cLDA) as the analysis model with time since baseline as a categorical variable. Inferences using MMRM/cLDA focus on the between-group contrast at the pre-determined, end-of-study assessments, thus are less efficient (eg, less power).},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/wang et al_2022_proportional constrained longitudinal data analysis models for clinical trials.pdf}
}

@article{wangRandomizationbasedInferenceChoice2019,
  title = {Randomization-Based Inference and the Choice of Randomization Procedures},
  author = {Wang, Yanying and Rosenberger, William F. and Uschner, Diane},
  year = {2019},
  month = apr,
  journal = {Statistical Papers},
  volume = {60},
  number = {2},
  pages = {395--404},
  issn = {0932-5026, 1613-9798},
  doi = {10.1007/s00362-018-01070-y},
  urldate = {2023-12-15},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/IN3ZP8ZB/Wang et al. - 2019 - Randomization-based inference and the choice of ra.pdf;/Users/zenn/Zotero/storage/FMIM3LYB/s00362-018-01070-y.html}
}

@article{wangRandomizationBasedInterval2020,
  title = {Randomization-based Interval Estimation in Randomized Clinical Trials},
  author = {Wang, Yanying and Rosenberger, William F.},
  year = {2020},
  month = sep,
  journal = {Statistics in Medicine},
  volume = {39},
  number = {21},
  pages = {2843--2854},
  issn = {0277-6715, 1097-0258},
  doi = {10.1002/sim.8577},
  urldate = {2023-12-15},
  abstract = {Abstract             Randomization-based interval estimation takes into account the particular randomization procedure in the analysis and preserves the confidence level even in the presence of heterogeneity. It is distinguished from population-based confidence intervals with respect to three aspects: definition, computation, and interpretation. The article contributes to the discussion of how to construct a confidence interval for a treatment difference from randomization tests when analyzing data from randomized clinical trials. The discussion covers (i) the definition of a confidence interval for a treatment difference in randomization-based inference, (ii) computational algorithms for efficiently approximating the endpoints of an interval, and (iii) evaluation of statistical properties (ie, coverage probability and interval length) of randomization-based and population-based confidence intervals under a selected set of randomization procedures when assuming heterogeneity in patient outcomes. The method is illustrated with a case study.},
  langid = {english}
}

@article{wangRandomizationTestsMultiarmed2020,
  title = {Randomization Tests for Multiarmed Randomized Clinical Trials},
  author = {Wang, Yanying and Rosenberger, William F. and Uschner, Diane},
  year = {2020},
  month = feb,
  journal = {Statistics in Medicine},
  volume = {39},
  number = {4},
  pages = {494--509},
  issn = {0277-6715, 1097-0258},
  doi = {10.1002/sim.8418},
  urldate = {2023-12-15},
  abstract = {We examine the use of randomization-based inference for analyzing multiarmed randomized clinical trials, including the application of conditional randomization tests to multiple comparisons. The view is taken that the linkage of the statistical test to the experimental design (randomization procedure) should be recognized. A selected collection of randomization procedures generalized to multiarmed treatment allocation is summarized, and generalizations for two randomization procedures that heretofore were designed for only two treatments are developed. We explain the process of computing the randomization test and conditional randomization test via Monte Carlo simulation, developing an efficient algorithm that makes multiple comparisons possible that would not be possible using a standard algorithm, demonstrate the preservation of type I error rate, and explore the relationship of statistical power to the randomization procedure in the presence of a time trend and outliers. We distinguish between the interpretation of the               p               -value in the randomization test and in the population test and verify that the randomization test can be approximated by the population test on some occasions. Data from two multiarmed clinical trials from the literature are reanalyzed to illustrate the methodology.},
  langid = {english}
}

@article{wangStatisticalConsiderationsDelayedstart2019,
  title = {Statistical Considerations in a Delayed-Start Design to Demonstrate Disease Modification Effect in Neurodegenerative Disorders},
  author = {Wang, Deli and Robieson, Weining and Zhao, Jun and Wiener, Catherine and Koch, Gary},
  year = {2019},
  month = jul,
  journal = {Pharmaceutical Statistics},
  volume = {18},
  number = {4},
  pages = {407--419},
  publisher = {{John Wiley and Sons Ltd}},
  issn = {15391612},
  doi = {10.1002/PST.1931},
  urldate = {2022-07-19},
  abstract = {There has been a paradigm shift in diagnostic conceptualization of Alzheimer's disease (AD) based on the current evidence suggesting that structure and biology changes start to occur before clinical symptoms emerge. Consequently, therapeutic drug development is also shifting to treat early AD patients using biomarkers for enrichment in clinical trials. A similar paradigm shift is occurring for Parkinson disease. In the absence of acceptable biomarkers that could be combined with a clinical endpoint to demonstrate a disease modification (DM) effect in neurodegenerative disorders, a delayed-start design can be applied to demonstrate a lasting effect on the disease course. The delayed-start design includes two treatment periods, where in period 1, patients are randomized to receive an active treatment or placebo, and in period 2, placebo patients are switched to the active treatment while patients in the active treatment arm will continue the same treatment. The hypothesis is that patients who start the active treatment later will fail to catch up to the treatment benefit achieved by patients who receive the active treatment in both periods. A usual analytical approach has sought to demonstrate the divergence of slope during period 1 and the parallelism of slopes during period 2 as the DM effect. However, due to heterogeneity in timing and the magnitude of maximal effect among patients, nonlinear response over time could be observed within the two treatment arms in both periods. We propose an approach to evaluate the DM effect with the linearity assumption for treatment differences, but not for each arm separately.},
  pmid = {30697912},
  keywords = {delayed-start analysis,disease modification,neurogenerative disorders},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/wang et al_2019_statistical considerations in a delayed-start design to demonstrate disease.pdf}
}

@article{wangStatisticalMethodsComputing2016,
  title = {Statistical Methods and Computing for Big Data},
  author = {Wang, Chun and Chen, Ming-Hui and Schifano, Elizabeth and Wu, Jing and Yan, Jun},
  year = {2016},
  journal = {Statistics and its interface},
  volume = {9},
  number = {4},
  pages = {399--414},
  issn = {1938-7989},
  doi = {10.4310/SII.2016.v9.n4.a1},
  urldate = {2024-05-20},
  abstract = {Big data are data on a massive scale in terms of volume, intensity, and complexity that exceed the capacity of standard analytic tools. They present opportunities as well as challenges to statisticians. The role of computational statisticians in scientific discovery from big data analyses has been under-recognized even by peer statisticians. This article summarizes recent methodological and software developments in statistics that address the big data challenges. Methodologies are grouped into three classes: subsampling-based, divide and conquer, and online updating for stream data. As a new contribution, the online updating approach is extended to variable selection with commonly used criteria, and their performances are assessed in a simulation study with stream data. Software packages are summarized with focuses on the open source  R and  R packages, covering recent tools that help break the barriers of computer memory and computing power. Some of the tools are illustrated in a case study with a logistic regression for the chance of airline delay.},
  pmcid = {PMC5041595},
  pmid = {27695593},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/wang et al_2016_statistical methods and computing for big data.pdf}
}

@incollection{wangTestingDepartureHardy2012,
  title = {Testing {{Departure}} from {{Hardy}}--{{Weinberg Proportions}}},
  booktitle = {Statistical {{Human Genetics}}: {{Methods}} and {{Protocols}}},
  author = {Wang, Jian and Shete, Sanjay},
  editor = {Elston, Robert C. and Satagopan, Jaya M. and Sun, Shuying},
  year = {2012},
  series = {Methods in {{Molecular Biology}}},
  pages = {77--102},
  publisher = {Humana Press},
  address = {Totowa, NJ},
  doi = {10.1007/978-1-61779-555-8_6},
  urldate = {2022-11-05},
  abstract = {The Hardy--Weinberg principle, one of the most important principles in population genetics, was originally developed for the study of allele frequency changes in a population over generations. It is now, however, widely used in studies of human diseases to detect inbreeding, populations stratification, and genotyping errors. For assessment of deviation from the Hardy--Weinberg proportions in data, the most popular approaches include the asymptotic Pearson's chi-square goodness-of-fit test and the exact test. The Pearson's chi-square goodness-of-fit test is simple and straightforward, but it is very sensitive to small sample size or rare allele frequency. The exact test of Hardy--Weinberg proportions is preferable in these situations. The exact test can be performed through complete enumeration of heterozygote genotypes or on the basis of the Markov chain Monte Carlo procedure. In this chapter, we describe the Hardy--Weinberg principle and the commonly used Hardy--Weinberg proportions tests and their applications, and we demonstrate how the chi-square test and exact test of Hardy--Weinberg proportions can be performed step-by-step using the popular software programs SAS, R, and PLINK, which have been widely used in genetic association studies, along with numerical examples. We also discuss recent approaches for testing Hardy--Weinberg proportions in case--control study designs that are better than traditional approaches for testing Hardy--Weinberg proportions in controls only. Finally, we note that deviation from the Hardy--Weinberg proportions in affected individuals can provide evidence for an association between genetic variants and diseases.},
  isbn = {978-1-61779-555-8},
  langid = {english},
  keywords = {Case-control genetic association study,Exact test,Genetic association study,Genotyping error,Hardy-Weinberg proportion,Pearson's chi-square goodness-of-fit test,PLINK,Population stratification,Quality control,R,SAS/Genetics},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/wang_shete_2012_testing departure from hardy–weinberg proportions.pdf}
}

@article{wangTestingDepartureHardy2012a,
  title = {Testing Departure from Hardy--{{Weinberg}} Proportions},
  author = {Wang, Jian and Shete, Sanjay},
  year = {2012},
  journal = {Statistical human genetics: methods and protocols},
  pages = {77--102},
  publisher = {Springer},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/wang_shete_2012_testing departure from hardy–weinberg proportions2.pdf;/Users/zenn/Zotero/storage/KP9LS8IF/978-1-61779-555-8_6.html}
}

@article{wangTestingDepartureHardyWeinberg2017,
  title = {Testing Departure from {{Hardy-Weinberg}} Proportions},
  author = {Wang, Jian and Shete, Sanjay},
  year = {2017},
  journal = {Statistical Human Genetics: Methods and Protocols},
  pages = {83--115},
  publisher = {Springer},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/wang_shete_2017_testing departure from hardy-weinberg proportions.pdf;/Users/zenn/Zotero/storage/R6ASKSVF/978-1-4939-7274-6_6.html}
}

@article{wangTwoPeriodLinear2019,
  title = {Two-period Linear Mixed Effects Models to Analyze Clinical Trials with Run-in Data When the Primary Outcome Is Continuous: {{Applications}} to {{Alzheimer}}'s Disease},
  shorttitle = {Two-period Linear Mixed Effects Models to Analyze Clinical Trials with Run-in Data When the Primary Outcome Is Continuous},
  author = {Wang, Guoqiao and Aschenbrenner, Andrew J. and Li, Yan and McDade, Eric and Liu, Lei and Benzinger, Tammie L.S. and Bateman, Randall J. and Morris, John C. and Hassenstab, Jason J. and Xiong, Chengjie},
  year = {2019},
  month = jan,
  journal = {Alzheimer's \& Dementia: Translational Research \& Clinical Interventions},
  volume = {5},
  number = {1},
  pages = {450--457},
  issn = {2352-8737, 2352-8737},
  doi = {10.1016/j.trci.2019.07.007},
  urldate = {2023-04-14},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/wang et al_2019_two‐period linear mixed effects models to analyze clinical trials with run‐in.pdf}
}

@article{wangUtilitiesPitfallsStratified2022,
  title = {The Utilities and Pitfalls of Stratified Analysis in Challenging Situations},
  author = {Wang, Jin},
  year = {2022},
  journal = {Pharmaceutical Statistics},
  volume = {21},
  number = {6},
  pages = {1114--1120},
  issn = {1539-1612},
  doi = {10.1002/pst.2232},
  urldate = {2023-05-06},
  abstract = {Stratified analysis is commonly used to control confounding factors in evaluating treatment effect at both design and analysis stages. Motivated by a real-life experience, this article illustrates the utilities and pitfalls of stratified analysis through continuous and binary endpoints by comparing some typical analysis methodologies. Stratified analyses in some challenging situations, including propensity score stratification are discussed.},
  langid = {english},
  keywords = {Farrington-Manning,propensity score,Simpson's paradox,stratified analysis},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/wang_2022_the utilities and pitfalls of stratified analysis in challenging situations.pdf;/Users/zenn/Zotero/storage/M6Q99MV5/pst.html}
}

@article{ward1993trimethoprim,
  title = {Trimethoprim-Sulfamethoxazole Prophylaxis in Granulocytopenic Patients with Acute Leukemia: Evaluation of Serum Antibiotic Levels in a Randomized, Double-Blind, Placebo-Controlled {{Department}} of {{Veterans Affairs Cooperative Study}}},
  author = {Ward, {\relax TT} and Thomas, {\relax RG} and Fye, {\relax CL} and Arbeit, R and Coltman Jr, {\relax CA} and Craig, W and Dana, {\relax BW} and Finegold, {\relax SM} and Lentino, J and Penn, {\relax RL} and others},
  year = {1993},
  journal = {Clinical infectious diseases},
  volume = {17},
  number = {3},
  pages = {323--332},
  publisher = {The University of Chicago Press}
}

@article{wareMissingData2012,
  title = {Missing {{Data}}},
  author = {Ware, James H. and Harrington, David and Hunter, David J. and D'Agostino, Ralph B.},
  year = {2012},
  month = oct,
  journal = {New England Journal of Medicine},
  volume = {367},
  number = {14},
  pages = {1353--1354},
  publisher = {Massachusetts Medical Society},
  issn = {0028-4793},
  doi = {10.1056/NEJMsm1210043},
  urldate = {2023-03-02},
  abstract = {Missing data threaten the validity of many clinical trials. In this issue of the Journal, the members of an expert panel convened by the National Research Council (NRC) provide recommendations regarding the design, conduct, and analysis of studies to minimize that threat.1 The authors define missing data as ``values that are not available and that would be meaningful for analysis if they were observed.'' They find that there is no analytic approach that can assuredly produce unbiased estimates of treatment effects when relevant data are missing and therefore recommend that investigators place increased emphasis on strategies for designing and conducting . . .},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/ware et al_2012_missing data.pdf}
}

@article{weiner1998comparison,
  title = {A Comparison of the {{Cohen-Mansfield}} Agitation Inventory with the Cerad Behavioral Rating Scale for Dementia in Community-Dwelling Persons with {{Alzheimers}} Disease},
  author = {Weiner, Myron F and Koss, Elisabeth and Patterson, Marian and Jin, Shelia and Teri, Linda and Thomas, Ron and Thal, Leon J and Whitehouse, Peter},
  year = {1998},
  journal = {Journal of psychiatric research},
  volume = {32},
  number = {6},
  pages = {347--351},
  publisher = {Pergamon}
}

@article{weiner2000quantifying,
  title = {Quantifying Behavioral Disturbance in {{Alzheimer}}'s Disease Patients},
  author = {Weiner, Myron F and Tractenberg, Rochelle and Teri, Linda and Logsdon, Rebecca and Thomas, Ronald G and Gamst, Anthony and Thal, Leon J},
  year = {2000},
  journal = {Journal of Psychiatric Research},
  volume = {34},
  number = {2},
  pages = {163--167},
  publisher = {Pergamon}
}

@article{weiner2002assessing,
  title = {Assessing {{Alzheimer}}'s Disease Patients with the {{Cohen-Mansfield Agitation Inventory}}: Scoring and Clinical Implications},
  author = {Weiner, Myron F and Tractenberg, Rochelle E and Jin, Shelia and Gamst, Anthony and Thomas, Ronald G and Koss, Elisabeth and Thal, Leon J},
  year = {2002},
  journal = {Journal of Psychiatric Research},
  volume = {36},
  number = {1},
  pages = {19--25},
  publisher = {Pergamon}
}

@article{weiner2002no,
  title = {No Long-Term Effect of Behavioral Treatment on Psychotropic Drug Use for Agitation in {{Alzheimer}}'s Disease Patients},
  author = {Weiner, Myron F and Tractenberg, Rochelle E and Sano, Mary and Logsdon, Rebecca and Teri, Linda and Galasko, Douglas and Gamst, Anthony and Thomas, Ron and Thal, Leon J},
  year = {2002},
  journal = {Journal of geriatric psychiatry and neurology},
  volume = {15},
  number = {2},
  pages = {95--98},
  publisher = {Sage Publications Sage CA: Thousand Oaks, CA}
}

@article{weiPropensityScoreWeighted,
  title = {Propensity Score Weighted Multi-Source Exchangeability Models for Incorporating External Control Data in Randomized Clinical Trials},
  author = {Wei, Wei and Zhang, Yunxuan and Roychoudhury, Satrajit and Initiative, the Alzheimer's Disease Neuroimaging},
  journal = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.10158},
  urldate = {2024-06-28},
  abstract = {Among clinical trialists, there has been a growing interest in using external data to improve decision-making and accelerate drug development in randomized clinical trials (RCTs). Here we propose a novel approach that combines the propensity score weighting (PW) and the multi-source exchangeability modelling (MEM) approaches to augment the control arm of a RCT in the rare disease setting. First, propensity score weighting is used to construct weighted external controls that have similar observed pre-treatment characteristics as the current trial population. Next, the MEM approach evaluates the similarity in outcome distributions between the weighted external controls and the concurrent control arm. The amount of external data we borrow is determined by the similarities in pretreatment characteristics and outcome distributions. The proposed approach can be applied to binary, continuous and count data. We evaluate the performance of the proposed PW-MEM method and several competing approaches based on simulation and re-sampling studies. Our results show that the PW-MEM approach improves the precision of treatment effect estimates while reducing the biases associated with borrowing data from external sources.},
  langid = {english},
  keywords = {Bayesian design,hybrid control,pediatric study,rare disease},
  file = {/Users/zenn/Zotero/storage/WLBJ3TIH/Wei et al. - Propensity score weighted multi-source exchangeabi.pdf;/Users/zenn/Zotero/storage/E2L7REPT/sim.html}
}

@article{weiUnifiedExactDesign2021,
  title = {Unified Exact Design with Early Stopping Rules for Single Arm Clinical Trials with Multiple Endpoints},
  author = {Wei, Wei and Esserman, Denise and Kane, Michael and Zelterman, Daniel},
  year = {2021},
  month = jul,
  journal = {Statistical Methods in Medical Research},
  volume = {30},
  number = {7},
  pages = {1575--1588},
  issn = {0962-2802, 1477-0334},
  doi = {10.1177/09622802211013062},
  urldate = {2023-11-15},
  abstract = {Adaptive designs are gaining popularity in early phase clinical trials because they enable investigators to change the course of a study in response to accumulating data. We propose a novel design to simultaneously monitor several endpoints. These include efficacy, futility, toxicity and other outcomes in early phase, single-arm studies. We construct a recursive relationship to compute the exact probabilities of stopping for any combination of endpoints without the need for simulation, given pre-specified decision rules. The proposed design is flexible in the number and timing of interim analyses. A R Shiny app with user-friendly web interface has been created to facilitate the implementation of the proposed design.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/UUGVJFHU/Wei et al. - 2021 - Unified exact design with early stopping rules for.pdf}
}

@article{wenningNewInsightsAtypical2011,
  title = {New Insights into Atypical Parkinsonism},
  author = {Wenning, Gregor K. and Krismer, Florian and Poewe, Werner},
  year = {2011},
  month = aug,
  journal = {Current Opinion in Neurology},
  volume = {24},
  number = {4},
  pages = {331--338},
  issn = {1473-6551},
  doi = {10.1097/WCO.0b013e3283480569},
  abstract = {PURPOSE OF REVIEW: Atypical parkinsonian disorders (APDs) comprise a heterogenous group of disorders including multiple system atrophy (MSA), dementia with Lewy bodies (DLB), progressive supranuclear palsy (PSP) and corticobasal degeneration (CBD). Based on literature published in 2010, we here review recent advances in the APD field. RECENT FINDINGS: Genome-wide association studies have provided robust evidence of increased disease risk conferred by synuclein and tau gene variants in MSA and PSP. Furthermore, advanced imaging tools have been established in the differential diagnosis and as surrogate markers of disease activity in patients with APDs. Finally, although therapeutic options are still disappointing, translational research into disease-modifying strategies has accelerated with the increasing availability of transgenic animal models, particularly for MSA. SUMMARY: Remarkable progress has been achieved in the field of APDs, and advances in the genetics, molecular biology and neuroimaging of these disorders will continue to facilitate intensified clinical trial activity.},
  langid = {english},
  pmcid = {PMC6200126},
  pmid = {21577106},
  keywords = {alpha-Synuclein,Animals,Animals Genetically Modified,Clinical Trials as Topic,Diagnosis Differential,Genome-Wide Association Study,Humans,Lewy Body Disease,Multiple System Atrophy,Parkinsonian Disorders,Supranuclear Palsy Progressive,tau Proteins},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/wenning et al_2011_new insights into atypical parkinsonism.pdf}
}

@article{Wessels2015,
  title = {A {{Combined Measure}} of {{Cognition}} and {{Function}} for {{Clinical Trials}}: {{The Integrated Alzheimer}}'s {{Disease Rating Scale}} ({{iADRS}})},
  author = {Wessels, A M and Siemers, E R and Yu, P and Andersen, S W and Holdridge, K C and Sims, J R and Sundell, K and Stern, Y and Rentz, D M and Dubois, B and Jones, R W and Cummings, J and Aisen, P S},
  year = {2015},
  journal = {J Prev Alz Dis},
  volume = {2},
  number = {4},
  abstract = {It is generally recognized that more sensitive instruments for the earliest stages of Alzheimer's disease (AD) are needed. The integrated Alzheimer's Disease Rating Scale (iADRS) combines scores from 2 widely accepted measures, the Alzheimer's Disease Assessment Scale-Cognitive subscale (ADAS-Cog) and the Alzheimer's Disease Cooperative Study -- instrumental Activities of Daily Living (ADCS-iADL). Disease progression and treatment differences as measured by the iADRS were analyzed using data from solanezumab EXPEDITION, EXPEDITION2, and EXPEDITION-EXT Studies; semagacestat IDENTITY Study; and donepezil ADCS -- mild cognitive impairment (ADCS-MCI) Study. Psychometric properties of the iADRS were established through principal component analysis (PCA) and estimation of contributions of subscores and individual item scores to the iADRS total score. The iADRS performed better than most composites and scales in detecting disease progression and comparably or better than individual scales in detecting treatment differences. PCA demonstrated the iADRS can be divided into two principal components primarily representing cognitive items and instrumental ADLs. Dynamic ranges of the subscales were similar across all studies, reflecting approximately equal contributions from both subscales to the iADRS total score. In item analyses, every item contributed to the total score, with varying strength of contributions by item and across data sets. The iADRS demonstrated acceptable psychometric properties and was effective in capturing disease progression from MCI through moderate AD and treatment effects across the early disease spectrum. These findings suggest the iADRS can be used in studies of mixed populations, ensuring sensitivity to treatment effects as subjects progress during studies of putative disease-modifying agents. Key words: iADRS, Alzheimer's disease, clinical trials, outcome measure.},
  keywords = {alzheimer,clinical trials,iadrs,outcome measure},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/wessels et al_2015_a combined measure of cognition and function for clinical trials.pdf}
}

@article{Wharf2011,
  title = {Qualification Opinion of Low Hippocampal Volume ( Atrophy ) by {{MRI}} for Use in Regulatory Clinical Trials - in Pre-Dementia Stage of {{Alzheimer}} ' s Disease},
  author = {Wharf, Canary and Kingdom, United},
  year = {2011},
  journal = {Biomarkers},
  volume = {44},
  number = {October},
  abstract = {29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 Background The European Medicines Agency's (EMA) qualification process is a new, voluntary, scientific pathway leading to either a CHMP opinion or a Scientific Advice of novel methodologies on innovative methods or drug development tools. It includes qualification of biomarkers developed by consortia, networks, public/private partnerships, learned societies or pharmaceutical industry for a specific intended use in pharmaceutical research and development. The present opinion addresses the question as to whether the use of baseline measurement of low hippocampal volume (atrophy) by MRI are qualified in selecting (i.e. to categorize) subjects for trials in early Alzheimer's Disease (AD) as having a high probability of being in the prodromal stage of the disease as defined by the Dubois Criteria (2007). The vast majority of the data used in CHMP's evaluation have been submitted by CAMD, the applicant that requested the qualification, and are all published literature available in the public domain. They have been supplemented by further information searched required by members of the qualification team. Background information as submitted by the Applicant},
  keywords = {0,20 7418 8400 facsimile,20 7523 7040,44,7 westferry circus,canary wharf,london e14 4hb,mri biomarker,pre-dementia alzheimer,qualification opinion,s disease,telephone,united kingdom},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/wharf_kingdom_2011_qualification opinion of low hippocampal volume ( atrophy ) by mri for use in.pdf}
}

@article{whitehouse1997multicenter,
  title = {A Multicenter Evaluation of New Treatment Efficacy},
  author = {Whitehouse, Peter J and Schmitt, HFrederick A and Sano, Mary and Thomas, Ronald G},
  year = {1997},
  journal = {Alzheimer Disease and Associated Disorders},
  volume = {11},
  number = {2},
  pages = {I997}
}

@article{whitwellBiomarkersRandomizedClinical2016,
  title = {Biomarkers in {{Randomized Clinical Trials}}: {{Magnetic Resonance Imaging}}},
  shorttitle = {Biomarkers in {{Randomized Clinical Trials}}},
  author = {Whitwell, Jennifer L.},
  year = {2016},
  journal = {Frontiers of Neurology and Neuroscience},
  volume = {39},
  pages = {101--108},
  issn = {1662-2804},
  doi = {10.1159/000445419},
  abstract = {BACKGROUND: It is essential that randomized clinical trials (RCTs) incorporate biomarkers of disease progression that would be sensitive to the effects of disease-modifying treatments. Magnetic resonance imaging (MRI) can be safely repeated over time, and is routinely performed in clinical centers, making it an ideal modality to be incorporated into RCTs. SUMMARY: This chapter discusses potential structural MRI biomarkers that have been proposed for a number of different neurodegenerative disorders, including Alzheimer's disease (AD), dementia with Lewy bodies (DLB), frontotemporal dementia (FTD), progressive supranuclear palsy syndrome (PSPS), and Parkinson's disease (PD). All of these disorders represent targets for ongoing and future RCTs. Rates of hippocampal atrophy and ventricular expansion provide excellent biomarkers of disease progression in AD, and may also provide biomarkers in prodromal and preclinical phases of the disease, as well as in DLB. Rates of ventricular expansion also perform well in FTD, although regional frontal and temporal measurements could also be useful. Rates of midbrain atrophy provide the most feasible MRI biomarker in PSPS. In contrast, PD is not associated with specific patterns of cerebral atrophy and further work is needed in order to define useful MRI biomarkers. Sample size calculations using these MRI biomarkers are presented and discussed. KEY MESSAGES: Rates of cerebral atrophy provide valuable potential biomarkers of disease progression in neurodegenerative disorders, and have already begun to be utilized as outcome measures in RCTs. Measurements from other structural and functional MRI modalities require more longitudinal validation, but may prove to be useful in the future.},
  langid = {english},
  pmid = {27463684},
  keywords = {Biomarkers,Brain,Humans,Magnetic Resonance Imaging,Nervous System Diseases,Randomized Controlled Trials as Topic}
}

@article{whitwellRatesBrainAtrophy2012,
  title = {Rates of Brain Atrophy and Clinical Decline over 6 and 12-Month Intervals in {{PSP}}: Determining Sample Size for Treatment Trials},
  shorttitle = {Rates of Brain Atrophy and Clinical Decline over 6 and 12-Month Intervals in {{PSP}}},
  author = {Whitwell, Jennifer L. and Xu, Jia and Mandrekar, Jay N. and Gunter, Jeffrey L. and Jack, Clifford R. and Josephs, Keith A.},
  year = {2012},
  month = mar,
  journal = {Parkinsonism \& Related Disorders},
  volume = {18},
  number = {3},
  pages = {252--256},
  issn = {1873-5126},
  doi = {10.1016/j.parkreldis.2011.10.013},
  abstract = {Imaging biomarkers are useful outcome measures in treatment trials. We compared sample size estimates for future treatment trials performed over 6 or 12-months in progressive supranuclear palsy using both imaging and clinical measures. We recruited 16 probable progressive supranuclear palsy patients that underwent baseline, 6 and 12-month brain scans, and 16 age-matched controls with serial scans. Disease severity was measured at each time-point using the progressive supranuclear palsy rating scale. Rates of ventricular expansion and rates of atrophy of the whole brain, superior frontal lobe, thalamus, caudate and midbrain were calculated. Rates of atrophy and clinical decline were used to calculate sample sizes required to power placebo-controlled treatment trials over 6 and 12-months. Rates of whole brain, thalamus and midbrain atrophy, and ventricular expansion, were increased over 6 and 12-months in progressive supranuclear palsy compared to controls. The progressive supranuclear palsy rating scale increased by 9 points over 6-months, and 18 points over 12-months. The smallest sample size estimates for treatment trials over 6-months were achieved using rate of midbrain atrophy, followed by rate of whole brain atrophy and ventricular expansion. Sample size estimates were further reduced over 12-month intervals. Sample size estimates for the progressive supranuclear palsy rating scale were worse than imaging measures over 6-months, but comparable over 12-months. Atrophy and clinical decline can be detected over 6-months in progressive supranuclear palsy. Sample size estimates suggest that treatment trials could be performed over this interval, with rate of midbrain atrophy providing the best outcome measure.},
  langid = {english},
  pmcid = {PMC3399183},
  pmid = {22079523},
  keywords = {Adult,Aged,Atrophy,Brain,Clinical Trials as Topic,Female,Humans,Magnetic Resonance Imaging,Male,Middle Aged,Sample Size,Supranuclear Palsy Progressive},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/whitwell et al_2012_rates of brain atrophy and clinical decline over 6 and 12-month intervals in psp2.pdf}
}

@article{whitwellRatesBrainAtrophy2012a,
  title = {Rates of Brain Atrophy and Clinical Decline over 6 and 12-Month Intervals in {{PSP}}: Determining Sample Size for Treatment Trials},
  shorttitle = {Rates of Brain Atrophy and Clinical Decline over 6 and 12-Month Intervals in {{PSP}}},
  author = {Whitwell, Jennifer L. and Xu, Jia and Mandrekar, Jay N. and Gunter, Jeffrey L. and Jack, Clifford R. and Josephs, Keith A.},
  year = {2012},
  month = mar,
  journal = {Parkinsonism \& Related Disorders},
  volume = {18},
  number = {3},
  pages = {252--256},
  issn = {1873-5126},
  doi = {10.1016/j.parkreldis.2011.10.013},
  abstract = {Imaging biomarkers are useful outcome measures in treatment trials. We compared sample size estimates for future treatment trials performed over 6 or 12-months in progressive supranuclear palsy using both imaging and clinical measures. We recruited 16 probable progressive supranuclear palsy patients that underwent baseline, 6 and 12-month brain scans, and 16 age-matched controls with serial scans. Disease severity was measured at each time-point using the progressive supranuclear palsy rating scale. Rates of ventricular expansion and rates of atrophy of the whole brain, superior frontal lobe, thalamus, caudate and midbrain were calculated. Rates of atrophy and clinical decline were used to calculate sample sizes required to power placebo-controlled treatment trials over 6 and 12-months. Rates of whole brain, thalamus and midbrain atrophy, and ventricular expansion, were increased over 6 and 12-months in progressive supranuclear palsy compared to controls. The progressive supranuclear palsy rating scale increased by 9 points over 6-months, and 18 points over 12-months. The smallest sample size estimates for treatment trials over 6-months were achieved using rate of midbrain atrophy, followed by rate of whole brain atrophy and ventricular expansion. Sample size estimates were further reduced over 12-month intervals. Sample size estimates for the progressive supranuclear palsy rating scale were worse than imaging measures over 6-months, but comparable over 12-months. Atrophy and clinical decline can be detected over 6-months in progressive supranuclear palsy. Sample size estimates suggest that treatment trials could be performed over this interval, with rate of midbrain atrophy providing the best outcome measure.},
  langid = {english},
  pmcid = {PMC3399183},
  pmid = {22079523},
  keywords = {Adult,Aged,Atrophy,Brain,Clinical Trials as Topic,Female,Humans,Magnetic Resonance Imaging,Male,Middle Aged,Sample Size,Supranuclear Palsy Progressive},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/whitwell et al_2012_rates of brain atrophy and clinical decline over 6 and 12-month intervals in psp.pdf}
}

@book{wickhamAdvanced2019,
  title = {Advanced r},
  author = {Wickham, Hadley},
  year = {2019},
  publisher = {{chapman and hall/CRC}},
  urldate = {2024-05-20}
}

@article{wiggintonNoteExactTests2005,
  title = {A Note on Exact Tests of {{Hardy-Weinberg}} Equilibrium},
  author = {Wigginton, Janis E. and Cutler, David J. and Abecasis, Gon{\c c}alo R.},
  year = {2005},
  journal = {The American Journal of Human Genetics},
  volume = {76},
  number = {5},
  pages = {887--893},
  publisher = {Elsevier},
  file = {/Users/zenn/Zotero/storage/TVVW72V4/Wigginton et al. - 2005 - A note on exact tests of Hardy-Weinberg equilibriu.pdf}
}

@inproceedings{williams1997quality,
  title = {Quality of Life among Elderly Adults with Macular Degeneration},
  booktitle = {Investigative Ophthalmology \& Visual Science},
  author = {Williams, {\relax RA} and Brody, {\relax BL} and Kaplan, {\relax RM} and Thomas, {\relax RG} and Brown, {\relax SI}},
  year = {1997},
  volume = {38},
  pages = {3169--3169},
  publisher = {LIPPINCOTT-RAVEN PUBL 227 EAST WASHINGTON SQ, PHILADELPHIA, PA 19106}
}

@article{williams1998psychosocial,
  title = {The Psychosocial Impact of Macular Degeneration},
  author = {Williams, Rebecca A and Brody, Barbara L and Thomas, Ronald G and Kaplan, Robert M and Brown, Stuart I},
  year = {1998},
  journal = {Archives of ophthalmology},
  volume = {116},
  number = {4},
  pages = {514--520},
  publisher = {American Medical Association}
}

@article{willsModifiedProgressiveSupranuclear2022,
  title = {A {{Modified Progressive Supranuclear Palsy Rating Scale}} for {{Virtual Assessments}}},
  author = {Wills, Anne-Marie and Pantelyat, Alexander and Espay, Alberto and Chan, James and Litvan, Irene and Xie, Tao and Dale, Marian L. and Gunzler, Steven A. and Tartaglia, Maria Carmela and Fox, Susan H. and {Rodriguez-Porcel}, Federico and Sharma, Mansi and Lang, Anthony E. and Boxer, Adam L. and Group, AL-108-231 Study and Golbe, Lawrence I.},
  year = {2022},
  journal = {Movement Disorders},
  volume = {37},
  number = {6},
  pages = {1265--1271},
  issn = {1531-8257},
  doi = {10.1002/mds.28991},
  urldate = {2024-04-23},
  abstract = {Background The reliability of the Progressive Supranuclear Palsy Rating Scale (PSPRS) using teleneurology has not been assessed. Objectives To test whether removing items inadequately assessed by video would impact measurement of PSP severity and progression. Methods We performed secondary analyses of two data sets: the phase 2/3 trial of Davunetide in PSP and a large single-center cohort. We examined two modifications of the PSPRS: (1) removing neck rigidity, limb rigidity, and postural stability (25 items; mPSPRS-25) and (2) also removing three ocular motor items and limb dystonia (21 items; mPSPRS-21). Proportional agreement relative to the possible total scores was measured using the intraclass correlation coefficient, compared to the original PSPRS baseline values and change over 6 and 12 months. We examined the ability of both scales to predict survival in the single-center cohort using proportional hazards models. Results The mPSPRS-25 showed excellent agreement (0.99; P {$<$} 0.001) with the original PSPRS at baseline, 0.98 (P {$<$} 0.001) agreement in measuring change over 6 months, and 0.98 (P {$<$} 0.001) over 12 months. The mPSPRS-21 showed agreement of 0.94 (P {$<$} 0.001) with the original PSPRS at baseline, 0.92 (P {$<$} 0.001) at 6 months, and 0.95 (P {$<$} 0.001) at 12 months. Baseline and 6-month change in both modified scales were highly predictive of survival in the single-center cohort. Conclusions Modified versions of the PSPRS which can be administered remotely show excellent agreement with the original scale and predict survival in PSP. The mPSPRS-21 should facilitate clinical care and research in PSP via teleneurology. {\copyright} 2022 International Parkinson and Movement Disorder Society},
  langid = {english},
  keywords = {PSP,PSPRS,telemedicine,teleneurology,virtual},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/wills et al_2022_a modified progressive supranuclear palsy rating scale for virtual assessments5.pdf;/Users/zenn/Zotero/storage/DNSZ5SJB/mds.html}
}

@article{willsModifiedProgressiveSupranuclear2022a,
  title = {A {{Modified Progressive Supranuclear Palsy Rating Scale}} for {{Virtual Assessments}}},
  author = {Wills, Anne-Marie and Pantelyat, Alexander and Espay, Alberto and Chan, James and Litvan, Irene and Xie, Tao and Dale, Marian L. and Gunzler, Steven A. and Tartaglia, Maria Carmela and Fox, Susan H. and {Rodriguez-Porcel}, Federico and Sharma, Mansi and Lang, Anthony E. and Boxer, Adam L. and {AL-108-231 Study Group} and Golbe, Lawrence I.},
  year = {2022},
  month = jun,
  journal = {Movement Disorders: Official Journal of the Movement Disorder Society},
  volume = {37},
  number = {6},
  pages = {1265--1271},
  issn = {1531-8257},
  doi = {10.1002/mds.28991},
  abstract = {BACKGROUND: The reliability of the Progressive Supranuclear Palsy Rating Scale (PSPRS) using teleneurology has not been assessed. OBJECTIVES: To test whether removing items inadequately assessed by video would impact measurement of PSP severity and progression. METHODS: We performed secondary analyses of two data sets: the phase 2/3 trial of Davunetide in PSP and a large single-center cohort. We examined two modifications of the PSPRS: (1) removing neck rigidity, limb rigidity, and postural stability (25 items; mPSPRS-25) and (2) also removing three ocular motor items and limb dystonia (21 items; mPSPRS-21). Proportional agreement relative to the possible total scores was measured using the intraclass correlation coefficient, compared to the original PSPRS baseline values and change over 6 and 12~months. We examined the ability of both scales to predict survival in the single-center cohort using proportional hazards models. RESULTS: The mPSPRS-25 showed excellent agreement (0.99; P\,{$<$}\,0.001) with the original PSPRS at baseline, 0.98 (P\,{$<$}\,0.001) agreement in measuring change over 6\,months, and 0.98 (P\,{$<$}\,0.001) over 12~months. The mPSPRS-21 showed agreement of 0.94 (P\,{$<$}\,0.001) with the original PSPRS at baseline, 0.92 (P\,{$<$}\,0.001) at 6\,months, and 0.95 (P\,{$<$}\,0.001) at 12~months. Baseline and 6-month change in both modified scales were highly predictive of survival in the single-center cohort. CONCLUSIONS: Modified versions of the PSPRS which can be administered remotely show excellent agreement with the original scale and predict survival in PSP. The mPSPRS-21 should facilitate clinical care and research in PSP via teleneurology. {\copyright} 2022 International Parkinson and Movement Disorder Society.},
  langid = {english},
  pmcid = {PMC9232989},
  pmid = {35363932},
  keywords = {Clinical Trials Phase II as Topic,Clinical Trials Phase III as Topic,Humans,PSP,PSPRS,Reproducibility of Results,Supranuclear Palsy Progressive,telemedicine,teleneurology,virtual},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/wills et al_2022_a modified progressive supranuclear palsy rating scale for virtual assessments4.pdf}
}

@article{willsModifiedProgressiveSupranuclear2022b,
  title = {A {{Modified Progressive Supranuclear Palsy Rating Scale}} for {{Virtual Assessments}}},
  author = {Wills, Anne-Marie and Pantelyat, Alexander and Espay, Alberto and Chan, James and Litvan, Irene and Xie, Tao and Dale, Marian L. and Gunzler, Steven A. and Tartaglia, Maria Carmela and Fox, Susan H. and {Rodriguez-Porcel}, Federico and Sharma, Mansi and Lang, Anthony E. and Boxer, Adam L. and {AL-108-231 Study Group} and Golbe, Lawrence I.},
  year = {2022},
  month = jun,
  journal = {Movement Disorders: Official Journal of the Movement Disorder Society},
  volume = {37},
  number = {6},
  pages = {1265--1271},
  issn = {1531-8257},
  doi = {10.1002/mds.28991},
  abstract = {BACKGROUND: The reliability of the Progressive Supranuclear Palsy Rating Scale (PSPRS) using teleneurology has not been assessed. OBJECTIVES: To test whether removing items inadequately assessed by video would impact measurement of PSP severity and progression. METHODS: We performed secondary analyses of two data sets: the phase 2/3 trial of Davunetide in PSP and a large single-center cohort. We examined two modifications of the PSPRS: (1) removing neck rigidity, limb rigidity, and postural stability (25 items; mPSPRS-25) and (2) also removing three ocular motor items and limb dystonia (21 items; mPSPRS-21). Proportional agreement relative to the possible total scores was measured using the intraclass correlation coefficient, compared to the original PSPRS baseline values and change over 6 and 12~months. We examined the ability of both scales to predict survival in the single-center cohort using proportional hazards models. RESULTS: The mPSPRS-25 showed excellent agreement (0.99; P\,{$<$}\,0.001) with the original PSPRS at baseline, 0.98 (P\,{$<$}\,0.001) agreement in measuring change over 6\,months, and 0.98 (P\,{$<$}\,0.001) over 12~months. The mPSPRS-21 showed agreement of 0.94 (P\,{$<$}\,0.001) with the original PSPRS at baseline, 0.92 (P\,{$<$}\,0.001) at 6\,months, and 0.95 (P\,{$<$}\,0.001) at 12~months. Baseline and 6-month change in both modified scales were highly predictive of survival in the single-center cohort. CONCLUSIONS: Modified versions of the PSPRS which can be administered remotely show excellent agreement with the original scale and predict survival in PSP. The mPSPRS-21 should facilitate clinical care and research in PSP via teleneurology. {\copyright} 2022 International Parkinson and Movement Disorder Society.},
  langid = {english},
  pmcid = {PMC9232989},
  pmid = {35363932},
  keywords = {Clinical Trials Phase II as Topic,Clinical Trials Phase III as Topic,Humans,PSP,PSPRS,Reproducibility of Results,Supranuclear Palsy Progressive,telemedicine,teleneurology,virtual},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/wills et al_2022_a modified progressive supranuclear palsy rating scale for virtual assessments3.pdf}
}

@article{willsModifiedProgressiveSupranuclear2022c,
  title = {A {{Modified Progressive Supranuclear Palsy Rating Scale}} for {{Virtual Assessments}}},
  author = {Wills, Anne-Marie and Pantelyat, Alexander and Espay, Alberto and Chan, James and Litvan, Irene and Xie, Tao and Dale, Marian L. and Gunzler, Steven A. and Tartaglia, Maria Carmela and Fox, Susan H. and {Rodriguez-Porcel}, Federico and Sharma, Mansi and Lang, Anthony E. and Boxer, Adam L. and {AL-108-231 Study Group} and Golbe, Lawrence I.},
  year = {2022},
  month = jun,
  journal = {Movement Disorders: Official Journal of the Movement Disorder Society},
  volume = {37},
  number = {6},
  pages = {1265--1271},
  issn = {1531-8257},
  doi = {10.1002/mds.28991},
  abstract = {BACKGROUND: The reliability of the Progressive Supranuclear Palsy Rating Scale (PSPRS) using teleneurology has not been assessed. OBJECTIVES: To test whether removing items inadequately assessed by video would impact measurement of PSP severity and progression. METHODS: We performed secondary analyses of two data sets: the phase 2/3 trial of Davunetide in PSP and a large single-center cohort. We examined two modifications of the PSPRS: (1) removing neck rigidity, limb rigidity, and postural stability (25 items; mPSPRS-25) and (2) also removing three ocular motor items and limb dystonia (21 items; mPSPRS-21). Proportional agreement relative to the possible total scores was measured using the intraclass correlation coefficient, compared to the original PSPRS baseline values and change over 6 and 12~months. We examined the ability of both scales to predict survival in the single-center cohort using proportional hazards models. RESULTS: The mPSPRS-25 showed excellent agreement (0.99; P\,{$<$}\,0.001) with the original PSPRS at baseline, 0.98 (P\,{$<$}\,0.001) agreement in measuring change over 6\,months, and 0.98 (P\,{$<$}\,0.001) over 12~months. The mPSPRS-21 showed agreement of 0.94 (P\,{$<$}\,0.001) with the original PSPRS at baseline, 0.92 (P\,{$<$}\,0.001) at 6\,months, and 0.95 (P\,{$<$}\,0.001) at 12~months. Baseline and 6-month change in both modified scales were highly predictive of survival in the single-center cohort. CONCLUSIONS: Modified versions of the PSPRS which can be administered remotely show excellent agreement with the original scale and predict survival in PSP. The mPSPRS-21 should facilitate clinical care and research in PSP via teleneurology. {\copyright} 2022 International Parkinson and Movement Disorder Society.},
  langid = {english},
  pmcid = {PMC9232989},
  pmid = {35363932},
  keywords = {Clinical Trials Phase II as Topic,Clinical Trials Phase III as Topic,Humans,PSP,PSPRS,Reproducibility of Results,Supranuclear Palsy Progressive,telemedicine,teleneurology,virtual},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/wills et al_2022_a modified progressive supranuclear palsy rating scale for virtual assessments2.pdf}
}

@article{willsModifiedProgressiveSupranuclear2022d,
  title = {A {{Modified Progressive Supranuclear Palsy Rating Scale}} for {{Virtual Assessments}}},
  author = {Wills, Anne-Marie and Pantelyat, Alexander and Espay, Alberto and Chan, James and Litvan, Irene and Xie, Tao and Dale, Marian L. and Gunzler, Steven A. and Tartaglia, Maria Carmela and Fox, Susan H. and {Rodriguez-Porcel}, Federico and Sharma, Mansi and Lang, Anthony E. and Boxer, Adam L. and {AL-108-231 Study Group} and Golbe, Lawrence I.},
  year = {2022},
  month = jun,
  journal = {Movement Disorders: Official Journal of the Movement Disorder Society},
  volume = {37},
  number = {6},
  pages = {1265--1271},
  issn = {1531-8257},
  doi = {10.1002/mds.28991},
  abstract = {BACKGROUND: The reliability of the Progressive Supranuclear Palsy Rating Scale (PSPRS) using teleneurology has not been assessed. OBJECTIVES: To test whether removing items inadequately assessed by video would impact measurement of PSP severity and progression. METHODS: We performed secondary analyses of two data sets: the phase 2/3 trial of Davunetide in PSP and a large single-center cohort. We examined two modifications of the PSPRS: (1) removing neck rigidity, limb rigidity, and postural stability (25 items; mPSPRS-25) and (2) also removing three ocular motor items and limb dystonia (21 items; mPSPRS-21). Proportional agreement relative to the possible total scores was measured using the intraclass correlation coefficient, compared to the original PSPRS baseline values and change over 6 and 12~months. We examined the ability of both scales to predict survival in the single-center cohort using proportional hazards models. RESULTS: The mPSPRS-25 showed excellent agreement (0.99; P\,{$<$}\,0.001) with the original PSPRS at baseline, 0.98 (P\,{$<$}\,0.001) agreement in measuring change over 6\,months, and 0.98 (P\,{$<$}\,0.001) over 12~months. The mPSPRS-21 showed agreement of 0.94 (P\,{$<$}\,0.001) with the original PSPRS at baseline, 0.92 (P\,{$<$}\,0.001) at 6\,months, and 0.95 (P\,{$<$}\,0.001) at 12~months. Baseline and 6-month change in both modified scales were highly predictive of survival in the single-center cohort. CONCLUSIONS: Modified versions of the PSPRS which can be administered remotely show excellent agreement with the original scale and predict survival in PSP. The mPSPRS-21 should facilitate clinical care and research in PSP via teleneurology. {\copyright} 2022 International Parkinson and Movement Disorder Society.},
  langid = {english},
  pmcid = {PMC9232989},
  pmid = {35363932},
  keywords = {Clinical Trials Phase II as Topic,Clinical Trials Phase III as Topic,Humans,PSP,PSPRS,Reproducibility of Results,Supranuclear Palsy Progressive,telemedicine,teleneurology,virtual},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/wills et al_2022_a modified progressive supranuclear palsy rating scale for virtual assessments.pdf}
}

@article{wilson1993controlled,
  title = {A Controlled Trial of Two Forms of Self-Management Education for Adults with Asthma},
  author = {Wilson, Sandra R and Scamagas, Peter and German, Donald F and Hughes, Gary W and Lulla, Sulochina and Coss, Stamatiki and Chardon, Luis and Thomas, Ronald G and {Starr-Schneidkraut}, Norma and Stancavage, Frances B and others},
  year = {1993},
  journal = {The American journal of medicine},
  volume = {94},
  number = {6},
  pages = {564--576},
  publisher = {Elsevier}
}

@article{winkensOptimalNumberRepeated2006,
  title = {Optimal Number of Repeated Measures and Group Sizes in Clinical Trials with Linearly Divergent Treatment Effects},
  author = {Winkens, Bjorn and Schouten, Hubert J. A. and {van Breukelen}, Gerard J. P. and Berger, Martijn P. F.},
  year = {2006},
  month = feb,
  journal = {Contemporary Clinical Trials},
  volume = {27},
  number = {1},
  pages = {57--69},
  issn = {1551-7144},
  doi = {10.1016/j.cct.2005.09.005},
  urldate = {2023-04-15},
  abstract = {The effect of number of repeated measures on the variance of the generalized least squares (GLS) treatment effect estimator is considered assuming a linearly divergent treatment effect, equidistant time-points and either a fixed number of subjects or a fixed study budget. The optimal combination of group sizes and number of repeated measures is calculated by minimizing this variance subject to a linear cost function. For a fixed number of subjects, the variance of the GLS treatment effect estimator can be decreased by adding intermediate measures per subject. This decrease is relatively large if a) the covariance structure is compound symmetric or b) the structure approaches compound symmetry and the correlation between two repeated measures does not exceed 0.80, or c) the correlation between two repeated measures does not exceed 0.60 if the time-lag goes to zero. In case the sample sizes and number of repeated measures are limited by budget constraints and the covariance structure includes a first-order auto-regression part, two repeated measures per subject yield highly efficient treatment effect estimators. Otherwise, it is more efficient to have more than two repeated measures. If the covariance structure is unknown, the optimal design based on a first-order auto-regressive structure with measurement error is preferable in terms of robustness against misspecification of the covariance structure. The numerical results are illustrated by three examples.},
  langid = {english},
  keywords = {Cost function,Generalized least squares,Group sizes,Linear divergence,Number of repeated measures},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/winkens et al_2006_optimal number of repeated measures and group sizes in clinical trials with.pdf}
}

@article{winkensOptimalTimepointsClinical2005,
  title = {Optimal Time-Points in Clinical Trials with Linearly Divergent Treatment Effects},
  author = {Winkens, Bjorn and Schouten, Hubert J. A. and {van Breukelen}, Gerard J. P. and Berger, Martijn P. F.},
  year = {2005},
  month = dec,
  journal = {Statistics in Medicine},
  volume = {24},
  number = {24},
  pages = {3743--3756},
  issn = {0277-6715, 1097-0258},
  doi = {10.1002/sim.2385},
  urldate = {2023-04-15},
  abstract = {In repeated measures studies, equidistant time-points do not always yield e cient treatment e ect estimators. In the present paper, the optimal allocation of time-points is calculated for a small number of repeated measures, di erent covariance structures and linearly divergent treatment e ects. The gain in e ciency of the treatment e ect estimator by using optimally allocated time-points instead of equidistant time-points or by adding optimally spaced measures (at the expense of patients) is then computed. The assumed covariance structure is crucial for the results. For a compound symmetric covariance structure, a large gain in e ciency is obtained by adding repeated measures at the end of the study. For a {\"y}rst-order auto-regressive covariance structure, highly e cient treatment e ect estimators are obtained with only two repeated measures, i.e. at the start and at the end of the study. For a {\"y}rst-order auto-regressive covariance structure including measurement error, the gain in e ciency by adding optimally spaced measures depends on the covariance parameter values. The gain in e ciency is similar with or without a random intercept. For a {\"y}xed study budget, the commonly used design with more than two equally spaced measures was never optimal for the linear cost function and covariance structures that were used. If the covariance structure is unknown, the optimal design based on a {\"y}rst-order auto-regressive covariance structure with measurement error is preferable in terms of robustness against misspeci{\"y}cation of the covariance structure. The numerical results are illustrated by two examples. Copyright ? 2005 John Wiley \& Sons, Ltd.},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/winkens et al_2005_optimal time-points in clinical trials with linearly divergent treatment effects.pdf}
}

@article{winkensRandomizedClinicalTrials2007,
  title = {Randomized Clinical Trials with a Pre-and a Post-Treatment Measurement: Repeated Measures versus {{ANCOVA}} Models},
  shorttitle = {Randomized Clinical Trials with a Pre-and a Post-Treatment Measurement},
  author = {Winkens, Bjorn and {van Breukelen}, Gerard JP and Schouten, Hubert JA and Berger, Martijn PF},
  year = {2007},
  journal = {Contemporary clinical trials},
  volume = {28},
  number = {6},
  pages = {713--719},
  publisher = {Elsevier},
  urldate = {2023-12-23}
}

@article{winkensRandomizedClinicalTrials2007a,
  title = {Randomized Clinical Trials with a Pre- and a Post-Treatment Measurement: {{Repeated}} Measures versus {{ANCOVA}} Models},
  shorttitle = {Randomized Clinical Trials with a Pre- and a Post-Treatment Measurement},
  author = {Winkens, Bjorn and {van Breukelen}, Gerard J. P. and Schouten, Hubert J. A. and Berger, Martijn P. F.},
  year = {2007},
  month = nov,
  journal = {Contemporary Clinical Trials},
  volume = {28},
  number = {6},
  pages = {713--719},
  issn = {1551-7144},
  doi = {10.1016/j.cct.2007.04.002},
  urldate = {2023-12-23},
  abstract = {Repeated measures (RM) and ANCOVA models are compared with respect to treatment effect estimation in randomized clinical trials with a pre- and a post-treatment measure. The covariance matrices of repeated measures are assumed to be I) homogeneous or II) heterogeneous across groups. In situation I, ANCOVA is preferred to RM, because the estimated variance of the treatment effect estimator is unbiased for ANCOVA and biased downwards for RM. In situation II, RM with Kenward and Roger's adjustment is preferred to ANCOVA, because the ANCOVA variance estimator does not correct for unknown pre-treatment expectation. The results are illustrated with an example.},
  keywords = {Analysis of covariance,Generalized least squares,Kenward and Roger's adjustment,Repeated measures,Restricted maximum likelihood,Treatment effect estimation},
  file = {/Users/zenn/Zotero/storage/FYZZQGQY/S1551714407000481.html}
}

@misc{Wittes_2002_sampleSizeCalculations,
  title = {Wittes\_2002\_sample Size Calculations for Randomized Controlled Trials.Pdf},
  journal = {Google Docs},
  urldate = {2024-06-17},
  howpublished = {https://drive.google.com/file/d/1GqLCtPsOQT1Cnp34u-ENIXLTNYVslf93/view?usp=drive\_open\&usp=embed\_facebook},
  file = {/Users/zenn/Zotero/storage/CYK7NBXF/view.html}
}

@article{Wittes2002,
  title = {Sample {{Size Calculations}} for {{Randomized Controlled Trials}}},
  author = {Wittes, Janet},
  year = {2002},
  journal = {Epidemiologic Reviews},
  volume = {24},
  number = {1},
  keywords = {sample size},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/wittes_2002_sample size calculations for randomized controlled trials.pdf}
}

@article{wright1996familial,
  title = {Familial Melanoma and Pancreatic Cancer},
  author = {Wright, {\relax FA} and Thomas, {\relax RG}},
  year = {1996},
  journal = {The New England journal of medicine},
  volume = {334},
  number = {7},
  pages = {470--472}
}

@article{Wu2021,
  title = {Multi-Omic Analysis in Injured Humans: {{Patterns}} Align with Outcomes and Treatment Responses},
  author = {Wu, Junru and Vodovotz, Yoram and Abdelhamid, Sultan and Guyette, Francis X. and Yaffe, Michael B. and Gruen, Danielle S. and Cyr, Anthony and Okonkwo, David O. and Kar, Upendra K. and Krishnamoorthi, Neha and Voinchet, Robert G. and Billiar, Isabel M. and Yazer, Mark H. and Namas, Rami A. and Daley, Brian J. and Miller, Richard S. and Harbrecht, Brian G. and Claridge, Jeffrey A. and Phelan, Herbert A. and Zuckerbraun, Brian S. and Johansson, P{\"a}r I. and Stensballe, Jakob and Morrissey, James H. and Tracy, Russell P. and Wisniewski, Stephen R. and Neal, Matthew D. and Sperry, Jason L. and Billiar, Timothy R.},
  year = {2021},
  journal = {Cell Reports Medicine},
  volume = {2},
  number = {12},
  pages = {100478},
  issn = {26663791},
  doi = {10.1016/j.xcrm.2021.100478},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/wu et al_2021_multi-omic analysis in injured humans.pdf}
}

@misc{wuPMCLLaMAFurtherFinetuning2023,
  title = {{{PMC-LLaMA}}: {{Further Finetuning LLaMA}} on {{Medical Papers}}},
  shorttitle = {{{PMC-LLaMA}}},
  author = {Wu, Chaoyi and Zhang, Xiaoman and Zhang, Ya and Wang, Yanfeng and Xie, Weidi},
  year = {2023},
  month = apr,
  number = {arXiv:2304.14454},
  eprint = {2304.14454},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2023-05-02},
  abstract = {Large Language Models (LLMs) have showcased remarkable capabilities in natural language understanding in various domains. These models can usually behave well on daily dialog, or question answering scenarios, however, in areas that value precision, for example, in medical applications, they often exhibit unsatisfactory performance due to a lack of domain-specific knowledge. In this report, we introduce PMC-LLaMA, an open-source language model that is acquired by fine-tuning an open-source language model on a total of 4.8 million biomedical academic papers for further injecting medical knowledge, enhancing its capability in medical domain. Our preliminary evaluations are conducted on three biomedical QA datasets, including PubMedQA, MedMCQA, and USMLE, showing that the our model after finetuning, i.e., PMC-LLaMA, demonstrates better understanding of biomedical domain-specific concepts, thus achieving high performance on QA benchmarks. The model and codes, along with an online demo, are publicly available1,2.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/wu et al_2023_pmc-llama.pdf}
}

@article{Xi2019,
  title = {An Additive Boundary for Group Sequential Designs with Connection to Conditional Error},
  author = {Xi, Dong and Gallo, Paul},
  year = {2019},
  journal = {Statistics in Medicine},
  volume = {38},
  number = {23},
  pages = {4656--4669},
  issn = {10970258},
  doi = {10.1002/sim.8325},
  abstract = {Group sequential designs allow stopping a clinical trial for meeting its efficacy objectives based on interim evaluation of the accumulating data. Various methods to determine group sequential boundaries that control the probability of crossing the boundary at an interim or the final analysis have been proposed. To monitor trials with uncertainty in group sizes at each analysis, error spending functions are often used to derive stopping boundaries. Although flexible, most spending functions are generic increasing functions with parameters that are difficult to interpret. They are often selected arbitrarily, sometimes using trial and error, so that the corresponding boundaries approximate the desired behavior numerically. Lan and DeMets proposed a spending function that approximates in a natural way the O'Brien-Fleming boundary based on the Brownian motion process. We extend this approach to a general family that has an additive boundary for the Brownian motion process. The spending function and the group sequential boundary share a common parameter that regulates how fast the error is spent. Three subfamilies are considered with different additive terms. In the first subfamily, the parameter has an interpretation as the conditional error rate, which is the conditional probability to reject the null hypothesis at the final analysis. This parameter also provides a connection between group sequential and adaptive design methodology. More choices of designs are allowed in the other two subfamilies. Numerical results are provided to illustrate flexibility and interpretability of the proposed procedures. A clinical trial is described to illustrate the utility of conditional error in boundary determination.},
  pmid = {31338847},
  keywords = {additive boundary,Brownian motion process,conditional error,error spending function,group sequential design,interim analysis},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/xi_gallo_2019_an additive boundary for group sequential designs with connection to.pdf}
}

@article{xuContinuousEmpiricalCharacteristic2010,
  title = {Continuous {{Empirical Characteristic Function Estimation}} of {{Mixtures}} of {{Normal Parameters}}},
  author = {Xu, Dinghai and Knight, John},
  year = {2010},
  month = nov,
  journal = {Econometric Reviews},
  volume = {30},
  number = {1},
  pages = {25--50},
  publisher = {Taylor \& Francis},
  issn = {0747-4938},
  doi = {10.1080/07474938.2011.520565},
  urldate = {2024-05-11},
  abstract = {This article develops an efficient method for estimating the discrete mixtures of normal family based on the continuous empirical characteristic function (CECF). An iterated estimation procedure based on the closed form objective distance function is proposed to improve the estimation efficiency. The results from the Monte Carlo simulation reveal that the CECF estimator produces good finite sample properties. In particular, it outperforms the discrete type of methods when the maximum likelihood estimation fails to converge. An empirical example is provided for illustrative purposes.},
  keywords = {C13,C15,C16,Empirical characteristic function,Mixtures of normal},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/xu_knight_2010_continuous empirical characteristic function estimation of mixtures of normal.pdf}
}

@article{xuPackageModelFitting2019,
  title = {An {{R}} Package for Model Fitting, Model Selection and the Simulation for Longitudinal Data with Dropout Missingness},
  author = {Xu, Cong and Li, Zheng and Xue, Yuan and Zhang, Lijun and Wang, Ming},
  year = {2019},
  month = oct,
  journal = {Communications in Statistics - Simulation and Computation},
  volume = {48},
  number = {9},
  pages = {2812--2829},
  publisher = {Taylor \& Francis},
  issn = {0361-0918},
  doi = {10.1080/03610918.2018.1468457},
  urldate = {2023-02-12},
  abstract = {Missing data arise frequently in clinical and epidemiological fields, in particular in longitudinal studies. This paper describes the core features of an R package wgeesel, which implements marginal model fitting (i.e., weighted generalized estimating equations, WGEE; doubly robust GEE) for longitudinal data with dropouts under the assumption of missing at random. More importantly, this package comprehensively provide existing information criteria for WGEE model selection on marginal mean or correlation structures. Also, it can serve as a valuable tool for simulating longitudinal data with missing outcomes. Lastly, a real data example and simulations are presented to illustrate and validate our package.},
  keywords = {Dropout missingness,generalized estimating equations,inverse probability weight,missing at random,model selection,quasi-likelihood,R},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/xu et al_2019_an r package for model fitting, model selection and the simulation for.pdf}
}

@article{yanEyeMovementsGuided2014,
  title = {Eye Movements Guided by Morphological Structure: {{Evidence}} from the {{Uighur}} Language},
  shorttitle = {Eye Movements Guided by Morphological Structure},
  author = {Yan, Ming and Zhou, Wei and Shu, Hua and Yusupu, Rizwangul and Miao, Dongxia and Kr{\"u}gel, Andr{\'e} and Kliegl, Reinhold},
  year = {2014},
  month = aug,
  journal = {Cognition},
  volume = {132},
  number = {2},
  pages = {181--215},
  issn = {00100277},
  doi = {10.1016/j.cognition.2014.03.008},
  urldate = {2023-02-14},
  abstract = {It is generally accepted that low-level features (e.g., inter-word spaces) are responsible for saccade-target selection in eye-movement control during reading. In two experiments using Uighur script known for its rich suffixes, we demonstrate that, in addition to word length and launch site, the number of suffixes influences initial landing positions. We also demonstrate an influence of word frequency. These results are difficult to explain purely by low-level guidance of eye movements and indicate that due to properties specific to Uighur script low-level visual information and high-level information such as morphological structure of parafoveal words jointly influence saccade programming.},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/yan et al_2014_eye movements guided by morphological structure.pdf}
}

@article{yaseenMaximumLikelihoodApproach2016,
  title = {Maximum {{Likelihood Approach}} for {{Longitudinal Models}} with {{Nonignorable Missing Data Mechanism Using Fractional Imputation}}},
  author = {Yaseen, Abdallah S A and Gad, Ahmed M and Ahmed, Abeer S},
  year = {2016},
  journal = {American Journal of Applied Mathematics and Statistics},
  volume = {4},
  number = {3},
  pages = {59--66},
  doi = {10.12691/ajams-4-3-1},
  abstract = {In longitudinal studies data are collected for the same set of units for two or more occasions. This is in contrast to cross-sectional studies where a single outcome is measured for each individual. Some intended measurements might not be available for some units resulting in a missing data setting. When the probability of missing depends on the missing values, missing mechanism is termed nonrandom. One common type of the missing patterns is the dropout where the missing values never followed by an observed value. In nonrandom dropout, missing data mechanism must be included in the analysis to get unbiased estimates. The parametric fractional imputation method is proposed to handle the missingness problem in longitudinal studies and to get unbiased estimates in the presence of nonrandom dropout mechanism. Also, in this setting the jackknife replication method is used to find the standard errors for the fractionally imputed estimates. Finally, the proposed method is applied to a real data (mastitis data) in addition to a simulation study.},
  keywords = {longitudinal data,mastitis data,missing data,nonrandom dropout,parametric fractional imputation,repeated measures,standard errors},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/yaseen et al_2016_maximum likelihood approach for longitudinal models with nonignorable missing.pdf}
}

@article{yiEstimatingSampleSize2002,
  title = {Estimating Sample Size for Tests on Trends across Repeated Measurements with Missing Data Based on the Interaction Term in a Mixed Model},
  author = {Yi, Qilong and Panzarella, Tony},
  year = {2002},
  month = oct,
  journal = {Controlled Clinical Trials},
  volume = {23},
  number = {5},
  pages = {481--496},
  issn = {0197-2456},
  doi = {10.1016/S0197-2456(02)00223-4},
  urldate = {2023-08-12},
  abstract = {A formula to estimate the required sample size for a study with repeated measurements was constructed based on the test of an interaction term in a mixed model. It covers both random effects and serial correlation and allows for missing data. This formula indicates that the method suggested by Dawson is conservative. A simulation study further verified the accuracy of the formula. Factors that influence the required sample size, such as the number of repeated measurements, the structure of the within-subject correlation, and their interaction, were investigated in detail.},
  langid = {english},
  keywords = {Mixed model,Repeated measurements,Sample size},
  file = {/Users/zenn/Zotero/storage/3M9APIDD/S0197245602002234.html}
}

@article{yiEstimatingSampleSize2002a,
  title = {Estimating Sample Size for Tests on Trends across Repeated Measurements with Missing Data Based on the Interaction Term in a Mixed Model},
  author = {Yi, Qilong and Panzarella, Tony},
  year = {2002},
  month = oct,
  journal = {Controlled Clinical Trials},
  volume = {23},
  number = {5},
  pages = {481--496},
  issn = {0197-2456},
  doi = {10.1016/S0197-2456(02)00223-4},
  urldate = {2024-06-19},
  abstract = {A formula to estimate the required sample size for a study with repeated measurements was constructed based on the test of an interaction term in a mixed model. It covers both random effects and serial correlation and allows for missing data. This formula indicates that the method suggested by Dawson is conservative. A simulation study further verified the accuracy of the formula. Factors that influence the required sample size, such as the number of repeated measurements, the structure of the within-subject correlation, and their interaction, were investigated in detail.},
  keywords = {Mixed model,Repeated measurements,Sample size},
  file = {/Users/zenn/Zotero/storage/HHCAQ4U3/S0197245602002234.html}
}

@article{yongzouMeritsTestingHardyWeinberg2006,
  title = {The {{Merits}} of {{Testing Hardy-Weinberg Equilibrium}} in the {{Analysis}} of {{Unmatched Case-Control Data}}: {{A Cautionary Note}}},
  shorttitle = {The {{Merits}} of {{Testing Hardy-Weinberg Equilibrium}} in the {{Analysis}} of {{Unmatched Case-Control Data}}},
  author = {Yong Zou, Guang and Donner, Allan},
  year = {2006},
  journal = {Annals of Human Genetics},
  volume = {70},
  number = {6},
  pages = {923--933},
  issn = {1469-1809},
  doi = {10.1111/j.1469-1809.2006.00267.x},
  urldate = {2022-11-05},
  abstract = {Testing for departures from the assumption of Hardy-Weinberg equilibrium (HWE) has been widely recommended as a preliminary step in the analysis of genetic case-control studies. Some authors suggest using a two-stage procedure in which gene/disease associations are ultimately evaluated using either the Pearson chi-square procedure or the Cochran-Armitage test for trend. Other authors go further and encourage investigators to discard data that are in violation of HWE, essentially using the test as a tool for identifying genotyping errors. In this paper we show that 1) testing for HWE should not be used as a tool to identify genotyping errors; and 2) it is not necessary, and possibly even harmful, to test the HWE assumption before testing for association between alleles and disease. Instead one should inherently account for deviations from HWE with an adjusted chi-square test statistic, a procedure which in the present context is identical to the trend test. Examples from previous reports are used to illustrate the methodology.},
  langid = {english},
  keywords = {adjusted chi-square,allelic correlation,Cochran-Mantel-Haenszel test,genotyping error,HuGE,inbreeding coefficient,sample size,trend test},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/yong zou_donner_2006_the merits of testing hardy-weinberg equilibrium in the analysis of unmatched.pdf}
}

@article{yooImpactDichotomizationLongitudinal2010,
  title = {The Impact of Dichotomization in Longitudinal Data Analysis: A Simulation Study: {{The}} Impact of Dichotomization in Longitudinal Data Analysis},
  shorttitle = {The Impact of Dichotomization in Longitudinal Data Analysis},
  author = {Yoo, Bongin},
  year = {2010},
  month = oct,
  journal = {Pharmaceutical Statistics},
  volume = {9},
  number = {4},
  pages = {298--312},
  issn = {15391604},
  doi = {10.1002/pst.396},
  urldate = {2023-02-12},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/yoo_2010_the impact of dichotomization in longitudinal data analysis.pdf}
}

@article{youngMinimalClinicallyImportant2018,
  title = {Minimal Clinically Important Difference of Voice Handicap Index-10 in Vocal Fold Paralysis},
  author = {Young, VyVy N. and Jeong, Kwonho and Rothenberger, Scott D. and Gillespie, Amanda I. and Smith, Libby J. and Gartner-Schmidt, Jackie L. and Rosen, Clark A.},
  year = {2018},
  month = jun,
  journal = {The Laryngoscope},
  volume = {128},
  number = {6},
  pages = {1419--1424},
  issn = {0023-852X, 1531-4995},
  doi = {10.1002/lary.27001},
  urldate = {2024-06-05},
  abstract = {Objectives/Hypothesis               The Voice Handicap Index-10 (VHI-10) is commonly used to measure patients' perception of vocal handicap. Clinical consensus has previously defined clinically meaningful improvement as a decrease {$\geq$}5. This study determines the minimal clinically important difference (MCID) for VHI-10 in patients with unilateral vocal fold paralysis (UVFP) using anchor-based methodology.                                         Study Design               Prospective cohort questionnaire analysis.                                         Methods               Two hundred eighty-one UVFP patients completed the VHI-10 on two consecutive visits (within 3 months). At the follow-up visit, patients answered an 11-point Global Rating of Change Questionnaire (GRCQ) scored from -5 to +5. Relationship between the GRCQ and change in VHI-10 was quantified using analysis of variance, and MCID for the VHI-10 was determined using receiver operating characteristic (ROC) curve analysis.                                         Results                                Overall mean VHI-10 change was -3.71 (standard deviation [SD] = 8.89) and mean GRCQ was 1.37 (SD = 2.51). Average interval between measurements was 1.73 months (SD = 0.83). Mean changes in VHI-10 scores were -7.45, -0.53, and +4.40 for patients whose GRCQ scores indicated improvement, no change, and worsening, respectively. Differences between mean scores were statistically significant (                 P                 {$<$} .001). Area under the ROC curve was 0.80, demonstrating the classification accuracy of VHI-10 change scores. A VHI-10 change of -4 was determined to be the optimal threshold that discriminated between improvement and no improvement (sensitivity and specificity 0.62 and 0.88, respectively).                                                        Conclusions               The MCID for improvement in VHI-10 in UVFP patients is a decrease of 4. This information improves understanding of patients' response to treatment and allows comparison between different treatments. Future research should determine MCID for VHI-10 across all voice disorders.                                         Level of Evidence                                4.                 Laryngoscope                 , 128:1419--1424, 2018},
  copyright = {http://onlinelibrary.wiley.com/termsAndConditions\#vor},
  langid = {english}
}

@article{youngUncoveringHeterogeneityTemporal2018,
  title = {Uncovering the Heterogeneity and Temporal Complexity of Neurodegenerative Diseases with {{Subtype}} and {{Stage Inference}}},
  author = {Young, Alexandra L. and Marinescu, Razvan V. and Oxtoby, Neil P. and Bocchetta, Martina and Yong, Keir and Firth, Nicholas C. and Cash, David M. and Thomas, David L. and Dick, Katrina M. and Cardoso, Jorge and {van Swieten}, John and Borroni, Barbara and Galimberti, Daniela and Masellis, Mario and Tartaglia, Maria Carmela and Rowe, James B. and Graff, Caroline and Tagliavini, Fabrizio and Frisoni, Giovanni B. and Laforce, Robert and Finger, Elizabeth and {de Mendon{\c c}a}, Alexandre and Sorbi, Sandro and Warren, Jason D. and Crutch, Sebastian and Fox, Nick C. and Ourselin, Sebastien and Schott, Jonathan M. and Rohrer, Jonathan D. and Alexander, Daniel C.},
  year = {2018},
  month = oct,
  journal = {Nature Communications},
  volume = {9},
  number = {1},
  pages = {4273},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-018-05892-0},
  urldate = {2023-11-09},
  abstract = {The heterogeneity of neurodegenerative diseases is a key confound to disease understanding and treatment development, as study cohorts typically include multiple phenotypes on distinct disease trajectories. Here we introduce a machine-learning technique---Subtype and Stage Inference (SuStaIn)---able to uncover data-driven disease phenotypes with distinct temporal progression patterns, from widely available cross-sectional patient studies. Results from imaging studies in two neurodegenerative diseases reveal subgroups and their distinct trajectories of regional neurodegeneration. In genetic frontotemporal dementia, SuStaIn identifies genotypes from imaging alone, validating its ability to identify subtypes; further the technique reveals within-genotype heterogeneity. In Alzheimer's disease, SuStaIn uncovers three subtypes, uniquely characterising their temporal complexity. SuStaIn provides fine-grained patient stratification, which substantially enhances the ability to predict conversion between diagnostic categories over standard models that ignore subtype (p\,=\,7.18\,{\texttimes}\,10-4) or temporal stage (p\,=\,3.96\,{\texttimes}\,10-5). SuStaIn offers new promise for enabling disease subtype discovery and precision medicine.},
  copyright = {2018 The Author(s)},
  langid = {english},
  keywords = {Computer science,Neurodegenerative diseases},
  file = {/Users/zenn/Zotero/storage/SHN337FW/Young et al. - 2018 - Uncovering the heterogeneity and temporal complexi.pdf}
}

@article{yuEmpiricalCharacteristicFunction2004,
  title = {Empirical {{Characteristic Function Estimation}} and {{Its Applications}}},
  author = {Yu, Jun},
  year = {2004},
  month = dec,
  journal = {Econometric Reviews},
  volume = {23},
  number = {2},
  pages = {93--123},
  publisher = {Taylor \& Francis},
  issn = {0747-4938},
  doi = {10.1081/ETC-120039605},
  urldate = {2024-05-11},
  abstract = {This paper reviews the method of model-fitting via the empirical characteristic function. The advantage of using this procedure is that one can avoid difficulties inherent in calculating or maximizing the likelihood function. Thus it is a desirable estimation method when the maximum likelihood approach encounters difficulties but the characteristic function has a tractable expression. The basic idea of the empirical characteristic function method is to match the characteristic function derived from the model and the empirical characteristic function obtained from data. Ideas are illustrated by using the methodology to estimate a diffusion model that includes a self-exciting jump component. A Monte Carlo study shows that the finite sample performance of the proposed procedure offers an improvement over a GMM procedure. An application using over 72 years of DJIA daily returns reveals evidence of jump clustering.},
  keywords = {C13,C15,C22,Diffusion process,G10,GMM,Jump clustering,Poisson jump,Self-exciting},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/yu_2004_empirical characteristic function estimation and its applications.pdf}
}

@article{zayaruznayaSupplementaryOnlineContent2015,
  title = {Supplementary Online Content},
  author = {Zayaruznaya, Anna},
  year = {2015},
  journal = {The Monstrous New Art},
  pages = {xiii-xiv},
  doi = {10.1017/cbo9781139626293.001},
  abstract = {Context Patients with metastatic colorectal cancer who have KRAS codon 12 or KRAS codon 13mutated tumors are presently excluded from treatment with the anti epidermal growth factor receptor monoclonal antibody cetuximab. Objective To test the hypothesis that KRAS codon 13 mutations are associated with a better outcome after treatment with cetuximab than observed with otherKRASmutations. Design, Setting, and Patients We studied the association between KRAS mutation status (p.G13D vs other KRAS mutations) and response and survival in a pooled data set of 579 patients with chemotherapy-refractory colorectal cancer treated with cetuximab between 2001 and 2008. Patients were included in the CO.17, BOND, MABEL, EMR202600, EVEREST, BABEL, or SALVAGE clinical trials or received offstudy treatment. Univariate and multivariate analyses, adjusting for possible prognostic factors and data set, were performed. The effect of the different mutations was studied in vitro by constructing isogenic cell lines with wild-type KRAS, p.G12V, or p.G13D mutant alleles and treating them with cetuximab. Main Outcome Measures The main efficacy end point was overall survival. Secondary efficacy end points were response rate and progression-free survival. Results In comparison with patients with other KRAS-mutated tumors, patients with p.G13D-mutated tumors (n=32) treated with cetuximab had longer overall survival (median, 7.6 95\% confidence interval CI, 5.7-20.5 months vs 5.7 95\% CI, 4.9- 6.8 months; adjusted hazard ratio HR, 0.50; 95\% CI, 0.31-0.81; P=.005) and longer progression-free survival (median, 4.0 95\% CI, 1.9-6.2 months vs 1.9 95\% CI, 1.8- 2.8 months; adjusted HR, 0.51; 95\% CI, 0.32-0.81; P=.004). There was a significant interaction between KRAS mutation status (p.G13D vs other KRAS mutations) and overall survival benefit with cetuximab treatment (adjusted HR, 0.30; 95\% CI, 0.14- 0.67; P=.003). In vitro and mouse model analysis showed that although p.G12Vmutated colorectal cells were insensitive to cetuximab, p.G13D-mutated cells were sensitive, as were KRAS wild-type cells. Conclusions In this analysis, use of cetuximab was associated with longer overall and progression-free survival among patients with chemotherapy-refractory colorectal cancer with p.G13D-mutated tumors than with other KRAS-mutated tumors. Evaluation of cetuximab therapy in these tumors in prospective randomized trials may be warranted.},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/zayaruznaya_2015_supplementary online content.pdf}
}

@article{Zeger2016,
  title = {{{ILongitudinal Data Analysis}} of {{Continuous}} and {{Discrete Responses}} for {{Pre-Post Designs}}},
  author = {liang kung ye Zeger, Scott L;},
  year = {2016},
  volume = {62},
  number = {1},
  pages = {134--148},
  keywords = {c17},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/zeger_2016_ilongitudinal data analysis of continuous and discrete responses for pre-post.pdf}
}

@article{zhangFourierMethodsEstimating1990,
  title = {Fourier {{Methods}} for {{Estimating Mixing Densities}} and {{Distributions}}},
  author = {Zhang, Cun-Hui},
  year = {1990},
  journal = {The Annals of Statistics},
  volume = {18},
  number = {2},
  eprint = {2242135},
  eprinttype = {jstor},
  pages = {806--831},
  publisher = {Institute of Mathematical Statistics},
  issn = {0090-5364},
  urldate = {2023-03-01},
  abstract = {Let X1, X2, {$\cdots$} be iid observations from a mixture density f(x) = {$\int$} f(x {$\mid$} {\texttheta})dG({\texttheta}), where f(x {$\mid$} {\texttheta}) is a known parametric family of density functions and G is an unknown distribution function. This paper concerns estimating the mixing density g = G' and the mixing distribution G. Fourier methods are used to derive kernel estimators, upper bounds for their rates of convergence and lower bounds for the optimal rate of convergence. Sufficient conditions are given under which the kernel estimators are asymptotically normal. Our estimators achieve the optimal rate of convergence (log n)-1/2 for the normal family and (log n)-1 for the Cauchy family.},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/zhang_1990_fourier methods for estimating mixing densities and distributions.pdf}
}

@article{Zhao2021,
  title = {Power Formulas for Mixed Effects Models with Random Slope and Intercept Comparing Rate of Change across Groups},
  author = {Zhao, Yu and Edland, Steven D.},
  year = {2021},
  journal = {International Journal of Biostatistics},
  issn = {15574679},
  doi = {10.1515/ijb-2020-0107},
  abstract = {We have previously derived power calculation formulas for cohort studies and clinical trials using the longitudinal mixed effects model with random slopes and intercepts to compare rate of change across groups [Ard \& Edland, Power calculations for clinical trials in Alzheimer's disease. J Alzheim Dis 2011;21:369-77]. We here generalize these power formulas to accommodate 1) missing data due to study subject attrition common to longitudinal studies, 2) unequal sample size across groups, and 3) unequal variance parameters across groups. We demonstrate how these formulas can be used to power a future study even when the design of available pilot study data (i.e., number and interval between longitudinal observations) does not match the design of the planned future study. We demonstrate how differences in variance parameters across groups, typically overlooked in power calculations, can have a dramatic effect on statistical power. This is especially relevant to clinical trials, where changes over time in the treatment arm reflect background variability in progression observed in the placebo control arm plus variability in response to treatment, meaning that power calculations based only on the placebo arm covariance structure may be anticonservative. These more general power formulas are a useful resource for understanding the relative influence of these multiple factors on the efficiency of cohort studies and clinical trials, and for designing future trials under the random slopes and intercepts model.},
  keywords = {clinical trial,linear mixed effects model; power,sample size,study subject attrition},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/zhao_edland_2021_power formulas for mixed effects models with random slope and intercept.pdf}
}

@article{zhaoAsymptoticMaximalProcedure2018,
  title = {The Asymptotic Maximal Procedure for Subject Randomization in Clinical Trials},
  author = {Zhao, Wenle and Berger, Vance W and Yu, Zhenning},
  year = {2018},
  month = jul,
  journal = {Statistical Methods in Medical Research},
  volume = {27},
  number = {7},
  pages = {2142--2153},
  issn = {0962-2802, 1477-0334},
  doi = {10.1177/0962280216677107},
  urldate = {2023-12-15},
  abstract = {The maximal procedure is a restricted randomization method that maximizes the number of feasible allocation sequences under the constraints of the maximum tolerated imbalance and the allocation sequence length. It assigns an equal probability to all feasible sequences. However, its implementation is not easy due to the lack of the Markovian property of the conditional allocation probabilities. In this paper, we propose the asymptotic maximal procedure, which replaces the sequence-length-dependent conditional allocation probabilities with their asymptotic values. The new randomization procedure is compared with the original maximal procedure and few other randomization procedures with the maximum tolerated imbalance via simulations and is found to be a practical choice for future clinical trials.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/6LEMVVRS/Zhao et al. - 2018 - The asymptotic maximal procedure for subject rando.pdf}
}

@article{zhaoMinimalSufficientBalance2015,
  title = {Minimal Sufficient Balance---a New Strategy to Balance Baseline Covariates and Preserve Randomness of Treatment Allocation},
  author = {Zhao, Wenle and Hill, Michael D and Palesch, Yuko},
  year = {2015},
  month = dec,
  journal = {Statistical Methods in Medical Research},
  volume = {24},
  number = {6},
  pages = {989--1002},
  issn = {0962-2802, 1477-0334},
  doi = {10.1177/0962280212436447},
  urldate = {2023-12-15},
  abstract = {In many clinical trials, baseline covariates could affect the primary outcome. Commonly used strategies to balance baseline covariates include stratified constrained randomization and minimization. Stratification is limited to few categorical covariates. Minimization lacks the randomness of treatment allocation. Both apply only to categorical covariates. As a result, serious imbalances could occur in important baseline covariates not included in the randomization algorithm. Furthermore, randomness of treatment allocation could be significantly compromised because of the high proportion of deterministic assignments associated with stratified block randomization and minimization, potentially resulting in selection bias. Serious baseline covariate imbalances and selection biases often contribute to controversial interpretation of the trial results. The National Institute of Neurological Disorders and Stroke recombinant tissue plasminogen activator Stroke Trial and the Captopril Prevention Project are two examples. In this article, we propose a new randomization strategy, termed the minimal sufficient balance randomization, which will dually prevent serious imbalances in all important baseline covariates, including both categorical and continuous types, and preserve the randomness of treatment allocation. Computer simulations are conducted using the data from the National Institute of Neurological Disorders and Stroke recombinant tissue plasminogen activator Stroke Trial. Serious imbalances in four continuous and one categorical covariate are prevented with a small cost in treatment allocation randomness. A scenario of simultaneously balancing 11 baseline covariates is explored with similar promising results. The proposed minimal sufficient balance randomization algorithm can be easily implemented in computerized central randomization systems for large multicenter trials.},
  langid = {english},
  file = {/Users/zenn/Zotero/storage/KZT53I9E/Zhao et al. - 2015 - Minimal sufficient balance—a new strategy to balan.pdf;/Users/zenn/Zotero/storage/UJZBLR4L/0962280212436447.html}
}

@article{zhaoPowerFormulasMixed2022,
  title = {Power Formulas for Mixed Effects Models with Random Slope and Intercept Comparing Rate of Change across Groups},
  author = {Zhao, Yu and Edland, Steven D.},
  year = {2022},
  month = may,
  journal = {The International Journal of Biostatistics},
  volume = {18},
  number = {1},
  pages = {173--182},
  publisher = {De Gruyter},
  issn = {1557-4679},
  doi = {10.1515/ijb-2020-0107},
  urldate = {2023-12-23},
  abstract = {We have previously derived power calculation formulas for cohort studies and clinical trials using the longitudinal mixed effects model with random slopes and intercepts to compare rate of change across groups [Ard \&amp; Edland, Power calculations for clinical trials in Alzheimer's disease. J Alzheim Dis 2011;21:369--77]. We here generalize these power formulas to accommodate 1) missing data due to study subject attrition common to longitudinal studies, 2) unequal sample size across groups, and 3) unequal variance parameters across groups. We demonstrate how these formulas can be used to power a future study even when the design of available pilot study data (i.e., number and interval between longitudinal observations) does not match the design of the planned future study. We demonstrate how differences in variance parameters across groups, typically overlooked in power calculations, can have a dramatic effect on statistical power. This is especially relevant to clinical trials, where changes over time in the treatment arm reflect background variability in progression observed in the placebo control arm plus variability in response to treatment, meaning that power calculations based only on the placebo arm covariance structure may be anticonservative. These more general power formulas are a useful resource for understanding the relative influence of these multiple factors on the efficiency of cohort studies and clinical trials, and for designing future trials under the random slopes and intercepts model.},
  copyright = {De Gruyter expressly reserves the right to use all content for commercial text and data mining within the meaning of Section 44b of the German Copyright Act.},
  langid = {english},
  keywords = {clinical trial,linear mixed effects model,power,sample size,study subject attrition},
  file = {/Users/zenn/Zotero/storage/HQ5PFQ2D/Zhao and Edland - 2022 - Power formulas for mixed effects models with rando.pdf}
}

@article{zhengPredictorsSurvivalPatients2024,
  title = {Predictors for Survival in Patients with {{Alzheimer}}'s Disease: A Large Comprehensive Meta-Analysis},
  shorttitle = {Predictors for Survival in Patients with {{Alzheimer}}'s Disease},
  author = {Zheng, Xiaoting and Wang, Shichan and Huang, Jingxuan and Li, Chunyu and Shang, Huifang},
  year = {2024},
  month = apr,
  journal = {Translational Psychiatry},
  volume = {14},
  number = {1},
  pages = {1--9},
  publisher = {Nature Publishing Group},
  issn = {2158-3188},
  doi = {10.1038/s41398-024-02897-w},
  urldate = {2024-04-12},
  abstract = {The prevalence of Alzheimer's disease (AD) is increasing as the population ages, and patients with AD have a poor prognosis. However, knowledge on factors for predicting the survival of AD remains sparse. Here, we aimed to systematically explore predictors of AD survival. We searched the PubMed, Embase and Cochrane databases for relevant literature from inception to December 2022. Cohort and case-control studies were selected, and multivariable adjusted relative risks (RRs) were pooled by random-effects models. A total of 40,784 reports were identified, among which 64 studies involving 297,279 AD patients were included in the meta-analysis after filtering based on predetermined criteria. Four aspects, including demographic features (n\,=\,7), clinical features or comorbidities (n\,=\,13), rating scales (n\,=\,3) and biomarkers (n\,=\,3), were explored and 26 probable prognostic factors were finally investigated for AD survival. We observed that AD patients who had hyperlipidaemia (RR: 0.69) were at a lower risk of death. In contrast, male sex (RR: 1.53), movement disorders (including extrapyramidal signs) (RR: 1.60) and cancer (RR: 2.07) were detrimental to AD patient survival. However, our results did not support the involvement of education, hypertension, APOE genotype, A{$\beta$}42 and t-tau in AD survival. Our study comprehensively summarized risk factors affecting survival in patients with AD, provided a better understanding on the role of different factors in the survival of AD from four dimensions, and paved the way for further research.},
  copyright = {2024 The Author(s)},
  langid = {english},
  keywords = {Diseases,Neuroscience},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/zheng et al_2024_predictors for survival in patients with alzheimer’s disease2.pdf}
}

@article{zhengPredictorsSurvivalPatients2024a,
  title = {Predictors for Survival in Patients with {{Alzheimer}}'s Disease: A Large Comprehensive Meta-Analysis},
  shorttitle = {Predictors for Survival in Patients with {{Alzheimer}}'s Disease},
  author = {Zheng, Xiaoting and Wang, Shichan and Huang, Jingxuan and Li, Chunyu and Shang, Huifang},
  year = {2024},
  month = apr,
  journal = {Translational Psychiatry},
  volume = {14},
  number = {1},
  pages = {1--9},
  publisher = {Nature Publishing Group},
  issn = {2158-3188},
  doi = {10.1038/s41398-024-02897-w},
  urldate = {2024-04-11},
  abstract = {The prevalence of Alzheimer's disease (AD) is increasing as the population ages, and patients with AD have a poor prognosis. However, knowledge on factors for predicting the survival of AD remains sparse. Here, we aimed to systematically explore predictors of AD survival. We searched the PubMed, Embase and Cochrane databases for relevant literature from inception to December 2022. Cohort and case-control studies were selected, and multivariable adjusted relative risks (RRs) were pooled by random-effects models. A total of 40,784 reports were identified, among which 64 studies involving 297,279 AD patients were included in the meta-analysis after filtering based on predetermined criteria. Four aspects, including demographic features (n\,=\,7), clinical features or comorbidities (n\,=\,13), rating scales (n\,=\,3) and biomarkers (n\,=\,3), were explored and 26 probable prognostic factors were finally investigated for AD survival. We observed that AD patients who had hyperlipidaemia (RR: 0.69) were at a lower risk of death. In contrast, male sex (RR: 1.53), movement disorders (including extrapyramidal signs) (RR: 1.60) and cancer (RR: 2.07) were detrimental to AD patient survival. However, our results did not support the involvement of education, hypertension, APOE genotype, A{$\beta$}42 and t-tau in AD survival. Our study comprehensively summarized risk factors affecting survival in patients with AD, provided a better understanding on the role of different factors in the survival of AD from four dimensions, and paved the way for further research.},
  copyright = {2024 The Author(s)},
  langid = {english},
  keywords = {Diseases,Neuroscience},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/zheng et al_2024_predictors for survival in patients with alzheimer’s disease.pdf}
}

@article{Zhou2018,
  title = {Predictive Probability Methods for Interim Monitoring in Clinical Trials with Longitudinal Outcomes},
  author = {Zhou, Ming and Tang, Qi and Lang, Lixin and Xing, Jun and Tatsuoka, Kay},
  year = {2018},
  journal = {Statistics in Medicine},
  volume = {37},
  number = {14},
  pages = {2187--2207},
  issn = {10970258},
  doi = {10.1002/sim.7685},
  abstract = {In clinical research and development, interim monitoring is critical for better decision-making and minimizing the risk of exposing patients to possible ineffective therapies. For interim futility or efficacy monitoring, predictive probability methods are widely adopted in practice. Those methods have been well studied for univariate variables. However, for longitudinal studies, predictive probability methods using univariate information from only completers may not be most efficient, and data from on-going subjects can be utilized to improve efficiency. On the other hand, leveraging information from on-going subjects could allow an interim analysis to be potentially conducted once a sufficient number of subjects reach an earlier time point. For longitudinal outcomes, we derive closed-form formulas for predictive probabilities, including Bayesian predictive probability, predictive power, and conditional power and also give closed-form solutions for predictive probability of success in a future trial and the predictive probability of success of the best dose. When predictive probabilities are used for interim monitoring, we study their distributions and discuss their analytical cutoff values or stopping boundaries that have desired operating characteristics. We show that predictive probabilities utilizing all longitudinal information are more efficient for interim monitoring than that using information from completers only. To illustrate their practical application for longitudinal data, we analyze 2 real data examples from clinical trials.},
  pmid = {29664214},
  keywords = {conditional power,interim monitoring,longitudinal data,predictive probability},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/zhou et al_2018_predictive probability methods for interim monitoring in clinical trials with.pdf}
}

@article{zhuComparisonFourMethods2014,
  title = {Comparison of {{Four Methods}} for {{Handing Missing Data}} in {{Longitudinal Data Analysis}} through a {{Simulation Study}}},
  author = {Zhu, Xiaoping},
  year = {2014},
  journal = {Open Journal of Statistics},
  volume = {04},
  number = {11},
  pages = {933--944},
  issn = {2161-718X, 2161-7198},
  doi = {10.4236/ojs.2014.411088},
  urldate = {2023-02-12},
  abstract = {Missing data can frequently occur in a longitudinal data analysis. In the literature, many methods have been proposed to handle such an issue. Complete case (CC), mean substitution (MS), last observation carried forward (LOCF), and multiple imputation (MI) are the four most frequently used methods in practice. In a real-world data analysis, the missing data can be MCAR, MAR, or MNAR depending on the reasons that lead to data missing. In this paper, simulations under various situations (including missing mechanisms, missing rates, and slope sizes) were conducted to evaluate the performance of the four methods considered using bias, RMSE, and 95\% coverage probability as evaluation criteria. The results showed that LOCF has the largest bias and the poorest 95\% coverage probability in most cases under both MAR and MCAR missing mechanisms. Hence, LOCF should not be used in a longitudinal data analysis. Under MCAR missing mechanism, CC and MI method are performed equally well. Under MAR missing mechanism, MI has the smallest bias, smallest RMSE, and best 95\% coverage probability. Therefore, CC or MI method is the appropriate method to be used under MCAR while MI method is a more reliable and a better grounded statistical method to be used under MAR.},
  langid = {english},
  file = {/Users/zenn/Library/CloudStorage/GoogleDrive-rgthomas47@gmail.com/My Drive/zhu_2014_comparison of four methods for handing missing data in longitudinal data.pdf}
}
